[{"imageId": "n161313", "question": "Is it overcast?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it overcast?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n235859", "question": "Who is wearing the dress?", "program": "BOX0=LOC(image=IMAGE,object='dress')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the dress?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n336443", "question": "Does the utensil on top of the table look clean and black?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the utensil look clean?')\nANSWER1=VQA(image=IMAGE1,question='What color is the utensil?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'clean' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n179136", "question": "Is the surfer that looks wet wearing a wetsuit?", "program": "BOX0=LOC(image=IMAGE,object='surfer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the surfer wet?')\nANSWER1=VQA(image=IMAGE0,question='Is the surfer wearing a wetsuit?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n518912", "question": "How tall is the chair in the bottom of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How tall is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n435808", "question": "What kind of device is on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What kind of device is on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n414992", "question": "What is the airplane flying above?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the airplane flying above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n446242", "question": "What color are the pants?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n168412", "question": "Is the ground blue or brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the ground?')\nANSWER1=EVAL(expr=\"'blue' if {ANSWER0} == 'blue' else 'brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n23181", "question": "What is around the open window?", "program": "BOX0=LOC(image=IMAGE,object='open window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is around the open window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n23181", "question": "What's around the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is around the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n52544", "question": "Who is standing at the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing at the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n23181", "question": "Are there drapes to the right of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drapes')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n578564", "question": "What is hanging above the chalkboard?", "program": "BOX0=LOC(image=IMAGE,object='chalkboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging above the chalkboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n437064", "question": "Is the cake on a platter?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='platter')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n4777", "question": "Is the person to the right of the cup wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n435808", "question": "What device is sitting next to the mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is sitting next to the mouse pad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n554880", "question": "Does the sweater look open and blue?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the sweater look open?')\nANSWER1=VQA(image=IMAGE0,question='What color is the sweater?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'open' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n151768", "question": "Is the jacket long sleeved and black?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the jacket long sleeved?')\nANSWER1=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n49438", "question": "Are there beds next to the small outlet?", "program": "BOX0=LOC(image=IMAGE,object='small outlet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nBOX2=LOC(image=IMAGE0,object='bed',direction='left')\nBOX3=LOC(image=IMAGE0,object='bed',direction='right')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=COUNT(box=BOX3)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} + {ANSWER2} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"imageId": "n313060", "question": "On which side of the picture is the leather bag?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='leather bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n54424", "question": "Is the blue pillow square and large?", "program": "BOX0=LOC(image=IMAGE,object='blue pillow')\nANSWER0=VQA(image=IMAGE,question='Is the pillow square?')\nANSWER1=VQA(image=IMAGE,question='Is the pillow large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n200692", "question": "Which color is the cake?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the cake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n578564", "question": "What is the name of the cooking utensil that is hang from the hook?", "program": "BOX0=LOC(image=IMAGE,object='hook')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the cooking utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n52544", "question": "Where is the skinny person standing?", "program": "BOX0=LOC(image=IMAGE,object='skinny person')\nIMAGE0=CROP(image=IMAGE, box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the skinny person standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n546616", "question": "Are the plates on top of an ottoman?", "program": "BOX0=LOC(image=IMAGE,object='ottoman')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n579256", "question": "Is the freezer near the wall small or large?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='freezer')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} > 0 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n546616", "question": "What type of food is to the left of the baby that is sitting atop the woman?", "program": "BOX0=LOC(image=IMAGE,object='baby')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='LEFT')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What type of food is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n117888", "question": "Is the fence made of cement or aluminum?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='What material is the fence made of?')\nANSWER1=EVAL(expr=\"'cement' if 'cement' in {ANSWER0} else 'aluminum'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n525029", "question": "Which side are the white houses on?", "program": "BOX0=LOC(image=IMAGE,object='white house')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n315887", "question": "Are both the phone and the coffee cup the same color?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='coffee cup')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the phone?')\nANSWER1=VQA(image=IMAGE1,question='What color is the coffee cup?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n579256", "question": "Are there either any small refrigerators or microwaves in the picture?", "program": "BOX0=LOC(image=IMAGE,object='small refrigerator')\nBOX1=LOC(image=IMAGE,object='microwave')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n413761", "question": "How does that car look like, orange or maybe white?", "program": "ANSWER0=VQA(image=IMAGE,question='How does that car look like, orange or maybe white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n293477", "question": "What color is the book?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the book?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n130638", "question": "What color is the dirt?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n293477", "question": "Is the bag made of leather lying on top of a sofa?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the bag made of leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n23181", "question": "What are the drapes around of?", "program": "BOX0=LOC(image=IMAGE,object='drapes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the drapes around of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n314171", "question": "On which side is the picture?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n115614", "question": "What material is the crosswalk in front of the stores?", "program": "BOX0=LOC(image=IMAGE,object='stores')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='crosswalk')\nANSWER0=VQA(image=IMAGE0,question='What material is the crosswalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n296467", "question": "How large are the sprinkles that are sprinkled on the cupcakes?", "program": "ANSWER0=VQA(image=IMAGE,question='How large are the sprinkles?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n115614", "question": "What type of material is the crosswalk near the street lamp made of?", "program": "BOX0=LOC(image=IMAGE,object='street lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='crosswalk')\nANSWER0=VQA(image=IMAGE0,question='What type of material is the crosswalk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n274905", "question": "Which kind of clothing is pink?", "program": "BOX0=LOC(image=IMAGE,object='pink clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is pink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n274905", "question": "How is the clothing item that is pink called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the clothing item that is pink called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n274905", "question": "Which kind of clothing is not pink?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the clothing?')\nANSWER1=EVAL(expr=\"'not pink' if {ANSWER0} != 'pink' else 'pink'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n250715", "question": "Is this helicopter on or off?", "program": "BOX0=LOC(image=IMAGE,object='helicopter')\nANSWER0=VQA(image=IMAGE,question='Is the helicopter on or off?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n16656", "question": "Do you see any cats?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n16656", "question": "Is that shoe behind a dog?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shoe')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n274905", "question": "What kind of clothing is sleeveless?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of clothing is sleeveless?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n146522", "question": "Is the field soft and snowy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the field soft?')\nANSWER1=VQA(image=IMAGE,question='Is the field snowy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n207708", "question": "What fruits are beneath the microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruits')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE,question='What fruits are these?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n488874", "question": "Which color is the shirt?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n207708", "question": "What is beneath the microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is beneath the microwave?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n511913", "question": "On which side of the picture is the chair?", "program": "ANSWER0=VQA(image=IMAGE,question='On which side of the picture is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n71728", "question": "Is the happy man to the left or to the right of the woman in the center?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='happy')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n126087", "question": "Who is wearing a wristband?", "program": "BOX0=LOC(image=IMAGE,object='wristband')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a wristband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n207708", "question": "Is there a pear beneath the appliance that looks silver and black?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='silver and black')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='pear')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n97485", "question": "Is this a bed or a cabinet?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='cabinet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'bed' if {ANSWER0} > 0 else 'cabinet'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n435808", "question": "On which side is the router?", "program": "BOX0=LOC(image=IMAGE,object='router')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n518912", "question": "What is the color of the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n137182", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n137182", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n243701", "question": "What's the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n48494", "question": "Are there rivers or oceans that are not calm?", "program": "BOX0=LOC(image=IMAGE,object='river')\nBOX1=LOC(image=IMAGE,object='ocean')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n275148", "question": "What is the picture frame hanging from?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nANSWER0=VQA(image=IMAGE,question='What is the picture frame hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n214497", "question": "How do the cars look like, dense or sparse?", "program": "ANSWER0=VQA(image=IMAGE,question='How do the cars look like, dense or sparse?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n296467", "question": "What food isn't baked?", "program": "ANSWER0=VQA(image=IMAGE,question='What food isn\\'t baked?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n256120", "question": "Which kind of vehicle is in front of the flag?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is in front of the flag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n256120", "question": "What is the vehicle that is in front of the flag?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n275148", "question": "What is hanging from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n130464", "question": "What's the skateboarder jumping off of?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skateboarder jumping off of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n256120", "question": "Is the van in front of a balloon?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='balloon')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n145498", "question": "What is the color of this bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n501609", "question": "Are the cabinets below the stove wooden and open?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabinets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='wooden')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='open')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"imageId": "n95313", "question": "How is the item of furniture that is plaid called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the item of furniture that is plaid called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n151768", "question": "Are the boxes to the right of the man full and square?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boxes')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='full')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='square')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"imageId": "n6309", "question": "Is the horse next to the other horse both baby and brown?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 1 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the horse?')\nANSWER3=VQA(image=IMAGE0,question='Is the horse a baby?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'brown' and {ANSWER3} == 'yes' else 'no'\")\nANSWER5=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER4} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"imageId": "n477215", "question": "Is the river wide or is it narrow?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the river wide or narrow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n64959", "question": "What appliance is the refrigerator larger than?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is the refrigerator larger than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n403734", "question": "Is the umbrella in the bottom part of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n296467", "question": "What is inside the bowl to the right of the beans?", "program": "BOX0=LOC(image=IMAGE,object='beans')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nANSWER0=VQA(image=IMAGE0,question='What is inside the bowl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n317260", "question": "How clean do you think is the face mask the catcher is wearing?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the face mask?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n570181", "question": "Where is the catcher standing on?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the catcher standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n317260", "question": "What is the color of the glove?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the glove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n470920", "question": "Does the blanket look soft and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the blanket look soft?')\nANSWER1=VQA(image=IMAGE,question='What color is the blanket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n35676", "question": "What color are the drawers?", "program": "BOX0=LOC(image=IMAGE,object='drawers')\nANSWER0=VQA(image=IMAGE,question='What color are the drawers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n278312", "question": "Are there refrigerators to the left of the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='refrigerator')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n88933", "question": "Which kind of clothing is bright?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is bright?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n571179", "question": "Is there an elephant near the person that is wearing a coat?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='coat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='elephant')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n571179", "question": "What is the woman wearing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n571179", "question": "What do you think is the standing person near the man wearing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the standing person near the man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n88933", "question": "Which type of clothing is pink?", "program": "BOX0=LOC(image=IMAGE,object='pink clothing')\nANSWER0=VQA(image=IMAGE,question='Which type of clothing is pink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n566028", "question": "What is the person that is sitting down sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person sitting atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n500209", "question": "What's standing on the floor?", "program": "ANSWER0=VQA(image=IMAGE,question='What is standing on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n531359", "question": "What items of furniture are to the left of the boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 0 else 'yes'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n500209", "question": "What is in front of the wall that is not short?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='object')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n259949", "question": "How wide is the parking lot made of cement?", "program": "ANSWER0=VQA(image=IMAGE,question='How wide is the parking lot made of cement?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n473688", "question": "On which side of the picture is the clean mirror?", "program": "BOX0=LOC(image=IMAGE,object='clean mirror')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n315887", "question": "What is the device in front of the flat computer?", "program": "BOX0=LOC(image=IMAGE,object='flat computer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n554880", "question": "What is sitting on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n37274", "question": "Is there a blender to the right of the yellow drink?", "program": "BOX0=LOC(image=IMAGE,object='yellow drink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blender')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n554880", "question": "Is the gift sitting on the floor?", "program": "BOX0=LOC(image=IMAGE,object='gift')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='floor')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n250715", "question": "Which material makes up the round glasses, glass or wire?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material makes up the round glasses, glass or wire?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n250715", "question": "What are the glasses made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the glasses made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n14087", "question": "What animal is the couch behind of?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the couch behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n367944", "question": "What is the color of the device that is on the left of the photo?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n369313", "question": "Is the knife to the right of a man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knife')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n315887", "question": "What device is above the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is above the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n318684", "question": "What is the man to the left of the glasses doing?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n315887", "question": "What is the phone made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the phone made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n309148", "question": "Are there any red fire trucks?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the fire truck?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n208302", "question": "Which kind of vehicle is waiting for the traffic light?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n208302", "question": "What kind of vehicle is waiting for the traffic light?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n403734", "question": "The electronic device to the left of the notebook has what color?", "program": "BOX0=LOC(image=IMAGE,object='notebook')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='electronic device')\nANSWER0=VQA(image=IMAGE0,question='What color is the electronic device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n208302", "question": "What are the vehicles above the road near the side walk?", "program": "BOX0=LOC(image=IMAGE,object='road')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='side walk')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n208302", "question": "What is waiting for the traffic light?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is waiting for the traffic light?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n507959", "question": "What is sitting in front of the table that looks yellow and black?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='yellow and black')\nANSWER0=VQA(image=IMAGE0,question='What is sitting in front of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n473688", "question": "Are there both toothbrushes and mats in this picture?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nBOX1=LOC(image=IMAGE,object='mat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n473688", "question": "Is the soap dish to the right of the soap dispenser?", "program": "BOX0=LOC(image=IMAGE,object='soap dispenser')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soap dish')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n208302", "question": "The parked vehicles are waiting for what?", "program": "ANSWER0=VQA(image=IMAGE,question='The parked vehicles are waiting for what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n298104", "question": "Are the shorts large and blue?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nANSWER0=VQA(image=IMAGE,question='What size are the shorts?')\nANSWER1=VQA(image=IMAGE,question='What color are the shorts?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n473688", "question": "The soap dispenser made of chrome is sitting on what?", "program": "BOX0=LOC(image=IMAGE,object='chrome soap dispenser')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the soap dispenser sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n55058", "question": "What color is the serving tray that looks rectangular?", "program": "BOX0=LOC(image=IMAGE,object='serving tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the serving tray?')\nANSWER1=EVAL(expr=\"'rectangular' if {ANSWER0} == 'rectangle' else 'unknown'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the serving tray?')\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n398257", "question": "Does the device under the picture frame look black?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=VQA(image=IMAGE0,question='What color is the device?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n526228", "question": "Which material are the trousers made of, cloth or leather?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material are the trousers made of, cloth or leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n351318", "question": "How do the pens look, colorful or black and white?", "program": "ANSWER0=VQA(image=IMAGE,question='How do the pens look?')\nANSWER1=EVAL(expr=\"'colorful' if {ANSWER0} == 'color' else 'black and white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n342511", "question": "Who is the jacket worn around?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the jacket worn around?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n351318", "question": "On which side of the picture are the pens?", "program": "BOX0=LOC(image=IMAGE,object='pens')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n315859", "question": "Do you see any skis?", "program": "BOX0=LOC(image=IMAGE,object='skis')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n111390", "question": "What is the item of furniture to the right of the lady that is looking down at the cake called?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cake')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n429883", "question": "Is the man to the left of the performer brunette or blond?", "program": "BOX0=LOC(image=IMAGE,object='performer')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='What hair color is the man?')\nANSWER1=EVAL(expr=\"'brunette' if {ANSWER0} == 'brunette' else 'blond'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n293477", "question": "Is the cell phone lying on top of a desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cell phone')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n471866", "question": "Is the plastic helmet to the left of a woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic helmet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n184385", "question": "Does the utensil beside the pan have black color and small size?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the utensil?')\nANSWER1=VQA(image=IMAGE1,question='What size is the utensil?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n204894", "question": "Who is wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n146522", "question": "Do the balls to the left of the other ball look light?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ball')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n222297", "question": "What gender is the swimsuit?", "program": "BOX0=LOC(image=IMAGE,object='swimsuit')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What gender is the swimsuit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n314630", "question": "Is the toaster to the right of a refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toaster')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n494677", "question": "Are the trees on the field bare or lush?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'lush' if {ANSWER0} > 0 else 'bare'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n66756", "question": "Is the net in front of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='net')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n494677", "question": "Is the weather cloudy?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the weather like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'cloudy' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n567860", "question": "What is common to the door and the kitten?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the door and the kitten?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n67005", "question": "Is the jacket made of cotton large or small?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the jacket made of?')\nANSWER1=VQA(image=IMAGE,question='Is the jacket large or small?')\nFINAL_RESULT=RESULT(var=ANSWER0, var=ANSWER1)"}, {"imageId": "n527290", "question": "Is the gray chair to the left or to the right of the couch in the picture?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gray chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n259002", "question": "Is the soccer player that is to the left of the ball female or male?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer player')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'female' if {ANSWER0} > 0 else 'male'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n171169", "question": "Was iron used to make the fence?", "program": "ANSWER0=VQA(image=IMAGE,question='Was iron used to make the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n324908", "question": "What color is the hair?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n281241", "question": "What is the picture hanging above?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n281241", "question": "The framed picture is hanging above what?", "program": "BOX0=LOC(image=IMAGE,object='framed picture')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the framed picture hanging above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n39114", "question": "Is the hat wet?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the hat wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n259002", "question": "Who is running?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is running?')\nFINAL_RESULT=RESULT(var=ANSWER0)"},{"imageId": "n282436", "question": "What is the large device called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the large device called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n471866", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n386682", "question": "What is beneath the microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is beneath the microwave?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n234683", "question": "Is the dress shirt gray or teal?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the dress shirt?')\nANSWER1=EVAL(expr=\"'gray' if {ANSWER0} == 'gray' else 'teal'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n351318", "question": "Of what color are the scissors?", "program": "ANSWER0=VQA(image=IMAGE,question='Of what color are the scissors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n59147", "question": "On which side of the photo is the toilet brush?", "program": "BOX0=LOC(image=IMAGE,object='toilet brush')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n262929", "question": "What is the boy on?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the boy on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n59147", "question": "Do you see either any containers or dream catchers?", "program": "BOX0=LOC(image=IMAGE,object='container')\nBOX1=LOC(image=IMAGE,object='dream catcher')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n262929", "question": "Is the young person on the bike?", "program": "BOX0=LOC(image=IMAGE,object='bike')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n512257", "question": "What is the name of the clothing item that is navy?", "program": "BOX0=LOC(image=IMAGE,object='clothing item')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the clothing item?')\nANSWER1=EVAL(expr=\"'navy' if {ANSWER0} == 'navy' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n513429", "question": "What is in front of the poster?", "program": "BOX0=LOC(image=IMAGE,object='poster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the poster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n350732", "question": "Are there both girls and soccer balls in this image?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nBOX1=LOC(image=IMAGE,object='soccer ball')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n546616", "question": "What kind of food is to the left of the baby?", "program": "BOX0=LOC(image=IMAGE,object='baby')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of food is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n59147", "question": "What item of furniture is the toilet paper to the right of the toilet resting on?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet paper')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What item of furniture is the toilet paper resting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n59147", "question": "The toilet paper to the right of the toilet is resting on what?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet paper')\nANSWER0=VQA(image=IMAGE0,question='What is the toilet paper resting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n352479", "question": "Are there either any skateboarders or snowboarders that are jumping?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nBOX1=LOC(image=IMAGE,object='snowboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='jumping')\nBOX3=LOC(image=IMAGE1,object='jumping')\nANSWER0=COUNT(box=BOX2)\nANSWER1=COUNT(box=BOX3)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n39114", "question": "What shape is the bench?", "program": "ANSWER0=VQA(image=IMAGE,question='What shape is the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n496803", "question": "What is the person below the crowd bigger than?", "program": "BOX0=LOC(image=IMAGE,object='crowd')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='What is the person bigger than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n66756", "question": "Does the brown field appear to be large and dirty?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the brown field appear to be large and dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n162586", "question": "Does the picture frame made of plastic look black and small?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the picture frame made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the picture frame?')\nANSWER2=VQA(image=IMAGE0,question='Is the picture frame small?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' and {ANSWER1} == 'black' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"imageId": "n532191", "question": "Is there a silver laptop or DVD player?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nBOX1=LOC(image=IMAGE,object='DVD player')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n352479", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n181355", "question": "What piece of furniture is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nANSWER0=VQA(image=IMAGE,question='What piece of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n181355", "question": "What piece of furniture is wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='What piece of furniture is wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n181355", "question": "How the piece of furniture that is made of wood is called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the piece of furniture made of wood called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n259002", "question": "Who is looking up?", "program": "BOX0=LOC(image=IMAGE,object='up')\nANSWER0=VQA(image=IMAGE,question='Who is looking up?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n88933", "question": "Which kind of furniture is blue?", "program": "BOX0=LOC(image=IMAGE,object='blue')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n513429", "question": "What is that monitor in front of?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the monitor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n88933", "question": "What type of furniture is this, a cabinet or a sofa?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nBOX1=LOC(image=IMAGE,object='sofa')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'cabinet' if {ANSWER0} > {ANSWER1} else 'sofa'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n259002", "question": "What do you think is that spectator doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is that spectator doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n88933", "question": "What piece of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What piece of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n500209", "question": "What is the container made of glass sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the container sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n433532", "question": "What is the name of the smooth piece of clothing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the name of the smooth piece of clothing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n429883", "question": "On which side of the photo are the chairs?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n557666", "question": "What color is the shirt the woman wears?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n140421", "question": "Do the soap bottle and the clock have the same color?", "program": "BOX0=LOC(image=IMAGE,object='soap bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='clock')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the soap bottle?')\nANSWER1=VQA(image=IMAGE1,question='What color is the clock?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n500209", "question": "What is sitting on top of the shelf?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on top of the shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n497789", "question": "Does the vehicle behind the zebras look black?", "program": "BOX0=LOC(image=IMAGE,object='zebras')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n23762", "question": "How tall do you think is the person?", "program": "ANSWER0=VQA(image=IMAGE,question='How tall do you think is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n276011", "question": "The wood floor is what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the wood floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n238266", "question": "Are the brown cookies on the right of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown cookies')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n246334", "question": "Are there any televisions or curtains in the picture?", "program": "BOX0=LOC(image=IMAGE,object='television')\nBOX1=LOC(image=IMAGE,object='curtain')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n500308", "question": "What appliance is in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is in front of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n500308", "question": "Is there a refrigerator in front of the wall made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wall made of wood')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='refrigerator')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n513100", "question": "What is the name of the piece of furniture in front of the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n513100", "question": "What's in front of the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n192021", "question": "How clean are the walls the window is on?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean are the walls the window is on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n513100", "question": "Which kind of furniture is in front of the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is in front of the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n524855", "question": "What animal is standing against the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is standing against the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n65202", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n280089", "question": "Are the mugs to the right of the plastic utensils?", "program": "BOX0=LOC(image=IMAGE,object='plastic utensils')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mugs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n508641", "question": "On which side of the photo is the catcher?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n429961", "question": "What is in the basket?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in the basket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n141939", "question": "What is the sink on?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nANSWER0=VQA(image=IMAGE,question='What is the sink on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n260762", "question": "Is the player to the right of the frisbee that looks white?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='player')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n346247", "question": "Do you see a fence in front of the tree that is in front of the school?", "program": "BOX0=LOC(image=IMAGE,object='school')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tree')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='fence')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n119944", "question": "Do the baskets that are not empty look colorful?", "program": "BOX0=LOC(image=IMAGE,object='not empty baskets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE,question='Do the baskets look colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n432591", "question": "Is there any bed or table that is not dark brown?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n433692", "question": "Which kind of device is to the left of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n98544", "question": "Does the heater next to the toilet look white and large?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='heater')\nANSWER0=VQA(image=IMAGE0,question='What color is the heater?')\nANSWER1=VQA(image=IMAGE0,question='Is the heater large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n119944", "question": "Does the man appear to be sitting?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the man appear to be sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n466319", "question": "How large is the bike below the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bike')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the bike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n276011", "question": "What is located on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n283587", "question": "Does the side table that is not big look wooden and long?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nBOX1=LOC(image=IMAGE,object='big')\nBOX2=LOC(image=IMAGE,object='wooden')\nBOX3=LOC(image=IMAGE,object='long')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {BOX1} == 0 and {BOX2} > 0 and {BOX3} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n240666", "question": "Does the porcelain sink have round shape?", "program": "BOX0=LOC(image=IMAGE,object='porcelain sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the porcelain sink?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n546884", "question": "What is the lid made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the lid made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n302358", "question": "Is the person near the grass sitting on a bench?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='bench')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n480253", "question": "What is parked alongside the barn?", "program": "BOX0=LOC(image=IMAGE,object='barn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is parked alongside the barn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n557666", "question": "Which kind of vehicle is metallic?", "program": "BOX0=LOC(image=IMAGE,object='metallic')\nANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n480253", "question": "Is the ambulance that is to the left of the workers parked alongside the barn?", "program": "BOX0=LOC(image=IMAGE,object='workers')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ambulance')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='barn')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n480253", "question": "What vehicle is parked alongside the barn?", "program": "BOX0=LOC(image=IMAGE,object='barn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is parked alongside the barn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n279173", "question": "Are the flags triangular and red?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the flag?')\nANSWER1=VQA(image=IMAGE0,question='What color is the flag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'triangular' and {ANSWER1} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n143935", "question": "Does the calf have brown color and large size?", "program": "BOX0=LOC(image=IMAGE,object='calf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the calf?')\nANSWER1=VQA(image=IMAGE0,question='What size is the calf?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n196058", "question": "What is beneath the zebras the rock sits beside?", "program": "BOX0=LOC(image=IMAGE,object='zebras')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rock')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is beneath the rock?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n196058", "question": "What is beneath the zebra that is not large?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is beneath the zebra?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n507959", "question": "Does the blue bag look small?", "program": "BOX0=LOC(image=IMAGE,object='blue bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the bag look small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n570181", "question": "Is the baseball mitt bright?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the baseball mitt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'bright' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n235859", "question": "Who is wearing the watch?", "program": "BOX0=LOC(image=IMAGE,object='watch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the watch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n235859", "question": "Who is wearing a watch?", "program": "BOX0=LOC(image=IMAGE,object='watch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a watch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n235859", "question": "Where are the people to the left of the bulb sitting?", "program": "BOX0=LOC(image=IMAGE,object='bulb')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='people')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n554880", "question": "What is the name of the device that the young man near the gift is holding?", "program": "BOX0=LOC(image=IMAGE,object='gift')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the name of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n77818", "question": "Which kind of device isn't illuminated?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='Which kind of device is illuminated?')\nANSWER1=EVAL(expr=\"'light bulb' if {ANSWER0} == 'lamp' else 'lamp'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n499081", "question": "What is resting on the marble counter?", "program": "BOX0=LOC(image=IMAGE,object='marble counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is resting on the marble counter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n499081", "question": "Are the books to the left or to the right of the wood cabinet?", "program": "BOX0=LOC(image=IMAGE,object='wood cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n489699", "question": "Is the sky above a train?", "program": "BOX0=LOC(image=IMAGE,object='train')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sky')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n28572", "question": "Is the mug in front of the cup green and small?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the mug?')\nANSWER3=VQA(image=IMAGE0,question='What size is the mug?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'green' and {ANSWER3} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"imageId": "n493357", "question": "Are there any seals or bunnies in the picture?", "program": "BOX0=LOC(image=IMAGE,object='seal')\nBOX1=LOC(image=IMAGE,object='bunny')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n489699", "question": "Is the sky above an airplane?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sky')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n557666", "question": "What is the large vehicle?", "program": "BOX0=LOC(image=IMAGE,object='large vehicle')\nANSWER0=VQA(image=IMAGE,question='What is the large vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n525901", "question": "What is the piece of furniture that is not small called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the piece of furniture that is not small called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n525901", "question": "What kind of furniture isn't small?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is small?')\nANSWER1=EVAL(expr=\"'not ' + {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n55058", "question": "Do you see any forks?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n549922", "question": "Which kind of toy is soft?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of toy is soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n403734", "question": "What's the bottle made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the bottle made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n549922", "question": "What is the colorful toy in the picture?", "program": "BOX0=LOC(image=IMAGE,object='colorful toy')\nANSWER0=VQA(image=IMAGE,question='What is the colorful toy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n59676", "question": "What is on the pan?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the pan?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n250715", "question": "Does the chair look large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the chair look large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n579256", "question": "Is the container made of plastic light and blue?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the container made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the container?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' and {ANSWER1} == 'light blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n579256", "question": "What tone does the container made of plastic have?", "program": "ANSWER0=VQA(image=IMAGE,question='What tone does the container made of plastic have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n579256", "question": "Which side of the picture is the plastic container on, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic container')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n541854", "question": "Which kind of fruit is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fruit is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n9856", "question": "What clothing item is not long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved')\nANSWER0=VQA(image=IMAGE,question='What clothing item is not long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n153293", "question": "What color are the towels made of cloth, black or white?", "program": "BOX0=LOC(image=IMAGE,object='towels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the towels?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n37274", "question": "What color are the shorts that the man is wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n507959", "question": "What is the piece of furniture that the luggage that is brown and black is sitting in front of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the piece of furniture that the luggage that is brown and black is sitting in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n468864", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n35676", "question": "Are there any new dishwashers?", "program": "ANSWER0=VQA(image=IMAGE,question='Are there any new dishwashers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n499081", "question": "How big is the sink?", "program": "ANSWER0=VQA(image=IMAGE,question='How big is the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n54424", "question": "Does the shirt seem to be sleeveless or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt seem to be sleeveless or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n319845", "question": "Does the ceiling above the table look blue and clean?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ceiling')\nANSWER0=VQA(image=IMAGE0,question='What color is the ceiling?')\nANSWER1=VQA(image=IMAGE0,question='Is the ceiling clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'clean' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n160664", "question": "Who is staring at the giraffe?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is staring at the giraffe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n16378", "question": "Is there any bag that is black?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nANSWER0=VQA(image=IMAGE,question='Is there any black bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n160664", "question": "What animal is the person in front of the post staring at?", "program": "BOX0=LOC(image=IMAGE,object='post')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is the person staring at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n160664", "question": "What animal is the woman staring at?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the woman staring at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n160664", "question": "Which kind of animal is the woman staring at?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is the woman staring at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n98544", "question": "What color is the small bathroom?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the small bathroom?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n207708", "question": "Does the table look brown and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n382416", "question": "Is the plate different in color than the purse?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='purse')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the plate?')\nANSWER1=VQA(image=IMAGE1,question='What color is the purse?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n272098", "question": "Which kind of clothing is yellow?", "program": "BOX0=LOC(image=IMAGE,object='yellow clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is yellow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n400036", "question": "What is common to the soccer ball and the backpack?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the soccer ball and the backpack?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n272098", "question": "What kind of clothing is yellow?", "program": "BOX0=LOC(image=IMAGE,object='yellow clothing')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is yellow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n546616", "question": "The table has which color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n347706", "question": "Is the kid wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the kid wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'shorts' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n347706", "question": "What's the child wearing?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the child wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n324644", "question": "Is the sticker both white and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='sticker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sticker?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the sticker?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n159284", "question": "Do you think this boy is real?", "program": "ANSWER0=VQA(image=IMAGE,question='Do you think this boy is real?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n324644", "question": "What color is the sticker that looks rectangular?", "program": "BOX0=LOC(image=IMAGE,object='rectangular sticker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sticker?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n274905", "question": "What is the color of the shirt?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n541482", "question": "What color is the sky?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n355339", "question": "Do you see any chairs that are not red?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=VQA(image=IMAGE,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if 'red' not in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n16656", "question": "The man is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The man is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n16656", "question": "Who is in front of the tree that is in front of the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tree')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is in front of the tree?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n16425", "question": "Does the person in front of the other person appear to be sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 1 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n355339", "question": "What item of furniture is in front of the people that are sitting around the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='people')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What item of furniture is in front?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n16656", "question": "What is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n146555", "question": "What is the sidewalk made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sidewalk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n574498", "question": "Are there green snowboards or rackets?", "program": "BOX0=LOC(image=IMAGE,object='snowboard')\nBOX1=LOC(image=IMAGE,object='racket')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n155555", "question": "Does the blue sky look bright and clear?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the blue sky look bright and clear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n410476", "question": "How heavy is the bison?", "program": "ANSWER0=VQA(image=IMAGE,question='How heavy is the bison?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n146555", "question": "Does the concrete sidewalk look rough and paved?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the concrete sidewalk look rough and paved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n186491", "question": "What kind of device is to the left of the tomatoes?", "program": "BOX0=LOC(image=IMAGE,object='tomatoes')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n186491", "question": "Are there any phones to the left of the tomatoes that are being in the bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tomatoes')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='phone')\nIMAGE2=CROP_LEFTOF(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n275148", "question": "What is the device to the right of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n410476", "question": "What is the bison doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the bison doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n186491", "question": "What type of device is sitting on the square table?", "program": "BOX0=LOC(image=IMAGE,object='square table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of device is sitting on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n554880", "question": "What device is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n554880", "question": "What is the device that the young woman is holding?", "program": "BOX0=LOC(image=IMAGE,object='young woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the device she is holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n579256", "question": "Which color is the floor?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n126891", "question": "Are there glasses or women?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nBOX1=LOC(image=IMAGE,object='woman')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n295771", "question": "What is common to the door and the room?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the door and the room?')\nFINAL_RESULT=RESULT(var=ANSWER0)"},{"imageId": "n141939", "question": "What type of appliance is under the sink that is shown in the picture?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of appliance is under the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n141939", "question": "Which kind of appliance is under the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is under the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n141939", "question": "What is under the sink on the counter top?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='counter top')\nANSWER0=VQA(image=IMAGE0,question='What is under the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n141939", "question": "What's under the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n150962", "question": "What is the window made of, glass or plastic?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the window made of?')\nANSWER1=EVAL(expr=\"'glass' if {ANSWER0} == 'glass' else 'plastic'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n141939", "question": "Do you see any drawers under the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drawers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n525029", "question": "What is the vehicle that is parked near the houses called?", "program": "BOX0=LOC(image=IMAGE,object='houses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n520071", "question": "Do the tall books look colorful and thick?", "program": "BOX0=LOC(image=IMAGE,object='tall books')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do the tall books look colorful?')\nANSWER1=VQA(image=IMAGE0,question='Do the tall books look thick?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n334278", "question": "Who in this photograph is staring?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is staring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n151768", "question": "What is the woman that is not young sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman sitting on top of?')\nANSWER1=EVAL(expr=\"'nothing' if {ANSWER0} == 'floor' else {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n16656", "question": "What animal is the shoe behind of?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the shoe behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n314171", "question": "What is the room holding?", "program": "BOX0=LOC(image=IMAGE,object='room')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the room holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n170941", "question": "What kind of furniture is wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n441859", "question": "Are the life vest and the shirt the same color?", "program": "BOX0=LOC(image=IMAGE,object='life vest')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the life vest?')\nANSWER1=VQA(image=IMAGE1,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n145498", "question": "Does the table lamp have the same color as the pillow?", "program": "BOX0=LOC(image=IMAGE,object='table lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pillow')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the table lamp?')\nANSWER1=VQA(image=IMAGE1,question='What color is the pillow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n24526", "question": "In which part is the open umbrella?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In which part is the open umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n566028", "question": "Does the skateboard have brown color and large size?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the skateboard?')\nANSWER1=VQA(image=IMAGE0,question='What size is the skateboard?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n451187", "question": "Is the bench in front of the woman the man is to the left of?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the bench in front of the woman the man is to the left of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n119886", "question": "What is beneath the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is beneath the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n146555", "question": "Is plastic used to make the bottle to the right of the cow?", "program": "BOX0=LOC(image=IMAGE,object='cow')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=VQA(image=IMAGE0,question='What material is the bottle made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n137182", "question": "Is the building in front of the trees that are not short?", "program": "BOX0=LOC(image=IMAGE,object='not short trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the building in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n181355", "question": "What device is to the right of the man that is sitting in front of the pillow?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='RIGHT')\nANSWER0=VQA(image=IMAGE1,question='What device is to the right?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n543966", "question": "What color is the dirt the elephants are on?", "program": "BOX0=LOC(image=IMAGE,object='elephants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n433532", "question": "Do you think that lady is looking down?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the lady looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n382416", "question": "Is the suitcase to the right of the other suitcase tall and brown?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='suitcase')\nANSWER0=COUNT(box=BOX1)\nANSWER1=VQA(image=IMAGE0,question='Is the suitcase tall?')\nANSWER2=VQA(image=IMAGE0,question='What color is the suitcase?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 'tall' and {ANSWER2} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"imageId": "n433532", "question": "What is the lady doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the lady doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n369313", "question": "What is the woman wearing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n369313", "question": "What is the happy woman wearing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n511913", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n334278", "question": "Is the athletic person in front of the umpire young and female?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='athletic person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='Is the athletic person young and female?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"imageId": "n398429", "question": "Is the window rectangular and white?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the window?')\nANSWER1=VQA(image=IMAGE0,question='What color is the window?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rectangular' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n479092", "question": "Do the silver forks look hard?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the silver forks look hard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n249639", "question": "What shape is the large mirror?", "program": "BOX0=LOC(image=IMAGE,object='large mirror')\nANSWER0=VQA(image=IMAGE,question='What shape is the large mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n554880", "question": "Is the camera on the right side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='camera')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n249639", "question": "Is there a mirror near the white lamp?", "program": "BOX0=LOC(image=IMAGE,object='white lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n431447", "question": "What makes up the napkin, paper or cloth?", "program": "ANSWER0=VQA(image=IMAGE,question='What makes up the napkin, paper or cloth?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n240666", "question": "Is the garbage can behind a mat?", "program": "BOX0=LOC(image=IMAGE,object='mat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='garbage can')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n431447", "question": "How clean is that napkin?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is that napkin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n240666", "question": "Is the small trash can underneath the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small trash can')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n429961", "question": "On which side of the picture is the eggplant?", "program": "BOX0=LOC(image=IMAGE,object='eggplant')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n240666", "question": "Is the garbage bin below a sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='garbage bin')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n28792", "question": "Is the chubby man to the left of the umbrella wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chubby man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the man wearing?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'shorts' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n28792", "question": "What does the chubby man hold?", "program": "BOX0=LOC(image=IMAGE,object='chubby man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the chubby man hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n16378", "question": "What is the woman doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the woman doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n435808", "question": "The monitor to the right of the other monitor has which color?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='monitor')\nANSWER0=VQA(image=IMAGE0,question='What color is the monitor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n335542", "question": "What animal is walking on the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is walking on the ground?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n435808", "question": "What sits on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What sits on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n386688", "question": "Does the sky look bright and blue?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sky?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n317260", "question": "Are both the spectators to the left of the batter and the spectators that are to the right of the batter sitting?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='spectators')\nIMAGE1=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX2=LOC(image=IMAGE1,object='spectators')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n548534", "question": "Is the plastic container on the left side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic container')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n575770", "question": "Does the suitcase to the right of the rug have small size?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='suitcase')\nANSWER0=VQA(image=IMAGE0,question='What size is the suitcase?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n275148", "question": "What is the name of the wooden piece of furniture?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the name of the wooden piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n275148", "question": "Which kind of furniture is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n281241", "question": "Do both the smiling gentleman in front of the picture and the Caucasian person look young?", "program": "BOX0=LOC(image=IMAGE,object='smiling gentleman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='picture')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='Caucasian person')\nANSWER0=VQA(image=IMAGE0,question='Does the smiling gentleman look young?')\nANSWER1=VQA(image=IMAGE1,question='Does the Caucasian person look young?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n157375", "question": "How big is the plane?", "program": "BOX0=LOC(image=IMAGE,object='plane')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the plane?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n126087", "question": "What color does the wrist watch the woman is wearing have?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wrist watch')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the wrist watch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n281241", "question": "How old is the gentleman?", "program": "ANSWER0=VQA(image=IMAGE,question='How old is the gentleman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n232810", "question": "Which color do you think the wood floor is?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the wood floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n538684", "question": "On which side of the image are the baseball players?", "program": "BOX0=LOC(image=IMAGE,object='baseball player')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n274905", "question": "Is there a colorful hat or scarf?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nBOX1=LOC(image=IMAGE,object='scarf')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n222297", "question": "What's the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n6309", "question": "Are there both a horse and a fence in the image?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n545516", "question": "Are there both trucks and airplanes?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nBOX1=LOC(image=IMAGE,object='airplane')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n310625", "question": "What is this, a cup or a bottle?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nBOX1=LOC(image=IMAGE,object='bottle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'cup' if {ANSWER0} > 0 else 'bottle'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n280089", "question": "What are the jars sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='jars')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the jars sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n455563", "question": "Are there any curtains or trash cans in the photo?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nBOX1=LOC(image=IMAGE,object='trash cans')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n159802", "question": "What is the Asian person near the water bottle wearing?", "program": "BOX0=LOC(image=IMAGE,object='Asian person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n159802", "question": "What is the man wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n67005", "question": "Which kind of furniture is fluffy?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is fluffy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n525901", "question": "What is the pen made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the pen made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n525901", "question": "What is located on top of the white paper?", "program": "BOX0=LOC(image=IMAGE,object='white paper')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n433532", "question": "What color is the hair, gray or red?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the hair?')\nANSWER1=EVAL(expr=\"'gray' if {ANSWER0} == 'gray' else 'red'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n525901", "question": "What material is the pen?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the pen?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n100991", "question": "Do you see any waffles to the left of the fork?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='waffles')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n290409", "question": "Is the truck in front of the basket?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='truck')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n119944", "question": "What color is the large animal?", "program": "BOX0=LOC(image=IMAGE,object='large animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the large animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n49310", "question": "Are the sweater and the black dress shirt both long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='black dress shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Are the sleeves long?')\nANSWER1=VQA(image=IMAGE1,question='Are the sleeves long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n146522", "question": "What makes up the jacket, cloth or leather?", "program": "ANSWER0=VQA(image=IMAGE,question='What makes up the jacket, cloth or leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n480253", "question": "Is the car to the left or to the right of the vehicle that is parked along the street?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='street')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='car')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n489190", "question": "Who wears a knee pad?", "program": "BOX0=LOC(image=IMAGE,object='knee pad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears a knee pad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n489190", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n489190", "question": "Who is wearing the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n489190", "question": "Who is skating on the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is skating on the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n489190", "question": "Who is wearing a knee pad?", "program": "BOX0=LOC(image=IMAGE,object='knee pad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a knee pad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n49310", "question": "Does the striped sweater look long sleeved and black?", "program": "BOX0=LOC(image=IMAGE,object='striped sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of sleeves does the sweater have?')\nANSWER1=VQA(image=IMAGE0,question='What color is the sweater?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'long sleeved' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n501951", "question": "Is the driver in the photo wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='driver')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the driver wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n119944", "question": "Is the fat woman to the right of an elephant?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fat woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n240973", "question": "Which kind of furniture are the shelves sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture are the shelves sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n240973", "question": "What type of furniture is above the newspaper that looks red and white?", "program": "BOX0=LOC(image=IMAGE,object='newspaper')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is above the newspaper?')\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 'red and white' else {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n335542", "question": "Is the bear that is to the left of the other bear long and white?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bear')\nANSWER0=VQA(image=IMAGE0,question='What color is the bear?')\nANSWER1=VQA(image=IMAGE0,question='Is the bear long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n234722", "question": "What kind of food is not tasty?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food is not tasty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n234722", "question": "Which type of food is not tasty?", "program": "ANSWER0=VQA(image=IMAGE,question='Which type of food is not tasty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n540852", "question": "Where in the photograph is the umbrella, in the top or in the bottom?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nBOX1=LOC(image=IMAGE,object='TOP')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n208302", "question": "Is the weather cloudy?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the weather like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'cloudy' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n19152", "question": "Which place is this?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n556604", "question": "Does the smooth table have brown color?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the texture of the table?')\nANSWER1=VQA(image=IMAGE0,question='What color is the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'smooth' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n200225", "question": "What is the name of the food that is on the food with the spinach?", "program": "BOX0=LOC(image=IMAGE,object='food with spinach')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n200225", "question": "What food is on the pizza?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What food is on the pizza?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n574498", "question": "Is the man to the left of a ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n527290", "question": "Is she to the right of the couch that is to the left of the television?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='she')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n393305", "question": "Is the traffic sign behind the girl octagonal and red?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic sign')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What shape is the traffic sign?')\nANSWER3=VQA(image=IMAGE0,question='What color is the traffic sign?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'octagonal' and {ANSWER3} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"imageId": "n272313", "question": "What is the color of the long pants?", "program": "BOX0=LOC(image=IMAGE,object='long pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the long pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n119944", "question": "How hard are the brown sandals?", "program": "ANSWER0=VQA(image=IMAGE,question='How hard are the brown sandals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n275148", "question": "What is the color of the picture frame which is hanging from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='picture frame')\nANSWER0=VQA(image=IMAGE0,question='What color is the picture frame?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n508733", "question": "Who is in front of the window frame that looks light brown?", "program": "BOX0=LOC(image=IMAGE,object='light brown window frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the window frame?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n199286", "question": "What is the color of the shorts made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the shorts?')\nANSWER1=EVAL(expr=\"'cloth' if {ANSWER0} != 'unknown' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n508733", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n477702", "question": "Is the shirt made of cotton short sleeved and gray?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the shirt made of?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the shirt have?')\nANSWER2=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'cotton' and {ANSWER1} == 'short sleeved' and {ANSWER2} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"imageId": "n199286", "question": "Are both the shorts and the black leggings made of cloth?", "program": "ANSWER0=VQA(image=IMAGE,question='What material are the shorts made of?')\nANSWER1=VQA(image=IMAGE,question='What material are the black leggings made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'cloth' and {ANSWER1} == 'cloth' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n219840", "question": "What kind of animal is beautiful?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of animal is beautiful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n578564", "question": "Is the cooking utensil in front of the window blue and metallic?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the cooking utensil?')\nANSWER3=VQA(image=IMAGE0,question='What material is the cooking utensil made of?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'blue' and {ANSWER3} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"imageId": "n450919", "question": "What is the height of the green grass near the mud?", "program": "BOX0=LOC(image=IMAGE,object='mud')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green grass')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the height of the green grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n282607", "question": "What does the man hold?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the man hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n58220", "question": "Is the water wavy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the water wavy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n118102", "question": "Is the round cake to the right of the young girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cake')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n411121", "question": "Does the backpack appear to be clean and blue?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the backpack?')\nANSWER1=VQA(image=IMAGE0,question='Does the backpack appear to be clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n282607", "question": "What is the person behind the net playing with?", "program": "BOX0=LOC(image=IMAGE,object='net')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person playing with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n526228", "question": "Is there a lamp in this picture that is large?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nANSWER0=VQA(image=IMAGE,question='Is the lamp large?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n356822", "question": "Is the girl to the right of the man happy and old?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Is the girl happy?')\nANSWER3=VQA(image=IMAGE1,question='Is the girl old?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"imageId": "n556604", "question": "Is the woman near the man standing on the bricks?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bricks')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='woman')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n556604", "question": "The woman near the man is standing on what?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the woman standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n411121", "question": "How is the animal that is in the backpack called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the animal that is in the backpack called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n79078", "question": "What material is the stop sign on top of the pole made of?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stop sign')\nANSWER0=VQA(image=IMAGE0,question='What material is the stop sign made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n49310", "question": "Is the person to the left of the glasses wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n508641", "question": "What is the person on top of the field holding?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n513100", "question": "What is the yard in front of?", "program": "BOX0=LOC(image=IMAGE,object='yard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the yard in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n508641", "question": "What is the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n49310", "question": "What's the man sitting on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n470131", "question": "On which side of the picture is the small bottle?", "program": "BOX0=LOC(image=IMAGE,object='small bottle')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n429961", "question": "What kind of food is not round?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food is not round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n66756", "question": "What is the batter standing beside of?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the batter standing beside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n335542", "question": "What is filled with bird?", "program": "ANSWER0=VQA(image=IMAGE,question='What is filled with bird?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n199097", "question": "Is the coat comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the coat comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n433532", "question": "Is the robe red and smooth?", "program": "BOX0=LOC(image=IMAGE,object='robe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the robe?')\nANSWER1=VQA(image=IMAGE0,question='What texture is the robe?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'smooth' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n260521", "question": "Is that car silver?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the car?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n437064", "question": "Does the plate look white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the plate look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n118102", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n470920", "question": "Do the striped pants appear to be black and white?", "program": "BOX0=LOC(image=IMAGE,object='striped pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n54180", "question": "Which side of the image is the cup on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cup')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n119886", "question": "Does the toilet look brown?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n222915", "question": "What does the mug sit on?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the mug sit on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n209843", "question": "Does the door look black?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the door look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"imageId": "n470920", "question": "Is the jacket gray and bright?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE,question='Is the jacket bright?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"imageId": "n414992", "question": "Does the sunny beach look bright?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the sunny beach look bright?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n285391", "question": "What kind of furniture is wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n285391", "question": "What kind of furniture is made of wood?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n414992", "question": "Does the man that is to the left of the other man seem to be standing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the man seem to be standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n69237", "question": "Which kind of furniture is black?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"imageId": "n69237", "question": "What is the black item of furniture?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the black item?')\nFINAL_RESULT=RESULT(var=ANSWER0)"},{"index": 451, "imageId": "n285391", "question": "What is the old piece of furniture in the photo?", "program": "BOX0=LOC(image=IMAGE,object='old piece of furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the old piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 452, "imageId": "n579928", "question": "Where are the grouped people standing on?", "program": "BOX0=LOC(image=IMAGE,object='grouped people')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where are the grouped people standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 453, "imageId": "n513100", "question": "Is that a small fence?", "program": "ANSWER0=VQA(image=IMAGE,question='Is that a small fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 454, "imageId": "n313060", "question": "Which color is the bag that is made of leather, tan or purple?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the bag made of?')\nANSWER1=EVAL(expr=\"'tan' if {ANSWER0} == 'leather' else 'purple'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 455, "imageId": "n310828", "question": "Is the mouse pad to the right of her both clean and large?", "program": "BOX0=LOC(image=IMAGE,object='her')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mouse pad')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='Is the mouse pad clean?')\nANSWER3=VQA(image=IMAGE0,question='Is the mouse pad large?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 456, "imageId": "n199097", "question": "Does the hat have a different color than the jacket?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='jacket')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 457, "imageId": "n278312", "question": "Does the knife in the knife block have black color and short length?", "program": "BOX0=LOC(image=IMAGE,object='knife block')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knife')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the knife?')\nANSWER3=VQA(image=IMAGE0,question='What is the length of the knife?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'black' and {ANSWER3} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 458, "imageId": "n199097", "question": "Is the color of the sidewalk different than the street sign?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='street sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the sidewalk?')\nANSWER1=VQA(image=IMAGE1,question='What color is the street sign?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 459, "imageId": "n262920", "question": "What are the doors made of?", "program": "BOX0=LOC(image=IMAGE,object='doors')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the doors made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 460, "imageId": "n117888", "question": "Does the fence in front of the bench look tall and gray?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the fence?')\nANSWER3=VQA(image=IMAGE0,question='Does the fence look tall?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'gray' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 461, "imageId": "n130638", "question": "What color is the girl that is sitting down?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 462, "imageId": "n579256", "question": "Does this fridge look wide and new?", "program": "BOX0=LOC(image=IMAGE,object='fridge')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does this fridge look wide?')\nANSWER1=VQA(image=IMAGE0,question='Does this fridge look new?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 463, "imageId": "n578564", "question": "What is the color of the flower pot?", "program": "BOX0=LOC(image=IMAGE,object='flower pot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the flower pot?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 464, "imageId": "n116329", "question": "Who do you think is in front of the door made of wood?", "program": "BOX0=LOC(image=IMAGE,object='door made of wood')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the door made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 465, "imageId": "n200692", "question": "Is there a tomato in this photo?", "program": "BOX0=LOC(image=IMAGE,object='tomato')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 466, "imageId": "n222297", "question": "Is the frisbee above the pool both round and white?", "program": "BOX0=LOC(image=IMAGE,object='pool')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='frisbee')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the frisbee?')\nANSWER3=VQA(image=IMAGE0,question='What shape is the frisbee?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'white' and {ANSWER3} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 467, "imageId": "n140421", "question": "Is the sink dirty and gray?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the sink dirty?')\nANSWER1=VQA(image=IMAGE0,question='What color is the sink?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dirty' and {ANSWER1} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 468, "imageId": "n293477", "question": "Which kind of bag is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of bag is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 469, "imageId": "n131634", "question": "Are there both a helmet and a motorcycle in the image?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nBOX1=LOC(image=IMAGE,object='motorcycle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 470, "imageId": "n131634", "question": "Is the large vehicle to the right or to the left of the vehicle that is parked along the street?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nBOX1=LOC(image=IMAGE,object='street')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='vehicle')\nIMAGE1=CROP_RIGHTOF(image=IMAGE,box=BOX1)\nBOX3=LOC(image=IMAGE1,object='vehicle')\nANSWER0=EVAL(expr=\"'right' if {BOX2} == {BOX0} else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 471, "imageId": "n293477", "question": "Which kind of bag is green?", "program": "BOX0=LOC(image=IMAGE,object='green bag')\nANSWER0=VQA(image=IMAGE,question='Which kind of bag is green?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 472, "imageId": "n181210", "question": "How does the fruit in front of the cup look, unpeeled or peeled?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruit')\nANSWER0=VQA(image=IMAGE0,question='How does the fruit look?')\nANSWER1=EVAL(expr=\"'unpeeled' if {ANSWER0} == 'unpeeled' else 'peeled'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 473, "imageId": "n274905", "question": "What is the color of the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 474, "imageId": "n162586", "question": "What is the color of the television?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the television?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 475, "imageId": "n204894", "question": "Does the shirt have the same color as the chair?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='chair')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the chair?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 476, "imageId": "n250715", "question": "Are the words large and black?", "program": "BOX0=LOC(image=IMAGE,object='large')\nBOX1=LOC(image=IMAGE,object='black')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 477, "imageId": "n146522", "question": "Does the bag to the left of the boy look black?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the bag?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'black' else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 478, "imageId": "n160664", "question": "Is there a woman that is not young?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='young')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 479, "imageId": "n16656", "question": "What is in front of the animal that is in front of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 480, "imageId": "n222915", "question": "What vegetable is sitting on the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What vegetable is sitting on the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 481, "imageId": "n342511", "question": "How old is the person that the jacket is worn around?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How old is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 482, "imageId": "n90294", "question": "What material is the calculator that is to the right of the charger made of?", "program": "BOX0=LOC(image=IMAGE,object='charger')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the calculator made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 483, "imageId": "n90294", "question": "Are both the device next to the book and the calculator made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='book')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='calculator')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='What material is the device made of?')\nANSWER1=VQA(image=IMAGE2,question='What material is the calculator made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' and {ANSWER1} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 484, "imageId": "n518912", "question": "Are the cups made of plastic or porcelain?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nANSWER0=VQA(image=IMAGE,question='What material are the cups made of?')\nANSWER1=EVAL(expr=\"'plastic' if 'plastic' in {ANSWER0} else 'porcelain'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 485, "imageId": "n518912", "question": "What is located on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 486, "imageId": "n16656", "question": "What's in front of the cat?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the cat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 487, "imageId": "n279173", "question": "What is in front of the building the sky is above?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sky')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 488, "imageId": "n279173", "question": "What is in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 489, "imageId": "n315887", "question": "Which kind of device is reflective?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of device is reflective?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 490, "imageId": "n412144", "question": "Is the shirt short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 491, "imageId": "n379991", "question": "What kind of cooking utensil is on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of cooking utensil is on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 492, "imageId": "n435808", "question": "Does the router that is to the left of the chair look rectangular and black?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='router')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What shape is the router?')\nANSWER3=VQA(image=IMAGE1,question='What color is the router?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'rectangular' and {ANSWER3} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 493, "imageId": "n531731", "question": "Does the helmet have blue color?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the helmet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 494, "imageId": "n455563", "question": "Is the mug to the left of a plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 495, "imageId": "n296467", "question": "What shape does the food the cupcakes are to the left of have?", "program": "BOX0=LOC(image=IMAGE,object='cupcakes')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape does the food have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 496, "imageId": "n406334", "question": "Is the bus near the people black and small?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nBOX1=LOC(image=IMAGE,object='people')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 497, "imageId": "n279581", "question": "Do the shoes look black or pink?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shoes?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'pink'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 498, "imageId": "n290409", "question": "What is the mirror made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the mirror made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 499, "imageId": "n275148", "question": "What type of furniture is to the right of the device that is on top of the TV stand?", "program": "BOX0=LOC(image=IMAGE,object='TV stand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nIMAGE2=CROP_RIGHTOF(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What type of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 500, "imageId": "n140421", "question": "Is the chandelier to the left of the clock made of metal or glass?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chandelier')\nANSWER0=VQA(image=IMAGE0,question='What material is the chandelier made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'metal' or {ANSWER0} == 'glass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 501, "imageId": "n429961", "question": "Are there any fruits or toilets?", "program": "BOX0=LOC(image=IMAGE,object='fruit')\nBOX1=LOC(image=IMAGE,object='toilet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 502, "imageId": "n262920", "question": "The black backpack is hanging on what?", "program": "BOX0=LOC(image=IMAGE,object='black backpack')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The black backpack is hanging on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 503, "imageId": "n526228", "question": "Is the man that is looking down wearing a uniform?", "program": "BOX0=LOC(image=IMAGE,object='man looking down')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man wearing a uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 504, "imageId": "n531731", "question": "What color is the wood bench?", "program": "BOX0=LOC(image=IMAGE,object='wood bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the wood bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 505, "imageId": "n111390", "question": "What do you think is the old lady wearing?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is the old lady wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 506, "imageId": "n6309", "question": "Are there any horses in front of the white fence?", "program": "BOX0=LOC(image=IMAGE,object='white fence')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 507, "imageId": "n95313", "question": "Which color is the bed that the closet is behind of?", "program": "BOX0=LOC(image=IMAGE,object='closet')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nANSWER0=VQA(image=IMAGE0,question='Which color is the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 508, "imageId": "n151768", "question": "To what is the barrier made of metal mounted?", "program": "BOX0=LOC(image=IMAGE,object='barrier')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='To what is the barrier made of metal mounted?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 509, "imageId": "n39114", "question": "What's the mound in front of?", "program": "BOX0=LOC(image=IMAGE,object='mound')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the mound in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 510, "imageId": "n551964", "question": "Who is walking next to the boy on the left of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boy')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is walking next to the boy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 511, "imageId": "n455563", "question": "Is there any mug in the bathroom?", "program": "BOX0=LOC(image=IMAGE,object='bathroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 512, "imageId": "n279581", "question": "Are both the helmet and the bat made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bat')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the helmet made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the bat made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 513, "imageId": "n278312", "question": "What appliance is to the left of the light brown object on the counter?", "program": "BOX0=LOC(image=IMAGE,object='light brown object')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What appliance is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 514, "imageId": "n278312", "question": "Is the stove to the left of a drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 515, "imageId": "n35676", "question": "Are the drawers underneath the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drawers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 516, "imageId": "n570181", "question": "Who is in front of the person that is crouching?", "program": "BOX0=LOC(image=IMAGE,object='person crouching')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the person that is crouching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 517, "imageId": "n35676", "question": "What kind of furniture is underneath the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is underneath the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 518, "imageId": "n207893", "question": "Does the brown grass look tall?", "program": "BOX0=LOC(image=IMAGE,object='brown grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the brown grass look tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 519, "imageId": "n538039", "question": "Which color is the frisbee, red or yellow?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the frisbee?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'yellow'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 520, "imageId": "n538039", "question": "What is about to hit the green grass?", "program": "BOX0=LOC(image=IMAGE,object='green grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is about to hit the green grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 521, "imageId": "n88933", "question": "Which kind of clothing is pink?", "program": "BOX0=LOC(image=IMAGE,object='pink clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is pink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 522, "imageId": "n538039", "question": "What is the frisbee about to hit?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the frisbee about to hit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 523, "imageId": "n413002", "question": "The short sleeved shirt is what color?", "program": "BOX0=LOC(image=IMAGE,object='short sleeved shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the short sleeved shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 524, "imageId": "n531359", "question": "Are the trees behind the young boy?", "program": "BOX0=LOC(image=IMAGE,object='young boy')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 525, "imageId": "n207893", "question": "Are there any bicycles?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 526, "imageId": "n65885", "question": "What are the shelves made of?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the shelves made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 527, "imageId": "n554880", "question": "What device is to the left of the television?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the left of the television?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 528, "imageId": "n95904", "question": "What is the ground made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the ground made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 529, "imageId": "n37274", "question": "What is the blender full of?", "program": "BOX0=LOC(image=IMAGE,object='blender')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the blender full of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 530, "imageId": "n37274", "question": "What is that blender sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='blender')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is that blender sitting atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 531, "imageId": "n250715", "question": "Which kind of clothing is dark colored?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is dark colored?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 532, "imageId": "n37274", "question": "What is sitting atop the crate?", "program": "BOX0=LOC(image=IMAGE,object='crate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting atop the crate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 533, "imageId": "n233607", "question": "Does she seem to be sitting?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does she seem to be sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 534, "imageId": "n431447", "question": "Inside what is the pizza?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Inside what is the pizza?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 535, "imageId": "n65885", "question": "Are the shelves made of wood?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material are the shelves made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 536, "imageId": "n51658", "question": "Is the tennis racket round and red?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the tennis racket?')\nANSWER1=VQA(image=IMAGE0,question='What color is the tennis racket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 537, "imageId": "n334278", "question": "The pitcher stands where?", "program": "BOX0=LOC(image=IMAGE,object='pitcher')\nANSWER0=VQA(image=IMAGE,question='The pitcher stands where?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 538, "imageId": "n334278", "question": "What is throwing the baseball?", "program": "BOX0=LOC(image=IMAGE,object='baseball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is throwing the baseball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 539, "imageId": "n12404", "question": "How large is the concrete sidewalk?", "program": "ANSWER0=VQA(image=IMAGE,question='How large is the concrete sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 540, "imageId": "n500209", "question": "What is in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 541, "imageId": "n167552", "question": "What type of furniture is to the left of the shelf that looks light brown?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is this?')\nANSWER1=EVAL(expr=\"'light brown' in {ANSWER0}\")\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 542, "imageId": "n496803", "question": "Who is wearing the skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 543, "imageId": "n433532", "question": "Which kind of furniture is made of wood?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 544, "imageId": "n309148", "question": "Does the fire truck on the street look dirty and white?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fire truck')\nANSWER0=VQA(image=IMAGE0,question='What color is the fire truck?')\nANSWER1=VQA(image=IMAGE0,question='Does the fire truck look dirty?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 545, "imageId": "n346736", "question": "Do the trees look tall and green?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nANSWER0=VQA(image=IMAGE,question='Do the trees look tall?')\nANSWER1=VQA(image=IMAGE,question='Do the trees look green?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 546, "imageId": "n326988", "question": "Does the person in front of the cabinets have brunette color?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 547, "imageId": "n433532", "question": "Does the shelf that is made of wood look high and brown?", "program": "BOX0=LOC(image=IMAGE,object='wood shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the wood shelf?')\nANSWER1=VQA(image=IMAGE0,question='Does the wood shelf look high?')\nANSWER2=VQA(image=IMAGE0,question='Does the wood shelf look brown?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 548, "imageId": "n410476", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 549, "imageId": "n546616", "question": "Is the small cup made of glass?", "program": "BOX0=LOC(image=IMAGE,object='small cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the small cup made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'glass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 550, "imageId": "n334278", "question": "Who is in front of the umpire that is staring?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='staring')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is in front of the umpire?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 551, "imageId": "n410476", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 552, "imageId": "n12404", "question": "Are there either women or men that are eating?", "program": "BOX0=LOC(image=IMAGE,object='women')\nBOX1=LOC(image=IMAGE,object='men')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 553, "imageId": "n298104", "question": "Where do you think is the happy person standing on?", "program": "BOX0=LOC(image=IMAGE,object='happy person')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the happy person standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 554, "imageId": "n298104", "question": "Who do you think wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who do you think wears a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 555, "imageId": "n470920", "question": "Is the brown bag behind the bright fruits?", "program": "BOX0=LOC(image=IMAGE,object='bright fruits')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 556, "imageId": "n229548", "question": "What aircraft is military?", "program": "BOX0=LOC(image=IMAGE,object='aircraft')\nANSWER0=VQA(image=IMAGE,question='What aircraft is military?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 557, "imageId": "n334278", "question": "Who is the batter in front of?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the batter in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 558, "imageId": "n229548", "question": "What aircraft is heavy?", "program": "ANSWER0=VQA(image=IMAGE,question='What aircraft is heavy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 559, "imageId": "n259949", "question": "Do you see any skaters in the parking lot?", "program": "BOX0=LOC(image=IMAGE,object='parking lot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skaters')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 560, "imageId": "n229548", "question": "In which part is the large helicopter, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large helicopter')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 561, "imageId": "n150962", "question": "Is the door behind the mat open and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='mat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='door')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='door')\nIMAGE1=CROP(image=IMAGE0,box=BOX2)\nANSWER2=VQA(image=IMAGE1,question='Is the door open?')\nANSWER3=VQA(image=IMAGE1,question='Is the door rectangular?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 562, "imageId": "n141939", "question": "Is the countertop brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the countertop?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 563, "imageId": "n54424", "question": "Which kind of clothing is striped?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of clothing is striped?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 564, "imageId": "n526228", "question": "Is the small side table to the right or to the left of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small side table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 565, "imageId": "n501951", "question": "Is the helmet made of plastic or metal?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the helmet made of?')\nANSWER1=EVAL(expr=\"'plastic' if 'plastic' in {ANSWER0} else 'metal'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 566, "imageId": "n501951", "question": "Is the street next to the sidewalk hard and paved?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='street')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 567, "imageId": "n351318", "question": "What are the scissors on?", "program": "BOX0=LOC(image=IMAGE,object='scissors')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the scissors on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 568, "imageId": "n380113", "question": "Is the soccer ball on the right side or on the left?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='soccer ball')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 569, "imageId": "n310625", "question": "Does the toothbrush to the left of the faucet seem to be small and blue?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toothbrush')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the toothbrush?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'blue' else 'no'\")\nANSWER4=VQA(image=IMAGE0,question='Does the toothbrush seem to be small?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} == 'small' else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 570, "imageId": "n153118", "question": "What is on the pole that is not short?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not short object')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is on the pole?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 571, "imageId": "n153118", "question": "What is on the pole?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the pole?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 572, "imageId": "n153118", "question": "Is the traffic light red or black?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the traffic light?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 573, "imageId": "n373692", "question": "Is the player next to the other player female or male?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other player')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'female' if {ANSWER0} > 0 else 'male'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 574, "imageId": "n373692", "question": "Is the player next to the other player Caucasian and male?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other player')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='Caucasian')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='male')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 575, "imageId": "n315887", "question": "Does the tape that is made of plastic look small and yellow?", "program": "BOX0=LOC(image=IMAGE,object='plastic tape')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tape?')\nANSWER1=VQA(image=IMAGE0,question='Does the tape look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 576, "imageId": "n100991", "question": "How long is the cooked sausage?", "program": "ANSWER0=VQA(image=IMAGE,question='How long is the cooked sausage?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 577, "imageId": "n282436", "question": "What device is not black?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='What color is the device?')\nANSWER1=EVAL(expr=\"'not black' if {ANSWER0} != 'black' else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 578, "imageId": "n282436", "question": "What device is black?", "program": "BOX0=LOC(image=IMAGE,object='black')\nANSWER0=VQA(image=IMAGE,question='What device is black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 579, "imageId": "n171169", "question": "Do you see any small cars or windows?", "program": "BOX0=LOC(image=IMAGE,object='small car')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 580, "imageId": "n324908", "question": "Is the shirt bright and black and white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'bright and black and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 581, "imageId": "n37274", "question": "What appliance is right of the liquor?", "program": "BOX0=LOC(image=IMAGE,object='liquor')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is right of the liquor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 582, "imageId": "n65202", "question": "Who is wearing the sneakers?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the sneakers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 583, "imageId": "n89148", "question": "Who is posing?", "program": "BOX0=LOC(image=IMAGE,object='posing')\nANSWER0=VQA(image=IMAGE,question='Who is posing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 584, "imageId": "n259002", "question": "What is the vehicle to the right of the soccer player that is wearing a jersey?", "program": "BOX0=LOC(image=IMAGE,object='soccer player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='jersey')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=VQA(image=IMAGE1,question='What is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 585, "imageId": "n151768", "question": "What is the vegetable inside of?", "program": "BOX0=LOC(image=IMAGE,object='vegetable')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the vegetable inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 586, "imageId": "n310828", "question": "Is the shirt green?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 587, "imageId": "n256120", "question": "What is in front of the tree leaves?", "program": "BOX0=LOC(image=IMAGE,object='tree leaves')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the tree leaves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 588, "imageId": "n234683", "question": "Do the telephone and the suit have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='telephone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='suit')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the telephone?')\nANSWER1=VQA(image=IMAGE1,question='What color is the suit?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 589, "imageId": "n92308", "question": "Does the sand on the beach look wet and rough?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the sand on the beach look wet?')\nANSWER1=VQA(image=IMAGE0,question='Does the sand on the beach look rough?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 590, "imageId": "n206785", "question": "Is the person pulling a tie?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person pulling a tie?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 591, "imageId": "n92308", "question": "Does the sand that looks wet look smooth or rough?", "program": "BOX0=LOC(image=IMAGE,object='wet sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the wet sand look smooth or rough?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 592, "imageId": "n44249", "question": "Are there any benches in front of the green trees?", "program": "BOX0=LOC(image=IMAGE,object='green trees')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='benches')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 593, "imageId": "n153118", "question": "Which kind of vehicle are the buildings behind of?", "program": "BOX0=LOC(image=IMAGE,object='buildings')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle are the buildings behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 594, "imageId": "n283587", "question": "Are the chairs square and black?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=VQA(image=IMAGE,question='What shape is the chair?')\nANSWER1=VQA(image=IMAGE,question='What color is the chair?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'square' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 595, "imageId": "n83784", "question": "What's inside the flower pot?", "program": "BOX0=LOC(image=IMAGE,object='flower pot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the flower pot?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 596, "imageId": "n283587", "question": "What shape are the tall chairs?", "program": "BOX0=LOC(image=IMAGE,object='tall chairs')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape are the tall chairs?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 597, "imageId": "n83784", "question": "What is located on top of the side table?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=VQA(image=IMAGE0,question='What is located on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 598, "imageId": "n83784", "question": "What's located on top of the side table?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 599, "imageId": "n536256", "question": "Does the Wii remotes look white and small?", "program": "BOX0=LOC(image=IMAGE,object='Wii remotes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the Wii remotes?')\nANSWER1=VQA(image=IMAGE0,question='What size are the Wii remotes?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 600, "imageId": "n352479", "question": "Who is riding?", "program": "BOX0=LOC(image=IMAGE,object='riding')\nANSWER0=VQA(image=IMAGE,question='Who is riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"},{"index": 601, "imageId": "n468864", "question": "Is the black hair long or short?", "program": "BOX0=LOC(image=IMAGE,object='black hair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'long' if {ANSWER0} > 0 else 'short'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 602, "imageId": "n9856", "question": "Is the shape of the log different than the tree?", "program": "BOX0=LOC(image=IMAGE,object='log')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='tree')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is the shape of the log?')\nANSWER1=VQA(image=IMAGE1,question='What is the shape of the tree?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 603, "imageId": "n496803", "question": "Which is bigger, the racket or the wristband?", "program": "ANSWER0=VQA(image=IMAGE,question='Which is bigger, the racket or the wristband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 604, "imageId": "n88933", "question": "What type of furniture is the girl to the left of the hamburger sitting in?", "program": "BOX0=LOC(image=IMAGE,object='hamburger')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of furniture is the girl sitting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 605, "imageId": "n315887", "question": "What's underneath the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 606, "imageId": "n88933", "question": "What is the girl to the left of the plate sitting in?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the girl sitting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 607, "imageId": "n293477", "question": "What is the item of furniture called?", "program": "BOX0=LOC(image=IMAGE,object='item of furniture')\nANSWER0=VQA(image=IMAGE,question='What is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 608, "imageId": "n293477", "question": "Which kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 609, "imageId": "n166008", "question": "What is the man eating?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man eating?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 610, "imageId": "n350732", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 611, "imageId": "n350732", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 612, "imageId": "n449058", "question": "Are the doors open or closed?", "program": "BOX0=LOC(image=IMAGE,object='doors')\nANSWER0=VQA(image=IMAGE,question='Are the doors open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 613, "imageId": "n184385", "question": "Are there pots?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 614, "imageId": "n98544", "question": "On which side of the photo is the small faucet?", "program": "BOX0=LOC(image=IMAGE,object='small faucet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 615, "imageId": "n98544", "question": "Does the tap that is not dirty look small and silver?", "program": "BOX0=LOC(image=IMAGE,object='tap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the tap dirty?')\nANSWER1=VQA(image=IMAGE0,question='What color is the tap?')\nANSWER2=VQA(image=IMAGE0,question='Is the tap small?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} == 'silver' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 616, "imageId": "n315887", "question": "What kind of furniture is underneath the device that looks long?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='long')\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is underneath the device that looks long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 617, "imageId": "n214497", "question": "What's full of the stone?", "program": "BOX0=LOC(image=IMAGE,object='stone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is full of the stone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 618, "imageId": "n415215", "question": "What is the gender of the person near the toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the gender of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 619, "imageId": "n214497", "question": "What's the entrance full of?", "program": "BOX0=LOC(image=IMAGE,object='entrance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's the entrance full of?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 620, "imageId": "n417401", "question": "Does that toilet seat seem to be white and small?", "program": "BOX0=LOC(image=IMAGE,object='toilet seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet seat?')\nANSWER1=VQA(image=IMAGE0,question='Is the toilet seat small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 621, "imageId": "n214497", "question": "Do you see both doors and windows?", "program": "BOX0=LOC(image=IMAGE,object='door')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 622, "imageId": "n475030", "question": "Who is riding?", "program": "BOX0=LOC(image=IMAGE,object='riding')\nANSWER0=VQA(image=IMAGE,question='Who is riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 623, "imageId": "n66756", "question": "Is the batter in front of the catcher?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='batter')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 624, "imageId": "n276011", "question": "What items of furniture are wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='What items of furniture are wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 625, "imageId": "n23181", "question": "Is the fireplace near the couch white and closed?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fireplace')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='white')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='closed')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 626, "imageId": "n393305", "question": "Is the young girl wearing a skirt?", "program": "BOX0=LOC(image=IMAGE,object='young girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the young girl wearing a skirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'skirt' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 627, "imageId": "n393305", "question": "Who is wearing a skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 628, "imageId": "n393305", "question": "Who is wearing the skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 629, "imageId": "n192021", "question": "Is the carpet yellow and soft?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the carpet?')\nANSWER1=VQA(image=IMAGE0,question='Is the carpet soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 630, "imageId": "n398257", "question": "Are there metal chairs or lamps?", "program": "BOX0=LOC(image=IMAGE,object='metal chair')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 631, "imageId": "n234683", "question": "Does the dress shirt seem to be ugly?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the dress shirt seem to be ugly?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 632, "imageId": "n278312", "question": "What are the items of furniture that are to the right of the refrigerator made of stainless steel?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What are the items of furniture made of stainless steel?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 633, "imageId": "n556604", "question": "Does the skatepark look hard and smooth?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the skatepark look hard?')\nANSWER1=VQA(image=IMAGE,question='Does the skatepark look smooth?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 634, "imageId": "n276011", "question": "Is the window clear and high?", "program": "BOX0=LOC(image=IMAGE,object='window')\nANSWER0=VQA(image=IMAGE,question='Is the window clear?')\nANSWER1=VQA(image=IMAGE,question='Is the window high?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 635, "imageId": "n187961", "question": "Is the jacket white and open?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE0,question='Is the jacket open?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 636, "imageId": "n187961", "question": "Does the jacket appear to be red?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 637, "imageId": "n344136", "question": "What color is the round mirror?", "program": "BOX0=LOC(image=IMAGE,object='round mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 638, "imageId": "n432591", "question": "What is the bed made of?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bed made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 639, "imageId": "n508733", "question": "What is the color of the coffee cup which is on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='coffee cup')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the coffee cup?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 640, "imageId": "n347706", "question": "Do the shorts look small and blue?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE0,question='Do the shorts look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 641, "imageId": "n541688", "question": "Who is in front of the table that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is in front of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 642, "imageId": "n541688", "question": "Who is in front of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 643, "imageId": "n125122", "question": "What kind of furniture is to the right of the lamp above the table?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of furniture is to the right of the lamp?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 644, "imageId": "n507959", "question": "What's the purse hanging from?", "program": "BOX0=LOC(image=IMAGE,object='purse')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the purse hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 645, "imageId": "n429961", "question": "Does the container that is not large look white or brown?", "program": "BOX0=LOC(image=IMAGE,object='not large container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the container?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 646, "imageId": "n507959", "question": "What is hanging from the table that is to the left of the guitar?", "program": "BOX0=LOC(image=IMAGE,object='guitar')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is hanging from the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 647, "imageId": "n71728", "question": "How tall is the person that is not old?", "program": "BOX0=LOC(image=IMAGE,object='person who is not old')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How tall is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 648, "imageId": "n302387", "question": "Does the fireplace have white color?", "program": "BOX0=LOC(image=IMAGE,object='fireplace')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the fireplace?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 649, "imageId": "n542609", "question": "Does the train that looks orange and gray look old or new?", "program": "BOX0=LOC(image=IMAGE,object='train')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the train?')\nANSWER1=VQA(image=IMAGE0,question='Does the train look old or new?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 650, "imageId": "n196058", "question": "Is the grass tall or short?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nANSWER0=VQA(image=IMAGE,question='Is the grass tall or short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 651, "imageId": "n196058", "question": "Does the grass below the zebra appear to be green and short?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nANSWER0=VQA(image=IMAGE0,question='What color is the grass?')\nANSWER1=VQA(image=IMAGE0,question='Is the grass short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 652, "imageId": "n240973", "question": "Is there a towel that is gray?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the towel?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 653, "imageId": "n234683", "question": "Is the person in front of the frame healthy and adult?", "program": "BOX0=LOC(image=IMAGE,object='frame')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 654, "imageId": "n342511", "question": "Is the color of the hat the same as the coat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='coat')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the coat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 655, "imageId": "n64959", "question": "Is the bed sheet the same material as the pipe?", "program": "BOX0=LOC(image=IMAGE,object='bed sheet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pipe')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the bed sheet made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the pipe made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 656, "imageId": "n278312", "question": "Which kind of furniture is white?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 657, "imageId": "n234722", "question": "Are there chairs that are not short?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=VQA(image=IMAGE,question='Are there chairs that are not short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 658, "imageId": "n125122", "question": "Are the paintings on the right or on the left side?", "program": "BOX0=LOC(image=IMAGE,object='paintings')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 659, "imageId": "n278312", "question": "What are the cabinets made of?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the cabinets made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 660, "imageId": "n100552", "question": "The elephant is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The elephant is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 661, "imageId": "n532191", "question": "What kind of furniture is the smiling person sitting on?", "program": "BOX0=LOC(image=IMAGE,object='smiling person')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the smiling person sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 662, "imageId": "n14087", "question": "What animal is wearing the hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is wearing the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 663, "imageId": "n309148", "question": "Is the pedestrian to the right of the fire truck female and young?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pedestrian')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='Is the pedestrian female and young?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 664, "imageId": "n9181", "question": "Which side is the mirror on?", "program": "ANSWER0=VQA(image=IMAGE,question='Which side is the mirror on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 665, "imageId": "n313060", "question": "Is the black sweatshirt off or on?", "program": "BOX0=LOC(image=IMAGE,object='black sweatshirt')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'off' if {ANSWER0} == 0 else 'on'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 666, "imageId": "n488874", "question": "What are the trees growing on?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the trees growing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 667, "imageId": "n309148", "question": "Is the pedestrian old or young?", "program": "BOX0=LOC(image=IMAGE,object='pedestrian')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the pedestrian old or young?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 668, "imageId": "n488874", "question": "Are the trees sparse or dense?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'sparse' if {ANSWER0} < 5 else 'dense'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 669, "imageId": "n488874", "question": "What is growing on the dirt the beach is in front of?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dirt')\nANSWER0=VQA(image=IMAGE0,question='What is growing on the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 670, "imageId": "n256120", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 671, "imageId": "n256120", "question": "Does the girl that is to the right of the other girl seem to be walking?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the girl seem to be walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 672, "imageId": "n346736", "question": "Does the bus in front of the trees look red?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 673, "imageId": "n497658", "question": "Is the door white and open?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the door?')\nANSWER1=VQA(image=IMAGE0,question='Is the door open?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 674, "imageId": "n223750", "question": "Are there any umbrellas or folding chairs in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nBOX1=LOC(image=IMAGE,object='folding chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 675, "imageId": "n223750", "question": "Is she wearing a skirt?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is she wearing a skirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'skirt' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 676, "imageId": "n403734", "question": "Is the bottle to the left of the purse?", "program": "BOX0=LOC(image=IMAGE,object='purse')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 677, "imageId": "n363445", "question": "Are there both bowls and carrots in this photo?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nBOX1=LOC(image=IMAGE,object='carrot')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 678, "imageId": "n369595", "question": "What kind of place is pictured, a beach or a park?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nBOX1=LOC(image=IMAGE,object='park')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'beach' if {ANSWER0} > 0 else 'park'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 679, "imageId": "n507959", "question": "Is the luggage that is tan and black sitting in front of a bookcase?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='luggage')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 680, "imageId": "n541854", "question": "What is the fork on?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fork on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 681, "imageId": "n570181", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 682, "imageId": "n86120", "question": "Are these animals of the same species?", "program": "ANSWER0=VQA(image=IMAGE,question='Are these animals of the same species?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 683, "imageId": "n346247", "question": "On which side of the photo is the sculpture?", "program": "ANSWER0=VQA(image=IMAGE,question='On which side of the photo is the sculpture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 684, "imageId": "n346247", "question": "Does the sculpture made of metal look curved?", "program": "BOX0=LOC(image=IMAGE,object='sculpture made of metal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the sculpture look curved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 685, "imageId": "n346247", "question": "Does the sculpture look tall and curved?", "program": "BOX0=LOC(image=IMAGE,object='sculpture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the sculpture look tall?')\nANSWER1=VQA(image=IMAGE0,question='Does the sculpture look curved?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 686, "imageId": "n59627", "question": "Who is on top of the elephant?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is on top of the elephant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 687, "imageId": "n313060", "question": "Does the table that is made of wood look square or round?", "program": "BOX0=LOC(image=IMAGE,object='wood table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the table look square or round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 688, "imageId": "n28572", "question": "Are the white flowers behind the menu?", "program": "BOX0=LOC(image=IMAGE,object='menu')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white flowers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 689, "imageId": "n489699", "question": "Is the parent that is to the right of the other parent male and happy?", "program": "BOX0=LOC(image=IMAGE,object='parent')\nBOX1=LOC(image=IMAGE,object='other parent')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is the gender of the parent?')\nANSWER1=VQA(image=IMAGE0,question='What is the emotion of the parent?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'male' and {ANSWER1} == 'happy' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 690, "imageId": "n192021", "question": "Does the curtain to the left of the other curtain look soft?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtain')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the curtain look soft?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'soft' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 691, "imageId": "n16656", "question": "Is the shirt soft and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the shirt soft?')\nANSWER1=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'soft' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 692, "imageId": "n88366", "question": "Do the mountain side and the pole have the same color?", "program": "BOX0=LOC(image=IMAGE,object='mountain side')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pole')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the mountain side?')\nANSWER1=VQA(image=IMAGE1,question='What color is the pole?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 693, "imageId": "n256120", "question": "Is the flag green?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the flag?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 694, "imageId": "n28572", "question": "What is the fork in front of?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fork in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 695, "imageId": "n433692", "question": "Is the color of the plant different than the mouse?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='mouse')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the plant?')\nANSWER1=VQA(image=IMAGE1,question='What color is the mouse?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 696, "imageId": "n95904", "question": "Is the person wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person wearing a hat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'hat' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 697, "imageId": "n95904", "question": "What is the person near the wall walking on?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person walking on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 698, "imageId": "n95904", "question": "What is the person walking on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person walking on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 699, "imageId": "n347706", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 700, "imageId": "n347706", "question": "Which place is this?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 701, "imageId": "n347706", "question": "Is the young child to the right or to the left of the person that is wearing a shirt?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the young child to the right or to the left of the person that is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 702, "imageId": "n400036", "question": "On which side is the soccer ball?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='soccer ball')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 703, "imageId": "n413761", "question": "Does the car in front of the hill look white and large?", "program": "BOX0=LOC(image=IMAGE,object='hill')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the car?')\nANSWER3=VQA(image=IMAGE0,question='Is the car large?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 704, "imageId": "n369970", "question": "Who is wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 705, "imageId": "n167552", "question": "What is hanging from the large tree?", "program": "BOX0=LOC(image=IMAGE,object='large tree')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the large tree?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 706, "imageId": "n131634", "question": "Is the van blue?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the van?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 707, "imageId": "n498712", "question": "Are there women in front of the person that is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 708, "imageId": "n498712", "question": "Who is the woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 709, "imageId": "n202379", "question": "Is the hat the same color as the uniform?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='uniform')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the uniform?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 710, "imageId": "n77818", "question": "Which kind of device isn't on?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='Which kind of device isn\\'t on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 711, "imageId": "n52544", "question": "Who is wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 712, "imageId": "n498712", "question": "Who is in front of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 713, "imageId": "n326988", "question": "What's located on top of the television?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 714, "imageId": "n217003", "question": "On which side of the picture is the traffic cone?", "program": "ANSWER0=VQA(image=IMAGE,question='On which side of the picture is the traffic cone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 715, "imageId": "n155555", "question": "What is the color of the rocky mountains?", "program": "BOX0=LOC(image=IMAGE,object='rocky mountains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the rocky mountains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 716, "imageId": "n125122", "question": "Does the pillow to the left of the bed seem to be red?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 717, "imageId": "n326988", "question": "What is located on top of the device the man is looking at?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='TOP')\nANSWER0=VQA(image=IMAGE1,question='What is located on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 718, "imageId": "n369970", "question": "Is the snowboarder wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='snowboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the snowboarder wearing a hat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'hat' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 719, "imageId": "n155555", "question": "Are the mountains dark and rocky?", "program": "BOX0=LOC(image=IMAGE,object='mountains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the mountains?')\nANSWER1=VQA(image=IMAGE0,question='What texture do the mountains have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' and {ANSWER1} == 'rocky' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 720, "imageId": "n16425", "question": "Does the shirt look yellow?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 721, "imageId": "n554880", "question": "Who wears the sweater?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the sweater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 722, "imageId": "n554880", "question": "Who wears a sweater?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears a sweater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 723, "imageId": "n554880", "question": "What does the person to the left of the man wear?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='What does the person wear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 724, "imageId": "n546884", "question": "Is the cup on the left side or on the right?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 725, "imageId": "n546616", "question": "In which part is the white marshmallow, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white marshmallow')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 726, "imageId": "n65866", "question": "What's the pipe made of?", "program": "BOX0=LOC(image=IMAGE,object='pipe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pipe made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 727, "imageId": "n432591", "question": "What kind of furniture are the books sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture are the books sitting atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 728, "imageId": "n554880", "question": "What does the woman wear?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the woman wear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 729, "imageId": "n117888", "question": "Which part of the picture is the athlete in, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nBOX1=LOC(image=IMAGE,object='LEFT')\nBOX2=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'left' if {ANSWER1} > 0 else 'right' if {ANSWER2} > 0 else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 730, "imageId": "n92308", "question": "Is this photo showing a park?", "program": "ANSWER0=VQA(image=IMAGE,question='Is this photo showing a park?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 731, "imageId": "n295771", "question": "Are the couch and the sky the same color?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sky')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the couch?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sky?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 732, "imageId": "n295771", "question": "Are both the rose and the couch the same color?", "program": "BOX0=LOC(image=IMAGE,object='rose')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='couch')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the rose?')\nANSWER1=VQA(image=IMAGE1,question='What color is the couch?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 733, "imageId": "n92308", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 734, "imageId": "n350766", "question": "Do you see any towels there?", "program": "BOX0=LOC(image=IMAGE,object='towels')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 735, "imageId": "n151768", "question": "How old is the person in the bottom part of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How old is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 736, "imageId": "n334278", "question": "Is the shirt that is made of cloth black and long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the shirt made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER2=VQA(image=IMAGE0,question='What type of sleeves does the shirt have?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'cloth' and {ANSWER1} == 'black' and {ANSWER2} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 737, "imageId": "n334278", "question": "Is the shirt long sleeved or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Is the shirt long sleeved or short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 738, "imageId": "n187544", "question": "Do the shoes look black and clean?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shoes?')\nANSWER1=VQA(image=IMAGE0,question='Do the shoes look clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 739, "imageId": "n460385", "question": "What color is the chair that the woman is to the right of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 740, "imageId": "n314171", "question": "What color is the picture?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 741, "imageId": "n24526", "question": "Is the umbrella green?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the umbrella?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 742, "imageId": "n145498", "question": "What is he doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is he doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 743, "imageId": "n4777", "question": "What kind of toy is hanging from the stroller?", "program": "BOX0=LOC(image=IMAGE,object='stroller')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toy')\nANSWER0=VQA(image=IMAGE0,question='What kind of toy is hanging from the stroller?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 744, "imageId": "n326988", "question": "Who is playing at the television?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is playing at the television?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 745, "imageId": "n4777", "question": "What is the stuffed dog hanging from?", "program": "BOX0=LOC(image=IMAGE,object='stuffed dog')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the stuffed dog hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 746, "imageId": "n249639", "question": "What is the item of furniture that is below the folded towel near the sink?", "program": "BOX0=LOC(image=IMAGE,object='folded towel')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sink')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 747, "imageId": "n326988", "question": "Which kind of device is the man playing at?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is the man playing at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 748, "imageId": "n315887", "question": "What device is the computer behind of?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is the computer behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 749, "imageId": "n146555", "question": "Is the bottle made of the same material as the motorcycle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='motorcycle')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the bottle made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the motorcycle made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 750, "imageId": "n546616", "question": "Is the white cake short or tall?", "program": "BOX0=LOC(image=IMAGE,object='white cake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the cake short or tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"},{"index": 1001, "imageId": "n95313", "question": "What is in front of the bookshelf?", "program": "BOX0=LOC(image=IMAGE,object='bookshelf')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the bookshelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1002, "imageId": "n229548", "question": "How heavy is the helicopter?", "program": "ANSWER0=VQA(image=IMAGE,question='How heavy is the helicopter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1003, "imageId": "n229548", "question": "What is carrying the ship?", "program": "BOX0=LOC(image=IMAGE,object='ship')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is carrying the ship?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1004, "imageId": "n154856", "question": "What color is the lamp to the right of the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=VQA(image=IMAGE0,question='What color is the lamp?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1005, "imageId": "n315859", "question": "How wide are the skis on the bottom of the plane?", "program": "BOX0=LOC(image=IMAGE,object='plane')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skis')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How wide are the skis on the bottom of the plane?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1006, "imageId": "n54180", "question": "Is the toilet paper on the right side of the image?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet paper')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1007, "imageId": "n117888", "question": "Does the sand look shallow?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the sand look shallow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1008, "imageId": "n280089", "question": "On which side of the image are the metal utensils?", "program": "BOX0=LOC(image=IMAGE,object='metal utensils')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1009, "imageId": "n166008", "question": "On which side of the picture is the water bottle, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='water bottle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1010, "imageId": "n314171", "question": "What drink is in the appliance that is using seasonings?", "program": "BOX0=LOC(image=IMAGE,object='seasonings')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What drink is in the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1011, "imageId": "n314630", "question": "Does the container that is to the right of the paper towel look small and orange?", "program": "BOX0=LOC(image=IMAGE,object='paper towel')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='container')\nANSWER0=VQA(image=IMAGE0,question='What color is the container?')\nANSWER1=VQA(image=IMAGE0,question='Is the container small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1012, "imageId": "n314171", "question": "What do you think is the alcohol in?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is the alcohol in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1013, "imageId": "n437064", "question": "Is the color of the bowl the same as the table?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bowl?')\nANSWER1=VQA(image=IMAGE1,question='What color is the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1014, "imageId": "n88933", "question": "What is the blue item of furniture in the picture?", "program": "BOX0=LOC(image=IMAGE,object='blue')\nBOX1=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the blue item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1015, "imageId": "n16378", "question": "What's in front of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1016, "imageId": "n282436", "question": "How large is the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How large is the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1017, "imageId": "n262920", "question": "Which room is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which room is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1018, "imageId": "n100991", "question": "What kind of food is to the left of the white egg?", "program": "BOX0=LOC(image=IMAGE,object='white egg')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of food is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1019, "imageId": "n39114", "question": "Are there both hats and boys in the picture?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nBOX1=LOC(image=IMAGE,object='boy')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1020, "imageId": "n259002", "question": "Is the black car to the right of the person that is watching the soccer player?", "program": "BOX0=LOC(image=IMAGE,object='person watching soccer player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black car')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1021, "imageId": "n159802", "question": "What item of clothing is long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved')\nANSWER0=VQA(image=IMAGE,question='What item of clothing is long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1022, "imageId": "n159802", "question": "Which kind of clothing is soft?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1023, "imageId": "n159802", "question": "What type of clothing in this picture is soft?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nANSWER0=VQA(image=IMAGE,question='What type of clothing is soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1024, "imageId": "n262929", "question": "Are there any large gloves or hats?", "program": "BOX0=LOC(image=IMAGE,object='large gloves')\nBOX1=LOC(image=IMAGE,object='large hats')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1025, "imageId": "n554880", "question": "What device is to the right of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the right of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1026, "imageId": "n311910", "question": "Are there cars or buses?", "program": "BOX0=LOC(image=IMAGE,object='car')\nBOX1=LOC(image=IMAGE,object='bus')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1027, "imageId": "n411121", "question": "Is the male person carrying a snowboard?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the male person carrying a snowboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1028, "imageId": "n481777", "question": "Are both the sky and the mountain side the same color?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='mountain side')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE1,question='What color is the mountain side?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1029, "imageId": "n206785", "question": "What's the person getting on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's the person getting on?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1030, "imageId": "n305495", "question": "Which kind of clothing is dark?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is dark?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1031, "imageId": "n411121", "question": "What does the male person ride on?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the male person ride on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1032, "imageId": "n59147", "question": "Which kind of furniture in the photo is not small?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is not small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1033, "imageId": "n206785", "question": "What is the person wearing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1034, "imageId": "n206785", "question": "The person is wearing what?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The person is wearing what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1035, "imageId": "n206785", "question": "Is this a white cabinet?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the cabinet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1036, "imageId": "n54180", "question": "What material is the cup above the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cup')\nANSWER0=VQA(image=IMAGE0,question='What material is the cup?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1037, "imageId": "n54180", "question": "What is the cup made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the cup made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1038, "imageId": "n66756", "question": "How clean is the large field?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the large field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1039, "imageId": "n532191", "question": "Are there any TVs or laptops in the image?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nBOX1=LOC(image=IMAGE,object='laptop')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1040, "imageId": "n16378", "question": "Is the large bag on the left side or on the right?", "program": "BOX0=LOC(image=IMAGE,object='large bag')\nBOX1=LOC(image=IMAGE,object='LEFT')\nBOX2=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'left' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'right' if {ANSWER0} > 0 and {ANSWER2} > 0 else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1041, "imageId": "n111390", "question": "Is the dessert on the table white or blue?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nANSWER0=VQA(image=IMAGE0,question='What color is the dessert?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1042, "imageId": "n309148", "question": "Is the material of the building the same as the grill?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='grill')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the building made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the grill made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1043, "imageId": "n386688", "question": "How large is the sailboat below the airplane?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sailboat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the sailboat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1044, "imageId": "n393305", "question": "Is the tee shirt open and black?", "program": "BOX0=LOC(image=IMAGE,object='tee shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the tee shirt open?')\nANSWER1=VQA(image=IMAGE0,question='What color is the tee shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'open' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1045, "imageId": "n468864", "question": "Does the hair seem to be black or blond?", "program": "BOX0=LOC(image=IMAGE,object='hair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hair?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'blond'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1046, "imageId": "n398257", "question": "The book is on what?", "program": "BOX0=LOC(image=IMAGE,object='book')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The book is on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1047, "imageId": "n143672", "question": "What is the skier to the right of the other skier doing?", "program": "BOX0=LOC(image=IMAGE,object='skier')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other skier')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the skier doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1048, "imageId": "n293477", "question": "Is the wallet lying on top of a desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wallet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1049, "imageId": "n143672", "question": "Who in the image is looking down?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1050, "imageId": "n159802", "question": "Is the color of the sweatshirt different than the water bottle?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='water bottle')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the sweatshirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the water bottle?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1051, "imageId": "n79078", "question": "Is the crosswalk different in color than the stop sign?", "program": "BOX0=LOC(image=IMAGE,object='crosswalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='stop sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the crosswalk?')\nANSWER1=VQA(image=IMAGE1,question='What color is the stop sign?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1052, "imageId": "n381072", "question": "What is located on top of the table that is not narrow?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not narrow')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1053, "imageId": "n140421", "question": "Does the refrigerator look tall?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nANSWER0=VQA(image=IMAGE,question='Does the refrigerator look tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1054, "imageId": "n350732", "question": "Who is wearing sandals?", "program": "BOX0=LOC(image=IMAGE,object='sandals')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing sandals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1055, "imageId": "n233607", "question": "What is perched on the table the rug is beneath of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is perched on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1056, "imageId": "n23762", "question": "Is the mug to the left of the vase white and small?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vase')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE,box=BOX0)\nANSWER2=VQA(image=IMAGE1,question='What color is the mug?')\nANSWER3=VQA(image=IMAGE1,question='What size is the mug?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1057, "imageId": "n240666", "question": "Is the mirror made of metal?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the mirror made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'metal' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1058, "imageId": "n534106", "question": "Is that floor blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the floor?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1059, "imageId": "n544255", "question": "Are there any airplanes above the brown ground?", "program": "BOX0=LOC(image=IMAGE,object='brown ground')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='airplane')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1060, "imageId": "n545516", "question": "Is the man wearing a tie?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man wearing a tie?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'tie' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1061, "imageId": "n544255", "question": "What animal is above the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is above the ground?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1062, "imageId": "n545516", "question": "Is the heavy person below an airplane?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='heavy person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1063, "imageId": "n192021", "question": "Is the fan wooden and brown?", "program": "BOX0=LOC(image=IMAGE,object='fan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the fan made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the fan?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1064, "imageId": "n262920", "question": "Does the window look round and long?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the window look round?')\nANSWER1=VQA(image=IMAGE0,question='Does the window look long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1065, "imageId": "n204894", "question": "Do you think the window is open or closed?", "program": "BOX0=LOC(image=IMAGE,object='window')\nANSWER0=VQA(image=IMAGE,question='Do you think the window is open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1066, "imageId": "n55058", "question": "What cooking utensil is red?", "program": "BOX0=LOC(image=IMAGE,object='red')\nBOX1=LOC(image=IMAGE,object='cooking utensil')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1067, "imageId": "n55058", "question": "What kind of cooking utensil is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of cooking utensil is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1068, "imageId": "n357126", "question": "Is the small building in front or behind the vehicle the window is wrapped around?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP_AROUND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='small building')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'front' if {ANSWER0} > 0 else 'behind'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1069, "imageId": "n520071", "question": "How clean is the radio?", "program": "BOX0=LOC(image=IMAGE,object='radio')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the radio?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1070, "imageId": "n477702", "question": "Who in this scene is playing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who in this scene is playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1071, "imageId": "n240666", "question": "How big is the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1072, "imageId": "n48494", "question": "Is there a train or a fence in the image?", "program": "BOX0=LOC(image=IMAGE,object='train')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1073, "imageId": "n511881", "question": "What animal is grazing on grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is grazing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1074, "imageId": "n579928", "question": "On which side is the large vehicle?", "program": "BOX0=LOC(image=IMAGE,object='large vehicle')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1075, "imageId": "n250715", "question": "Which type of material is used to make the chair?", "program": "ANSWER0=VQA(image=IMAGE,question='Which type of material is used to make the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1076, "imageId": "n302387", "question": "How hard is the instrument next to the fire place?", "program": "BOX0=LOC(image=IMAGE,object='fire place')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How hard is the instrument?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1077, "imageId": "n250715", "question": "Are there either tables or chairs that are not metallic?", "program": "BOX0=LOC(image=IMAGE,object='table')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1078, "imageId": "n64959", "question": "Does the pipe have a different color than the fridge?", "program": "BOX0=LOC(image=IMAGE,object='pipe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fridge')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the pipe?')\nANSWER1=VQA(image=IMAGE1,question='What color is the fridge?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1079, "imageId": "n263180", "question": "Of which color are the clouds above the apartment building?", "program": "BOX0=LOC(image=IMAGE,object='apartment building')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clouds')\nANSWER0=VQA(image=IMAGE0,question='Of which color are the clouds?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1080, "imageId": "n386682", "question": "What is under the cabinets?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the cabinets?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1081, "imageId": "n578564", "question": "Is the picture white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the picture?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1082, "imageId": "n69237", "question": "Are there any coffee tables or beds that are not low?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nBOX1=LOC(image=IMAGE,object='bed')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1083, "imageId": "n240973", "question": "What is the gray towel sitting on?", "program": "BOX0=LOC(image=IMAGE,object='gray towel')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the gray towel sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1084, "imageId": "n240973", "question": "What is sitting on the shelves?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on the shelves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1085, "imageId": "n296467", "question": "Which kind of vegetable is to the right of the carrots?", "program": "BOX0=LOC(image=IMAGE,object='carrots')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of vegetable is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1086, "imageId": "n222915", "question": "Which color is the mat, red or blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the mat, red or blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1087, "imageId": "n293477", "question": "What is the color of the pens that are lying on top of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pens')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the pens?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1088, "imageId": "n35676", "question": "Is the floor tan and dirty?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the floor?')\nANSWER1=VQA(image=IMAGE0,question='Is the floor dirty?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'tan' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1089, "imageId": "n488874", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1090, "imageId": "n309148", "question": "What type of vehicle do you think is the pedestrian behind of?", "program": "BOX0=LOC(image=IMAGE,object='pedestrian')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of vehicle is behind the pedestrian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1091, "imageId": "n346736", "question": "Do you see a bus in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1092, "imageId": "n525029", "question": "Above what are the wires hanging?", "program": "BOX0=LOC(image=IMAGE,object='wires')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Above what are the wires hanging?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1093, "imageId": "n488874", "question": "What is in front of the dirt?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1094, "imageId": "n488874", "question": "Is this a farm or a beach?", "program": "ANSWER0=VQA(image=IMAGE,question='Is this a farm or a beach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1095, "imageId": "n282607", "question": "What is the man playing with?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man playing with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1096, "imageId": "n278312", "question": "What appliance is to the right of the refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is to the right of the refrigerator?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1097, "imageId": "n578564", "question": "In which part is the pan?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In which part is the pan?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1098, "imageId": "n497658", "question": "Are the glass windows large or small?", "program": "BOX0=LOC(image=IMAGE,object='glass windows')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'large' if {ANSWER0} > 0 else 'small'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1099, "imageId": "n346247", "question": "Is the window near the sign closed or open?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='sign')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'closed' if {ANSWER0} > 0 else 'open'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1100, "imageId": "n386682", "question": "What is the shape of the appliance that is beneath the microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the shape of the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1101, "imageId": "n28572", "question": "Are there either red tables or chairs?", "program": "BOX0=LOC(image=IMAGE,object='red table')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1102, "imageId": "n250715", "question": "Which kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1103, "imageId": "n546884", "question": "Is the table square and granite?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the table?')\nANSWER1=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'square' and {ANSWER1} == 'granite' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1104, "imageId": "n250715", "question": "Are there tables in this image?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1105, "imageId": "n296467", "question": "What are the sprinkles sprinkled on?", "program": "BOX0=LOC(image=IMAGE,object='sprinkles')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the sprinkles sprinkled on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1106, "imageId": "n59627", "question": "Does the man next to the other man look short and young?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other man')\nANSWER0=VQA(image=IMAGE0,question='Does the man look short and young?')\nANSWER1=VQA(image=IMAGE0,question='Does the other man look short and young?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1107, "imageId": "n570181", "question": "Is the male person behind the catcher wearing a face mask?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='male person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the person wearing a face mask?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1108, "imageId": "n235859", "question": "What drink is the large glass filled with?", "program": "BOX0=LOC(image=IMAGE,object='large glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What drink is the large glass filled with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1109, "imageId": "n344136", "question": "Which kind of furniture is not wooden?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is not wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1110, "imageId": "n344136", "question": "Is the bookcase on the right side?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1111, "imageId": "n90294", "question": "Is the laptop near the charger modern and black?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='charger')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='laptop')\nIMAGE1=CROP(image=IMAGE0,box=BOX2)\nANSWER2=VQA(image=IMAGE1,question='What color is the laptop?')\nANSWER3=VQA(image=IMAGE1,question='Is the laptop modern?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'black' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1112, "imageId": "n235859", "question": "What is filled with wine?", "program": "BOX0=LOC(image=IMAGE,object='wine')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is filled with wine?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1113, "imageId": "n235859", "question": "What is filled with the wine?", "program": "BOX0=LOC(image=IMAGE,object='wine')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is filled with the wine?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1114, "imageId": "n131634", "question": "How hard is the sidewalk?", "program": "ANSWER0=VQA(image=IMAGE,question='How hard is the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1115, "imageId": "n16656", "question": "Does the sky look orange and bright?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE0,question='Does the sky look bright?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1116, "imageId": "n346736", "question": "Is this a train or a bus?", "program": "BOX0=LOC(image=IMAGE,object='train')\nBOX1=LOC(image=IMAGE,object='bus')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'train' if {ANSWER0} > 0 else 'bus'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1117, "imageId": "n538039", "question": "What is common to the truck and the frisbee?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the truck and the frisbee?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1118, "imageId": "n160664", "question": "Is the animal near the man both black and long?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='black')\nANSWER2=COUNT(box=BOX2)\nBOX3=LOC(image=IMAGE0,object='long')\nANSWER3=COUNT(box=BOX3)\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} > 0 and {ANSWER3} > 0 else 'no'\")\nANSWER5=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER4} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 1119, "imageId": "n288870", "question": "On which side of the picture is the young person?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1120, "imageId": "n318370", "question": "Does the bottle near the drink look white and closed?", "program": "BOX0=LOC(image=IMAGE,object='drink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='white')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='closed')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 1121, "imageId": "n501609", "question": "Are there white dishwashers or ovens?", "program": "BOX0=LOC(image=IMAGE,object='dishwasher')\nBOX1=LOC(image=IMAGE,object='oven')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1122, "imageId": "n498140", "question": "How clean is the chimney?", "program": "BOX0=LOC(image=IMAGE,object='chimney')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the chimney?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1123, "imageId": "n207708", "question": "What kind of furniture is in front of the door?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is in front of the door?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1124, "imageId": "n207708", "question": "What is that table in front of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is that table in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1125, "imageId": "n62458", "question": "What is on the motorbike that is shown in this photo?", "program": "BOX0=LOC(image=IMAGE,object='motorbike')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the motorbike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1126, "imageId": "n324644", "question": "What are the traffic lights hanging from?", "program": "BOX0=LOC(image=IMAGE,object='traffic lights')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the traffic lights hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1127, "imageId": "n324644", "question": "What is hanging from the cables?", "program": "BOX0=LOC(image=IMAGE,object='cables')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the cables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1128, "imageId": "n324644", "question": "What is hanging above the sign that looks white and red?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white and red')\nANSWER0=VQA(image=IMAGE0,question='What is hanging above the sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1129, "imageId": "n324644", "question": "Are the traffic lights hanging from the cables?", "program": "BOX0=LOC(image=IMAGE,object='traffic lights')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cables')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1130, "imageId": "n400036", "question": "Do you see both mattresses and soccer balls there?", "program": "BOX0=LOC(image=IMAGE,object='mattresses')\nBOX1=LOC(image=IMAGE,object='soccer balls')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1131, "imageId": "n355339", "question": "What is the person to the right of the chair watching?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1132, "imageId": "n260521", "question": "What is standing on the stage?", "program": "BOX0=LOC(image=IMAGE,object='stage')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing on the stage?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1133, "imageId": "n324644", "question": "What do you think are the traffic lights that look black and white hanging above?", "program": "BOX0=LOC(image=IMAGE,object='traffic lights')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think are the traffic lights that look black and white hanging above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1134, "imageId": "n527290", "question": "Is the chair to the left or to the right of the device that is on top of the shelves?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_TOP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='chair')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1135, "imageId": "n314171", "question": "Is there a white flag or balloon?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nBOX1=LOC(image=IMAGE,object='balloon')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1136, "imageId": "n100552", "question": "What animal is inside the zoo?", "program": "BOX0=LOC(image=IMAGE,object='zoo')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is inside the zoo?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1137, "imageId": "n513429", "question": "Are there any keyboards near the laptop on the desk?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='desk')\nIMAGE1=CROP_NEAR(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='keyboard')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1138, "imageId": "n52544", "question": "Where is the woman standing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=VQA(image=IMAGE,question='Where is the woman standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1139, "imageId": "n77818", "question": "Does the cat that is to the right of the towels look black or white?", "program": "BOX0=LOC(image=IMAGE,object='towels')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the cat?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1140, "imageId": "n52544", "question": "What kind of furniture is the woman standing at?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the woman standing at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1141, "imageId": "n513429", "question": "What device is to the right of the bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the right of the bowl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1142, "imageId": "n64959", "question": "Is the black stove to the left or to the right of the kitchen faucet?", "program": "BOX0=LOC(image=IMAGE,object='kitchen faucet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black stove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1143, "imageId": "n64959", "question": "Is the stove to the right of a cabinet?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1144, "imageId": "n572716", "question": "Is there a traffic light above the sign near the runway?", "program": "BOX0=LOC(image=IMAGE,object='runway')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='traffic light')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1145, "imageId": "n70461", "question": "Is the road black or white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the road?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1146, "imageId": "n4777", "question": "Is the chair that is to the right of the bag brown or blue?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'brown' if {ANSWER0} == 'brown' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1147, "imageId": "n406334", "question": "How clean is that street?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is that street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1148, "imageId": "n172618", "question": "Are there any airplanes above the grass in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='airplane')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1149, "imageId": "n4777", "question": "Is the chair to the right of the stuffed dog both hard and brown?", "program": "BOX0=LOC(image=IMAGE,object='stuffed dog')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER3=VQA(image=IMAGE0,question='What texture is the chair?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'brown' and {ANSWER3} == 'hard' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1150, "imageId": "n146555", "question": "Which kind of animal is to the left of the bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1151, "imageId": "n167552", "question": "Which kind of animal is playing?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1152, "imageId": "n546884", "question": "On which side of the picture is the white cream?", "program": "BOX0=LOC(image=IMAGE,object='white cream')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1153, "imageId": "n435808", "question": "What kind of furniture is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1154, "imageId": "n65866", "question": "What's located on top of the cabinet?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the cabinet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1155, "imageId": "n525029", "question": "What kind of vehicle is to the right of the houses?", "program": "BOX0=LOC(image=IMAGE,object='houses')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1156, "imageId": "n117888", "question": "Is the grass that is green and light brown short or tall?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the grass?')\nANSWER1=EVAL(expr=\"'short' if {ANSWER0} == 'green' or {ANSWER0} == 'light brown' else 'tall'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1157, "imageId": "n296467", "question": "Which shape is the container?", "program": "BOX0=LOC(image=IMAGE,object='container')\nANSWER0=VQA(image=IMAGE,question='Which shape is the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1158, "imageId": "n95313", "question": "What piece of furniture is not covered?", "program": "BOX0=LOC(image=IMAGE,object='covered')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is not covered?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1159, "imageId": "n140421", "question": "Is the glass table to the left of the fridge both round and small?", "program": "BOX0=LOC(image=IMAGE,object='fridge')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What shape is the glass table?')\nANSWER3=VQA(image=IMAGE0,question='What size is the glass table?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'round' and {ANSWER3} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1160, "imageId": "n65202", "question": "Who is wearing the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1161, "imageId": "n170941", "question": "Is there any bacon to the right of the pancake that is on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pancake')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='bacon')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1162, "imageId": "n170941", "question": "What meat is to the right of the pancake?", "program": "BOX0=LOC(image=IMAGE,object='pancake')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='meat')\nANSWER0=VQA(image=IMAGE0,question='What meat is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1163, "imageId": "n140421", "question": "Do you see a large mirror or table?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1164, "imageId": "n216553", "question": "Is the horse behind the man standing against a fence?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horse')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='fence')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1165, "imageId": "n406334", "question": "Are there any people next to the vehicle that is yellow and black?", "program": "BOX0=LOC(image=IMAGE,object='vehicle',color='yellow and black')\nBOX1=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nIMAGE1=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=COUNT(box=BOX1,image=IMAGE0)\nANSWER1=COUNT(box=BOX1,image=IMAGE1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1166, "imageId": "n485969", "question": "What are the clean clothing items?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the clean clothing items?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1167, "imageId": "n46510", "question": "Is the tall tree on the right?", "program": "BOX0=LOC(image=IMAGE,object='tall tree')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1168, "imageId": "n314171", "question": "Are there any small women or men?", "program": "BOX0=LOC(image=IMAGE,object='small women')\nBOX1=LOC(image=IMAGE,object='small men')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1169, "imageId": "n35676", "question": "Is the countertop above a refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='countertop')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1170, "imageId": "n363445", "question": "What is the fork inside of?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_INSIDE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fork inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1171, "imageId": "n157375", "question": "Is the plane above the vehicle in the bottom part?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='plane')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1172, "imageId": "n146555", "question": "Are there any buses or cars?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nBOX1=LOC(image=IMAGE,object='car')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1173, "imageId": "n249639", "question": "Is the table large and metallic?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='Is the table large?')\nANSWER1=VQA(image=IMAGE,question='Is the table metallic?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1174, "imageId": "n181355", "question": "Which material makes up the pillow, cloth or leather?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which material makes up the pillow, cloth or leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1175, "imageId": "n37274", "question": "Which side is the blender on?", "program": "BOX0=LOC(image=IMAGE,object='blender')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1176, "imageId": "n37274", "question": "What is the appliance to the right of the man that is in front of the bicycle?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bicycle')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1177, "imageId": "n363445", "question": "What is inside the container that is made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='plastic container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1178, "imageId": "n579256", "question": "Who is holding the white food inside the fridge?", "program": "BOX0=LOC(image=IMAGE,object='fridge')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is holding the white food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1179, "imageId": "n579256", "question": "What is the person that is to the left of the bottle holding?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1180, "imageId": "n579256", "question": "What is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1181, "imageId": "n579256", "question": "What is the food that the woman that is not short is holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not short')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1182, "imageId": "n579256", "question": "What kind of food is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of food is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1183, "imageId": "n71728", "question": "What item of furniture is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1184, "imageId": "n159284", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1185, "imageId": "n71728", "question": "What item of furniture is oblong?", "program": "BOX0=LOC(image=IMAGE,object='oblong')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is oblong?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1186, "imageId": "n398429", "question": "Is there any white bed or table in this picture?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1187, "imageId": "n51002", "question": "Does that fireplace appear to be on?", "program": "BOX0=LOC(image=IMAGE,object='fireplace')\nANSWER0=VQA(image=IMAGE,question='Does that fireplace appear to be on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1188, "imageId": "n344136", "question": "Are there either couches or TVs?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nBOX1=LOC(image=IMAGE,object='TV')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1189, "imageId": "n275148", "question": "What type of furniture is to the right of the TV stand the television is on top of?", "program": "BOX0=LOC(image=IMAGE,object='TV stand')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='television')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nANSWER0=VQA(image=IMAGE1,question='What type of furniture is to the right of the television?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1190, "imageId": "n279173", "question": "On which side of the image is the male person?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='male person')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1191, "imageId": "n513100", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1192, "imageId": "n16425", "question": "Is the person who is to the left of the other person male or female?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the person male or female?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1193, "imageId": "n200692", "question": "What is the color of the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1194, "imageId": "n357784", "question": "What kind of animal is to the left of the bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1195, "imageId": "n167164", "question": "Is the SUV in front of the truck large and green?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='SUV')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='SUV')\nIMAGE1=CROP(image=IMAGE0,box=BOX2)\nANSWER2=VQA(image=IMAGE1,question='What color is the SUV?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'green' else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1196, "imageId": "n556604", "question": "Are there men to the right of the woman that is holding the camera?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='camera')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='man')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1197, "imageId": "n37274", "question": "Is the man that is to the left of the liquor wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='liquor')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='Is the man wearing gloves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1198, "imageId": "n249639", "question": "Do you see either any mirrors or benches?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nBOX1=LOC(image=IMAGE,object='bench')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1199, "imageId": "n216553", "question": "Is the brown animal to the right or to the left of the young man?", "program": "BOX0=LOC(image=IMAGE,object='young man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown animal')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1200, "imageId": "n429961", "question": "Which size is the box that is to the right of the eggplant, small or large?", "program": "BOX0=LOC(image=IMAGE,object='eggplant')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='box')\nANSWER0=VQA(image=IMAGE0,question='Which size is the box?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1201, "imageId": "n501609", "question": "Is the microwave silver and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the microwave?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the microwave?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1202, "imageId": "n335542", "question": "How big are the rocks?", "program": "BOX0=LOC(image=IMAGE,object='rocks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big are the rocks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1203, "imageId": "n335542", "question": "Are there either any salt shakers or crowns in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='salt shaker')\nBOX1=LOC(image=IMAGE,object='crown')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1204, "imageId": "n159802", "question": "Do you think this girl is brunette?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the girl\\'s hair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brunette' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1205, "imageId": "n317260", "question": "How long do you think are the bleachers?", "program": "ANSWER0=VQA(image=IMAGE,question='How long are the bleachers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1206, "imageId": "n369970", "question": "Does the wet ground look rocky?", "program": "BOX0=LOC(image=IMAGE,object='wet ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the wet ground look like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'rocky' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1207, "imageId": "n477215", "question": "Which kind of animal is small?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1208, "imageId": "n532213", "question": "What place is pictured?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is pictured?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1209, "imageId": "n154856", "question": "On which side of the photo is the dark vehicle, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='dark vehicle')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1210, "imageId": "n317260", "question": "Are the bleachers that are not long made of wood?", "program": "BOX0=LOC(image=IMAGE,object='bleachers')\nBOX1=LOC(image=IMAGE,object='long')\nBOX2=LOC(image=IMAGE,object='wood')\nBOX3=DIFF(box1=BOX0,box2=BOX1)\nANSWER0=COUNT(box=BOX3)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1211, "imageId": "n200225", "question": "Is the cooked sausage on the right or on the left side?", "program": "BOX0=LOC(image=IMAGE,object='cooked sausage')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1212, "imageId": "n451187", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='sitting')\nANSWER0=VQA(image=IMAGE,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1213, "imageId": "n334278", "question": "Who is wearing a belt?", "program": "BOX0=LOC(image=IMAGE,object='belt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a belt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1214, "imageId": "n526228", "question": "Is the coffee table large or small?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the coffee table large or small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1215, "imageId": "n451187", "question": "Is the woman on the right side or on the left of the image?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=EVAL(expr=\"'right' if {BOX0.x} > IMAGE.width/2 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1216, "imageId": "n195249", "question": "What color is the field?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1217, "imageId": "n164272", "question": "Do you see a goat above the flowers?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='goat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1218, "imageId": "n274905", "question": "Which side of the image is the man on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1219, "imageId": "n164272", "question": "Is the black and white cow black and white and large?", "program": "BOX0=LOC(image=IMAGE,object='black and white cow')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX1=LOC(image=IMAGE,object='large')\nANSWER2=COUNT(box=BOX1)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1220, "imageId": "n259002", "question": "How tall is the grass?", "program": "ANSWER0=VQA(image=IMAGE,question='How tall is the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1221, "imageId": "n141939", "question": "Does the soap seem to be white and large?", "program": "BOX0=LOC(image=IMAGE,object='soap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the soap?')\nANSWER1=VQA(image=IMAGE0,question='Is the soap large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1222, "imageId": "n164272", "question": "Is the cow above the flowers black and white or colorful?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cow')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'black and white' if {ANSWER0} > 0 else 'colorful'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1223, "imageId": "n278453", "question": "Are there any spoons or plates in this photo?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nBOX1=LOC(image=IMAGE,object='plate')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1224, "imageId": "n545516", "question": "Which kind of device is above the pavement?", "program": "BOX0=LOC(image=IMAGE,object='pavement')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is above the pavement?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1225, "imageId": "n520071", "question": "Are there beds near the bookcase?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1226, "imageId": "n143672", "question": "Is the backpack large and black?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the backpack?')\nANSWER1=VQA(image=IMAGE0,question='What color is the backpack?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1227, "imageId": "n520071", "question": "Is the metal lamp to the right or to the left of the books that are to the right of the radio?", "program": "BOX0=LOC(image=IMAGE,object='radio')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='metal lamp')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1228, "imageId": "n312206", "question": "In which part of the photo is the Caucasian person, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='Caucasian person')\nBOX1=LOC(image=IMAGE,object='TOP')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1229, "imageId": "n311910", "question": "Which kind of vehicle is on top of the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1230, "imageId": "n148872", "question": "Who is holding the racket?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1231, "imageId": "n309148", "question": "Is the person on the right side?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1232, "imageId": "n355567", "question": "Which material is the clock that is to the left of the tennis ball made of, stainless steel or brick?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clock')\nANSWER0=VQA(image=IMAGE0,question='Which material is the clock made of?')\nANSWER1=EVAL(expr=\"'stainless steel' if {ANSWER0} == 'stainless steel' else 'brick'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1233, "imageId": "n433532", "question": "Does the pot look small and green?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the pot?')\nANSWER1=VQA(image=IMAGE0,question='Does the pot look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1234, "imageId": "n49438", "question": "Does the bed near the dresser look thick?", "program": "BOX0=LOC(image=IMAGE,object='dresser')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1235, "imageId": "n118102", "question": "Who is looking at the dessert that is on top of the tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is looking at the dessert?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1236, "imageId": "n23762", "question": "Are the vase and the chair made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='chair')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the vase made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the chair made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1237, "imageId": "n234722", "question": "Is the chair that looks dark brown long and curved?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=VQA(image=IMAGE0,question='Is the chair long?')\nANSWER2=VQA(image=IMAGE0,question='Is the chair curved?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'dark brown' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1238, "imageId": "n525901", "question": "How big is the open book?", "program": "BOX0=LOC(image=IMAGE,object='open book')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the open book?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1239, "imageId": "n44249", "question": "Does the sitting-down child that is to the right of the woman look young?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sitting-down child')\nANSWER0=VQA(image=IMAGE0,question='Does the child look young?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1240, "imageId": "n410476", "question": "Does the giraffe look wide?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the giraffe look wide?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1241, "imageId": "n171169", "question": "Which kind of animal is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1242, "imageId": "n544255", "question": "What is worn on the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is worn on the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1243, "imageId": "n527589", "question": "Is the woman above the bananas on top of the basket?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bananas')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='woman')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1244, "imageId": "n264887", "question": "How big is the desk made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the desk made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1245, "imageId": "n184551", "question": "What color are the long pants?", "program": "BOX0=LOC(image=IMAGE,object='long pants')\nANSWER0=VQA(image=IMAGE,question='What color are the long pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1246, "imageId": "n386688", "question": "Does the sky have a different color than the ocean?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='ocean')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE1,question='What color is the ocean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1247, "imageId": "n334278", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1248, "imageId": "n386688", "question": "Is it indoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it indoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1249, "imageId": "n211324", "question": "Where is the traffic sign?", "program": "BOX0=LOC(image=IMAGE,object='traffic sign')\nANSWER0=VQA(image=IMAGE,question='Where is the traffic sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1250, "imageId": "n315859", "question": "Are both the windows and the skis made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='windows')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='skis')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material are the windows made of?')\nANSWER1=VQA(image=IMAGE1,question='What material are the skis made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1251, "imageId": "n315859", "question": "Are both the words and the trees the same color?", "program": "BOX0=LOC(image=IMAGE,object='words')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='trees')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the words?')\nANSWER1=VQA(image=IMAGE1,question='What color are the trees?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1252, "imageId": "n199097", "question": "Do the trousers look long and purple?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the trousers?')\nANSWER1=VQA(image=IMAGE0,question='Do the trousers look long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'purple' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1253, "imageId": "n315859", "question": "Is the pier made of the same material as the airplane?", "program": "BOX0=LOC(image=IMAGE,object='pier')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='airplane')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the pier made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the airplane made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1254, "imageId": "n199097", "question": "How long are the trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nANSWER0=LENGTH(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1255, "imageId": "n380113", "question": "What do both the soccer ball and the headband have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the soccer ball and the headband have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1256, "imageId": "n171169", "question": "What is on the fence that is made of wire?", "program": "BOX0=LOC(image=IMAGE,object='wire fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1257, "imageId": "n319845", "question": "What is the table behind the person made of?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=VQA(image=IMAGE0,question='What is the table made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1258, "imageId": "n200225", "question": "What vegetable is on the pizza?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What vegetable is on the pizza?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1259, "imageId": "n429883", "question": "On which side of the image are the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1260, "imageId": "n541482", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1261, "imageId": "n49438", "question": "What kind of furniture is the boy sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the boy sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1262, "imageId": "n49438", "question": "What's the boy sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the boy sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1263, "imageId": "n49438", "question": "What is the piece of furniture that the young boy is sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='young boy')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1264, "imageId": "n541482", "question": "Who is standing in front of the building that looks large?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing in front of the building that looks large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1265, "imageId": "n94074", "question": "Are there any women to the left of the man that is wearing a necktie?", "program": "BOX0=LOC(image=IMAGE,object='man wearing necktie')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1266, "imageId": "n181355", "question": "What is the remote control lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='remote control')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the remote control lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1267, "imageId": "n281241", "question": "In front of what is the gentleman?", "program": "BOX0=LOC(image=IMAGE,object='gentleman')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In front of what is the gentleman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1268, "imageId": "n23762", "question": "On which side is the bulb?", "program": "BOX0=LOC(image=IMAGE,object='bulb')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1269, "imageId": "n281241", "question": "Who is in front of the square picture?", "program": "BOX0=LOC(image=IMAGE,object='square picture')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the square picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1270, "imageId": "n281241", "question": "Who is in front of the picture?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1271, "imageId": "n262929", "question": "Is the young person to the left or to the right of the bag that is not big?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1272, "imageId": "n310828", "question": "What device is on?", "program": "ANSWER0=VQA(image=IMAGE,question='What device is on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1273, "imageId": "n500308", "question": "What is inside the fridge that is in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='fridge')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wall')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is inside the fridge?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1274, "imageId": "n200907", "question": "Who is wearing the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1275, "imageId": "n500308", "question": "What is the appliance that the glasses are inside of?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_INSIDE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1276, "imageId": "n200907", "question": "Who is wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1277, "imageId": "n206358", "question": "Is the man looking down or waiting?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man looking down?')\nANSWER1=VQA(image=IMAGE0,question='Is the man waiting?')\nANSWER2=EVAL(expr=\"'looking down' if {ANSWER0} == 'yes' else 'waiting'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1278, "imageId": "n570181", "question": "Who is standing in front of the umpire on the right?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Who is standing in front of the umpire?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1279, "imageId": "n470131", "question": "What do the foil and the bottle have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the foil and the bottle have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1280, "imageId": "n470131", "question": "Is the shape of the bottle the same as that of the cake?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cake')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is the shape of the bottle?')\nANSWER1=VQA(image=IMAGE1,question='What is the shape of the cake?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1281, "imageId": "n97485", "question": "What are the pieces of furniture to the right of the table called?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the pieces of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1282, "imageId": "n97485", "question": "Which kind of furniture is to the right of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is to the right of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1283, "imageId": "n546616", "question": "Does the marker look narrow?", "program": "BOX0=LOC(image=IMAGE,object='marker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the marker look narrow?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1284, "imageId": "n140421", "question": "On which side of the photo is the soap bottle?", "program": "BOX0=LOC(image=IMAGE,object='soap bottle')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1285, "imageId": "n65866", "question": "What item of furniture is dark brown?", "program": "BOX0=LOC(image=IMAGE,object='dark brown')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is {BOX0}?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1286, "imageId": "n100991", "question": "Is this a square tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is this a square tray?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1287, "imageId": "n498712", "question": "Is the person that is to the right of the woman walking or standing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person walking or standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1288, "imageId": "n59147", "question": "On which side is the vase?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1289, "imageId": "n200907", "question": "Are there either any silver faucets or fences?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1290, "imageId": "n12214", "question": "What is the gender of the person in the middle?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the gender of the person in the middle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1291, "imageId": "n100991", "question": "What fruit is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What fruit is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1292, "imageId": "n79078", "question": "Is the trash bin dirty and silver?", "program": "BOX0=LOC(image=IMAGE,object='trash bin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the trash bin dirty?')\nANSWER1=VQA(image=IMAGE0,question='What color is the trash bin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dirty' and {ANSWER1} == 'silver' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1293, "imageId": "n234683", "question": "On which side is the black device?", "program": "BOX0=LOC(image=IMAGE,object='black device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1294, "imageId": "n433532", "question": "How big is the appliance the oil is above?", "program": "BOX0=LOC(image=IMAGE,object='oil')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the appliance')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1295, "imageId": "n536256", "question": "Is the clean wall behind the dark boots?", "program": "BOX0=LOC(image=IMAGE,object='dark boots')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clean wall')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1296, "imageId": "n437064", "question": "Does the utensil above the spoon look metallic and dirty?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Does the utensil look metallic and dirty?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1297, "imageId": "n485969", "question": "What's wearing the belt?", "program": "BOX0=LOC(image=IMAGE,object='belt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is wearing the belt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1298, "imageId": "n485969", "question": "What is wearing a belt?", "program": "BOX0=LOC(image=IMAGE,object='belt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is wearing a belt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1299, "imageId": "n485969", "question": "What is wearing the baseball mitt?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is wearing the baseball mitt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1300, "imageId": "n119886", "question": "What is on the shelf near the window?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP_NEAR(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is on the shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1301, "imageId": "n119886", "question": "Is the flower pot on the shelf gray or orange?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flower pot')\nANSWER0=VQA(image=IMAGE0,question='What color is the flower pot?')\nANSWER1=EVAL(expr=\"'gray' if {ANSWER0} == 'gray' else 'orange'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1302, "imageId": "n560243", "question": "Who looks at the tennis ball?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who looks at the tennis ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1303, "imageId": "n560243", "question": "What does that athlete look at?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the athlete look at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1304, "imageId": "n485969", "question": "What is wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is wearing a hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1305, "imageId": "n146522", "question": "What bag lies on the field?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='What bag lies on the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1306, "imageId": "n209843", "question": "On which side of the picture is the striped towel?", "program": "BOX0=LOC(image=IMAGE,object='striped towel')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1307, "imageId": "n181355", "question": "Is the young person to the left or to the right of the Wii controller in the middle?", "program": "BOX0=LOC(image=IMAGE,object='Wii controller')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1308, "imageId": "n28996", "question": "Is there any cheese or meat in the photo?", "program": "BOX0=LOC(image=IMAGE,object='cheese')\nBOX1=LOC(image=IMAGE,object='meat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1309, "imageId": "n527589", "question": "What color are the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nANSWER0=VQA(image=IMAGE,question='What color are the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1310, "imageId": "n527290", "question": "Do you see any televisions on top of the shelves that are on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelves')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='television')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1311, "imageId": "n263180", "question": "What is the vehicle that is parked behind the bus?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1312, "imageId": "n263180", "question": "What is parked behind the bus?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is parked behind the bus?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1313, "imageId": "n470920", "question": "Is the jacket the same color as the purse?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='purse')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE1,question='What color is the purse?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1314, "imageId": "n318684", "question": "Are the clouds thin and white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the clouds?')\nANSWER1=VQA(image=IMAGE,question='Are the clouds thin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1315, "imageId": "n449058", "question": "What place could this be?", "program": "ANSWER0=VQA(image=IMAGE,question='What place could this be?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1316, "imageId": "n449058", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1317, "imageId": "n528403", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1318, "imageId": "n263180", "question": "What's the car in front of?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the car in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1319, "imageId": "n470920", "question": "Does the blanket have a different color than the purse?", "program": "BOX0=LOC(image=IMAGE,object='blanket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='purse')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the blanket?')\nANSWER1=VQA(image=IMAGE1,question='What color is the purse?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1320, "imageId": "n187961", "question": "What animal is to the right of the child?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is to the right of the child?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1321, "imageId": "n58220", "question": "What color are the empty tables?", "program": "BOX0=LOC(image=IMAGE,object='empty tables')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the empty tables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1322, "imageId": "n187961", "question": "Are the mountains behind the hillside tall and blue?", "program": "BOX0=LOC(image=IMAGE,object='hillside')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mountains')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color are the mountains?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1323, "imageId": "n498712", "question": "Does the young person look happy and thin?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the young person look happy?')\nANSWER1=VQA(image=IMAGE0,question='Does the young person look thin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1324, "imageId": "n283587", "question": "What piece of furniture is to the left of the side table?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is to the left of the side table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1325, "imageId": "n283587", "question": "Which kind of furniture is on the right of the chairs?", "program": "BOX0=LOC(image=IMAGE,object='chairs')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is on the right?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1326, "imageId": "n319845", "question": "What is in front of the statue in the middle of the picture?", "program": "BOX0=LOC(image=IMAGE,object='statue')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='front')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the statue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1327, "imageId": "n538039", "question": "What kind of vehicle is to the right of the man that is old?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='old')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=VQA(image=IMAGE1,question='What kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1328, "imageId": "n69237", "question": "Which kind of furniture is not black?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What color is the furniture?')\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} != 'black' else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1329, "imageId": "n59676", "question": "Which kind of fast food is delicious?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fast food is delicious?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1330, "imageId": "n187961", "question": "Are the clouds gray and high?", "program": "BOX0=LOC(image=IMAGE,object='clouds')\nANSWER0=VQA(image=IMAGE,question='What color are the clouds?')\nANSWER1=VQA(image=IMAGE,question='How high are the clouds?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'high' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1331, "imageId": "n410289", "question": "Does the window look triangular and bright?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the window?')\nANSWER1=VQA(image=IMAGE0,question='Is the window bright?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'triangular' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1332, "imageId": "n119944", "question": "Is the red shirt short sleeved or sleeveless?", "program": "BOX0=LOC(image=IMAGE,object='red shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt short sleeved or sleeveless?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1333, "imageId": "n192021", "question": "Is the dark chair to the left or to the right of the couch that is on the carpet?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='carpet')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='dark chair')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1334, "imageId": "n52544", "question": "Which kind of clothing is long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1335, "imageId": "n545516", "question": "Is the man wearing a watch?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man wearing a watch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1336, "imageId": "n202379", "question": "Of which color is the field the fence is behind of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='field')\nANSWER0=VQA(image=IMAGE0,question='Of which color is the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1337, "imageId": "n28572", "question": "Is the color of the mug the same as the saucer?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='saucer')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the mug?')\nANSWER1=VQA(image=IMAGE1,question='What color is the saucer?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1338, "imageId": "n131634", "question": "What is the large vehicle parked behind of?", "program": "BOX0=LOC(image=IMAGE,object='large vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the large vehicle parked behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1339, "imageId": "n131634", "question": "Which kind of vehicle is parked behind the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is parked behind the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1340, "imageId": "n181210", "question": "What kind of meat is above the fork?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='meat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'beef' if {ANSWER0} > 0 else 'chicken'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1341, "imageId": "n162586", "question": "What device leans against the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device leans against the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1342, "imageId": "n216553", "question": "What is the fence made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1343, "imageId": "n126087", "question": "Are there people behind the tennis rackets?", "program": "BOX0=LOC(image=IMAGE,object='tennis rackets')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='people')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1344, "imageId": "n126087", "question": "What are the people behind the rackets lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='rackets')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the people lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1345, "imageId": "n216553", "question": "Is the big bag near the fence black and closed?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='big bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='black')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='closed')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 1346, "imageId": "n274905", "question": "Does the racket that is made of metal look silver or green?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the racket made of?')\nANSWER1=VQA(image=IMAGE0,question='What color does the racket look?')\nANSWER2=EVAL(expr=\"'silver' if {ANSWER0} == 'metal' and {ANSWER1} == 'silver' else 'green'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1347, "imageId": "n290409", "question": "What kind of vehicle are the trees behind of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1348, "imageId": "n90294", "question": "Is the remote to the right or to the left of the book?", "program": "BOX0=LOC(image=IMAGE,object='book')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1349, "imageId": "n90294", "question": "Is there any remote control next to the book?", "program": "BOX0=LOC(image=IMAGE,object='book')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote control')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1350, "imageId": "n527290", "question": "What device is to the right of the couch the woman is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nANSWER0=VQA(image=IMAGE1,question='What device is to the right of the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1351, "imageId": "n518912", "question": "Is there either a gold pillow or chair?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1352, "imageId": "n525901", "question": "Which kind of furniture is small?", "program": "BOX0=LOC(image=IMAGE,object='small')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1353, "imageId": "n179136", "question": "Is the surfboard in the bottom part or in the top of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surfboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1354, "imageId": "n69237", "question": "Is the floor green?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the floor?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1355, "imageId": "n507959", "question": "What kind of furniture is the cabinet sitting behind of?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the cabinet sitting behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1356, "imageId": "n501609", "question": "Do the cupboards look wooden and open?", "program": "BOX0=LOC(image=IMAGE,object='cupboards')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material do the cupboards look like?')\nANSWER1=VQA(image=IMAGE0,question='Are the cupboards open?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1357, "imageId": "n162108", "question": "Are there any hoses or envelopes in the picture?", "program": "BOX0=LOC(image=IMAGE,object='hose')\nBOX1=LOC(image=IMAGE,object='envelope')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1358, "imageId": "n541688", "question": "Does the toothbrush to the left of the other toothbrush have yellow color and large size?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toothbrush')\nANSWER0=VQA(image=IMAGE0,question='What color is the toothbrush?')\nANSWER1=VQA(image=IMAGE0,question='What size is the toothbrush?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1359, "imageId": "n480253", "question": "Do the trees behind the fire truck look ugly and tall?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='Do the trees look ugly and tall?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1360, "imageId": "n310828", "question": "What's the person working on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's the person working on?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1361, "imageId": "n296467", "question": "What kind of food is bunched?", "program": "BOX0=LOC(image=IMAGE,object='bunched')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of food is bunched?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1362, "imageId": "n296467", "question": "What kind of food is triangular?", "program": "BOX0=LOC(image=IMAGE,object='triangular food')\nANSWER0=VQA(image=IMAGE,question='What kind of food is triangular?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1363, "imageId": "n312206", "question": "Is the napkin red and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the napkin?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the napkin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1364, "imageId": "n77818", "question": "On which side of the picture is the book?", "program": "BOX0=LOC(image=IMAGE,object='book')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1365, "imageId": "n111390", "question": "Is the knife large and green?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nANSWER0=VQA(image=IMAGE,question='Is the knife large?')\nANSWER1=VQA(image=IMAGE,question='What color is the knife?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1366, "imageId": "n479092", "question": "What is the food called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the food called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1367, "imageId": "n479092", "question": "Which kind of food is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1368, "imageId": "n479092", "question": "What do you think is the food that is soft called?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is the food that is soft called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1369, "imageId": "n309148", "question": "What is parked alongside the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is parked alongside the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1370, "imageId": "n256120", "question": "What is attached to the pole in this image?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is attached to the pole?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1371, "imageId": "n256120", "question": "Is the green flag behind the vehicle made of metal?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green flag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1372, "imageId": "n111390", "question": "Is the knife in the top or in the bottom?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knife')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1373, "imageId": "n54424", "question": "Which side is the small pillow on?", "program": "BOX0=LOC(image=IMAGE,object='small pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1374, "imageId": "n357784", "question": "What are the cords plugged into?", "program": "BOX0=LOC(image=IMAGE,object='cords')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the cords plugged into?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1375, "imageId": "n483840", "question": "What kind of device is the man using?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is the man using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1376, "imageId": "n90294", "question": "Is the white bag made of cloth or leather?", "program": "BOX0=LOC(image=IMAGE,object='white bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the white bag made of?')\nANSWER1=EVAL(expr=\"'cloth' if {ANSWER0} == 'cloth' else 'leather'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1377, "imageId": "n489699", "question": "Are there helmets or suitcases that are hard?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nBOX1=LOC(image=IMAGE,object='suitcase')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1378, "imageId": "n483840", "question": "What's the man using?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1379, "imageId": "n262920", "question": "Who is looking at the doors the backpack is hanging on?", "program": "BOX0=LOC(image=IMAGE,object='doors')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='backpack')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is looking at the doors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1380, "imageId": "n16378", "question": "Who is wearing the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1381, "imageId": "n117888", "question": "Is the tall fence behind or in front of the bench made of wood?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tall fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'behind' if {ANSWER0} > 0 else 'in front'\")\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What material is the fence made of?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1382, "imageId": "n117888", "question": "Is that fence in front of a sheep?", "program": "BOX0=LOC(image=IMAGE,object='sheep')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1383, "imageId": "n117888", "question": "What is in front of the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1384, "imageId": "n117888", "question": "What is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1385, "imageId": "n117888", "question": "What is this fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is this fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1386, "imageId": "n560243", "question": "What color does the tennis ball have?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the tennis ball have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1387, "imageId": "n485969", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1388, "imageId": "n259949", "question": "Who is riding on a skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is riding on a skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1389, "imageId": "n16656", "question": "Where in this scene is the Caucasian person, in the bottom or in the top?", "program": "BOX0=LOC(image=IMAGE,object='Caucasian person')\nBOX1=LOC(image=IMAGE,object='TOP')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1390, "imageId": "n54424", "question": "What do the stars surround?", "program": "BOX0=LOC(image=IMAGE,object='stars')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do the stars surround?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1391, "imageId": "n16378", "question": "Who is the man following?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man following?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1392, "imageId": "n500209", "question": "Which kind of furniture is wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1393, "imageId": "n54424", "question": "What surrounds the shuttle?", "program": "BOX0=LOC(image=IMAGE,object='shuttle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What surrounds the shuttle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1394, "imageId": "n167552", "question": "What is the dog next to the tree doing?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dog')\nIMAGE1=CROP_NEXTTO(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the dog doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1395, "imageId": "n500209", "question": "What is the item of furniture that is brown called?", "program": "BOX0=LOC(image=IMAGE,object='brown')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1396, "imageId": "n500209", "question": "Which kind of furniture is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1397, "imageId": "n160664", "question": "Is the shirt striped and white?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='Is the shirt striped?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1398, "imageId": "n54424", "question": "Which kind of vehicle do the stars surround?", "program": "BOX0=LOC(image=IMAGE,object='stars')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle do the stars surround?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1399, "imageId": "n88366", "question": "Do the blue pants look sparse?", "program": "BOX0=LOC(image=IMAGE,object='blue pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do the blue pants look sparse?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1400, "imageId": "n449058", "question": "What's the policeman riding?", "program": "BOX0=LOC(image=IMAGE,object='policeman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the policeman riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1401, "imageId": "n336443", "question": "Is the napkin on the left side or on the right of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='napkin')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1402, "imageId": "n449058", "question": "What is the policeman to the left of the truck riding?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='policeman')\nANSWER0=VQA(image=IMAGE0,question='What is the policeman riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1403, "imageId": "n119944", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1404, "imageId": "n486200", "question": "Is there a traffic light to the left of the minivan?", "program": "BOX0=LOC(image=IMAGE,object='minivan')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic light')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1405, "imageId": "n65885", "question": "What is the name of the piece of furniture on top of the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the name of the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1406, "imageId": "n65885", "question": "What kind of furniture is on top of the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1407, "imageId": "n489190", "question": "What is the skateboarder that is not male doing, skateboarding or skating?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skateboarder doing?')\nANSWER1=EVAL(expr=\"'skateboarding' if {ANSWER0} == 'skateboarding' else 'skating'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1408, "imageId": "n184385", "question": "What color is the appliance that is beside the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP_BESIDE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1409, "imageId": "n249639", "question": "Are the towel and the lamp the same color?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='lamp')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the towel?')\nANSWER1=VQA(image=IMAGE1,question='What color is the lamp?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1410, "imageId": "n531731", "question": "What size is the baseball bat that is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='baseball bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the baseball bat?')\nANSWER1=EVAL(expr=\"'metal' if {ANSWER0} == 'metal' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1411, "imageId": "n543966", "question": "What are the animals that the trees are behind of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animals')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1412, "imageId": "n543966", "question": "What kind of animal are the trees behind of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal are the trees behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1413, "imageId": "n543966", "question": "Are the elephants in front of the small flowers?", "program": "BOX0=LOC(image=IMAGE,object='elephants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small flowers')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1414, "imageId": "n543966", "question": "What are the animals in front of the flowers called?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the animals called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1415, "imageId": "n116329", "question": "How wide is the crosswalk the man is standing by?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='crosswalk')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How wide is the crosswalk')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1416, "imageId": "n116329", "question": "What's the woman walking by?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's the woman walking by?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1417, "imageId": "n446242", "question": "Do the counter and the sink have the same color?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sink')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the counter?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sink?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1418, "imageId": "n302387", "question": "What is in front of the instrument that is to the right of the box?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='instrument')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the instrument?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1419, "imageId": "n279173", "question": "Does that backpack have blue color?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the backpack?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1420, "imageId": "n194179", "question": "How long are the trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nANSWER0=LENGTH(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1421, "imageId": "n500209", "question": "What is the item of furniture in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1422, "imageId": "n90944", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1423, "imageId": "n90944", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1424, "imageId": "n275148", "question": "What is the item of furniture on top of the floor called?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='item of furniture')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1425, "imageId": "n275148", "question": "Which kind of furniture is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is on top of the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1426, "imageId": "n526228", "question": "How does the white shirt look, short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='white shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How does the white shirt look, short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1427, "imageId": "n326988", "question": "Is there a doll inside the cabinets?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='doll')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1428, "imageId": "n154856", "question": "Does the window made of metal look black and short?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the window made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the window?')\nANSWER2=VQA(image=IMAGE0,question='Is the window short?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'metal' and {ANSWER1} == 'black' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1429, "imageId": "n326988", "question": "What type of furniture is the doll inside of?", "program": "BOX0=LOC(image=IMAGE,object='doll')\nIMAGE0=CROP_INSIDE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is the doll inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1430, "imageId": "n473688", "question": "What is she wearing?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is she wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1431, "imageId": "n473688", "question": "What is the girl wearing?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the girl wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1432, "imageId": "n315887", "question": "Are there computer mice on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='computer mice')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1433, "imageId": "n298104", "question": "What is that sign in front of?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is that sign in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1434, "imageId": "n206358", "question": "What is the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1435, "imageId": "n98540", "question": "Does the jersey look long sleeved and blue?", "program": "BOX0=LOC(image=IMAGE,object='jersey')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of sleeves does the jersey have?')\nANSWER1=VQA(image=IMAGE0,question='What color is the jersey?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'long sleeved' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1436, "imageId": "n310828", "question": "Do the glasses look black and large?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the glasses?')\nANSWER1=VQA(image=IMAGE0,question='Are the glasses large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1437, "imageId": "n229548", "question": "Is the helicopter that looks heavy using cords?", "program": "BOX0=LOC(image=IMAGE,object='helicopter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the helicopter using cords?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1438, "imageId": "n229548", "question": "How is the aircraft that is above the ocean called?", "program": "BOX0=LOC(image=IMAGE,object='ocean')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='aircraft')\nANSWER0=VQA(image=IMAGE0,question='How is the aircraft called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1439, "imageId": "n229548", "question": "Which kind of aircraft is above the ocean?", "program": "BOX0=LOC(image=IMAGE,object='ocean')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='aircraft')\nANSWER0=VQA(image=IMAGE0,question='Which kind of aircraft is above the ocean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1440, "imageId": "n55058", "question": "Is the small serving dish on top of a cutting board?", "program": "BOX0=LOC(image=IMAGE,object='cutting board')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small serving dish')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1441, "imageId": "n229548", "question": "What is the aircraft that is using the cables?", "program": "BOX0=LOC(image=IMAGE,object='cables')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the aircraft using the cables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1442, "imageId": "n460556", "question": "Who is on the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is on the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1443, "imageId": "n55058", "question": "What is the serving dish made of?", "program": "BOX0=LOC(image=IMAGE,object='serving dish')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the serving dish made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1444, "imageId": "n229548", "question": "What is the helicopter using?", "program": "BOX0=LOC(image=IMAGE,object='helicopter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the helicopter using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1445, "imageId": "n130464", "question": "What is the skateboarder that is not female jumping off of?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skateboarder jumping off of?')\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 'female' else {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1446, "imageId": "n164272", "question": "What animal is in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1447, "imageId": "n262920", "question": "In front of what are the laptops?", "program": "BOX0=LOC(image=IMAGE,object='laptops')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In front of what are the laptops?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1448, "imageId": "n164272", "question": "What animals are in front of the green trees?", "program": "BOX0=LOC(image=IMAGE,object='green trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animals')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1449, "imageId": "n164272", "question": "Which kind of animal is abundant?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is abundant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1450, "imageId": "n164272", "question": "Do the cows in front of the trees look abundant?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 5 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1451, "imageId": "n357784", "question": "Is this woman blond?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is this woman blond?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blond' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1452, "imageId": "n9856", "question": "Does the shirt look white and long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the shirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1453, "imageId": "n66756", "question": "Is the home plate different in color than the shoe?", "program": "BOX0=LOC(image=IMAGE,object='home plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shoe')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the home plate?')\nANSWER1=VQA(image=IMAGE1,question='What color is the shoe?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1454, "imageId": "n319845", "question": "What are the pieces of furniture around the table in front of the statue?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='statue')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1455, "imageId": "n305495", "question": "Are there both a lamp and a desk in the image?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='desk')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1456, "imageId": "n315887", "question": "What type of device is not framed, the telephone or the monitor?", "program": "BOX0=LOC(image=IMAGE,object='telephone')\nBOX1=LOC(image=IMAGE,object='monitor')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'telephone' if {ANSWER0} == 0 else 'monitor'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1457, "imageId": "n240973", "question": "Is the chicken standing on top of a sofa?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chicken')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1458, "imageId": "n541854", "question": "What is this fruit called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is this fruit called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1459, "imageId": "n67005", "question": "What is the item of furniture that the cord is on called?", "program": "BOX0=LOC(image=IMAGE,object='cord')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture that the cord is on called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1460, "imageId": "n373692", "question": "Who wears a jersey?", "program": "BOX0=LOC(image=IMAGE,object='jersey')\nANSWER0=VQA(image=IMAGE,question='Who wears a jersey?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1461, "imageId": "n373692", "question": "Who is wearing trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1462, "imageId": "n264887", "question": "Is the plastic cup to the left of the white keyboard?", "program": "BOX0=LOC(image=IMAGE,object='plastic cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='white keyboard')\nIMAGE1=CROP_LEFTOF(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1463, "imageId": "n67005", "question": "What is on the bed near the bag?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP_NEAR(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is on the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1464, "imageId": "n67005", "question": "What is on the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1465, "imageId": "n373692", "question": "What race is the player that is wearing trousers?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trousers')\nANSWER0=VQA(image=IMAGE0,question='What race is the player?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1466, "imageId": "n148872", "question": "Does the tennis racket look black?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tennis racket?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1467, "imageId": "n171169", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1468, "imageId": "n240666", "question": "Does the trashcan underneath the sink look large and white?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trashcan')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the trashcan?')\nANSWER3=VQA(image=IMAGE0,question='Does the trashcan look large?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1469, "imageId": "n470920", "question": "What color is the soft sweater?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sweater?')\nANSWER1=EVAL(expr=\"'soft' if {ANSWER0} == 'blue' else 'not soft'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1470, "imageId": "n171169", "question": "Is it indoors or outdoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it indoors or outdoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1471, "imageId": "n240666", "question": "What size is the trashcan, small or large?", "program": "BOX0=LOC(image=IMAGE,object='trashcan')\nANSWER0=VQA(image=IMAGE,question='What size is the trashcan?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1472, "imageId": "n233607", "question": "What is the computer perched on?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the computer perched on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1473, "imageId": "n6908", "question": "Do the flowers inside the glass look rotten?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flowers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1474, "imageId": "n159802", "question": "Is the striped blouse long sleeved and pink?", "program": "BOX0=LOC(image=IMAGE,object='striped blouse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the blouse long sleeved?')\nANSWER1=VQA(image=IMAGE0,question='What color is the blouse?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'pink' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1475, "imageId": "n39114", "question": "Is the bench short?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nANSWER0=VQA(image=IMAGE,question='Is the bench short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1476, "imageId": "n51002", "question": "Which kind of material is the black thing below the artwork made of?", "program": "BOX0=LOC(image=IMAGE,object='artwork')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black thing')\nANSWER0=VQA(image=IMAGE0,question='Which kind of material is the black thing made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1477, "imageId": "n429883", "question": "Are the tie and the suit the same color?", "program": "BOX0=LOC(image=IMAGE,object='tie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='suit')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the tie?')\nANSWER1=VQA(image=IMAGE1,question='What color is the suit?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1478, "imageId": "n350732", "question": "What type of furniture has the same color as the soccer ball?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the soccer ball?')\nBOX1=LOC(image=IMAGE,object='furniture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='What color is the furniture?')\nANSWER2=EVAL(expr=\"'{ANSWER1}' if {ANSWER0} == {ANSWER1} else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1479, "imageId": "n44249", "question": "What animal is the man on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the man on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1480, "imageId": "n48494", "question": "What is the width of the boat that is floating on the river?", "program": "BOX0=LOC(image=IMAGE,object='river')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boat')\nANSWER0=WIDTH(box=BOX1)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1481, "imageId": "n83784", "question": "Is the side table above the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='side table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1482, "imageId": "n83784", "question": "Does the clay flower pot look blue?", "program": "BOX0=LOC(image=IMAGE,object='clay flower pot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the clay flower pot?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1483, "imageId": "n19152", "question": "What's lying next to the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='next to')\nANSWER0=VQA(image=IMAGE0,question='What is lying next to the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1484, "imageId": "n274905", "question": "Who is standing behind the player to the right of the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is standing behind the player?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1485, "imageId": "n264887", "question": "Behind what device is the speaker?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Behind what device is the speaker?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1486, "imageId": "n336443", "question": "Does that table look wooden and large?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE0,question='Is the table large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1487, "imageId": "n546616", "question": "How hard are the plates?", "program": "ANSWER0=VQA(image=IMAGE,question='How hard are the plates?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1488, "imageId": "n37274", "question": "What do the watch and the bicycle have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the watch and the bicycle have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1489, "imageId": "n540852", "question": "What is the woman that is to the right of the man wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the woman wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1490, "imageId": "n274905", "question": "Who is wearing the shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1491, "imageId": "n468864", "question": "What color do you think the cellphones to the right of the cell phone have?", "program": "BOX0=LOC(image=IMAGE,object='cell phone')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cell phone')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color do you think the cellphones have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1492, "imageId": "n546616", "question": "What do you think is located on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1493, "imageId": "n501609", "question": "Is the sink that is not on silver or black?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sink?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} not in ['silver', 'black'] else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1494, "imageId": "n386688", "question": "Are the boats to the left of the sailboats still and white?", "program": "BOX0=LOC(image=IMAGE,object='sailboats')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boats')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color are the boats?')\nANSWER3=VQA(image=IMAGE1,question='Are the boats still?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1495, "imageId": "n259002", "question": "Which color is the garbage can?", "program": "BOX0=LOC(image=IMAGE,object='garbage can')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the garbage can?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1496, "imageId": "n386688", "question": "Which kind of watercraft is underneath the airplane?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watercraft')\nANSWER0=VQA(image=IMAGE0,question='Which kind of watercraft is underneath the airplane?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1497, "imageId": "n386688", "question": "Is there a sailboat underneath the airplane that is flying in the sky?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sailboat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1498, "imageId": "n386688", "question": "What is underneath the airplane?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the airplane?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1499, "imageId": "n55058", "question": "Do you see a plate on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1500, "imageId": "n279581", "question": "What's the catcher wearing?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's the catcher wearing?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1501, "imageId": "n500209", "question": "What kind of furniture is standing on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is standing on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1502, "imageId": "n415215", "question": "Does the toilet brush have a different color than the art work?", "program": "BOX0=LOC(image=IMAGE,object='toilet brush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='art work')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet brush?')\nANSWER1=VQA(image=IMAGE1,question='What color is the art work?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1503, "imageId": "n162586", "question": "Is this a table or a bed?", "program": "BOX0=LOC(image=IMAGE,object='table')\nBOX1=LOC(image=IMAGE,object='bed')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'table' if {ANSWER0} > 0 else 'bed'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1504, "imageId": "n497789", "question": "Which kind of animal is in front of the vehicle?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is in front of the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1505, "imageId": "n534106", "question": "What color is the bag?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1506, "imageId": "n475030", "question": "Is there a horse that is healthy?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nANSWER0=VQA(image=IMAGE,question='Is the horse healthy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1507, "imageId": "n116329", "question": "Are there any traffic lights or bombs in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nBOX1=LOC(image=IMAGE,object='bomb')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1508, "imageId": "n281241", "question": "Is the jacket the same color as the dress shirt?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='dress shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE1,question='What color is the dress shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1509, "imageId": "n222297", "question": "Which color is that frisbee?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the frisbee?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1510, "imageId": "n513100", "question": "What is the fence made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1511, "imageId": "n14087", "question": "Which kind of furniture is green?", "program": "BOX0=LOC(image=IMAGE,object='green')\nBOX1=LOC(image=IMAGE,object='furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'chair' if {ANSWER0} > 0 else 'table' if {ANSWER1} > 0 else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1512, "imageId": "n500308", "question": "Where is the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='Where is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1513, "imageId": "n310828", "question": "What is the mouse pad on?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the mouse pad on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1514, "imageId": "n433692", "question": "What do both the laptop and the mousepad have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the laptop and the mousepad have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1515, "imageId": "n480253", "question": "Of what weight is the ambulance the workers are standing by?", "program": "BOX0=LOC(image=IMAGE,object='ambulance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Of what weight is the ambulance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1516, "imageId": "n470131", "question": "What shape is the foil?", "program": "BOX0=LOC(image=IMAGE,object='foil')\nANSWER0=VQA(image=IMAGE,question='What shape is the foil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1517, "imageId": "n55058", "question": "What kind of fast food is to the right of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of fast food is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1518, "imageId": "n55058", "question": "Which kind of fast food is to the right of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of fast food is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1519, "imageId": "n6908", "question": "Does the picture seem to be gold?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the picture seem to be gold?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'gold' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1520, "imageId": "n49438", "question": "Is the dark curtain above a bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dark curtain')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1521, "imageId": "n309148", "question": "Where is the fire truck?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nANSWER0=VQA(image=IMAGE,question='Where is the fire truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1522, "imageId": "n309148", "question": "Are there tractors on the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tractor')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1523, "imageId": "n433532", "question": "Is the red towel small and striped?", "program": "BOX0=LOC(image=IMAGE,object='red towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the towel small?')\nANSWER1=VQA(image=IMAGE0,question='Is the towel striped?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1524, "imageId": "n496803", "question": "Who is the crowd watching?", "program": "BOX0=LOC(image=IMAGE,object='crowd')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the crowd watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1525, "imageId": "n508733", "question": "Does the glass on the table look clear and small?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass')\nANSWER0=VQA(image=IMAGE0,question='What does the glass on the table look like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'clear and small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1526, "imageId": "n100991", "question": "How tall is the cup made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How tall is the cup?')\nANSWER1=EVAL(expr=\"'made of plastic' if {ANSWER0} == 'plastic' else 'not made of plastic'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1527, "imageId": "n280089", "question": "Which kind of appliance is clean?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1528, "imageId": "n119944", "question": "What is the bag made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the bag made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1529, "imageId": "n100991", "question": "Is the cup in the bottom part or in the top of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cup')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1530, "imageId": "n276011", "question": "What is the short item of furniture called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the short item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1531, "imageId": "n160664", "question": "What is the woman staring at, a giraffe or a rhino?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='giraffe')\nBOX2=LOC(image=IMAGE0,object='rhino')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'giraffe' if {ANSWER0} > 0 else 'rhino'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1532, "imageId": "n272313", "question": "Who is the helmet worn on?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the helmet worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1533, "imageId": "n579928", "question": "What is this vehicle called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is this vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1534, "imageId": "n579928", "question": "What kind of vehicle is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1535, "imageId": "n566028", "question": "Does the person above the skateboard appear to be performing trick?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1536, "imageId": "n480253", "question": "Is that ambulance to the right of a tractor?", "program": "BOX0=LOC(image=IMAGE,object='tractor')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ambulance')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1537, "imageId": "n507959", "question": "Is there either a briefcase or a purse that is not blue?", "program": "BOX0=LOC(image=IMAGE,object='briefcase')\nBOX1=LOC(image=IMAGE,object='purse')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What color is the briefcase?')\nANSWER4=VQA(image=IMAGE,question='What color is the purse?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} != 'blue' or {ANSWER4} != 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 1538, "imageId": "n250715", "question": "Which color is the chair?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1539, "imageId": "n574498", "question": "Are there either boys or balls in this image?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nBOX1=LOC(image=IMAGE,object='ball')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1540, "imageId": "n507959", "question": "Is the purse blue and large?", "program": "BOX0=LOC(image=IMAGE,object='purse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the purse?')\nANSWER1=VQA(image=IMAGE0,question='Is the purse large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1541, "imageId": "n477702", "question": "Is the dark blue shirt short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='dark blue shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1542, "imageId": "n342511", "question": "Is the hat both dry and green?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE0,question='Is the hat dry?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1543, "imageId": "n240973", "question": "Which color does the bowl have?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color does the bowl have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1544, "imageId": "n329479", "question": "Are there any red scooters or skateboards?", "program": "BOX0=LOC(image=IMAGE,object='scooter')\nBOX1=LOC(image=IMAGE,object='skateboard')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1545, "imageId": "n302387", "question": "Which color is the instrument?", "program": "BOX0=LOC(image=IMAGE,object='instrument')\nANSWER0=VQA(image=IMAGE,question='Which color is the instrument?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1546, "imageId": "n16378", "question": "Is the bag to the right of the safety vest red or blue?", "program": "BOX0=LOC(image=IMAGE,object='safety vest')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='What color is the bag?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1547, "imageId": "n278312", "question": "Do the cabinets hang from the beige wall?", "program": "BOX0=LOC(image=IMAGE,object='beige wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabinets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1548, "imageId": "n393305", "question": "What is the girl in front of?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the girl in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1549, "imageId": "n222915", "question": "What are the papers sitting on?", "program": "BOX0=LOC(image=IMAGE,object='papers')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the papers sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1550, "imageId": "n293477", "question": "Are there either wood spoons or knives?", "program": "BOX0=LOC(image=IMAGE,object='wood spoon')\nBOX1=LOC(image=IMAGE,object='knife')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1551, "imageId": "n49310", "question": "What type of clothing is black?", "program": "BOX0=LOC(image=IMAGE,object='black clothing')\nANSWER0=VQA(image=IMAGE,question='What type of clothing is black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1552, "imageId": "n471866", "question": "What is the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1553, "imageId": "n28572", "question": "Does the table that is not little have square shape?", "program": "BOX0=LOC(image=IMAGE,object='table')\nBOX1=LOC(image=IMAGE,object='little')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What shape is the table?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'square' and {ANSWER1} != 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1554, "imageId": "n411121", "question": "Is the building behind a fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='building')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1555, "imageId": "n186491", "question": "Do you see either round tables or lamps?", "program": "BOX0=LOC(image=IMAGE,object='round table')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1556, "imageId": "n279173", "question": "Does the motorbike on the street look metallic and black?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorbike')\nANSWER0=VQA(image=IMAGE0,question='What color is the motorbike?')\nANSWER1=VQA(image=IMAGE0,question='What material is the motorbike made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1557, "imageId": "n49310", "question": "Which kind of clothing is collared?", "program": "BOX0=LOC(image=IMAGE,object='collared clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is collared?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1558, "imageId": "n223750", "question": "Is the person in front of the shrubs holding the umbrella that is not closed?", "program": "BOX0=LOC(image=IMAGE,object='shrub')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='umbrella')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='Is the umbrella closed?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1559, "imageId": "n398257", "question": "Do the computer monitor and the chair have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='computer monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='chair')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the computer monitor?')\nANSWER1=VQA(image=IMAGE1,question='What color is the chair?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1560, "imageId": "n507959", "question": "What is the color of the shirts?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='What is the color of the shirts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1561, "imageId": "n369595", "question": "Is that shirt sleeveless or is it long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt sleeveless or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1562, "imageId": "n507959", "question": "What is hanging from the wall behind the palm?", "program": "BOX0=LOC(image=IMAGE,object='palm')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wall')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is hanging from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1563, "imageId": "n507959", "question": "What is hanging from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1564, "imageId": "n541854", "question": "Which kind of fruit is round?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fruit is round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1565, "imageId": "n513429", "question": "How large is the speaker that is sitting on the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='speaker')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the speaker that is sitting on the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1566, "imageId": "n318684", "question": "Does that cap look brown?", "program": "BOX0=LOC(image=IMAGE,object='cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cap?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1567, "imageId": "n570181", "question": "Do the black pants seem to be long?", "program": "BOX0=LOC(image=IMAGE,object='black pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do the black pants seem to be long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1568, "imageId": "n153293", "question": "Is that toilet open or closed?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nANSWER0=VQA(image=IMAGE,question='Is the toilet open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1569, "imageId": "n260762", "question": "What is the player throwing?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the player throwing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1570, "imageId": "n260762", "question": "What is the person on the field throwing?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person throwing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1571, "imageId": "n260762", "question": "Who is throwing the frisbee?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is throwing the frisbee?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1572, "imageId": "n260762", "question": "Is the player throwing a baseball?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the player throwing a baseball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1573, "imageId": "n131634", "question": "What is the seat on?", "program": "BOX0=LOC(image=IMAGE,object='seat')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the seat on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1574, "imageId": "n187961", "question": "What is the street in front of?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the street in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1575, "imageId": "n260762", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1576, "imageId": "n260762", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1577, "imageId": "n14087", "question": "Is the small tree behind the wall that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small tree')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1578, "imageId": "n16656", "question": "What is located on top of the shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1579, "imageId": "n314630", "question": "Is the wine bottle that is made of glass reflecting in a coffee maker?", "program": "BOX0=LOC(image=IMAGE,object='wine bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='coffee maker')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1580, "imageId": "n98544", "question": "Is the bathroom small and clean?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the bathroom small?')\nANSWER1=VQA(image=IMAGE,question='Is the bathroom clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1581, "imageId": "n433692", "question": "Does the plant have a different color than the pot?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pot')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the plant?')\nANSWER1=VQA(image=IMAGE1,question='What color is the pot?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1582, "imageId": "n501609", "question": "Are the closed cabinets below the appliance that is not turned on?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='closed cabinets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1583, "imageId": "n68769", "question": "Are there any tables in front of the chair below the light fixture?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='table')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1584, "imageId": "n538039", "question": "Who is hugging the old woman?", "program": "BOX0=LOC(image=IMAGE,object='old woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is hugging the old woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1585, "imageId": "n501609", "question": "What items of furniture are below the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1586, "imageId": "n518912", "question": "Do the cups that are made of porcelain have blue color?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nBOX1=LOC(image=IMAGE,object='porcelain')\nBOX2=INTERSECT(box1=BOX0,box2=BOX1)\nIMAGE0=CROP(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE0,question='What color is the cup?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1587, "imageId": "n68769", "question": "What's the table in front of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the table in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1588, "imageId": "n16656", "question": "What's located on top of the shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1589, "imageId": "n526228", "question": "Is the happy man running or sitting?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man running or sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1590, "imageId": "n210269", "question": "Which kind of animal is pretty?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is pretty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1591, "imageId": "n65866", "question": "What's the sink made of?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sink made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1592, "imageId": "n446242", "question": "Are the towels that are to the left of her soft and white?", "program": "BOX0=LOC(image=IMAGE,object='her')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towels')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color are the towels?')\nANSWER3=VQA(image=IMAGE1,question='Are the towels soft?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1593, "imageId": "n210269", "question": "What animals are brown?", "program": "BOX0=LOC(image=IMAGE,object='brown animal')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1594, "imageId": "n400036", "question": "Is there a soccer ball in the picture that is blue?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the soccer ball?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1595, "imageId": "n498140", "question": "Is the grill below a bus driver?", "program": "BOX0=LOC(image=IMAGE,object='bus driver')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grill')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1596, "imageId": "n210269", "question": "What animals are large?", "program": "BOX0=LOC(image=IMAGE,object='large')\nANSWER0=VQA(image=IMAGE,question='What animals are large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1597, "imageId": "n210269", "question": "What do you think are the brown animals called?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think are the brown animals called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1598, "imageId": "n262929", "question": "Which color is the bandana?", "program": "BOX0=LOC(image=IMAGE,object='bandana')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the bandana?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1599, "imageId": "n435808", "question": "What is the device to the left of the plastic device?", "program": "BOX0=LOC(image=IMAGE,object='plastic device')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1600, "imageId": "n260521", "question": "This statue is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='statue')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='This statue is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1601, "imageId": "n488874", "question": "Are the boats behind the beach scattered on the dirty dirt?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boats')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Are the boats scattered on the dirty dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1602, "imageId": "n14087", "question": "What piece of furniture is comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='What piece of furniture is comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1603, "imageId": "n572716", "question": "Do the green trees look tall and dense?", "program": "BOX0=LOC(image=IMAGE,object='green trees')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1604, "imageId": "n95369", "question": "Are there either pens or dispensers in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='pen')\nBOX1=LOC(image=IMAGE,object='dispenser')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1605, "imageId": "n488874", "question": "What is scattered on the dirty dirt?", "program": "BOX0=LOC(image=IMAGE,object='dirty dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is scattered on the dirty dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1606, "imageId": "n488874", "question": "What watercraft is scattered on the dirt?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watercraft')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1607, "imageId": "n67005", "question": "What is the item of furniture that is the same color as the cord called?", "program": "BOX0=LOC(image=IMAGE,object='cord')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cord?')\nBOX1=LOC(image=IMAGE,object='furniture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='What is the item of furniture called?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1608, "imageId": "n488874", "question": "What are the boats scattered on?", "program": "BOX0=LOC(image=IMAGE,object='boats')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the boats scattered on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1609, "imageId": "n161313", "question": "Do you see both helmets and skis?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nBOX1=LOC(image=IMAGE,object='ski')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1610, "imageId": "n65866", "question": "What shape is the brown thing in the cabinet?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the brown thing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1611, "imageId": "n16936", "question": "What is the skateboarder skating on?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skateboarder skating on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1612, "imageId": "n259002", "question": "What's in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1613, "imageId": "n117888", "question": "What color is the grass that is not tall?", "program": "BOX0=LOC(image=IMAGE,object='tall grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nANSWER0=VQA(image=IMAGE0,question='What color is the grass?')\nANSWER1=EVAL(expr=\"'green' if {ANSWER0} != 'green' else 'not green'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1614, "imageId": "n525029", "question": "What does the train ride on?", "program": "BOX0=LOC(image=IMAGE,object='train')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the train ride on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1615, "imageId": "n259002", "question": "Is the car behind a motorcycle?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1616, "imageId": "n280089", "question": "What is this appliance called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is this appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1617, "imageId": "n488874", "question": "Is the dirt that looks dark brown dirty or clean?", "program": "BOX0=LOC(image=IMAGE,object='dark brown dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the dirt dirty or clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1618, "imageId": "n522733", "question": "Which side of the image is the beige car on?", "program": "BOX0=LOC(image=IMAGE,object='beige car')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='beige car')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1619, "imageId": "n259002", "question": "What vehicle do you think is in front of the trees that are not short?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='vehicle')\nIMAGE2=CROP_FRONT(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What vehicle do you think is in front of the trees that are not short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1620, "imageId": "n259002", "question": "What vehicle is in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1621, "imageId": "n497789", "question": "What kind of animal is the vehicle behind of?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is the vehicle behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1622, "imageId": "n334278", "question": "Is the fence that looks yellow and blue made of wood?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the fence?')\nANSWER1=VQA(image=IMAGE0,question='What material is the fence made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow and blue' and {ANSWER1} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1623, "imageId": "n222297", "question": "What is the palm tree inside of?", "program": "BOX0=LOC(image=IMAGE,object='palm tree')\nIMAGE0=CROP_INSIDE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the palm tree inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1624, "imageId": "n314171", "question": "Which side of the photo is the woman on, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1625, "imageId": "n4777", "question": "What kind of furniture is the bottle sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the bottle sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1626, "imageId": "n499081", "question": "Is the window above a bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1627, "imageId": "n250821", "question": "Is the man in the bottom or in the top of the picture?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1628, "imageId": "n534106", "question": "What is located on top of the couch that is not uncomfortable?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='uncomfortable')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='TOP')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What is located on top of the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1629, "imageId": "n95313", "question": "What is underneath the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1630, "imageId": "n37274", "question": "What kind of appliance is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of appliance is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1631, "imageId": "n523165", "question": "What is lying in the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is lying in the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1632, "imageId": "n37274", "question": "How is the appliance in this scene called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the appliance in this scene called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1633, "imageId": "n154160", "question": "Do you see a horse on the field?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1634, "imageId": "n37274", "question": "How is the half full appliance called?", "program": "BOX0=LOC(image=IMAGE,object='half full appliance')\nANSWER0=VQA(image=IMAGE,question='How is the half full appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1635, "imageId": "n347706", "question": "How old is the small person?", "program": "BOX0=LOC(image=IMAGE,object='small person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How old is the small person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1636, "imageId": "n579256", "question": "Do you see any cat on the floor that looks gray?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='gray')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1637, "imageId": "n382416", "question": "How big is the suitcase that looks square?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the suitcase?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1638, "imageId": "n579256", "question": "Where is the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=VQA(image=IMAGE,question='Where is the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1639, "imageId": "n282607", "question": "Of what color is the tshirt the man is wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tshirt')\nANSWER0=VQA(image=IMAGE0,question='Of what color is the tshirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1640, "imageId": "n315887", "question": "Is the monitor above the keyboard gray and small?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='monitor')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the monitor?')\nANSWER3=VQA(image=IMAGE0,question='What size is the monitor?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'gray' and {ANSWER3} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1641, "imageId": "n95313", "question": "Which kind of furniture is underneath the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is underneath the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1642, "imageId": "n460385", "question": "Is the drink full or empty?", "program": "BOX0=LOC(image=IMAGE,object='drink')\nANSWER0=VQA(image=IMAGE,question='Is the drink full or empty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1643, "imageId": "n216553", "question": "Is the brown horse in front of the leafy trees?", "program": "BOX0=LOC(image=IMAGE,object='brown horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='leafy trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1644, "imageId": "n275148", "question": "What is the storage box made of?", "program": "BOX0=LOC(image=IMAGE,object='storage box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the storage box made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1645, "imageId": "n146522", "question": "Does the helmet that is made of plastic look small?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the helmet made of?')\nANSWER1=VQA(image=IMAGE0,question='Does the helmet look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1646, "imageId": "n299528", "question": "Is the street sign metallic and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='street sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the street sign made of?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the street sign?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'metallic' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1647, "imageId": "n16656", "question": "Who is in front of the tree?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the tree?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1648, "imageId": "n90944", "question": "What is surrounding the sand?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is surrounding the sand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1649, "imageId": "n167164", "question": "What vehicle is in front of the red vehicle?", "program": "BOX0=LOC(image=IMAGE,object='red vehicle')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is in front?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1650, "imageId": "n141939", "question": "Is the radiator on the left side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='radiator')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='radiator')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1651, "imageId": "n90944", "question": "Where are the trees?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1652, "imageId": "n95313", "question": "Is that bookshelf both full and wooden?", "program": "BOX0=LOC(image=IMAGE,object='bookshelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the bookshelf full?')\nANSWER1=VQA(image=IMAGE0,question='What material is the bookshelf made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1653, "imageId": "n544255", "question": "Is the man above a skateboard?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1654, "imageId": "n534106", "question": "Do the shorts have black color and long length?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE0,question='What is the length of the shorts?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1655, "imageId": "n167552", "question": "Is the color of the shoes different than the pants?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pants')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the shoes?')\nANSWER1=VQA(image=IMAGE1,question='What color are the pants?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1656, "imageId": "n520071", "question": "Which kind of device is the cat on?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is the cat on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1657, "imageId": "n520071", "question": "Do you see cats on the device that is in the middle?", "program": "BOX0=LOC(image=IMAGE,object='middle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='cat')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1658, "imageId": "n520071", "question": "What is the piece of furniture to the right of the lamps on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamps')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='piece of furniture')\nANSWER0=VQA(image=IMAGE1,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1659, "imageId": "n64959", "question": "Do you see any faucets to the left of the fridge?", "program": "BOX0=LOC(image=IMAGE,object='fridge')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='faucets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1660, "imageId": "n435808", "question": "What type of device is not silver, the monitor or the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='keyboard')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the monitor?')\nANSWER1=VQA(image=IMAGE1,question='What color is the keyboard?')\nANSWER2=EVAL(expr=\"'monitor' if {ANSWER0} != 'silver' else 'keyboard'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1661, "imageId": "n64959", "question": "On which side of the image is the tap?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tap')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1662, "imageId": "n435808", "question": "Which kind of device is silver?", "program": "BOX0=LOC(image=IMAGE,object='silver')\nANSWER0=VQA(image=IMAGE,question='Which kind of device is silver?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1663, "imageId": "n532213", "question": "Do the pants have brown color and long length?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nANSWER1=VQA(image=IMAGE0,question='What is the length of the pants?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1664, "imageId": "n470920", "question": "Does the umbrella that is made of cloth look square and wet?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the umbrella made of?')\nANSWER1=VQA(image=IMAGE0,question='Does the umbrella look square?')\nANSWER2=VQA(image=IMAGE0,question='Does the umbrella look wet?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'cloth' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1665, "imageId": "n551964", "question": "Do you think the woman is sitting?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do you think the woman is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1666, "imageId": "n127705", "question": "Are the shorts different in color than the pants?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pants')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE1,question='What color are the pants?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1667, "imageId": "n154856", "question": "Is the parked van in front of the car metallic and white?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='van')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the van?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'metallic and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1668, "imageId": "n566028", "question": "Is the cotton shirt green and long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='cotton shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cotton shirt?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the cotton shirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1669, "imageId": "n357784", "question": "Are there either any towel dispensers or toys in the image?", "program": "BOX0=LOC(image=IMAGE,object='towel dispenser')\nBOX1=LOC(image=IMAGE,object='toy')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1670, "imageId": "n566028", "question": "What color is the shirt that is made of cotton?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='What material is the shirt made of?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if {ANSWER1} == 'cotton' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1671, "imageId": "n445353", "question": "What item of furniture are the bricks behind of?", "program": "BOX0=LOC(image=IMAGE,object='bricks')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture are the bricks behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1672, "imageId": "n310625", "question": "Are there any mirrors above the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1673, "imageId": "n324908", "question": "What type of animal is walking across the grassy pasture?", "program": "BOX0=LOC(image=IMAGE,object='grassy pasture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of animal is walking across the grassy pasture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1674, "imageId": "n141939", "question": "What is the soap in?", "program": "BOX0=LOC(image=IMAGE,object='soap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the soap in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1675, "imageId": "n141939", "question": "Is the white soap in the clean shower?", "program": "BOX0=LOC(image=IMAGE,object='clean shower')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white soap')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1676, "imageId": "n324908", "question": "Which kind of animal isn't large?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is large?')\nANSWER1=EVAL(expr=\"'not ' + {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1677, "imageId": "n324908", "question": "What kind of animal is not large, the horse or the goat?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of animal is not large, the horse or the goat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1678, "imageId": "n324908", "question": "Which kind of animal is large?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1679, "imageId": "n164272", "question": "What type of animal is the building behind of, cows or horses?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cows')\nBOX2=LOC(image=IMAGE0,object='horses')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'cows' if {ANSWER0} > {ANSWER1} else 'horses'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1680, "imageId": "n12404", "question": "What is the cone in front of?", "program": "BOX0=LOC(image=IMAGE,object='cone')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cone in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1681, "imageId": "n315887", "question": "What device is not large?", "program": "ANSWER0=VQA(image=IMAGE,question='What device is not large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1682, "imageId": "n67005", "question": "Is the bed white and small?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bed?')\nANSWER1=VQA(image=IMAGE0,question='What size is the bed?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1683, "imageId": "n12404", "question": "Is the small cone in front of the machine?", "program": "BOX0=LOC(image=IMAGE,object='machine')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small cone')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1684, "imageId": "n148872", "question": "The skinny girl is standing where?", "program": "BOX0=LOC(image=IMAGE,object='skinny girl')\nANSWER0=VQA(image=IMAGE,question='The skinny girl is standing where?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1685, "imageId": "n263180", "question": "Is this a white bus?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bus?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1686, "imageId": "n315887", "question": "What kind of device is not reflective?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of device is not reflective?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1687, "imageId": "n148872", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1688, "imageId": "n496803", "question": "Do the sneakers seem to be white and low?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the sneakers?')\nANSWER1=VQA(image=IMAGE0,question='What type of sneakers are they?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'low' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1689, "imageId": "n118102", "question": "Is she wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1690, "imageId": "n118102", "question": "Who is holding the utensil near the candles?", "program": "BOX0=LOC(image=IMAGE,object='candles')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nANSWER0=VQA(image=IMAGE0,question='Who is holding the utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1691, "imageId": "n125122", "question": "Are the white curtains behind the chair that is to the right of the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='white curtains')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1692, "imageId": "n125122", "question": "What kind of furniture are the curtains behind of?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture are the curtains behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1693, "imageId": "n97485", "question": "How large is the cabinet that is decorating the kitchen?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How large is the cabinet')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1694, "imageId": "n65885", "question": "Is there a fence or a dog in this picture?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='dog')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1695, "imageId": "n470920", "question": "What is the color of the soft blanket?", "program": "BOX0=LOC(image=IMAGE,object='soft blanket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the soft blanket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1696, "imageId": "n310625", "question": "What do you think is inside the mug?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is inside the mug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1697, "imageId": "n310625", "question": "What is inside the mug?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the mug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1698, "imageId": "n186491", "question": "Is the sandwich to the left of lettuce?", "program": "BOX0=LOC(image=IMAGE,object='lettuce')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sandwich')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1699, "imageId": "n531359", "question": "What ethnic group are the people behind the boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What ethnic group are the people?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1700, "imageId": "n357784", "question": "What animal is in front of the person that is looking at the mirror?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is in front of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1701, "imageId": "n357784", "question": "What animal is in front of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1702, "imageId": "n357784", "question": "Is the brown animal to the right or to the left of the open bottle?", "program": "BOX0=LOC(image=IMAGE,object='open bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown animal')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1703, "imageId": "n531359", "question": "Do you see people near the pink balloons?", "program": "BOX0=LOC(image=IMAGE,object='pink balloons')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='people')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1704, "imageId": "n184551", "question": "Are there any men or women that are happy?", "program": "BOX0=LOC(image=IMAGE,object='man')\nBOX1=LOC(image=IMAGE,object='woman')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1705, "imageId": "n264887", "question": "What makes up the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What makes up the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1706, "imageId": "n302387", "question": "Is the box square and brown?", "program": "BOX0=LOC(image=IMAGE,object='box')\nANSWER0=VQA(image=IMAGE,question='Is the box square?')\nANSWER1=VQA(image=IMAGE,question='What color is the box?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1707, "imageId": "n525029", "question": "Does the car look white or red?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the car?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'red'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1708, "imageId": "n159802", "question": "What is the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1709, "imageId": "n489190", "question": "Are both the person to the right of the other people and the skateboarder that is not male standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nBOX1=LOC(image=IMAGE,object='right of',reference=BOX0)\nBOX2=LOC(image=IMAGE,object='other people')\nBOX3=LOC(image=IMAGE,object='skateboarder')\nBOX4=LOC(image=IMAGE,object='not male')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=COUNT(box=BOX3)\nANSWER3=COUNT(box=BOX4)\nANSWER4=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 and {ANSWER2} > 0 and {ANSWER3} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1710, "imageId": "n324908", "question": "Is the pasture dry or wet?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the pasture dry or wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1711, "imageId": "n159802", "question": "What's the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1712, "imageId": "n199097", "question": "Which kind of sign is on the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=VQA(image=IMAGE0,question='Which kind of sign is on the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1713, "imageId": "n199097", "question": "What type of sign is on the wide sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='wide sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of sign is on the wide sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1714, "imageId": "n240973", "question": "What are the items of furniture to the right of the black device?", "program": "BOX0=LOC(image=IMAGE,object='black device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What are the items of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1715, "imageId": "n234722", "question": "What is the color of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='What color is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1716, "imageId": "n475030", "question": "Is the horse's tail long and white?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the horse\\'s tail?')\nANSWER1=VQA(image=IMAGE0,question='Is the horse\\'s tail long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1717, "imageId": "n469525", "question": "What animal stands on the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal stands on the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1718, "imageId": "n527589", "question": "Are these small bananas?", "program": "BOX0=LOC(image=IMAGE,object='small bananas')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1719, "imageId": "n556604", "question": "Is the lamp behind the tree wooden or metallic?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=VQA(image=IMAGE0,question='What material is the lamp made of?')\nANSWER1=EVAL(expr=\"'wooden' if {ANSWER0} == 'wooden' else 'metallic'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1720, "imageId": "n355567", "question": "What is standing beside the person to the right of the lady?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is standing beside the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1721, "imageId": "n126891", "question": "Are there either old men or women in the picture?", "program": "BOX0=LOC(image=IMAGE,object='old men')\nBOX1=LOC(image=IMAGE,object='women')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1722, "imageId": "n200225", "question": "Does the pepper look green?", "program": "BOX0=LOC(image=IMAGE,object='pepper')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the pepper?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1723, "imageId": "n541482", "question": "Is the woman wearing a scarf?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the woman wearing a scarf?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'scarf' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1724, "imageId": "n258500", "question": "What is the color of the devices in the top part?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the devices?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1725, "imageId": "n403734", "question": "Is the bottle to the left of the purse made of plastic or glass?", "program": "BOX0=LOC(image=IMAGE,object='purse')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=VQA(image=IMAGE0,question='What material is the bottle made of?')\nANSWER1=EVAL(expr=\"'plastic' if {ANSWER0} == 'plastic' else 'glass'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1726, "imageId": "n281241", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1727, "imageId": "n331357", "question": "On which side of the picture is the drink?", "program": "BOX0=LOC(image=IMAGE,object='drink')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1728, "imageId": "n232810", "question": "Does the suitcase on the floor have red color?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the suitcase?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1729, "imageId": "n281241", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1730, "imageId": "n258500", "question": "What's under the skater?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the skater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1731, "imageId": "n282436", "question": "What is the dog that looks brown and black sitting on?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the dog sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1732, "imageId": "n398257", "question": "Is the chair yellow and metallic?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=VQA(image=IMAGE0,question='What material is the chair made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1733, "imageId": "n524855", "question": "Are the trees short and green?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nANSWER0=VQA(image=IMAGE,question='Are the trees short?')\nANSWER1=VQA(image=IMAGE,question='Are the trees green?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1734, "imageId": "n398257", "question": "What material is the black chair made of?", "program": "BOX0=LOC(image=IMAGE,object='black chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the chair made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1735, "imageId": "n228268", "question": "Is the oar blue?", "program": "BOX0=LOC(image=IMAGE,object='oar')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the oar?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1736, "imageId": "n55058", "question": "Does the mug appear to be round and large?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the mug round?')\nANSWER1=VQA(image=IMAGE0,question='Is the mug large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1737, "imageId": "n55058", "question": "Does the mug look small or large?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE,question='Does the mug look small or large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1738, "imageId": "n65230", "question": "What are the shoes in front of?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the shoes in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1739, "imageId": "n59147", "question": "What is the wide piece of furniture?", "program": "BOX0=LOC(image=IMAGE,object='wide piece of furniture')\nANSWER0=VQA(image=IMAGE,question='What is the wide piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1740, "imageId": "n65230", "question": "What is the item of furniture that the shoes are in front of?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1741, "imageId": "n526228", "question": "How large are the closed books on top of the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='closed books')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large are the closed books?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1742, "imageId": "n65230", "question": "Are the shoes in front of a lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shoes')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1743, "imageId": "n127705", "question": "Are the shorts clean and blue?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE0,question='Are the shorts clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1744, "imageId": "n283587", "question": "Which kind of furniture is in front of the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is in front of the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1745, "imageId": "n283587", "question": "What kind of furniture is in front of the window that looks square?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC_SHAPE(image=IMAGE0,shape='square')\nBOX2=LOC(image=IMAGE0,object='furniture')\nBOX3=INTERSECT(box1=BOX1,box2=BOX2)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is in front of the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1746, "imageId": "n437192", "question": "Are there any large bears?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='large')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1747, "imageId": "n255161", "question": "What do the sign post and the artwork have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the sign post and the artwork have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1748, "imageId": "n119944", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1749, "imageId": "n352479", "question": "Is the snowboarder wearing goggles?", "program": "BOX0=LOC(image=IMAGE,object='snowboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the snowboarder wearing goggles?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'goggles' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1750, "imageId": "n312206", "question": "Who is the pie in front of?", "program": "BOX0=LOC(image=IMAGE,object='pie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the pie in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1751, "imageId": "n496803", "question": "Is the blue sign bigger than the logo?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the blue sign bigger than the logo?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1752, "imageId": "n352479", "question": "Who is wearing the ground?", "program": "There seems to be an error in the program. It is not clear what is meant by \"wearing the ground.\" Could you please provide more information or clarify the question?"}, {"index": 1753, "imageId": "n352479", "question": "Who is wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1754, "imageId": "n466319", "question": "Is the beach dry or wet?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the beach dry or wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1755, "imageId": "n527589", "question": "Do you see any women or men that are standing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nBOX1=LOC(image=IMAGE,object='man')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1756, "imageId": "n65866", "question": "What kind of furniture is not wooded?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is not wooded?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1757, "imageId": "n151768", "question": "Who is sitting on top of the steps?", "program": "BOX0=LOC(image=IMAGE,object='steps')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting on top of the steps?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1758, "imageId": "n259949", "question": "The hat the skater is wearing is of what color?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1759, "imageId": "n481777", "question": "What is the gender of the person to the right of the other person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the gender of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1760, "imageId": "n342511", "question": "Is there a dog in the image that is not uncomfortable?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='uncomfortable')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1761, "imageId": "n240973", "question": "What is the laptop sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the laptop sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1762, "imageId": "n240973", "question": "Is the device to the left of the shelves sitting beside the chicken?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE,object='chicken')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nANSWER0=EVAL(expr=\"'yes' if {IMAGE1} == {IMAGE2} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1763, "imageId": "n433532", "question": "What appliance is dark?", "program": "BOX0=LOC(image=IMAGE,object='dark')\nANSWER0=VQA(image=IMAGE,question='What appliance is dark?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1764, "imageId": "n219840", "question": "Does the wide sky look cloudy?", "program": "BOX0=LOC(image=IMAGE,object='wide sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the wide sky look cloudy?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'cloudy' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1765, "imageId": "n481777", "question": "Does the female person seem to be looking down?", "program": "BOX0=LOC(image=IMAGE,object='female person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the female person seem to be looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1766, "imageId": "n264887", "question": "What is the device that is on?", "program": "BOX0=LOC(image=IMAGE,object='on')\nANSWER0=VQA(image=IMAGE,question='What is the device that is on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1767, "imageId": "n433532", "question": "What kind of appliance is warm?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of appliance is warm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1768, "imageId": "n437064", "question": "What is the fork made of?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fork made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1769, "imageId": "n470920", "question": "Is the bag that looks brown sitting on top of a towel?", "program": "BOX0=LOC(image=IMAGE,object='brown bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towel')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1770, "imageId": "n497789", "question": "What is the fence around of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence around of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1771, "imageId": "n65230", "question": "What is the rug in front of?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the rug in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1772, "imageId": "n151768", "question": "What is the woman sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1773, "imageId": "n119886", "question": "On which side of the picture is the toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1774, "imageId": "n485969", "question": "What is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1775, "imageId": "n485969", "question": "What is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nANSWER0=VQA(image=IMAGE,question='What is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1776, "imageId": "n485969", "question": "What is throwing the baseball?", "program": "BOX0=LOC(image=IMAGE,object='baseball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is throwing the baseball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1777, "imageId": "n485969", "question": "What's the pitcher throwing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the pitcher throwing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1778, "imageId": "n162586", "question": "What is the color of the clothes made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='clothes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the clothes?')\nANSWER1=EVAL(expr=\"'cloth' if {ANSWER0} != 'unknown' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1779, "imageId": "n520071", "question": "Are the colorful books to the right of a radio?", "program": "BOX0=LOC(image=IMAGE,object='radio')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='colorful books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1780, "imageId": "n146522", "question": "On which side of the photo is the backpack?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1781, "imageId": "n181355", "question": "Does the hat appear to be crooked?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nANSWER0=VQA(image=IMAGE,question='Does the hat appear to be crooked?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1782, "imageId": "n181355", "question": "What is the magazine lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='magazine')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the magazine lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1783, "imageId": "n181355", "question": "Which kind of furniture is the magazine lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='magazine')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the magazine lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1784, "imageId": "n573460", "question": "Are these empty chairs?", "program": "BOX0=LOC(image=IMAGE,object='chairs')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1785, "imageId": "n28996", "question": "Is the spoon on top of the food below the grapes?", "program": "BOX0=LOC(image=IMAGE,object='grapes')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='spoon')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1786, "imageId": "n48494", "question": "Does the blue sky look cloudless?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the sky look cloudless?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1787, "imageId": "n181355", "question": "The woman is sitting on what?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The woman is sitting on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1788, "imageId": "n223750", "question": "Is the dress sleeveless?", "program": "BOX0=LOC(image=IMAGE,object='dress')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the dress sleeveless?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'sleeveless' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1789, "imageId": "n140421", "question": "What is covered by the curtains?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is covered by the curtains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1790, "imageId": "n140421", "question": "What is the window near the clock covered by?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the window covered by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1791, "imageId": "n432591", "question": "Is it a bedroom or a bathroom?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it a bedroom or a bathroom?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1792, "imageId": "n276011", "question": "What are the pieces of furniture underneath the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1793, "imageId": "n317260", "question": "Do the bat and the glove have the same color?", "program": "BOX0=LOC(image=IMAGE,object='bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='glove')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the glove?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1794, "imageId": "n279173", "question": "Is there a horse or a cow that is not tan?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nBOX1=LOC(image=IMAGE,object='cow')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if ({ANSWER0} > 0 or {ANSWER1} > 0) and not ({ANSWER0} > 0 and {ANSWER1} > 0) else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1795, "imageId": "n278453", "question": "What's on the ham?", "program": "BOX0=LOC(image=IMAGE,object='ham')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the ham?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1796, "imageId": "n276011", "question": "Are the chairs near the flowers comfortable or uncomfortable?", "program": "BOX0=LOC(image=IMAGE,object='chairs')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flowers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'comfortable' if {ANSWER0} > 0 else 'uncomfortable'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1797, "imageId": "n276011", "question": "What is underneath the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1798, "imageId": "n276011", "question": "What is underneath the covered table?", "program": "BOX0=LOC(image=IMAGE,object='covered table')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the covered table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1799, "imageId": "n410289", "question": "Is the ceiling above a bathtub?", "program": "BOX0=LOC(image=IMAGE,object='bathtub')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ceiling')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1800, "imageId": "n89148", "question": "What is lying next to the brick building?", "program": "BOX0=LOC(image=IMAGE,object='brick building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='next to')\nANSWER0=VQA(image=IMAGE0,question='What is lying next to the brick building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1801, "imageId": "n89148", "question": "Is the ladder below the windows?", "program": "BOX0=LOC(image=IMAGE,object='windows')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ladder')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1802, "imageId": "n255161", "question": "Is the cloudy sky beautiful or ugly?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the cloudy sky beautiful or ugly?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1803, "imageId": "n410289", "question": "Is the ceiling above a toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ceiling')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1804, "imageId": "n199758", "question": "Does the tall person look Asian?", "program": "BOX0=LOC(image=IMAGE,object='tall person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the tall person look Asian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1805, "imageId": "n12214", "question": "What is the skater holding onto?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skater holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1806, "imageId": "n12214", "question": "Who is holding onto the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding onto the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1807, "imageId": "n507959", "question": "What sits on top of the table that to the left of the guitar?", "program": "BOX0=LOC(image=IMAGE,object='guitar')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What sits on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1808, "imageId": "n28996", "question": "What do the brownie and the container have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the brownie and the container have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1809, "imageId": "n302387", "question": "Do you see instruments next to the fireplace?", "program": "BOX0=LOC(image=IMAGE,object='fireplace')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='instruments')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1810, "imageId": "n192021", "question": "Does the chair on the carpet look dark and round?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER3=VQA(image=IMAGE0,question='What shape is the chair?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'dark' and {ANSWER3} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1811, "imageId": "n412144", "question": "Where is the skateboarder near the fence standing on?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0,object='fence')\nANSWER0=VQA(image=IMAGE0,question='Where is the skateboarder near the fence standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1812, "imageId": "n202379", "question": "What is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1813, "imageId": "n501951", "question": "Who is riding?", "program": "BOX0=LOC(image=IMAGE,object='riding')\nANSWER0=VQA(image=IMAGE,question='Who is riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1814, "imageId": "n187961", "question": "Is the person near the goat wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='goat')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the person wearing a hat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1815, "imageId": "n52544", "question": "Is the blouse different in color than the name tag?", "program": "BOX0=LOC(image=IMAGE,object='blouse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='name tag')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the blouse?')\nANSWER1=VQA(image=IMAGE1,question='What color is the name tag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1816, "imageId": "n181210", "question": "On which side of the picture is the orange?", "program": "BOX0=LOC(image=IMAGE,object='orange')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1817, "imageId": "n131634", "question": "Is the van to the left of the car large and blue?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='van')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the van?')\nANSWER3=VQA(image=IMAGE0,question='Is the van large?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'blue' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1818, "imageId": "n187961", "question": "Where is the kid?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nANSWER0=VQA(image=IMAGE,question='Where is the kid?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1819, "imageId": "n260762", "question": "What color is the vehicle on the field?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1820, "imageId": "n95313", "question": "What is the item of furniture that the bed is in front of?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1821, "imageId": "n119944", "question": "Is the chicken standing?", "program": "BOX0=LOC(image=IMAGE,object='chicken')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1822, "imageId": "n216553", "question": "What color is the wood fence?", "program": "BOX0=LOC(image=IMAGE,object='wood fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the wood fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1823, "imageId": "n350766", "question": "What cooking utensil is to the left of the toaster?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1824, "imageId": "n350766", "question": "What cooking utensil is to the left of the electric appliance above the drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='electric appliance')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='cooking utensil')\nANSWER0=VQA(image=IMAGE1,question='What cooking utensil is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1825, "imageId": "n126087", "question": "Is the happy man wearing a cap?", "program": "BOX0=LOC(image=IMAGE,object='happy man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the happy man wearing a cap?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'cap' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1826, "imageId": "n210269", "question": "Which color is the hair that is not long?", "program": "BOX0=LOC(image=IMAGE,object='hair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='long')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which color is the hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1827, "imageId": "n518912", "question": "How tall is the chair that the man stands beside of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='How tall is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1828, "imageId": "n493357", "question": "What is the giraffe that is walking walking next to?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the giraffe walking next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1829, "imageId": "n195249", "question": "Does the necklace look thick?", "program": "BOX0=LOC(image=IMAGE,object='necklace')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the necklace look thick?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'thick' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1830, "imageId": "n119944", "question": "The male person is sitting on what?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The male person is sitting on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1831, "imageId": "n90294", "question": "Does the book have the same color as the charger?", "program": "BOX0=LOC(image=IMAGE,object='book')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='charger')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the book?')\nANSWER1=VQA(image=IMAGE1,question='What color is the charger?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1832, "imageId": "n179136", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1833, "imageId": "n518912", "question": "Are there chairs in this image that are not white?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=VQA(image=IMAGE,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if 'white' not in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1834, "imageId": "n210269", "question": "Is the hair on top of the horses long and white?", "program": "BOX0=LOC(image=IMAGE,object='horses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the hair long and white?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'long and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1835, "imageId": "n119944", "question": "Who is sitting next to the bag that is to the right of the elephant?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is sitting next to the bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1836, "imageId": "n88933", "question": "Is there a bottle or a cup?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nBOX1=LOC(image=IMAGE,object='cup')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1837, "imageId": "n318370", "question": "What is the person next to the sign eating?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person eating?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1838, "imageId": "n318370", "question": "What type of baked good is the person to the right of the bottle eating?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of baked good is the person eating?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1839, "imageId": "n507959", "question": "Are there cabinets to the left of the standing people that are standing behind the luggage?", "program": "BOX0=LOC(image=IMAGE,object='standing people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='luggage')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='cabinets')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1840, "imageId": "n523165", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1841, "imageId": "n77818", "question": "What is the shape of the book?", "program": "BOX0=LOC(image=IMAGE,object='book')\nANSWER0=VQA(image=IMAGE,question='What is the shape of the book?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1842, "imageId": "n496803", "question": "Are the gray chairs in the bottom or in the top of the image?", "program": "BOX0=LOC(image=IMAGE,object='gray chair')\nBOX1=LOC(image=IMAGE,object='TOP')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1843, "imageId": "n162148", "question": "Does the hair on top of the woman look curly?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the hair on top of the woman look curly?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1844, "imageId": "n97485", "question": "Are the shelves made of the same material as the utensils?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='utensils')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material are the shelves made of?')\nANSWER1=VQA(image=IMAGE1,question='What material are the utensils made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1845, "imageId": "n514467", "question": "Are the denim jeans blue and long?", "program": "BOX0=LOC(image=IMAGE,object='denim jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the denim jeans?')\nANSWER1=VQA(image=IMAGE0,question='Are the denim jeans long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1846, "imageId": "n571179", "question": "What is the color of the house made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='house')\nANSWER0=VQA(image=IMAGE0,question='What is the color of the house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1847, "imageId": "n479092", "question": "Are the sandwiches to the left of the napkin triangular and soft?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sandwiches')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Are the sandwiches triangular and soft?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1848, "imageId": "n262920", "question": "Are there TVs or controllers?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nBOX1=LOC(image=IMAGE,object='controller')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1849, "imageId": "n199097", "question": "Does that street sign look red?", "program": "BOX0=LOC(image=IMAGE,object='street sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the street sign?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1850, "imageId": "n296467", "question": "Which kind of dessert is sprinkled?", "program": "BOX0=LOC(image=IMAGE,object='sprinkles')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of dessert is sprinkled?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1851, "imageId": "n51002", "question": "Which kind of furniture is the pillow on?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the pillow on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1852, "imageId": "n441859", "question": "Are there people to the right of the life vest?", "program": "BOX0=LOC(image=IMAGE,object='life vest')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='people')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1853, "imageId": "n560243", "question": "Are there any glasses or tennis balls?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nBOX1=LOC(image=IMAGE,object='tennis ball')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1854, "imageId": "n441859", "question": "Does the person to the left of the life vest look male or female?", "program": "BOX0=LOC(image=IMAGE,object='life vest')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Does the person look male or female?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1855, "imageId": "n51002", "question": "What do you think is on the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is on the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1856, "imageId": "n39114", "question": "Is the shirt short sleeved and black?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of sleeves does the shirt have?')\nANSWER1=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'short sleeved' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1857, "imageId": "n551964", "question": "Are there engineers or police officers in this picture?", "program": "BOX0=LOC(image=IMAGE,object='engineer')\nBOX1=LOC(image=IMAGE,object='police officer')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1858, "imageId": "n54424", "question": "What is the vehicle to the left of the Wii remotes that is not big?", "program": "BOX0=LOC(image=IMAGE,object='Wii remotes')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the size of the vehicle?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'big' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1859, "imageId": "n579256", "question": "What is hang from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hang from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1860, "imageId": "n211324", "question": "How big is the bicycle the baby is on?", "program": "BOX0=LOC(image=IMAGE,object='baby')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bicycle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,questio='How big is the bicycle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1861, "imageId": "n274905", "question": "What's the player in front of?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the player in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1862, "imageId": "n326988", "question": "Which kind of furniture is to the left of the cabinets?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is to the left of the cabinets?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1863, "imageId": "n123075", "question": "Is there brown mud or grass?", "program": "BOX0=LOC(image=IMAGE,object='mud')\nBOX1=LOC(image=IMAGE,object='grass')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1864, "imageId": "n274905", "question": "Who is wearing an earring?", "program": "BOX0=LOC(image=IMAGE,object='earring')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing an earring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1865, "imageId": "n274905", "question": "Who is wearing the earring?", "program": "BOX0=LOC(image=IMAGE,object='earring')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the earring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1866, "imageId": "n77818", "question": "On which side of the picture is the metal device?", "program": "BOX0=LOC(image=IMAGE,object='metal device')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1867, "imageId": "n449058", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1868, "imageId": "n449058", "question": "Who is wearing the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1870, "imageId": "n279581", "question": "The net has what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the net?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1871, "imageId": "n65885", "question": "What kind of furniture do you think is the table in front of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is in front of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1872, "imageId": "n125122", "question": "Are there both a television and a phone in the photo?", "program": "BOX0=LOC(image=IMAGE,object='television')\nBOX1=LOC(image=IMAGE,object='phone')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1873, "imageId": "n525901", "question": "What is the item of furniture that the window is behind of?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1874, "imageId": "n526228", "question": "Does the coffee table in front of the man look small and wooden?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='coffee table')\nANSWER0=VQA(image=IMAGE0,question='What does the coffee table look like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small and wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1875, "imageId": "n23181", "question": "Which kind of furniture is sturdy, the desk or the couch?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is sturdy?')\nANSWER1=EVAL(expr=\"'desk' if {ANSWER0} == 'couch' else 'couch'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1876, "imageId": "n433692", "question": "What kind of animal is lying next to the computer mouse?", "program": "BOX0=LOC(image=IMAGE,object='computer mouse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is lying next to the computer mouse?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1877, "imageId": "n66756", "question": "Is the catcher to the left or to the right of the umpire that is on the left?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='catcher')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1878, "imageId": "n412144", "question": "Is the shirt white and short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the shirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'short sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1879, "imageId": "n90944", "question": "What do the people walk on?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do the people walk on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1880, "imageId": "n90944", "question": "What do the people that are walking walk on?", "program": "BOX0=LOC(image=IMAGE,object='walking people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do the people that are walking walk on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1881, "imageId": "n145498", "question": "What are the pieces of furniture that are on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1882, "imageId": "n145498", "question": "Which kind of furniture is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is on top of the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1883, "imageId": "n355339", "question": "Is the clear glass small or large?", "program": "BOX0=LOC(image=IMAGE,object='clear glass')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} < 100 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1884, "imageId": "n274905", "question": "What is common to the tennis racket and the fence?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the tennis racket and the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1885, "imageId": "n167552", "question": "Does that chair seem to be wide and metallic?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the chair seem wide?')\nANSWER1=VQA(image=IMAGE0,question='Does the chair seem metallic?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1886, "imageId": "n315887", "question": "What kind of device is to the left of the phone?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is to the left of the phone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1887, "imageId": "n257997", "question": "How tall is the grass?", "program": "ANSWER0=VQA(image=IMAGE,question='How tall is the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1888, "imageId": "n451187", "question": "Are the people female?", "program": "BOX0=LOC(image=IMAGE,object='people')\nANSWER0=VQA(image=IMAGE,question='Are the people female?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1889, "imageId": "n554880", "question": "What color is the sweater the woman is wearing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sweater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1890, "imageId": "n172618", "question": "Is the girl in front of the other girl short and old?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other girl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='short')\nANSWER2=COUNT(box=BOX2)\nBOX3=LOC(image=IMAGE0,object='old')\nANSWER3=COUNT(box=BOX3)\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} > 0 and {ANSWER3} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 1891, "imageId": "n282436", "question": "What's standing on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1892, "imageId": "n496803", "question": "Who wears the sneakers?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the sneakers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1893, "imageId": "n65885", "question": "What is the animal that is to the left of the cabinet called?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1894, "imageId": "n282436", "question": "What is the piece of furniture that the table lamp is standing on?", "program": "BOX0=LOC(image=IMAGE,object='table lamp')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1895, "imageId": "n65885", "question": "The furry animal near the window is lying on what?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furry animal')\nIMAGE1=CROP_NEAR(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the furry animal lying on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1896, "imageId": "n554880", "question": "What piece of clothing is blue?", "program": "BOX0=LOC(image=IMAGE,object='blue')\nANSWER0=VQA(image=IMAGE,question='What piece of clothing is blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1897, "imageId": "n257997", "question": "Is the grass short and green?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the length of the grass?')\nANSWER1=VQA(image=IMAGE0,question='What is the color of the grass?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'short' and {ANSWER1} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1898, "imageId": "n460556", "question": "Do you see dark backpacks or cars?", "program": "BOX0=LOC(image=IMAGE,object='backpack', color='dark')\nBOX1=LOC(image=IMAGE,object='car', color='dark')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1899, "imageId": "n310828", "question": "Which side is the person on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1900, "imageId": "n544255", "question": "What animal is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown')\nANSWER0=VQA(image=IMAGE,question='What animal is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1901, "imageId": "n262920", "question": "Is there a DVD player to the right of him?", "program": "BOX0=LOC(image=IMAGE,object='him')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='DVD player')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1902, "imageId": "n170941", "question": "What is the fluffy food called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fluffy food called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1903, "imageId": "n151768", "question": "Is the purse black?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the purse?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1904, "imageId": "n170941", "question": "Which kind of food is yellow?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of food is yellow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1905, "imageId": "n64959", "question": "What is bigger than the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is bigger than the stove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1906, "imageId": "n170941", "question": "What is located on top of the pancake?", "program": "BOX0=LOC(image=IMAGE,object='pancake')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the pancake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1907, "imageId": "n557666", "question": "Are these people the same gender?", "program": "ANSWER0=VQA(image=IMAGE,question='Are these people the same gender?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1908, "imageId": "n305495", "question": "Is the fan small?", "program": "BOX0=LOC(image=IMAGE,object='fan')\nANSWER0=VQA(image=IMAGE,question='Is the fan small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1909, "imageId": "n118102", "question": "Behind what kind of furniture is the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Behind what kind of furniture is the stove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1910, "imageId": "n118102", "question": "What appliance is behind the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is behind the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1911, "imageId": "n51002", "question": "What is common to the pillow and the fireplace?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the pillow and the fireplace?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1912, "imageId": "n153118", "question": "What is in front of the brick buildings?", "program": "BOX0=LOC(image=IMAGE,object='brick buildings')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the brick buildings?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1913, "imageId": "n398429", "question": "Does the white window look closed?", "program": "BOX0=LOC(image=IMAGE,object='white window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the window look closed?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'closed' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1914, "imageId": "n67005", "question": "Is the jacket that is made of cotton yellow or gray?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the jacket made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'cotton' and ({ANSWER1} == 'yellow' or {ANSWER1} == 'gray') else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1915, "imageId": "n554880", "question": "Is the chair to the left or to the right of the cellphone?", "program": "BOX0=LOC(image=IMAGE,object='cellphone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1916, "imageId": "n250715", "question": "Who is wearing the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1917, "imageId": "n250715", "question": "Who is wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1918, "imageId": "n184385", "question": "Is the round vegetable cooked or raw?", "program": "BOX0=LOC(image=IMAGE,object='round vegetable')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the round vegetable cooked or raw?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1919, "imageId": "n25275", "question": "Is that a short fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='Is that a short fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1920, "imageId": "n250715", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1921, "imageId": "n283587", "question": "What is in front of the large sofa?", "program": "BOX0=LOC(image=IMAGE,object='large sofa')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the large sofa?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1922, "imageId": "n283587", "question": "What's in front of the sofa?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the sofa?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1923, "imageId": "n6908", "question": "Are the flowers above the leaves sitting next to the chair?", "program": "BOX0=LOC(image=IMAGE,object='leaves')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flowers')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='chair')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1924, "imageId": "n246334", "question": "Does this sheet have long length and white color?", "program": "BOX0=LOC(image=IMAGE,object='sheet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the length of the sheet?')\nANSWER1=VQA(image=IMAGE0,question='What color is the sheet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'long' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1925, "imageId": "n554880", "question": "What is the item of furniture that the laptop computer to the right of the woman is sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop computer')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1926, "imageId": "n554880", "question": "What is the laptop sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the laptop sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1927, "imageId": "n6908", "question": "What is sitting next to the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting next to the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1928, "imageId": "n6908", "question": "What is sitting next to the comfortable chair?", "program": "BOX0=LOC(image=IMAGE,object='comfortable chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting next to the comfortable chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1929, "imageId": "n6908", "question": "What are the flowers sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the flowers sitting next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1930, "imageId": "n6908", "question": "What item of furniture are the flowers sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What item of furniture are the flowers sitting next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1931, "imageId": "n89148", "question": "What color is the doll below the windows?", "program": "BOX0=LOC(image=IMAGE,object='windows')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='doll')\nANSWER0=VQA(image=IMAGE0,question='What color is the doll?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1932, "imageId": "n276011", "question": "What is the old picture hanging above, a bed or a table?", "program": "BOX0=LOC(image=IMAGE,object='old picture')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nBOX2=LOC(image=IMAGE0,object='table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'bed' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1933, "imageId": "n12404", "question": "Is the hydrant on the right?", "program": "BOX0=LOC(image=IMAGE,object='hydrant')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1934, "imageId": "n184551", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1935, "imageId": "n28792", "question": "Is the road rough or smooth?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the road rough or smooth?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1936, "imageId": "n560243", "question": "Who is the shirt worn on?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the shirt worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1937, "imageId": "n23762", "question": "Does the room have small size?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the room have small size?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1938, "imageId": "n479092", "question": "Are the knives made of the same material as the forks?", "program": "BOX0=LOC(image=IMAGE,object='forks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='knives')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material are the forks made of?')\nANSWER1=VQA(image=IMAGE1,question='What material are the knives made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1939, "imageId": "n298104", "question": "What color are the mountains next to the ocean?", "program": "BOX0=LOC(image=IMAGE,object='ocean')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mountains')\nANSWER0=VQA(image=IMAGE0,question='What color are the mountains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1940, "imageId": "n381072", "question": "Do you see either a cake or a plate there?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nBOX1=LOC(image=IMAGE,object='plate')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1941, "imageId": "n434283", "question": "Are there both windows and doors in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1942, "imageId": "n479092", "question": "What do the plate and the jar have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the plate and the jar have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1943, "imageId": "n434283", "question": "Is the brown sand under the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown sand')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1944, "imageId": "n434283", "question": "What is under the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1945, "imageId": "n434283", "question": "What is under the mirror in the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is under the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1946, "imageId": "n318684", "question": "Are there men to the right of the glasses in the middle?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='men')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='middle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1947, "imageId": "n501609", "question": "What is the appliance on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the appliance on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1948, "imageId": "n159802", "question": "Are both the sweatshirt and the striped blouse black?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='striped blouse')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the sweatshirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the striped blouse?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1949, "imageId": "n6309", "question": "What kind of animal is to the left of the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is to the left of the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1950, "imageId": "n386688", "question": "Which kind of watercraft is to the right of the boats?", "program": "BOX0=LOC(image=IMAGE,object='boats')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of watercraft is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1951, "imageId": "n88933", "question": "Is the boy eating?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the boy eating?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1952, "imageId": "n59627", "question": "Is the blanket large or small?", "program": "BOX0=LOC(image=IMAGE,object='blanket')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'large' if {ANSWER0} > 100 else 'small'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1953, "imageId": "n532213", "question": "Is the street narrow?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the street narrow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1954, "imageId": "n49438", "question": "Does the narrow bed have small size?", "program": "BOX0=LOC(image=IMAGE,object='narrow bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the narrow bed?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1955, "imageId": "n97485", "question": "What piece of furniture is clean?", "program": "BOX0=LOC(image=IMAGE,object='clean')\nANSWER0=VQA(image=IMAGE,question='What piece of furniture is clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1956, "imageId": "n86120", "question": "Which kind of animal is the woman petting?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is the woman petting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1957, "imageId": "n508733", "question": "Are they in front of the window frame that is square?", "program": "BOX0=LOC(image=IMAGE,object='window frame')\nBOX1=LOC(image=IMAGE,object='square')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the window frame?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the window frame?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'window frame' and {ANSWER1} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1958, "imageId": "n171169", "question": "What does the man cover?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the man cover?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1959, "imageId": "n497789", "question": "Is there either a fence or a flag in the picture?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='flag')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1960, "imageId": "n508733", "question": "What are the women in front of?", "program": "BOX0=LOC(image=IMAGE,object='women')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the women in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1961, "imageId": "n415215", "question": "Are both the toilet brush and the tool made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='toilet brush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='tool')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the toilet brush made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the tool made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1962, "imageId": "n415215", "question": "Is the mirror made of the same material as the tool?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='tool')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the mirror made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the tool made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1963, "imageId": "n497789", "question": "Are the striped zebras standing in front of the giraffes?", "program": "BOX0=LOC(image=IMAGE,object='zebras')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='giraffes')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=IMAGE1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1964, "imageId": "n240666", "question": "Does the toilet paper underneath the window look large and round?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet paper')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1965, "imageId": "n173807", "question": "Do the large buildings look short?", "program": "BOX0=LOC(image=IMAGE,object='large buildings')\nANSWER0=VQA(image=IMAGE,question='Do the large buildings look short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1966, "imageId": "n285391", "question": "Are there both pillows and papers in this picture?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nBOX1=LOC(image=IMAGE,object='paper')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1967, "imageId": "n497789", "question": "What animal is standing in front of the giraffes?", "program": "BOX0=LOC(image=IMAGE,object='giraffes')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is standing in front?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1968, "imageId": "n171169", "question": "Who covers the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who covers the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1969, "imageId": "n23181", "question": "Is the lamp that is not turned-on silver and tall?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='turned-on lamp')\nBOX2=DIFF(box1=BOX0,box2=BOX1)\nANSWER0=VQA(image=IMAGE,question='What color is the lamp?')\nANSWER1=VQA(image=IMAGE,question='Is the lamp tall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1970, "imageId": "n12404", "question": "Who is standing beside the dirt the water is touching?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='water')\nIMAGE1=CROP_BESIDE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is standing beside the dirt the water is touching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1971, "imageId": "n23181", "question": "How does the silver lamp appear to be, on or off?", "program": "BOX0=LOC(image=IMAGE,object='silver lamp')\nANSWER0=VQA(image=IMAGE,question='How does the silver lamp appear to be, on or off?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1972, "imageId": "n500308", "question": "Which kind of appliance is clean?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1973, "imageId": "n204894", "question": "Which color does the rug on the right side of the picture have?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=VQA(image=IMAGE0,question='What color is the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1974, "imageId": "n579928", "question": "Are the grouped people standing on the grass?", "program": "BOX0=LOC(image=IMAGE,object='grouped people')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the surface they are standing on?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'grass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1975, "imageId": "n126891", "question": "What color is the boy's hair?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the boy\\'s hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1976, "imageId": "n143935", "question": "What kind of animal is large?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of animal is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1977, "imageId": "n283587", "question": "Is the cupboard square?", "program": "BOX0=LOC(image=IMAGE,object='cupboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the cupboard square?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1978, "imageId": "n450919", "question": "Is there a small hat or fence?", "program": "BOX0=LOC(image=IMAGE,object='small hat')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1979, "imageId": "n143672", "question": "Is the forest made of wood?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the forest made of wood?')\nANSWER1=EVAL(expr=\"'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1980, "imageId": "n143672", "question": "Is the snowy forest green or brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the snowy forest?')\nANSWER1=EVAL(expr=\"'green' if {ANSWER0} == 'green' else 'brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1981, "imageId": "n406334", "question": "On which side of the image are the metal cars?", "program": "BOX0=LOC(image=IMAGE,object='metal cars')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1982, "imageId": "n6309", "question": "Do the horses to the left of the jockey look adult?", "program": "BOX0=LOC(image=IMAGE,object='jockey')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horses')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1983, "imageId": "n477702", "question": "Is the bald man wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='bald man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the bald man wearing glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1984, "imageId": "n206785", "question": "What kind of furniture is this?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1985, "imageId": "n411121", "question": "Is the small bag to the right or to the left of the person that is not male?", "program": "BOX0=LOC(image=IMAGE,object='person',attribute='not male')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1986, "imageId": "n411121", "question": "What is the color of the clean shirt?", "program": "BOX0=LOC(image=IMAGE,object='clean shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the clean shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1987, "imageId": "n477702", "question": "What is the bald man sitting on?", "program": "BOX0=LOC(image=IMAGE,object='bald man')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bald man sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1988, "imageId": "n541688", "question": "Is the person in front of the table small and blond?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Is the person small and blond?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 1989, "imageId": "n290409", "question": "What is the color of the basket that the truck is in front of?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='basket')\nANSWER0=VQA(image=IMAGE0,question='What color is the basket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1990, "imageId": "n223750", "question": "Which kind of clothing is gray?", "program": "BOX0=LOC(image=IMAGE,object='gray clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is gray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1991, "imageId": "n100991", "question": "Is the cup made of glass?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the cup made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'glass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1992, "imageId": "n496803", "question": "Are there any athletes to the left of the person that is bigger than the sneakers?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sneakers')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='athlete')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1993, "imageId": "n39114", "question": "On which side of the image is the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1994, "imageId": "n184551", "question": "What is the man covered by?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man covered by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1995, "imageId": "n263180", "question": "Where is this?", "program": "ANSWER0=VQA(image=IMAGE,question='Where is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1996, "imageId": "n413319", "question": "Do the socks and the shorts have the same color?", "program": "BOX0=LOC(image=IMAGE,object='socks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shorts')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the socks?')\nANSWER1=VQA(image=IMAGE1,question='What color are the shorts?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 1997, "imageId": "n184551", "question": "Is the person to the left of the bag covered by an umbrella?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='umbrella')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 1998, "imageId": "n184551", "question": "What is the man on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 1999, "imageId": "n184551", "question": "Who is on the steps?", "program": "BOX0=LOC(image=IMAGE,object='steps')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is on the steps?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2000, "imageId": "n472825", "question": "Is the staircase below a snowboarder?", "program": "BOX0=LOC(image=IMAGE,object='snowboarder')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='staircase')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2001, "imageId": "n367944", "question": "Is the device to the right of the bag white and open?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the device?')\nANSWER1=VQA(image=IMAGE0,question='Is the device open?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2002, "imageId": "n302387", "question": "What is this suitcase on?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is this suitcase on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2003, "imageId": "n302387", "question": "What is the suitcase on?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the suitcase on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2004, "imageId": "n143935", "question": "What is the pasture surrounded by?", "program": "BOX0=LOC(image=IMAGE,object='pasture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pasture surrounded by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2005, "imageId": "n250715", "question": "Is the large chair to the right or to the left of the controller?", "program": "BOX0=LOC(image=IMAGE,object='controller')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2006, "imageId": "n143935", "question": "Is there a giraffe or a cow in the picture?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nBOX1=LOC(image=IMAGE,object='cow')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2007, "imageId": "n234683", "question": "Who is in front of the frame made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the frame made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2008, "imageId": "n289376", "question": "What place is shown?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is shown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2009, "imageId": "n315859", "question": "What is the shape of the windows?", "program": "BOX0=LOC(image=IMAGE,object='windows')\nANSWER0=VQA(image=IMAGE,question='What is the shape of the windows?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2010, "imageId": "n289376", "question": "What type of weather do you see?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of weather do you see?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2011, "imageId": "n234683", "question": "Is the fat man behind the plain wall?", "program": "BOX0=LOC(image=IMAGE,object='fat man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plain wall')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2012, "imageId": "n534106", "question": "What is the item of furniture called?", "program": "BOX0=LOC(image=IMAGE,object='item of furniture')\nANSWER0=VQA(image=IMAGE,question='What is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2013, "imageId": "n314630", "question": "What appliance is the paper towel reflected in?", "program": "BOX0=LOC(image=IMAGE,object='paper towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is the paper towel reflected in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2014, "imageId": "n513100", "question": "What is the bird standing on top of?", "program": "BOX0=LOC(image=IMAGE,object='bird')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bird standing on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2015, "imageId": "n525029", "question": "Is there a bus in this image?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2016, "imageId": "n551964", "question": "Is the person to the left of the motorcycle wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2017, "imageId": "n250821", "question": "What animal is the man watching?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the man watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2018, "imageId": "n206358", "question": "What place is this picture in?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is this picture in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2019, "imageId": "n79078", "question": "Is the shirt red?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2020, "imageId": "n363445", "question": "What is the food container made of?", "program": "BOX0=LOC(image=IMAGE,object='food container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the food container made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2021, "imageId": "n363445", "question": "What is on the table made of wood?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the table made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2022, "imageId": "n398257", "question": "What kind of device is made of the same material as the device above the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What material is the device made of?')\nANSWER1=VQA(image=IMAGE,question='What kind of device is made of {ANSWER0}?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2023, "imageId": "n363445", "question": "What's on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2024, "imageId": "n363445", "question": "What is the food container on?", "program": "BOX0=LOC(image=IMAGE,object='food container')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the food container on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2025, "imageId": "n433692", "question": "What shape is the mousepad, square or round?", "program": "BOX0=LOC(image=IMAGE,object='mousepad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the mousepad?')\nANSWER1=EVAL(expr=\"'square' if {ANSWER0} == 'square' else 'round'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2026, "imageId": "n481655", "question": "Is the catcher to the left or to the right of the person in the middle?", "program": "BOX0=LOC(image=IMAGE,object='person in the middle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='catcher')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2027, "imageId": "n570181", "question": "Does the shirt made of cotton look orange?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the shirt made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'cotton' and {ANSWER1} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2028, "imageId": "n125122", "question": "What is the shape of the television on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='television')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the shape of the television?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2029, "imageId": "n386688", "question": "In front of what is the ocean?", "program": "BOX0=LOC(image=IMAGE,object='ocean')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In front of what is the ocean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2030, "imageId": "n125122", "question": "What is the device on top of the desk that is to the right of the bed called?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='desk')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nANSWER0=VQA(image=IMAGE1,question='What is the device called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2031, "imageId": "n313060", "question": "Is the short person behind the purse that is made of leather?", "program": "BOX0=LOC(image=IMAGE,object='purse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='leather')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='short person')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2032, "imageId": "n187961", "question": "Is the kid small and happy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the kid small?')\nANSWER1=VQA(image=IMAGE,question='Is the kid happy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2033, "imageId": "n86120", "question": "What animal is this woman petting?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the woman petting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2034, "imageId": "n14087", "question": "Are the ornaments hanging from the green tree?", "program": "BOX0=LOC(image=IMAGE,object='green tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ornaments')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2035, "imageId": "n14087", "question": "What are the ornaments made of glass hanging from?", "program": "BOX0=LOC(image=IMAGE,object='glass ornaments')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the ornaments hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2036, "imageId": "n272098", "question": "Who is holding the open container?", "program": "BOX0=LOC(image=IMAGE,object='open container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the open container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2037, "imageId": "n382416", "question": "What is the cabinet made of?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cabinet made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2038, "imageId": "n272098", "question": "Is she wearing a skirt?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is she wearing a skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2039, "imageId": "n541482", "question": "What color is the cotton sweater?", "program": "BOX0=LOC(image=IMAGE,object='cotton sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cotton sweater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2040, "imageId": "n400036", "question": "How big is the soccer ball that the woman is kicking?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer ball')\nANSWER0=SIZE(box=BOX1)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2041, "imageId": "n347706", "question": "Are there any cars or bags?", "program": "BOX0=LOC(image=IMAGE,object='car')\nBOX1=LOC(image=IMAGE,object='bag')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2042, "imageId": "n210269", "question": "How big are the horses?", "program": "BOX0=LOC(image=IMAGE,object='horses')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2043, "imageId": "n199097", "question": "Which color is the jacket the man is wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='jacket')\nANSWER0=VQA(image=IMAGE0,question='Which color is the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2044, "imageId": "n527290", "question": "What color is the chair on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2045, "imageId": "n446242", "question": "What color does the mirror the picture is to the left of have?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=VQA(image=IMAGE0,question='What color is the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2046, "imageId": "n280089", "question": "What kind of appliance is the bowl sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of appliance is the bowl sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2047, "imageId": "n195925", "question": "The bridge is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='bridge')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The bridge is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2048, "imageId": "n195925", "question": "What is the bridge in front of?", "program": "BOX0=LOC(image=IMAGE,object='bridge')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bridge in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2049, "imageId": "n167552", "question": "Does that rug look red?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the rug?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2050, "imageId": "n513429", "question": "What is the bottle in front of?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bottle in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2051, "imageId": "n513429", "question": "What's the bottle in front of?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bottle in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2052, "imageId": "n541482", "question": "What color does the kite have?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the kite have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2053, "imageId": "n70461", "question": "What do you think are the busy people watching?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think are the busy people watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2054, "imageId": "n498712", "question": "Who is the girl in front of?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the girl in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2055, "imageId": "n92308", "question": "What is the dog doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the dog doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2056, "imageId": "n514467", "question": "Which kind of material is the wet sidewalk made of?", "program": "BOX0=LOC(image=IMAGE,object='wet sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of material is the wet sidewalk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2057, "imageId": "n513429", "question": "Are there any bottles or cups that are made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nBOX1=LOC(image=IMAGE,object='cup')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2058, "imageId": "n499081", "question": "How big is the silver mirror?", "program": "BOX0=LOC(image=IMAGE,object='silver mirror')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2059, "imageId": "n488874", "question": "What kind of watercraft is colorful?", "program": "BOX0=LOC(image=IMAGE,object='watercraft')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of watercraft is colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2060, "imageId": "n66756", "question": "Do you think the batter is heavy?", "program": "ANSWER0=VQA(image=IMAGE,question='Do you think the batter is heavy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2061, "imageId": "n488874", "question": "Which kind of watercraft is scattered?", "program": "BOX0=LOC(image=IMAGE,object='watercraft')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'scattered' if {ANSWER0} > 1 else 'not scattered'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2062, "imageId": "n488874", "question": "What type of watercraft is shown in the photograph?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of watercraft is shown in the photograph?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2063, "imageId": "n488874", "question": "What kind of watercraft is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of watercraft is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2064, "imageId": "n257997", "question": "Who is in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2065, "imageId": "n257997", "question": "What is the crowd in front of?", "program": "BOX0=LOC(image=IMAGE,object='crowd')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the crowd in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2066, "imageId": "n257997", "question": "What's the crowd in front of?", "program": "BOX0=LOC(image=IMAGE,object='crowd')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the crowd in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2067, "imageId": "n523165", "question": "Is the tall man near the rope wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='tall man')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rope')\nBOX2=LOC(image=IMAGE0,object='glasses')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2068, "imageId": "n523165", "question": "What is the man looking at?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2069, "imageId": "n257997", "question": "Who is in front of the trees that are not short?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nBOX1=LOC(image=IMAGE,object='short trees')\nBOX2=DIFF(box1=BOX0,box2=BOX1)\nIMAGE0=CROP(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2070, "imageId": "n523165", "question": "What is the tall man looking at?", "program": "BOX0=LOC(image=IMAGE,object='tall man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tall man looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2071, "imageId": "n257997", "question": "Is the crowd in front of the tall trees?", "program": "BOX0=LOC(image=IMAGE,object='crowd')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tall trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2072, "imageId": "n507959", "question": "Does the guitar have a different color than the pole?", "program": "BOX0=LOC(image=IMAGE,object='guitar')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pole')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the guitar?')\nANSWER1=VQA(image=IMAGE1,question='What color is the pole?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2073, "imageId": "n77818", "question": "What is the name of the piece of furniture that is made of the same material as the pepper grinder on the right?", "program": "BOX0=LOC(image=IMAGE,object='pepper grinder')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2074, "imageId": "n293477", "question": "What food is to the left of the hair clip?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What food is to the left of the hair clip?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2075, "imageId": "n77818", "question": "Is the entertainment center made of the same material as the pepper grinder?", "program": "BOX0=LOC(image=IMAGE,object='entertainment center')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pepper grinder')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the entertainment center made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the pepper grinder made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2076, "imageId": "n488874", "question": "Which color is the dirt?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nANSWER0=VQA(image=IMAGE,question='Which color is the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2077, "imageId": "n293477", "question": "Is the black food to the left of the wallet that is lying on top of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wallet')\nIMAGE1=CROP_ONTOP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nIMAGE2=CROP_LEFTOF(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What color is the food?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2078, "imageId": "n295771", "question": "Do you see doors that are green?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the door?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2079, "imageId": "n46510", "question": "What is in front of the building near the streetlight?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='streetlight')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2080, "imageId": "n46510", "question": "What is in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2081, "imageId": "n572716", "question": "Is the mountain different in color than the jet?", "program": "BOX0=LOC(image=IMAGE,object='mountain')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='jet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the mountain?')\nANSWER1=VQA(image=IMAGE1,question='What color is the jet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2082, "imageId": "n216553", "question": "How big is the bag?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2083, "imageId": "n572716", "question": "What is common to the building and the crane?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the building and the crane?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2084, "imageId": "n296467", "question": "What size is the food that is not thin, small or large?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the food?')\nANSWER1=EVAL(expr=\"'unknown' if {ANSWER0} not in ['thin', 'small', 'large'] else ''\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2085, "imageId": "n319845", "question": "Are the glass windows open or closed?", "program": "BOX0=LOC(image=IMAGE,object='glass windows')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the glass windows open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2086, "imageId": "n309148", "question": "Is the sticker in front of the fire truck that looks white and red?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sticker')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2087, "imageId": "n534106", "question": "Are there cones or mirrors?", "program": "BOX0=LOC(image=IMAGE,object='cone')\nBOX1=LOC(image=IMAGE,object='mirror')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2088, "imageId": "n411121", "question": "What is the name of the vehicle in front of the old building?", "program": "BOX0=LOC(image=IMAGE,object='old building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the name of the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2089, "imageId": "n319845", "question": "Are there skateboards or cabinets in the image?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nBOX1=LOC(image=IMAGE,object='cabinet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2090, "imageId": "n28572", "question": "Is the chair on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2091, "imageId": "n54424", "question": "Is the boy to the left or to the right of the pillow that looks square?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2092, "imageId": "n222915", "question": "Are there either apples or bananas that are not brown?", "program": "BOX0=LOC(image=IMAGE,object='apple')\nBOX1=LOC(image=IMAGE,object='banana')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2093, "imageId": "n95313", "question": "What item of furniture is covered?", "program": "BOX0=LOC(image=IMAGE,object='covered')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is covered?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2094, "imageId": "n400036", "question": "Which color are the trees next to the cars?", "program": "BOX0=LOC(image=IMAGE,object='cars')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=VQA(image=IMAGE0,question='Which color are the trees?')\nANSWER1=EVAL(expr=\"'green' if {ANSWER0} == 'green' else 'not green'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2095, "imageId": "n207708", "question": "On which side is the drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2096, "imageId": "n95313", "question": "Which kind of furniture is not metallic?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is not metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2097, "imageId": "n295771", "question": "Does the door look white and clear?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the door?')\nANSWER1=VQA(image=IMAGE0,question='Does the door look clear?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2098, "imageId": "n131634", "question": "What type of vehicle is made of the same material as the motorbike that is parked along the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='motorbike')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the motorbike made of?')\nBOX1=LOC(image=IMAGE,object='sidewalk')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER1=VQA(image=IMAGE1,question='What type of vehicle is made of the same material as the motorbike?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2099, "imageId": "n202379", "question": "Are the white socks tall or short?", "program": "BOX0=LOC(image=IMAGE,object='white socks')\nANSWER0=VQA(image=IMAGE,question='Are the white socks tall or short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2100, "imageId": "n334278", "question": "What is the batter looking at?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the batter looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2101, "imageId": "n131634", "question": "Are both the door and the mirror made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='mirror')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the door made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the mirror made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2102, "imageId": "n334278", "question": "Is the person to the left of the baseball wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='baseball')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2103, "imageId": "n334278", "question": "Who is looking at the baseball?", "program": "BOX0=LOC(image=IMAGE,object='baseball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking at the baseball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2104, "imageId": "n351318", "question": "Are there any chickens or chairs in the picture?", "program": "BOX0=LOC(image=IMAGE,object='chicken')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2105, "imageId": "n518912", "question": "What ethnic group is the person that is wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What ethnic group is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2106, "imageId": "n275148", "question": "Are there either any pictures or speakers in the picture?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nBOX1=LOC(image=IMAGE,object='speaker')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2107, "imageId": "n548534", "question": "Which kind of furniture is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2108, "imageId": "n450919", "question": "Which animal is this, a giraffe or a monkey?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nBOX1=LOC(image=IMAGE,object='monkey')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'giraffe' if {ANSWER0} > {ANSWER1} else 'monkey'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2109, "imageId": "n275148", "question": "Is the storage box that is made of metal empty and black?", "program": "BOX0=LOC(image=IMAGE,object='storage box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the storage box empty?')\nANSWER1=VQA(image=IMAGE0,question='What color is the storage box?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'empty' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2110, "imageId": "n406334", "question": "Are the old people on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='old people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2111, "imageId": "n16425", "question": "Which kind of vehicle is blue?", "program": "BOX0=LOC(image=IMAGE,object='blue')\nBOX1=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which kind of vehicle is blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2112, "imageId": "n413002", "question": "Do the pants look long and yellow?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nANSWER1=VQA(image=IMAGE0,question='Do the pants look long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2113, "imageId": "n16425", "question": "Which color is the bus to the right of the other bus?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which color is the bus?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2114, "imageId": "n229548", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2115, "imageId": "n511913", "question": "Is the woman that is not sad brunette and young?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nBOX1=LOC(image=IMAGE,object='sad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the hair color of the woman?')\nANSWER1=VQA(image=IMAGE0,question='What is the age of the woman?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brunette' and {ANSWER1} == 'young' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2116, "imageId": "n4777", "question": "What is the paper container sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='paper container')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the paper container sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2117, "imageId": "n200907", "question": "What is in front of the sturdy fence?", "program": "BOX0=LOC(image=IMAGE,object='sturdy fence')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the sturdy fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2118, "imageId": "n150962", "question": "Is the pot to the right or to the left of the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pot')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2119, "imageId": "n311910", "question": "What sign is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='metal')\nANSWER0=VQA(image=IMAGE,question='What sign is made of metal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2120, "imageId": "n311910", "question": "What is the name of the metal sign?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the name of the metal sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2121, "imageId": "n311910", "question": "What sign is white?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sign?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2122, "imageId": "n296467", "question": "Do you think that container is closed?", "program": "BOX0=LOC(image=IMAGE,object='container')\nANSWER0=VQA(image=IMAGE,question='Do you think that container is closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2123, "imageId": "n489699", "question": "The female kid to the right of the helmet is standing where?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='female kid')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2124, "imageId": "n16378", "question": "Who is the luggage cart pulled by?", "program": "BOX0=LOC(image=IMAGE,object='luggage cart')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the luggage cart pulled by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2125, "imageId": "n154856", "question": "What is in front of the silver car?", "program": "BOX0=LOC(image=IMAGE,object='silver car')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the silver car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2126, "imageId": "n460385", "question": "What piece of furniture is the plant on?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is the plant on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2127, "imageId": "n278312", "question": "Is the oven to the left of the bread on the counter?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bread')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='oven')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2128, "imageId": "n489699", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2129, "imageId": "n489699", "question": "Who is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2130, "imageId": "n489699", "question": "The kid that is not male is wearing what?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The kid that is not male is wearing what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2131, "imageId": "n16378", "question": "What is pulled by the woman that is not sad?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman pulling?')\nANSWER1=VQA(image=IMAGE0,question='Is the woman sad?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'no' else 'no'\")\nANSWER3=EVAL(expr=\"'{ANSWER0}' if {ANSWER2} == 'yes' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 2132, "imageId": "n489699", "question": "Is the female child wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='female child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the female child wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2133, "imageId": "n566028", "question": "Is the person that is looking down wearing a coat?", "program": "BOX0=LOC(image=IMAGE,object='person looking down')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'coat' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2134, "imageId": "n195249", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2135, "imageId": "n95904", "question": "Are there any briefcases or backpacks that are not blue?", "program": "BOX0=LOC(image=IMAGE,object='briefcase')\nBOX1=LOC(image=IMAGE,object='backpack')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What color are the briefcases?')\nANSWER4=VQA(image=IMAGE,question='What color are the backpacks?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} != 'blue' or {ANSWER4} != 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 2136, "imageId": "n206785", "question": "Are there both windows and doors in this image?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2137, "imageId": "n249639", "question": "Is the trashcan below a nightstand?", "program": "BOX0=LOC(image=IMAGE,object='nightstand')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trashcan')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2138, "imageId": "n259002", "question": "Who runs on the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who runs on the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2139, "imageId": "n259002", "question": "Who runs on the green grass underneath the ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green grass')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who runs on the green grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2140, "imageId": "n310828", "question": "What kind of furniture is the laptop on?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the laptop on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2141, "imageId": "n164272", "question": "How tall is the grass?", "program": "ANSWER0=VQA(image=IMAGE,question='How tall is the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2142, "imageId": "n470920", "question": "What do you think is covering the man that is wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='man wearing jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is covering the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2143, "imageId": "n164272", "question": "Is there any grass in the picture that is not tall?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nBOX1=LOC(image=IMAGE,object='tall grass')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2144, "imageId": "n51002", "question": "Does the device under the artwork seem to be off or on?", "program": "BOX0=LOC(image=IMAGE,object='artwork')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='Does the device seem to be off or on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2145, "imageId": "n280089", "question": "Which kind of appliance are the jars sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='jars')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance are the jars sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2146, "imageId": "n398257", "question": "What kind of furniture is under the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is under the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2147, "imageId": "n290409", "question": "What is the logo in front of?", "program": "BOX0=LOC(image=IMAGE,object='logo')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the logo in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2148, "imageId": "n90944", "question": "Are the buildings behind the trees large or small?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='buildings')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'large' if {ANSWER0} > 0 else 'small'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2149, "imageId": "n513429", "question": "What is the monitor in front of?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the monitor in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2150, "imageId": "n90944", "question": "What is in front of the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='front')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2151, "imageId": "n200225", "question": "Which is healthier, the pizza or the spinach?", "program": "ANSWER0=VQA(image=IMAGE,question='Which is healthier, the pizza or the spinach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2152, "imageId": "n314630", "question": "How big is the house?", "program": "ANSWER0=VQA(image=IMAGE,question='How big is the house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2153, "imageId": "n413002", "question": "Is there a child to the right of the backpack on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='backpack')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='child')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2154, "imageId": "n413002", "question": "What animal is standing on the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is standing on the ground?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2155, "imageId": "n413002", "question": "What is the animal that is standing on the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal that is standing on the ground?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2156, "imageId": "n566028", "question": "Do you think the person above the skateboard is male or female?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'male' if {ANSWER0} > 0 else 'female'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2157, "imageId": "n554880", "question": "The person near the gift is holding what?", "program": "BOX0=LOC(image=IMAGE,object='gift')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The person near the gift is holding what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2158, "imageId": "n357784", "question": "What is the animal in front of the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2159, "imageId": "n410476", "question": "Are there either any giraffes or bears that are not dark brown?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nBOX1=LOC(image=IMAGE,object='bear')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if ({ANSWER0} > 0 or {ANSWER1} > 0) and not ({ANSWER0} > 0 and {ANSWER1} > 0) else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2160, "imageId": "n554880", "question": "Which kind of device is the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2161, "imageId": "n65885", "question": "What is around the teddy bear?", "program": "BOX0=LOC(image=IMAGE,object='teddy bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is around the teddy bear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2162, "imageId": "n554880", "question": "What's the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's the man holding?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2163, "imageId": "n460556", "question": "Does the hat have large size and red color?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the hat?')\nANSWER1=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2164, "imageId": "n460556", "question": "Are there any gloves or hats that are not large?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nBOX1=LOC(image=IMAGE,object='hats')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE,object='large')\nANSWER3=COUNT(box=BOX2)\nANSWER4=EVAL(expr=\"'yes' if {ANSWER3} == 0 else 'no'\")\nANSWER5=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER4} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 2165, "imageId": "n12214", "question": "Are there cars to the right of the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2166, "imageId": "n51658", "question": "Who is watching the person that is holding onto the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2167, "imageId": "n51658", "question": "Do you see any blinds behind the standing person that is wearing a wrist band?", "program": "BOX0=LOC(image=IMAGE,object='standing person')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blinds')\nBOX2=LOC(image=IMAGE0,object='wrist band')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2168, "imageId": "n489190", "question": "What is the color of the helmet the skateboarder is wearing?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='helmet')\nANSWER0=VQA(image=IMAGE0,question='What color is the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2169, "imageId": "n429883", "question": "What color is that suit?", "program": "BOX0=LOC(image=IMAGE,object='suit')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the suit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2170, "imageId": "n234722", "question": "What kind of furniture isn't clean?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is clean?')\nANSWER1=EVAL(expr=\"'not ' + {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2171, "imageId": "n578564", "question": "What do both the window and the jar have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the window and the jar have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2172, "imageId": "n578564", "question": "Do the paper towels and the canisters have the same color?", "program": "BOX0=LOC(image=IMAGE,object='paper towels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='canisters')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the paper towels?')\nANSWER1=VQA(image=IMAGE1,question='What color are the canisters?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2173, "imageId": "n541482", "question": "Is the kite green and large?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the kite?')\nANSWER1=VQA(image=IMAGE0,question='Is the kite large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2174, "imageId": "n524855", "question": "What length is the tail?", "program": "BOX0=LOC(image=IMAGE,object='tail')\nANSWER0=LENGTH(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2175, "imageId": "n469525", "question": "What is the animal that is standing on the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2176, "imageId": "n204894", "question": "What's the child doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What\\'s the child doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2177, "imageId": "n200225", "question": "Are there both peppers and tomatoes in this scene?", "program": "BOX0=LOC(image=IMAGE,object='pepper')\nBOX1=LOC(image=IMAGE,object='tomato')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2178, "imageId": "n19152", "question": "What is the name of this vehicle?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the name of this vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2179, "imageId": "n100552", "question": "Which color is the container made of metal?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the container?')\nANSWER1=VQA(image=IMAGE0,question='What material is the container made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'metal' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2180, "imageId": "n219840", "question": "Are these animals of the same species?", "program": "ANSWER0=VQA(image=IMAGE,question='Are these animals of the same species?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2181, "imageId": "n299528", "question": "Is the brown fence behind the leafy bush?", "program": "BOX0=LOC(image=IMAGE,object='leafy bush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2182, "imageId": "n126891", "question": "Which kind of clothing is short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='short sleeved clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2183, "imageId": "n281241", "question": "Is the blue chair on the left side?", "program": "BOX0=LOC(image=IMAGE,object='blue chair')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2184, "imageId": "n55058", "question": "Which kind of meat is small?", "program": "BOX0=LOC(image=IMAGE,object='small')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of meat is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2185, "imageId": "n413319", "question": "Is he female and Caucasian?", "program": "ANSWER0=VQA(image=IMAGE,question='Is he female?')\nANSWER1=VQA(image=IMAGE,question='Is he Caucasian?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2186, "imageId": "n55058", "question": "Which kind of meat is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of meat is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2187, "imageId": "n55058", "question": "How is that meat called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is that meat called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2188, "imageId": "n55058", "question": "Is there any sofa inside the restaurant?", "program": "BOX0=LOC(image=IMAGE,object='restaurant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sofa')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2189, "imageId": "n126891", "question": "What kind of clothing is green?", "program": "BOX0=LOC(image=IMAGE,object='green clothing')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is green?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2190, "imageId": "n126891", "question": "Which kind of clothing is green?", "program": "BOX0=LOC(image=IMAGE,object='green clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is green?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2191, "imageId": "n55058", "question": "What's located on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2192, "imageId": "n55058", "question": "What is located on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2193, "imageId": "n55058", "question": "Is the onion on top of the cooking utensil that is on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='onion')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2194, "imageId": "n355567", "question": "Does the lady near the tennis ball appear to be antique?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lady')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2195, "imageId": "n49438", "question": "How big is the curtain?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2196, "imageId": "n54180", "question": "Is the color of the toilet paper different than the wall?", "program": "BOX0=LOC(image=IMAGE,object='toilet paper')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='wall')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet paper?')\nANSWER1=VQA(image=IMAGE1,question='What color is the wall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2197, "imageId": "n69237", "question": "Is there a door in this photo?", "program": "BOX0=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2198, "imageId": "n556604", "question": "Is the woman to the right of the camera standing in front of a sofa?", "program": "BOX0=LOC(image=IMAGE,object='camera')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='sofa')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2199, "imageId": "n44249", "question": "Is the fence on the left side?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=EVAL(expr=\"'yes' if {BOX0}['x'] < IMAGE['width']/2 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2200, "imageId": "n181210", "question": "Is the bread on the left side?", "program": "BOX0=LOC(image=IMAGE,object='bread')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2201, "imageId": "n315887", "question": "What is the keyboard made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the keyboard made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2202, "imageId": "n315887", "question": "What is the device on top of the desk that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2203, "imageId": "n65866", "question": "Do you see either faucets or cabinets that are modern?", "program": "BOX0=LOC(image=IMAGE,object='faucets')\nBOX1=LOC(image=IMAGE,object='cabinets')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='Are the faucets modern?')\nANSWER4=VQA(image=IMAGE,question='Are the cabinets modern?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} == 'yes' or {ANSWER4} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 2204, "imageId": "n181210", "question": "Which kind of food isn't soft?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food isn't soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2205, "imageId": "n498712", "question": "What is the door opening?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the door opening?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2206, "imageId": "n283587", "question": "Is there either a blue bed or sofa?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='sofa')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2207, "imageId": "n244826", "question": "Who is wearing a shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2208, "imageId": "n352479", "question": "Is the person that is not male wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the gender of the person?')\nANSWER1=VQA(image=IMAGE0,question='Is the person wearing a glove?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != 'male' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2209, "imageId": "n496803", "question": "What color is the skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2210, "imageId": "n324908", "question": "Is the dry pasture grassy and tall?", "program": "BOX0=LOC(image=IMAGE,object='dry pasture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the grassy and tall?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2211, "imageId": "n530733", "question": "Is the mirror above a sink?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sink')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2212, "imageId": "n293477", "question": "What do you think is lying next to the wallet that is not large?", "program": "BOX0=LOC(image=IMAGE,object='wallet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not large')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is lying next to the wallet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2213, "imageId": "n433532", "question": "What appliance is to the left of the lady?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is to the left of the lady?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2214, "imageId": "n234683", "question": "Is he wearing a necktie?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is he wearing a necktie?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2215, "imageId": "n259949", "question": "Where is the skater?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nANSWER0=VQA(image=IMAGE,question='Where is the skater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2216, "imageId": "n536256", "question": "Are there large televisions or printers?", "program": "BOX0=LOC(image=IMAGE,object='television', size='large')\nBOX1=LOC(image=IMAGE,object='printer', size='large')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2217, "imageId": "n259949", "question": "Where is that skater?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nANSWER0=VQA(image=IMAGE,question='Where is that skater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2218, "imageId": "n206785", "question": "Do the tie and the dress shirt have the same color?", "program": "BOX0=LOC(image=IMAGE,object='tie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='dress shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the tie?')\nANSWER1=VQA(image=IMAGE1,question='What color is the dress shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2219, "imageId": "n536256", "question": "Is the TV on top of the TV stand small or large?", "program": "BOX0=LOC(image=IMAGE,object='TV stand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TV')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} > 0 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2220, "imageId": "n560243", "question": "What color is the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2221, "imageId": "n23762", "question": "Is the table wooden and wide?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE0,question='Is the table wide?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2222, "imageId": "n222915", "question": "What is that glass made of?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is that glass made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2223, "imageId": "n222915", "question": "What is the glass made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the glass made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2224, "imageId": "n119944", "question": "How does the man look, skinny or fat?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How does the man look, skinny or fat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2225, "imageId": "n162586", "question": "Does the wide bed look soft and purple?", "program": "BOX0=LOC(image=IMAGE,object='wide bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the wide bed?')\nANSWER1=VQA(image=IMAGE0,question='Does the wide bed look soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'purple' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2226, "imageId": "n398257", "question": "What type of furniture is under the desk that is under the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='desk')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of furniture is under the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2227, "imageId": "n496803", "question": "What length is the skirt the athlete is wearing?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What length is the skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2228, "imageId": "n28996", "question": "Does the spoon have small size?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the spoon?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2229, "imageId": "n192021", "question": "Is the picture that is to the left of the curtain white and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the picture?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the picture?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2230, "imageId": "n143672", "question": "Who wears a cap?", "program": "BOX0=LOC(image=IMAGE,object='cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears a cap?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2231, "imageId": "n143672", "question": "Who wears the cap?", "program": "BOX0=LOC(image=IMAGE,object='cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the cap?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2232, "imageId": "n124651", "question": "Is there a bus to the right of the bicycle?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2233, "imageId": "n398257", "question": "What is under the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2234, "imageId": "n143672", "question": "Does the skier that is not female wear a glove?", "program": "BOX0=LOC(image=IMAGE,object='skier')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='female')\nIMAGE1=CROP_NOT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='glove')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2235, "imageId": "n299528", "question": "How tall is the house to the right of the skater?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='house')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How tall is the house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2236, "imageId": "n187961", "question": "Does the goat have white color?", "program": "BOX0=LOC(image=IMAGE,object='goat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the goat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2237, "imageId": "n140421", "question": "What is the appliance that the countertop is behind?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2238, "imageId": "n140421", "question": "Is the countertop below a cupboard?", "program": "BOX0=LOC(image=IMAGE,object='cupboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='countertop')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2239, "imageId": "n541688", "question": "What do both the picture and the wall have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the picture and the wall have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2240, "imageId": "n214497", "question": "Which kind of vehicle is heavy?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is heavy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2241, "imageId": "n214497", "question": "What kind of vehicle is dark?", "program": "BOX0=LOC(image=IMAGE,object='dark')\nANSWER0=VQA(image=IMAGE,question='What kind of vehicle is dark?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2242, "imageId": "n214497", "question": "What are the heavy vehicles called?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the heavy vehicles called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2243, "imageId": "n278453", "question": "Which kind of meat is on the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of meat is on the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2244, "imageId": "n283587", "question": "Is the floor wooden and dark?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the floor made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the floor?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'dark' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2245, "imageId": "n278453", "question": "What is the name of the meat on the porcelain plate?", "program": "BOX0=LOC(image=IMAGE,object='porcelain plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='meat')\nANSWER0=VQA(image=IMAGE0,question='What is the name of the meat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2246, "imageId": "n214497", "question": "What vehicles are dense?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'car' if {ANSWER0} > 5 else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2247, "imageId": "n28996", "question": "Is the container large and square?", "program": "BOX0=LOC(image=IMAGE,object='container')\nANSWER0=VQA(image=IMAGE,question='Is the container large?')\nANSWER1=VQA(image=IMAGE,question='Is the container square?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2248, "imageId": "n410289", "question": "Are there TVs in this image?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2249, "imageId": "n59676", "question": "What cooking utensil is not warm, the pan or the spatula?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='spatula')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Is the pan warm?')\nANSWER1=VQA(image=IMAGE1,question='Is the spatula warm?')\nANSWER2=EVAL(expr=\"'pan' if {ANSWER0} == 'no' else 'spatula'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2250, "imageId": "n28996", "question": "What is the food that is to the right of the dessert that is sitting inside the container?", "program": "BOX0=LOC(image=IMAGE,object='dessert')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='container')\nIMAGE1=CROP_INSIDE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nANSWER0=VQA(image=IMAGE1,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2251, "imageId": "n28996", "question": "Does the candy to the right of the brownie have orange color?", "program": "BOX0=LOC(image=IMAGE,object='brownie')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='candy')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the candy?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2252, "imageId": "n28996", "question": "Are there any candies to the right of the dessert in the middle?", "program": "BOX0=LOC(image=IMAGE,object='middle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='candies')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2253, "imageId": "n466319", "question": "Does the striped shirt look long sleeved and white?", "program": "BOX0=LOC(image=IMAGE,object='striped shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of sleeves does the shirt have?')\nANSWER1=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'long sleeved' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2254, "imageId": "n507959", "question": "What do the dolls sit on top of?", "program": "BOX0=LOC(image=IMAGE,object='dolls')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do the dolls sit on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2255, "imageId": "n299528", "question": "Is the fence behind the bush green or brown?", "program": "BOX0=LOC(image=IMAGE,object='bush')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=VQA(image=IMAGE0,question='What color is the fence?')\nANSWER1=EVAL(expr=\"'green' if {ANSWER0} == 'green' else 'brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2256, "imageId": "n111390", "question": "Who is looking down at the dessert which is on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is looking down at the dessert?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2257, "imageId": "n507959", "question": "Which kind of furniture do the dolls sit on top of?", "program": "BOX0=LOC(image=IMAGE,object='dolls')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture do the dolls sit on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2258, "imageId": "n192021", "question": "Are the pillows on the couch white and soft?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color are the pillows?')\nANSWER3=VQA(image=IMAGE0,question='Are the pillows soft?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 2259, "imageId": "n12214", "question": "The young skater is of what race?", "program": "BOX0=LOC(image=IMAGE,object='young skater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The young skater is of what race?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2260, "imageId": "n167552", "question": "What item of furniture is to the right of the male person?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is to the right?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2261, "imageId": "n260762", "question": "Where is the truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nANSWER0=VQA(image=IMAGE,question='Where is the truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2262, "imageId": "n260762", "question": "Are there trucks on the large field?", "program": "BOX0=LOC(image=IMAGE,object='large field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='truck')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2263, "imageId": "n313060", "question": "Who is the coffee in front of?", "program": "BOX0=LOC(image=IMAGE,object='coffee')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the coffee in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2264, "imageId": "n181210", "question": "What is the color of the bread?", "program": "BOX0=LOC(image=IMAGE,object='bread')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the bread?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2265, "imageId": "n194179", "question": "What plays with the athlete?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What plays with the athlete?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2266, "imageId": "n194179", "question": "Who does the racket that is playing play with?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who does the racket that is playing play with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2267, "imageId": "n146522", "question": "What are the pants made of, cloth or leather?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the pants made of?')\nANSWER1=EVAL(expr=\"'cloth' if {ANSWER0} == 'cloth' else 'leather'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2268, "imageId": "n194179", "question": "On which side of the photo is the racket?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='racket')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2269, "imageId": "n195249", "question": "Is the long necklace gold or blue?", "program": "BOX0=LOC(image=IMAGE,object='long necklace')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the long necklace?')\nANSWER1=EVAL(expr=\"'gold' if {ANSWER0} == 'gold' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2270, "imageId": "n541688", "question": "Do both the people have the same gender?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the gender of the first person?')\nANSWER1=VQA(image=IMAGE0,question='What is the gender of the second person?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2271, "imageId": "n119944", "question": "Is the round can in the bottom or in the top part?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='round can')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2272, "imageId": "n406334", "question": "Are the street lights made of the same material as the cars?", "program": "BOX0=LOC(image=IMAGE,object='street lights')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cars')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material are the street lights made of?')\nANSWER1=VQA(image=IMAGE1,question='What material are the cars made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2273, "imageId": "n466319", "question": "The person in the center of the photo is of what gender?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The person in the center of the photo is of what gender?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2274, "imageId": "n579928", "question": "Is the grass wet or dry?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the grass wet or dry?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2275, "imageId": "n574498", "question": "On which side of the image is the ball, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2276, "imageId": "n574498", "question": "Does the ball appear to be green and round?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the ball?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the ball?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2277, "imageId": "n565418", "question": "What color is the boat on top of the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boat')\nANSWER0=VQA(image=IMAGE0,question='What color is the boat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2278, "imageId": "n296467", "question": "Is there either rice or lettuce in this picture?", "program": "BOX0=LOC(image=IMAGE,object='rice')\nBOX1=LOC(image=IMAGE,object='lettuce')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2279, "imageId": "n507959", "question": "Is the tall cabinet open and green?", "program": "BOX0=LOC(image=IMAGE,object='tall cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the cabinet open?')\nANSWER1=VQA(image=IMAGE0,question='What color is the cabinet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'open' and {ANSWER1} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2280, "imageId": "n199758", "question": "Is the short person wearing a wrist watch?", "program": "BOX0=LOC(image=IMAGE,object='short person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the short person wearing a wrist watch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2281, "imageId": "n143935", "question": "Of which color is the house?", "program": "ANSWER0=VQA(image=IMAGE,question='Of which color is the house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2282, "imageId": "n199758", "question": "What is the short person holding, a remote control or a phone?", "program": "BOX0=LOC(image=IMAGE,object='short person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the short person holding?')\nANSWER1=EVAL(expr=\"'remote control' if {ANSWER0} == 'remote control' else 'phone'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2283, "imageId": "n143935", "question": "What size is the house, small or large?", "program": "BOX0=LOC(image=IMAGE,object='house')\nANSWER0=VQA(image=IMAGE,question='What size is the house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2284, "imageId": "n470920", "question": "Does the woman to the right of the berries appear to be sitting or running?", "program": "BOX0=LOC(image=IMAGE,object='berries')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=VQA(image=IMAGE0,question='Does the woman appear to be sitting or running?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2285, "imageId": "n143935", "question": "Does the house look large and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the house look large?')\nANSWER1=VQA(image=IMAGE,question='Does the house look white?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2286, "imageId": "n77818", "question": "Are there any books near the pepper grinder made of wood?", "program": "BOX0=LOC(image=IMAGE,object='pepper grinder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2287, "imageId": "n441859", "question": "What gender is the standing person who is holding the surfboard?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='standing person')\nANSWER0=VQA(image=IMAGE0,question='What gender is the standing person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2288, "imageId": "n77818", "question": "Is the book to the right of a laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='book')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2289, "imageId": "n575770", "question": "Is the newspaper both large and white?", "program": "BOX0=LOC(image=IMAGE,object='newspaper')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the newspaper?')\nANSWER1=VQA(image=IMAGE0,question='What color is the newspaper?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2290, "imageId": "n494918", "question": "How thick is the frisbee?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How thick is the frisbee?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2291, "imageId": "n350732", "question": "Are there chairs on the lawn?", "program": "BOX0=LOC(image=IMAGE,object='lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2292, "imageId": "n483840", "question": "What is the brown clothing item?", "program": "BOX0=LOC(image=IMAGE,object='brown clothing item')\nANSWER0=VQA(image=IMAGE,question='What is the brown clothing item?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2293, "imageId": "n140421", "question": "What appliance is to the right of the chandelier?", "program": "BOX0=LOC(image=IMAGE,object='chandelier')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is to the right of the chandelier?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2294, "imageId": "n411121", "question": "Does the short sleeved shirt look comfortable and blue?", "program": "BOX0=LOC(image=IMAGE,object='short sleeved shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the short sleeved shirt look comfortable?')\nANSWER1=VQA(image=IMAGE0,question='What color is the short sleeved shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'comfortable' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2295, "imageId": "n483840", "question": "What kind of clothing is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown clothing')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2296, "imageId": "n411121", "question": "Does the shirt that looks comfortable look clean?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look comfortable?')\nANSWER1=VQA(image=IMAGE0,question='Does the shirt look clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2297, "imageId": "n298104", "question": "How large is the sand?", "program": "ANSWER0=VQA(image=IMAGE,question='How large is the sand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2298, "imageId": "n523165", "question": "Is the rope different in color than the bike?", "program": "BOX0=LOC(image=IMAGE,object='rope')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bike')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the rope?')\nANSWER1=VQA(image=IMAGE1,question='What color is the bike?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2299, "imageId": "n363445", "question": "Which color is the large lid?", "program": "BOX0=LOC(image=IMAGE,object='large lid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the large lid?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2300, "imageId": "n95904", "question": "Does the umbrella that is not narrow have blue color?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the umbrella narrow?')\nANSWER1=VQA(image=IMAGE0,question='What color is the umbrella?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2301, "imageId": "n271392", "question": "Is the blue car in the bottom part of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blue car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2302, "imageId": "n100991", "question": "Are there knives to the right of the plate the sausage is on top of?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sausage')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='knife')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2303, "imageId": "n202379", "question": "Who is wearing the baseball mitt?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the baseball mitt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2304, "imageId": "n202379", "question": "Who do you think is wearing a baseball mitt?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a baseball mitt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2305, "imageId": "n511913", "question": "What do both the blinds and the pants have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the blinds and the pants have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2306, "imageId": "n202379", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2307, "imageId": "n83784", "question": "Is the black and white cat colorful and unhappy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the black and white cat colorful?')\nANSWER1=VQA(image=IMAGE,question='Is the black and white cat unhappy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2308, "imageId": "n202379", "question": "Who is wearing the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2309, "imageId": "n202379", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nANSWER0=VQA(image=IMAGE,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2310, "imageId": "n278312", "question": "What type of appliance is on the counter made of marble?", "program": "BOX0=LOC(image=IMAGE,object='counter made of marble')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of appliance is on the counter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2311, "imageId": "n54424", "question": "What's the shuttle surrounded by?", "program": "BOX0=LOC(image=IMAGE,object='shuttle')\nIMAGE0=CROP_AROUND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the shuttle surrounded by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2312, "imageId": "n541482", "question": "Who is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2313, "imageId": "n54424", "question": "Do you see a mirror or a couch?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nBOX1=LOC(image=IMAGE,object='couch')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2314, "imageId": "n551964", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2315, "imageId": "n278312", "question": "Which kind of appliance is on the counter?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is on the counter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2316, "imageId": "n125122", "question": "Do you see coffee tables or mirrors?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nBOX1=LOC(image=IMAGE,object='mirror')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2317, "imageId": "n431447", "question": "Does the clear container look closed?", "program": "BOX0=LOC(image=IMAGE,object='clear container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the clear container look closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2318, "imageId": "n243701", "question": "Who is wearing a shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2319, "imageId": "n243701", "question": "Who is wearing the shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2320, "imageId": "n179136", "question": "Is the surfer riding?", "program": "BOX0=LOC(image=IMAGE,object='surfer')\nANSWER0=VQA(image=IMAGE,question='Is the surfer riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2321, "imageId": "n243701", "question": "What is the old woman wearing?", "program": "BOX0=LOC(image=IMAGE,object='old woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the old woman wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2322, "imageId": "n410476", "question": "What color does the vast sky above the plain have?", "program": "BOX0=LOC(image=IMAGE,object='plain')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sky')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color does the sky have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2323, "imageId": "n554880", "question": "Which color is the floor?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2324, "imageId": "n449058", "question": "Who is riding?", "program": "BOX0=LOC(image=IMAGE,object='riding')\nANSWER0=VQA(image=IMAGE,question='Who is riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2325, "imageId": "n410476", "question": "Where is the tree?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nANSWER0=VQA(image=IMAGE,question='Where is the tree?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2326, "imageId": "n433692", "question": "On which side is the mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2327, "imageId": "n541854", "question": "What is the fruit that is green called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fruit that is green called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2328, "imageId": "n527290", "question": "What are the pieces of furniture that are on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2329, "imageId": "n527290", "question": "Are the wood shelves black or maybe green?", "program": "BOX0=LOC(image=IMAGE,object='wood shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the wood shelves?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'green' if {ANSWER0} == 'green' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2330, "imageId": "n571179", "question": "Are there any white scarves or gloves in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='scarf')\nBOX1=LOC(image=IMAGE,object='gloves')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2331, "imageId": "n400036", "question": "Who are the cars in front of?", "program": "BOX0=LOC(image=IMAGE,object='cars')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who are the cars in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2332, "imageId": "n400036", "question": "What kind of vehicle is in front of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is in front of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2333, "imageId": "n240973", "question": "Which kind of furniture is above the newspaper?", "program": "BOX0=LOC(image=IMAGE,object='newspaper')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is above the newspaper?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2334, "imageId": "n260521", "question": "Which side of the picture is the person on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2335, "imageId": "n148872", "question": "What is the color of the sneakers that are not large?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nBOX1=LOC(image=IMAGE,object='large')\nBOX2=DIFF(box1=BOX0,box2=BOX1)\nIMAGE0=CROP(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the sneakers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2336, "imageId": "n192021", "question": "How is the item of furniture that is made of same material as the fan on the ceiling called?", "program": "BOX0=LOC(image=IMAGE,object='fan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the fan made of?')\nBOX1=LOC(image=IMAGE,object='furniture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='What is the item of furniture called?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2337, "imageId": "n192021", "question": "What do both the table and the fan have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the table and the fan have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2338, "imageId": "n46510", "question": "Which kind of sign is yellow?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of sign is yellow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2339, "imageId": "n282436", "question": "Does the window made of glass look open or closed?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the window look open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2340, "imageId": "n546616", "question": "Do you see a baby in this picture that is standing?", "program": "BOX0=LOC(image=IMAGE,object='baby')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the baby standing?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'standing' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2341, "imageId": "n310828", "question": "Is she young and male?", "program": "ANSWER0=VQA(image=IMAGE,question='Is she young?')\nANSWER1=VQA(image=IMAGE,question='Is she male?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2342, "imageId": "n89148", "question": "What toy is above the girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2343, "imageId": "n262920", "question": "What is the name of the black item of furniture?", "program": "BOX0=LOC(image=IMAGE,object='black')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2344, "imageId": "n262920", "question": "Which kind of furniture is covered?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is covered?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2345, "imageId": "n170941", "question": "What is the food that is on top of the white plate near the fork called?", "program": "BOX0=LOC(image=IMAGE,object='white plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fork')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the food called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2346, "imageId": "n526228", "question": "What is located on top of the jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2347, "imageId": "n355567", "question": "Who is about to hit the tennis ball made of rubber?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is about to hit the tennis ball made of rubber?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2348, "imageId": "n548534", "question": "Is the chair on the right of the photo?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2349, "imageId": "n95313", "question": "Is the chair to the left of the rug both covered and metallic?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What material is the chair made of?')\nANSWER3=VQA(image=IMAGE0,question='What material is the rug made of?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'metallic' and {ANSWER3} == 'covered' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 2350, "imageId": "n393305", "question": "What is in front of the girl that the traffic sign is behind of?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic sign')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2351, "imageId": "n565418", "question": "Are there any black flags or boats?", "program": "BOX0=LOC(image=IMAGE,object='black flag')\nBOX1=LOC(image=IMAGE,object='boat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2352, "imageId": "n16378", "question": "Who are the papers in front of?", "program": "BOX0=LOC(image=IMAGE,object='papers')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who are the papers in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2353, "imageId": "n204894", "question": "What is worn on the kid?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is worn on the kid?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2354, "imageId": "n66756", "question": "Do the shoe and the mask have the same color?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='mask')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shoe?')\nANSWER1=VQA(image=IMAGE1,question='What color is the mask?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2355, "imageId": "n67005", "question": "What is the woman reflected on?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman reflected on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2356, "imageId": "n204894", "question": "Who is the crown worn on?", "program": "BOX0=LOC(image=IMAGE,object='crown')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the crown worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2357, "imageId": "n204894", "question": "What's worn on the child?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the child wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2358, "imageId": "n9181", "question": "Is the vest behind a wheelchair?", "program": "BOX0=LOC(image=IMAGE,object='wheelchair')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vest')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2359, "imageId": "n319845", "question": "Is the person on the right side of the photo?", "program": "BOX0=LOC(image=IMAGE,object='person')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2360, "imageId": "n233607", "question": "What kind of furniture is the computer perched on?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the computer perched on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2361, "imageId": "n207708", "question": "What appliance is above the bananas?", "program": "BOX0=LOC(image=IMAGE,object='bananas')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is above the bananas?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2362, "imageId": "n25275", "question": "Do you see any life jackets or bags?", "program": "BOX0=LOC(image=IMAGE,object='life jacket')\nBOX1=LOC(image=IMAGE,object='bag')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2363, "imageId": "n124651", "question": "Are there any bicycles or buckets?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nBOX1=LOC(image=IMAGE,object='bucket')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2364, "imageId": "n318684", "question": "Does the still man wear a helmet?", "program": "BOX0=LOC(image=IMAGE,object='still man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the still man wear a helmet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'helmet' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2365, "imageId": "n6908", "question": "What's hanging above the flowers?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2366, "imageId": "n554880", "question": "Are there either any silver DVD players or laptops?", "program": "BOX0=LOC(image=IMAGE,object='DVD player', color='silver')\nBOX1=LOC(image=IMAGE,object='laptop')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2367, "imageId": "n318684", "question": "Does the still man wear shorts?", "program": "BOX0=LOC(image=IMAGE,object='still man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'shorts' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2368, "imageId": "n318684", "question": "Who wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who wears a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2369, "imageId": "n398429", "question": "What appliance is to the left of the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 0 else 'appliance'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2370, "imageId": "n16378", "question": "Is the person that is not sad carrying a bag?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person sad?')\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2371, "imageId": "n435808", "question": "Of which shape is the router?", "program": "BOX0=LOC(image=IMAGE,object='router')\nANSWER0=VQA(image=IMAGE,question='Of which shape is the router?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2372, "imageId": "n51002", "question": "Does the mouse that is made of plastic look large and black?", "program": "BOX0=LOC(image=IMAGE,object='plastic mouse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the plastic mouse?')\nANSWER1=VQA(image=IMAGE0,question='Is the plastic mouse large?')\nANSWER2=VQA(image=IMAGE0,question='Is the plastic mouse black?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 2373, "imageId": "n548534", "question": "What appliance is above the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is above the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2374, "imageId": "n162586", "question": "Who is sleeping?", "program": "BOX0=LOC(image=IMAGE,object='sleeping')\nANSWER0=VQA(image=IMAGE,question='Who is sleeping?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2375, "imageId": "n162586", "question": "What is she doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is she doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2376, "imageId": "n289376", "question": "Is the mowed lawn sitting beside the gray gravel?", "program": "BOX0=LOC(image=IMAGE,object='mowed lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='gray gravel')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2377, "imageId": "n433692", "question": "Are there any pens to the right of the tall lamp near the laptop?", "program": "BOX0=LOC(image=IMAGE,object='tall lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='pens')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2378, "imageId": "n435808", "question": "What is the tall item of furniture called?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What is the tall item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2379, "imageId": "n386688", "question": "Are the sailboats below the boats white and large?", "program": "BOX0=LOC(image=IMAGE,object='boats')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sailboats')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='white')\nANSWER2=COUNT(box=BOX2)\nBOX3=LOC(image=IMAGE0,object='large')\nANSWER3=COUNT(box=BOX3)\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} > 0 and {ANSWER3} > 0 else 'no'\")\nANSWER5=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER4} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 2380, "imageId": "n181355", "question": "Is the cloth shirt short sleeved and black?", "program": "BOX0=LOC(image=IMAGE,object='cloth shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of sleeves does the cloth shirt have?')\nANSWER1=VQA(image=IMAGE0,question='What color is the cloth shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'short sleeved' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2381, "imageId": "n181355", "question": "Does the cloth shirt look short sleeved or sleeveless?", "program": "BOX0=LOC(image=IMAGE,object='cloth shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the cloth shirt look short sleeved or sleeveless?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2382, "imageId": "n382416", "question": "On which side is the black bag?", "program": "BOX0=LOC(image=IMAGE,object='black bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2383, "imageId": "n181355", "question": "Do the shorts made of cloth look gray and short?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material are the shorts made of?')\nANSWER1=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER2=VQA(image=IMAGE0,question='Are the shorts short?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'cloth' and {ANSWER1} == 'gray' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 2384, "imageId": "n501609", "question": "What kind of appliance is to the left of the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of appliance is to the left of the oven?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2385, "imageId": "n137182", "question": "Is the man to the right or to the left of the girl?", "program": "BOX0=LOC(image=IMAGE,object='man')\nBOX1=LOC(image=IMAGE,object='girl')\nANSWER0=EVAL(expr=\"'right' if {BOX0[0]} > {BOX1[0]} else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2386, "imageId": "n57848", "question": "Are both the words and the numbers the same color?", "program": "BOX0=LOC(image=IMAGE,object='words')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='numbers')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the words?')\nANSWER1=VQA(image=IMAGE1,question='What color are the numbers?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2387, "imageId": "n57848", "question": "Do the numbers and the steps have the same color?", "program": "BOX0=LOC(image=IMAGE,object='numbers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='steps')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the numbers?')\nANSWER1=VQA(image=IMAGE1,question='What color are the steps?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2389, "imageId": "n355567", "question": "Is the clock to the right of the lady near the tennis ball?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis ball')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='clock')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2390, "imageId": "n49438", "question": "Which kind of furniture is not narrow?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is not narrow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2391, "imageId": "n97485", "question": "Is the appliance to the left of the oven empty or full?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'empty' if {ANSWER0} == 0 else 'full'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2392, "imageId": "n334278", "question": "What is the player that is to the right of the batter doing?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='player')\nANSWER0=VQA(image=IMAGE0,question='What is the player doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2393, "imageId": "n49438", "question": "What kind of furniture is short?", "program": "BOX0=LOC(image=IMAGE,object='short')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2394, "imageId": "n574498", "question": "Is the athletic person wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='athletic person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2395, "imageId": "n171169", "question": "How is the vehicle in front of the trees called?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='How is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2396, "imageId": "n173807", "question": "What's the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2397, "imageId": "n173807", "question": "What is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2398, "imageId": "n497789", "question": "What animal is in front of the people?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the people?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2399, "imageId": "n497789", "question": "What animal is in front of the people near the vehicle?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='people')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nANSWER0=VQA(image=IMAGE1,question='What animal is in front of the people?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2400, "imageId": "n126891", "question": "What is the boy doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the boy doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2401, "imageId": "n126891", "question": "Who is playing?", "program": "BOX0=LOC(image=IMAGE,object='playing')\nANSWER0=VQA(image=IMAGE,question='Who is playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2402, "imageId": "n480253", "question": "What is the vehicle in front of the brown trees called?", "program": "BOX0=LOC(image=IMAGE,object='brown trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2403, "imageId": "n480253", "question": "What is in front of the brown trees?", "program": "BOX0=LOC(image=IMAGE,object='brown trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the brown trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2404, "imageId": "n298104", "question": "Does the shirt look short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2405, "imageId": "n508641", "question": "Who is catching the ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is catching the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2406, "imageId": "n508641", "question": "Who is catching the round ball?", "program": "BOX0=LOC(image=IMAGE,object='round ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is catching the round ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2407, "imageId": "n184551", "question": "The open umbrella is of what color?", "program": "BOX0=LOC(image=IMAGE,object='open umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the open umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2408, "imageId": "n485969", "question": "Behind what is the player standing?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Behind what is the player standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2409, "imageId": "n432591", "question": "What kind of furniture are the pillows to the left of the clock lying on?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillows')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of furniture are the pillows lying on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2410, "imageId": "n51658", "question": "Does the wrist band made of cloth look black or red?", "program": "BOX0=LOC(image=IMAGE,object='wrist band')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the wrist band made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the wrist band?')\nANSWER2=EVAL(expr=\"'black' if {ANSWER0} == 'cloth' and {ANSWER1} == 'black' else 'red'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2411, "imageId": "n432591", "question": "The pillows are lying on what?", "program": "BOX0=LOC(image=IMAGE,object='pillows')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The pillows are lying on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2412, "imageId": "n520071", "question": "What item of furniture is large?", "program": "BOX0=LOC(image=IMAGE,object='large')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2414, "imageId": "n282607", "question": "Is there either any black ball or fence?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2415, "imageId": "n520071", "question": "Which piece of furniture is large?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which piece of furniture is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2416, "imageId": "n520071", "question": "What piece of furniture is not large?", "program": "ANSWER0=VQA(image=IMAGE,question='What piece of furniture is not large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2417, "imageId": "n475030", "question": "Is the sky above the people both clear and blue?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sky?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'clear and blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2418, "imageId": "n256120", "question": "Does the jacket that looks beige look comfortable?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE0,question='Does the jacket look comfortable?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'beige' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2419, "imageId": "n433532", "question": "What is the name of the piece of furniture that is made of the same material as the spoon to the left of her?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2420, "imageId": "n433532", "question": "What is common to the shelf and the spoon?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the shelf and the spoon?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2421, "imageId": "n350732", "question": "Is the chair green?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2422, "imageId": "n350732", "question": "Are there any blue chairs?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2423, "imageId": "n334278", "question": "Who is the player that is crouching watching?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is crouching watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2424, "imageId": "n14087", "question": "Is it indoors or outdoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it indoors or outdoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2425, "imageId": "n496803", "question": "Who is wearing the wristband?", "program": "BOX0=LOC(image=IMAGE,object='wristband')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the wristband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2426, "imageId": "n496803", "question": "Who is wearing a wrist band?", "program": "BOX0=LOC(image=IMAGE,object='wrist band')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a wrist band?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2427, "imageId": "n466319", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2428, "imageId": "n496803", "question": "Is the athlete wearing a wristband?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wristband')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2429, "imageId": "n530733", "question": "Are the shelves on the left side?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nANSWER0=EVAL(expr=\"'yes' if {BOX0}['x'] < IMAGE['width']/2 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2430, "imageId": "n119944", "question": "Are there men near the baskets that are in front of the tree?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='baskets')\nIMAGE1=CROP_NEAR(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='men')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2431, "imageId": "n290409", "question": "Is the basket behind a train?", "program": "BOX0=LOC(image=IMAGE,object='train')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='basket')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2432, "imageId": "n171169", "question": "Is the animal in front of the trees brown and large?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the animal?')\nANSWER3=VQA(image=IMAGE0,question='What size is the animal?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'brown' and {ANSWER3} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 2433, "imageId": "n66756", "question": "What is the batter doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the batter doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2434, "imageId": "n496803", "question": "Who is wearing the tank top?", "program": "BOX0=LOC(image=IMAGE,object='tank top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the tank top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2435, "imageId": "n496803", "question": "Who is wearing a tank top?", "program": "BOX0=LOC(image=IMAGE,object='tank top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a tank top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2436, "imageId": "n196058", "question": "What are the animals that are above the grass that is not tall?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not tall')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What are the animals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2437, "imageId": "n196058", "question": "What kind of animal is above the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is above the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2438, "imageId": "n477702", "question": "Do the male people sit on a sofa?", "program": "BOX0=LOC(image=IMAGE,object='male people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sofa')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2439, "imageId": "n196058", "question": "Do the zebras above the grass look black and white?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='zebras')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2440, "imageId": "n432591", "question": "What is located on top of the white thing that is lying on the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white thing')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='TOP')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What is located on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2441, "imageId": "n367944", "question": "On which side of the photo is the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2442, "imageId": "n272313", "question": "Are there both a helmet and a motorcycle in this image?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nBOX1=LOC(image=IMAGE,object='motorcycle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2443, "imageId": "n184551", "question": "Does the person next to the woman appear to be sleeping or reading?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Does the person appear to be sleeping or reading?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2444, "imageId": "n250715", "question": "What type of furniture is to the right of the device that is not turned off?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='turned off')\nIMAGE1=CROP_NOT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nIMAGE2=CROP_RIGHTOF(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What type of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2445, "imageId": "n196058", "question": "What are the animals in front of the brush that is not tall?", "program": "BOX0=LOC(image=IMAGE,object='brush')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nBOX2=LOC(image=IMAGE0,object='tall')\nBOX3=LOC(image=IMAGE0,object='not tall')\nBOX4=INTERSECT(box1=BOX1,box2=BOX3)\nANSWER0=COUNT(box=BOX4)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2446, "imageId": "n196058", "question": "What animals are in front of the brush?", "program": "BOX0=LOC(image=IMAGE,object='brush')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animals are in front of the brush?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2447, "imageId": "n413319", "question": "Are there either any lamps or rackets that are metallic?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='racket')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2448, "imageId": "n367944", "question": "Which kind of device is not portable?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of device is not portable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2449, "imageId": "n283587", "question": "Which kind of furniture is tall?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2450, "imageId": "n222915", "question": "Are there dark blue plates?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the plate?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'dark blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2451, "imageId": "n570181", "question": "Does the shirt made of cloth look long sleeved and blue?", "program": "BOX0=LOC(image=IMAGE,object='shirt made of cloth')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt long sleeved?')\nANSWER1=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2452, "imageId": "n437192", "question": "Is the sidewalk red?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sidewalk?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2453, "imageId": "n433692", "question": "What color is the mousepad?", "program": "BOX0=LOC(image=IMAGE,object='mousepad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the mousepad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2454, "imageId": "n578564", "question": "Does the brown picture seem to be outdoors or indoors?", "program": "BOX0=LOC(image=IMAGE,object='brown picture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the brown picture seem to be outdoors or indoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2455, "imageId": "n206358", "question": "How big is the vehicle on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=SIZE(box=BOX1)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2456, "imageId": "n166008", "question": "Is the table square and wooden?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the table?')\nANSWER1=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'square' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2457, "imageId": "n382416", "question": "Is she to the left or to the right of the bag that is made of leather?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='leather')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='she')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2458, "imageId": "n318684", "question": "Where is the sand?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2459, "imageId": "n69237", "question": "On which side of the photo is the metal appliance?", "program": "BOX0=LOC(image=IMAGE,object='metal appliance')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2460, "imageId": "n319845", "question": "What is under the table near the windows?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='windows')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is under the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2461, "imageId": "n192021", "question": "Which color is the curtain to the right of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtain')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2462, "imageId": "n513100", "question": "Are there any white cabinets or chairs?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2463, "imageId": "n398257", "question": "Is the book different in color than the plant?", "program": "BOX0=LOC(image=IMAGE,object='book')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='plant')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the book?')\nANSWER1=VQA(image=IMAGE1,question='What color is the plant?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2464, "imageId": "n98540", "question": "How tall are the socks?", "program": "ANSWER0=VQA(image=IMAGE,question='How tall are the socks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2465, "imageId": "n346247", "question": "What is in front of the doors that are on the front of the school?", "program": "BOX0=LOC(image=IMAGE,object='school')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='doors')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the doors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2466, "imageId": "n92308", "question": "Is there any smooth sand or snow?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nBOX1=LOC(image=IMAGE,object='snow')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2467, "imageId": "n346247", "question": "What are the stairs in front of?", "program": "BOX0=LOC(image=IMAGE,object='stairs')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the stairs in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2468, "imageId": "n305495", "question": "Is the floor below a toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='floor')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2469, "imageId": "n513429", "question": "Is the speaker wide or narrow?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nANSWER0=VQA(image=IMAGE,question='Is the speaker wide or narrow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2470, "imageId": "n305495", "question": "Are the pants white and long?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nANSWER0=VQA(image=IMAGE,question='What color are the pants?')\nANSWER1=VQA(image=IMAGE,question='Are the pants long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2471, "imageId": "n578564", "question": "What is the color of the cooking utensil made of metal?", "program": "BOX0=LOC(image=IMAGE,object='cooking utensil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the cooking utensil?')\nANSWER1=EVAL(expr=\"'metal' if {ANSWER0} == 'silver' or {ANSWER0} == 'gray' else 'not metal'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2472, "imageId": "n150962", "question": "Does the chair have small size?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2473, "imageId": "n160664", "question": "Is that woman to the left of a bag?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2474, "imageId": "n541688", "question": "Is the wood table behind the young person that is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shirt')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='wood table')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2475, "imageId": "n336443", "question": "Are there any fries on the plate that sits atop the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='fries')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2476, "imageId": "n69237", "question": "Are there laptop computers or napkins?", "program": "BOX0=LOC(image=IMAGE,object='laptop computer')\nBOX1=LOC(image=IMAGE,object='napkin')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2477, "imageId": "n12214", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2478, "imageId": "n314630", "question": "Do the countertop and the light switch have the same color?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='light switch')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the countertop?')\nANSWER1=VQA(image=IMAGE1,question='What color is the light switch?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2479, "imageId": "n296467", "question": "What are the beans inside of?", "program": "BOX0=LOC(image=IMAGE,object='beans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the beans inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2480, "imageId": "n164272", "question": "Is there a goat in front of the large building?", "program": "BOX0=LOC(image=IMAGE,object='large building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='goat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2481, "imageId": "n83784", "question": "How is the piece of furniture that is made of same material as the brown chair called?", "program": "BOX0=LOC(image=IMAGE,object='brown chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the brown chair made of?')\nANSWER1=VQA(image=IMAGE,question='How is the piece of furniture that is made of same material as the brown chair called?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2482, "imageId": "n299528", "question": "How clean is the concrete sidewalk?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the concrete sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2483, "imageId": "n219840", "question": "What kind of animal is to the left of the deer?", "program": "BOX0=LOC(image=IMAGE,object='deer')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is to the left of the deer?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2484, "imageId": "n526228", "question": "Is the happy man behind a coffee table?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='coffee table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2485, "imageId": "n446242", "question": "Do you see any lamps or mirrors there?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='mirror')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2486, "imageId": "n355339", "question": "Is the person that is to the left of the screen sitting on a boat?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='boat')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2487, "imageId": "n542609", "question": "What kind of vehicle is to the right of the people?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2488, "imageId": "n296467", "question": "Are the green vegetables to the left of the bowl that is on the right of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='green vegetables')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2489, "imageId": "n296467", "question": "What vegetables are inside the bowl the cookies are to the right of?", "program": "BOX0=LOC(image=IMAGE,object='cookies')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What vegetables are inside the bowl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2490, "imageId": "n296467", "question": "What is inside the bowl that is to the right of the dip?", "program": "BOX0=LOC(image=IMAGE,object='dip')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is inside the bowl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2491, "imageId": "n77818", "question": "What type of device is to the right of the speaker?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of device is to the right of the speaker?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2492, "imageId": "n386688", "question": "Do the trees appear to be beautiful?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the trees appear to be beautiful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2493, "imageId": "n305495", "question": "What color is the chair?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2494, "imageId": "n329514", "question": "Do you think the skateboarder's hair is long?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the length of the skateboarder\\'s hair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2495, "imageId": "n514467", "question": "Is the trash can on the right?", "program": "BOX0=LOC(image=IMAGE,object='trash can')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2496, "imageId": "n195925", "question": "Is the boat in the bottom part or in the top of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2497, "imageId": "n514467", "question": "Is the sidewalk made of concrete dry or wet?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the sidewalk made of?')\nANSWER1=VQA(image=IMAGE0,question='Is the sidewalk dry or wet?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2498, "imageId": "n313060", "question": "What drink is in front of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What drink is in front of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2499, "imageId": "n488874", "question": "Who carries the surfboard?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who carries the surfboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2500, "imageId": "n65202", "question": "Do the sneakers look blue and comfortable?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the sneakers?')\nANSWER1=VQA(image=IMAGE0,question='Do the sneakers look comfortable?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2501, "imageId": "n544255", "question": "What color is that umbrella?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nANSWER0=VQA(image=IMAGE,question='What color is that umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2502, "imageId": "n326988", "question": "Which kind of furniture is to the right of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is to the right of the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2503, "imageId": "n130638", "question": "Who is in front of the person that is crouching?", "program": "BOX0=LOC(image=IMAGE,object='person crouching')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the person that is crouching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2504, "imageId": "n162108", "question": "Which side is the toilet paper on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet paper')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2505, "imageId": "n302358", "question": "Is the sky clear and high?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the sky clear?')\nANSWER1=VQA(image=IMAGE0,question='Is the sky high?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2506, "imageId": "n130638", "question": "Who is in front of the boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the boy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2507, "imageId": "n579256", "question": "Do you see any rugs on the floor that is presented in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2508, "imageId": "n507959", "question": "Are the white boats on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white boats')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2509, "imageId": "n65202", "question": "Is the color of the jeans the same as the sneakers?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sneakers')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the jeans?')\nANSWER1=VQA(image=IMAGE1,question='What color are the sneakers?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2510, "imageId": "n271392", "question": "What is in front of the men?", "program": "BOX0=LOC(image=IMAGE,object='men')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the men?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2511, "imageId": "n413002", "question": "Is the Caucasian woman posing or looking down?", "program": "BOX0=LOC(image=IMAGE,object='Caucasian woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the Caucasian woman posing or looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2512, "imageId": "n140421", "question": "What kind of furniture is the table surrounded by?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_AROUND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the table surrounded by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2513, "imageId": "n293477", "question": "What food is lying on top of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2514, "imageId": "n293477", "question": "What is the food to the left of the hair clip lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2515, "imageId": "n59627", "question": "Which kind of animal is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2516, "imageId": "n140421", "question": "What are the pieces of furniture that the small table is surrounded by?", "program": "BOX0=LOC(image=IMAGE,object='small table')\nIMAGE0=CROP_AROUND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the pieces of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2517, "imageId": "n414992", "question": "How big are the trunks that look black?", "program": "BOX0=LOC(image=IMAGE,object='trunks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big are the trunks that look black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2518, "imageId": "n313060", "question": "Are both the straw and the sidewalk made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='straw')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sidewalk')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the straw made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the sidewalk made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2519, "imageId": "n350766", "question": "Is the color of the drawer blue?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the drawer?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2520, "imageId": "n319845", "question": "How large is the vase?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2521, "imageId": "n313060", "question": "Is the building different in color than the sign?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the building?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sign?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2522, "imageId": "n432591", "question": "What is located on top of the blanket?", "program": "BOX0=LOC(image=IMAGE,object='blanket')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the blanket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2523, "imageId": "n534106", "question": "What shape are the pillows to the right of her?", "program": "BOX0=LOC(image=IMAGE,object='her')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillows')\nANSWER0=VQA(image=IMAGE0,question='What shape are the pillows?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2524, "imageId": "n413002", "question": "Who is holding the bananas?", "program": "BOX0=LOC(image=IMAGE,object='bananas')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the bananas?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2525, "imageId": "n16656", "question": "What is common to the shoe lace and the shirt?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the shoe lace and the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2526, "imageId": "n90294", "question": "Are both the charger and the calculator made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='charger')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='calculator')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the charger made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the calculator made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' and {ANSWER1} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2527, "imageId": "n160664", "question": "Is the old woman to the right or to the left of the man near the giraffe?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='giraffe')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='old woman')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2528, "imageId": "n382416", "question": "Is the color of the heels the same as the color of the leggings?", "program": "BOX0=LOC(image=IMAGE,object='heels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='leggings')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the heels?')\nANSWER1=VQA(image=IMAGE1,question='What color are the leggings?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2529, "imageId": "n90294", "question": "Does the white device look short?", "program": "BOX0=LOC(image=IMAGE,object='white device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the white device look short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2530, "imageId": "n250715", "question": "Does the device to the left of the telephone have white color?", "program": "BOX0=LOC(image=IMAGE,object='telephone')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the device?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2531, "imageId": "n125122", "question": "Does that desk look dirty and wooden?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the desk look dirty?')\nANSWER1=VQA(image=IMAGE0,question='Does the desk look wooden?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2532, "imageId": "n154160", "question": "Is the person that is not dirty wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='dirty')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nBOX2=LOC(image=IMAGE,object='helmet')\nIMAGE1=CROP(image=IMAGE,box=BOX2)\nBOX3=LOC(image=IMAGE1,object='person')\nANSWER1=COUNT(box=BOX3)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2533, "imageId": "n260762", "question": "Which side is the man on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2534, "imageId": "n544255", "question": "What's the man wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's the man wearing?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2535, "imageId": "n154160", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2536, "imageId": "n579256", "question": "What appliance is in the picture?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nANSWER0=VQA(image=IMAGE,question='What appliance is in the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2537, "imageId": "n116329", "question": "Do you think the door is small?", "program": "BOX0=LOC(image=IMAGE,object='door')\nANSWER0=VQA(image=IMAGE,question='Do you think the door is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2538, "imageId": "n344136", "question": "Are there any mirrors on the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2539, "imageId": "n202379", "question": "Are the pants blue?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2540, "imageId": "n398429", "question": "Is the table red and wooden?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2541, "imageId": "n52544", "question": "Which color is the bucket?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the bucket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2542, "imageId": "n496803", "question": "The crowd that is sitting-down is watching who?", "program": "BOX0=LOC(image=IMAGE,object='sitting-down crowd')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The crowd that is sitting-down is watching who?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2543, "imageId": "n275148", "question": "Does the speaker that is to the left of the other speaker look black and high?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='speaker')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the speaker?')\nANSWER1=VQA(image=IMAGE1,question='How tall is the speaker?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'high' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2544, "imageId": "n275148", "question": "Does the speaker to the left of the other speaker look blue?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='speaker')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the speaker?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2545, "imageId": "n207893", "question": "What is on the mountains?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the mountains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2546, "imageId": "n207893", "question": "What are the trees on?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the trees on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2547, "imageId": "n207893", "question": "What is on the mountains the grass is below?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mountains')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is on the mountains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2548, "imageId": "n523165", "question": "Is the tall person below the kite wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tall person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the tall person wearing a hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2549, "imageId": "n146555", "question": "Is the person that is standing wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='person that is standing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person wearing glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2550, "imageId": "n161313", "question": "Are the snow pants green?", "program": "BOX0=LOC(image=IMAGE,object='snow pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the snow pants?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2551, "imageId": "n531731", "question": "Is the helmet made of the same material as the bench?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bench')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the helmet made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the bench made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2552, "imageId": "n146555", "question": "Are the stone buildings new and tall?", "program": "BOX0=LOC(image=IMAGE,object='stone buildings')\nANSWER0=VQA(image=IMAGE,question='Are the stone buildings new?')\nANSWER1=VQA(image=IMAGE,question='Are the stone buildings tall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2553, "imageId": "n95313", "question": "What is the piece of furniture behind the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='piece of furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2554, "imageId": "n95313", "question": "What item of furniture is behind the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is behind the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2555, "imageId": "n95313", "question": "What item of furniture is the closet behind of?", "program": "BOX0=LOC(image=IMAGE,object='closet')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is the closet behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2556, "imageId": "n64959", "question": "What is the shape of the appliance the box is smaller than?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=SHAPE(box=BOX1)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2557, "imageId": "n151768", "question": "Is the person that is bending resting or reading?", "program": "BOX0=LOC(image=IMAGE,object='person bending')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person resting or reading?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2558, "imageId": "n278312", "question": "Which side is the fridge on?", "program": "BOX0=LOC(image=IMAGE,object='fridge')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2559, "imageId": "n296467", "question": "What is the dessert to the left of the food next to the cookies?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cookies')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='dessert')\nANSWER0=VQA(image=IMAGE1,question='What is the dessert?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2560, "imageId": "n579256", "question": "On which side of the photo is the bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2561, "imageId": "n470920", "question": "Are there either any cloth placemats or umbrellas?", "program": "BOX0=LOC(image=IMAGE,object='cloth placemats')\nBOX1=LOC(image=IMAGE,object='umbrellas')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2562, "imageId": "n445353", "question": "Are there books on the floor that looks red?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2563, "imageId": "n445353", "question": "What is standing against the red bricks?", "program": "BOX0=LOC(image=IMAGE,object='red bricks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing against the red bricks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2564, "imageId": "n445353", "question": "Where are the boxes?", "program": "BOX0=LOC(image=IMAGE,object='boxes')\nANSWER0=VQA(image=IMAGE,question='Where are the boxes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2565, "imageId": "n357784", "question": "What is located on top of the bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the bottle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2566, "imageId": "n319845", "question": "What color do you think the chairs the vase is to the right of are?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nANSWER0=VQA(image=IMAGE0,question='What color are the chairs?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2567, "imageId": "n357784", "question": "What the gray clothing item is called?", "program": "BOX0=LOC(image=IMAGE,object='gray clothing item')\nANSWER0=VQA(image=IMAGE,question='What is the gray clothing item called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2568, "imageId": "n357784", "question": "What material is the bottle cap on top of the bottle made of?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle cap')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the bottle cap made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2569, "imageId": "n357784", "question": "What is the bottle cap made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the bottle cap made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2570, "imageId": "n146555", "question": "Is the plastic bottle to the right of a cow?", "program": "BOX0=LOC(image=IMAGE,object='cow')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2571, "imageId": "n357784", "question": "What kind of clothing is worn?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of clothing is worn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2572, "imageId": "n249639", "question": "What is the trash can made of?", "program": "BOX0=LOC(image=IMAGE,object='trash can')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the trash can made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2573, "imageId": "n207708", "question": "Does the drawer below the countertop seem to be rectangular and white?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drawer')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What shape is the drawer?')\nANSWER1=VQA(image=IMAGE1,question='What color is the drawer?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rectangular' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2574, "imageId": "n37274", "question": "What is the drink that the cup to the right of the man is full of called?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cup')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the drink called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2575, "imageId": "n37274", "question": "What drink is the cup full of?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What drink is the cup full of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2576, "imageId": "n369970", "question": "What is the person that is standing doing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2577, "imageId": "n51658", "question": "Do the shorts and the shoes have the same color?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shoes')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE1,question='What color are the shoes?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2578, "imageId": "n573460", "question": "Are the white shoes behind the person that the hat is worn on?", "program": "BOX0=LOC(image=IMAGE,object='person with hat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white shoes')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2579, "imageId": "n548534", "question": "What are the knives made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the knives made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2580, "imageId": "n548534", "question": "The utensils made of metal are sitting on what?", "program": "BOX0=LOC(image=IMAGE,object='metal utensils')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The utensils made of metal are sitting on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2581, "imageId": "n16425", "question": "What vehicle is the telephone pole behind of, a train or a bus?", "program": "BOX0=LOC(image=IMAGE,object='telephone pole')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='train')\nBOX2=LOC(image=IMAGE0,object='bus')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'train' if {ANSWER0} > 0 else 'bus'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2582, "imageId": "n415215", "question": "Are there any toilets near the toilet brush made out of plastic?", "program": "BOX0=LOC(image=IMAGE,object='toilet brush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic')\nIMAGE1=CROP_NEAR(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='toilet')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2583, "imageId": "n455563", "question": "Where is she?", "program": "ANSWER0=VQA(image=IMAGE,question='Where is she?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2584, "imageId": "n551964", "question": "Is there any motorcycle in this photograph that is not clean?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the motorcycle clean?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2585, "imageId": "n194179", "question": "Is the short sleeved shirt black and white or colorful?", "program": "BOX0=LOC(image=IMAGE,object='short sleeved shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the short sleeved shirt?')\nANSWER1=EVAL(expr=\"'black and white' if {ANSWER0} == 'black' or {ANSWER0} == 'white' else 'colorful'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2586, "imageId": "n566028", "question": "What do you think does the professional person play with?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think does the professional person play with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2587, "imageId": "n125122", "question": "What color do you think these curtains are?", "program": "ANSWER0=VQA(image=IMAGE,question='What color do you think these curtains are?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2588, "imageId": "n310625", "question": "Is the bottle to the right or to the left of the toothbrush that looks green and white?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush',color='green and white')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2589, "imageId": "n566028", "question": "Is the professional person wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='professional person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the professional person wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2590, "imageId": "n314630", "question": "What is the house made of wood sitting beside, a toaster or a coffee maker?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toaster')\nBOX2=LOC(image=IMAGE0,object='coffee maker')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'toaster' if {ANSWER0} > 0 else 'coffee maker'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2591, "imageId": "n200225", "question": "Does the pepperoni have a different color than the spinach?", "program": "BOX0=LOC(image=IMAGE,object='pepperoni')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='spinach')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the pepperoni?')\nANSWER1=VQA(image=IMAGE1,question='What color is the spinach?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2592, "imageId": "n554880", "question": "Who wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who wears a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2593, "imageId": "n314630", "question": "What is sitting beside the appliance that is beside the knives?", "program": "BOX0=LOC(image=IMAGE,object='knives')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is sitting beside the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2594, "imageId": "n125122", "question": "Do these curtains look long and white?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do these curtains look long?')\nANSWER1=VQA(image=IMAGE0,question='Do these curtains look white?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2595, "imageId": "n167164", "question": "What kind of vehicle is behind the SUV?", "program": "BOX0=LOC(image=IMAGE,object='SUV')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is behind the SUV?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2596, "imageId": "n282436", "question": "Is the table lamp in the top part or in the bottom of the picture?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table lamp')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2597, "imageId": "n167164", "question": "What vehicle is the truck behind of?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is the truck behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2598, "imageId": "n233607", "question": "Are there any couches or lamps that are not pink?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What color are the couches?')\nANSWER4=VQA(image=IMAGE,question='What color are the lamps?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} != 'pink' or {ANSWER4} != 'pink' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 2599, "imageId": "n233607", "question": "Which color does the lamp made of metal have?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the lamp?')\nANSWER1=VQA(image=IMAGE0,question='What material is the lamp made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'metal' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2600, "imageId": "n460556", "question": "Does the light fixture have the same color as the hat?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hat')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the light fixture?')\nANSWER1=VQA(image=IMAGE1,question='What color is the hat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2601, "imageId": "n199097", "question": "Is the gentleman in the bottom part or in the top of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gentleman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2602, "imageId": "n199097", "question": "The gentleman is in front of who?", "program": "BOX0=LOC(image=IMAGE,object='gentleman')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The gentleman is in front of who?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2603, "imageId": "n501951", "question": "What is the person that is riding driving?", "program": "BOX0=LOC(image=IMAGE,object='riding')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person driving?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2604, "imageId": "n208458", "question": "Where is the long dock going into?", "program": "BOX0=LOC(image=IMAGE,object='long dock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the long dock going into?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2605, "imageId": "n501951", "question": "Who is driving the motorcycle?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is driving the motorcycle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2606, "imageId": "n9856", "question": "How does the baseball mitt look, open or closed?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How does the baseball mitt look, open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2607, "imageId": "n258500", "question": "Is the person that is looking down wearing a headband?", "program": "BOX0=LOC(image=IMAGE,object='person looking down')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person wearing a headband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2608, "imageId": "n258500", "question": "Is the logo green?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the logo?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2609, "imageId": "n314630", "question": "What do you think is the color of the appliance that looks hard?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is the color of the appliance that looks hard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2610, "imageId": "n531731", "question": "What color is the bag next to the player?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP_NEXTTO(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2611, "imageId": "n100552", "question": "Is the ground dry or wet?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the ground dry or wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2612, "imageId": "n281241", "question": "Is the man to the right of a gentleman?", "program": "BOX0=LOC(image=IMAGE,object='gentleman')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2613, "imageId": "n55058", "question": "On which side is the small meat?", "program": "BOX0=LOC(image=IMAGE,object='small meat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2614, "imageId": "n386682", "question": "What makes up the washing machine that is to the left of the dish washer?", "program": "BOX0=LOC(image=IMAGE,object='dish washer')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='washing machine')\nANSWER0=VQA(image=IMAGE0,question='What makes up the washing machine?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2615, "imageId": "n538684", "question": "Is the flat field above the spectators in the bottom of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='spectators')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='flat field')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2616, "imageId": "n538684", "question": "Are there any spectators above the dugout behind the batter?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dugout')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='spectators')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2617, "imageId": "n259002", "question": "Is the soccer player in front of the goal watching the ball?", "program": "BOX0=LOC(image=IMAGE,object='goal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer player')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='ball')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2618, "imageId": "n259002", "question": "What is the soccer player in front of the goal watching?", "program": "BOX0=LOC(image=IMAGE,object='goal')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer player')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the soccer player watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2619, "imageId": "n97485", "question": "Does the table have the same shape as the oven?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='oven')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What shape is the table?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the oven?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2620, "imageId": "n259002", "question": "Are there soccer players to the right of the trashcan that is in front of the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trashcan')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='soccer players')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2621, "imageId": "n259002", "question": "Who is watching the ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2622, "imageId": "n259002", "question": "Who is watching the ball on the grass?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2623, "imageId": "n55058", "question": "Which kind of fast food is to the right of the mug?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of fast food is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2624, "imageId": "n55058", "question": "What is the food to the right of the mug?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2625, "imageId": "n470131", "question": "Is the table that looks yellow dirty or clean?", "program": "BOX0=LOC(image=IMAGE,object='yellow table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the table dirty or clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2626, "imageId": "n65230", "question": "What is hanging above the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging above the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2627, "imageId": "n65230", "question": "Is the shirt long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt long sleeved?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2628, "imageId": "n498712", "question": "Who is the poster hanging above?", "program": "BOX0=LOC(image=IMAGE,object='poster')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the poster hanging above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2629, "imageId": "n184385", "question": "What is the vegetable that is the same shape as the stove top called?", "program": "BOX0=LOC(image=IMAGE,object='stove top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the vegetable that is the same shape as the stove top called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2630, "imageId": "n312206", "question": "What food is to the right of the container?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What food is to the right of the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2631, "imageId": "n527589", "question": "Who is wearing the earring?", "program": "BOX0=LOC(image=IMAGE,object='earring')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the earring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2632, "imageId": "n434283", "question": "Is the mirror in the top or in the bottom part?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2633, "imageId": "n434283", "question": "Are there bookcases above the sand?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bookcases')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2634, "imageId": "n433532", "question": "Do you see any stoves near the towel?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2635, "imageId": "n433532", "question": "What appliance is below the oil near the wine?", "program": "BOX0=LOC(image=IMAGE,object='oil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wine')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What appliance is below the oil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2636, "imageId": "n386688", "question": "What is underneath the boats?", "program": "BOX0=LOC(image=IMAGE,object='boats')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the boats?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2637, "imageId": "n433532", "question": "Do you see any food?", "program": "BOX0=LOC(image=IMAGE,object='food')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2638, "imageId": "n386688", "question": "What kind of watercraft floats on the ocean?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of watercraft floats on the ocean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2639, "imageId": "n282436", "question": "Do the mouse and the curtain have the same color?", "program": "BOX0=LOC(image=IMAGE,object='mouse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='curtain')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the mouse?')\nANSWER1=VQA(image=IMAGE1,question='What color is the curtain?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2640, "imageId": "n6908", "question": "The chair that is not uncomfortable has what color?", "program": "BOX0=LOC(image=IMAGE,object='uncomfortable chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'uncomfortable' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2641, "imageId": "n324908", "question": "Which is larger, the pasture or the horse?", "program": "BOX0=LOC(image=IMAGE,object='pasture')\nBOX1=LOC(image=IMAGE,object='horse')\nANSWER0=AREA(box=BOX0)\nANSWER1=AREA(box=BOX1)\nANSWER2=EVAL(expr=\"'pasture' if {ANSWER0} > {ANSWER1} else 'horse'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2642, "imageId": "n433532", "question": "Does the stove under the oil have white color?", "program": "BOX0=LOC(image=IMAGE,object='oil')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stove')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the stove?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2643, "imageId": "n309148", "question": "What is the bridge behind of, a fire truck or an ambulance?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bridge')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'fire truck' if {ANSWER0} > 0 else 'ambulance'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2644, "imageId": "n546616", "question": "Which is less healthy, the marshmallow or the raspberry?", "program": "BOX0=LOC(image=IMAGE,object='marshmallow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='raspberry')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='How healthy is the marshmallow?')\nANSWER1=VQA(image=IMAGE1,question='How healthy is the raspberry?')\nANSWER2=EVAL(expr=\"'marshmallow' if {ANSWER0} < {ANSWER1} else 'raspberry'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2645, "imageId": "n118102", "question": "Are there any tents or breads?", "program": "BOX0=LOC(image=IMAGE,object='tent')\nBOX1=LOC(image=IMAGE,object='bread')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2646, "imageId": "n470920", "question": "What is the bald man holding onto?", "program": "BOX0=LOC(image=IMAGE,object='bald man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bald man holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2647, "imageId": "n209843", "question": "What is the pattern of the towel?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pattern of the towel?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2648, "imageId": "n534106", "question": "Does the donut have brown color and square shape?", "program": "BOX0=LOC(image=IMAGE,object='donut')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the donut?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the donut?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2649, "imageId": "n209843", "question": "Does that towel have green color and striped pattern?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the towel?')\nANSWER1=VQA(image=IMAGE0,question='What pattern does the towel have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'striped' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2650, "imageId": "n336443", "question": "What is the food on the plate?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the food on the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2651, "imageId": "n336443", "question": "Which kind of food is on the plate?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is on the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2652, "imageId": "n222915", "question": "What's the glass sitting on?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the glass sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2653, "imageId": "n222915", "question": "What is the glass made of glass sitting on?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the glass sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2654, "imageId": "n485969", "question": "Do you see either white fences or hats?", "program": "BOX0=LOC(image=IMAGE,object='fences')\nBOX1=LOC(image=IMAGE,object='hats')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2655, "imageId": "n500308", "question": "What appliance is made of glass?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nANSWER0=VQA(image=IMAGE,question='What appliance is made of glass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2656, "imageId": "n500308", "question": "Which kind of appliance is this?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of appliance is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2657, "imageId": "n181355", "question": "Which kind of furniture is in front of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is in front of the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2658, "imageId": "n500308", "question": "What kind of appliance is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of appliance is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2659, "imageId": "n181355", "question": "What is in front of the couch made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cloth')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2660, "imageId": "n28996", "question": "What color is the bronwy that is sitting inside the container?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bronwy')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the bronwy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2661, "imageId": "n200692", "question": "Which size is the white cake, small or large?", "program": "BOX0=LOC(image=IMAGE,object='white cake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which size is the white cake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2662, "imageId": "n143672", "question": "Does the skier that is skiing appear to be male?", "program": "BOX0=LOC(image=IMAGE,object='skier')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the skier appear to be male?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2663, "imageId": "n271392", "question": "Are the old men to the left of a car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='old men')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2664, "imageId": "n398257", "question": "What color is the sweatshirt in front of the rug, brown or blue?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sweatshirt')\nANSWER0=VQA(image=IMAGE0,question='What color is the sweatshirt?')\nANSWER1=EVAL(expr=\"'brown' if {ANSWER0} == 'brown' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2665, "imageId": "n143672", "question": "Who is skiing?", "program": "BOX0=LOC(image=IMAGE,object='skiing')\nANSWER0=VQA(image=IMAGE,question='Who is skiing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2666, "imageId": "n500308", "question": "Is the clock both rectangular and black?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the clock?')\nANSWER1=VQA(image=IMAGE0,question='What color is the clock?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rectangular' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2667, "imageId": "n187961", "question": "What type of animal is behind the person on the right?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What type of animal is behind the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2668, "imageId": "n357126", "question": "Which side of the image is the brown house on?", "program": "BOX0=LOC(image=IMAGE,object='brown house')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='brown house')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2669, "imageId": "n58220", "question": "Is the jacket white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the jacket?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2670, "imageId": "n455563", "question": "Does she look old?", "program": "ANSWER0=VQA(image=IMAGE,question='Does she look old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2671, "imageId": "n451187", "question": "Who wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who wears a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2672, "imageId": "n140421", "question": "Are the curtains colorful?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the curtains colorful?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'colorful' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2673, "imageId": "n100552", "question": "What is the elephant inside of?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP_INSIDE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the elephant inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2674, "imageId": "n240666", "question": "What is in front of the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2675, "imageId": "n214497", "question": "What color are the vehicles the sign is taller than?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What color are the vehicles?')\nANSWER1=EVAL(expr=\"'taller than' if {ANSWER0} == 'blue' else 'not taller than'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2676, "imageId": "n89148", "question": "What is in front of the adult person?", "program": "BOX0=LOC(image=IMAGE,object='adult person')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the adult person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2677, "imageId": "n278453", "question": "Does the person that is sitting appear to be posing or looking down?", "program": "BOX0=LOC(image=IMAGE,object='person sitting')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the person appear to be posing or looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2678, "imageId": "n410289", "question": "Is the tap to the left of the toilet hard and metallic?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tap')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What is the material of the tap?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'hard and metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 2679, "imageId": "n195249", "question": "Which company is the hat from?", "program": "ANSWER0=VQA(image=IMAGE,question='Which company is the hat from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2680, "imageId": "n302358", "question": "What is located on top of the mud?", "program": "BOX0=LOC(image=IMAGE,object='mud')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the mud?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2681, "imageId": "n549922", "question": "What kind of furniture is the cable on?", "program": "BOX0=LOC(image=IMAGE,object='cable')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the cable on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2682, "imageId": "n302387", "question": "On which side of the picture is the square box?", "program": "BOX0=LOC(image=IMAGE,object='square box')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2683, "imageId": "n501609", "question": "Does the oven have a different color than the stove?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='stove')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the oven?')\nANSWER1=VQA(image=IMAGE1,question='What color is the stove?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2684, "imageId": "n14", "question": "Is the motorbike to the right of the skateboarder in this photo?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorbike')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2685, "imageId": "n342511", "question": "Which kind of clothing is red?", "program": "BOX0=LOC(image=IMAGE,object='red')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is red?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2686, "imageId": "n12214", "question": "Is the black van to the left of the car on the left of the image?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='black van')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2687, "imageId": "n342511", "question": "Which kind of clothing is not red, the coat or the hat?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hat')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the coat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the hat?')\nANSWER2=EVAL(expr=\"'coat' if {ANSWER0} != 'red' else 'hat'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2688, "imageId": "n69237", "question": "What is leaning against the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is leaning against the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2689, "imageId": "n69237", "question": "What is leaning against the glass window?", "program": "BOX0=LOC(image=IMAGE,object='glass window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is leaning against the glass window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2690, "imageId": "n329479", "question": "Is the color of the tee shirt black?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the tee shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2691, "imageId": "n14087", "question": "Which kind of furniture is the dog in front of?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the dog in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2692, "imageId": "n507959", "question": "Do the dolls that are to the left of the people look large and colorful?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dolls')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2693, "imageId": "n181210", "question": "Which kind of meat is crispy?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of meat is crispy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2694, "imageId": "n9181", "question": "Is the window cloudy and large?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the window cloudy?')\nANSWER1=VQA(image=IMAGE0,question='Is the window large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2695, "imageId": "n181210", "question": "What do you think is the crispy meat?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is the crispy meat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2696, "imageId": "n14087", "question": "What is the item of furniture that the dog is in front of?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2697, "imageId": "n260762", "question": "Who is the man watching?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2698, "imageId": "n181210", "question": "Which kind of meat is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of meat is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2699, "imageId": "n37274", "question": "Are the glasses on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2700, "imageId": "n356822", "question": "What is that boy holding?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the boy holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2701, "imageId": "n356822", "question": "Who is holding the baseball mitt?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the baseball mitt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2702, "imageId": "n356822", "question": "Who is holding the baseball mitt that is made of leather?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the baseball mitt?')\nANSWER1=VQA(image=IMAGE0,question='What material is the baseball mitt made of?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if '{ANSWER1}' == 'leather' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2703, "imageId": "n356822", "question": "Is the boy to the left or to the right of the person on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='boy')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2704, "imageId": "n260762", "question": "Where is the person that is standing standing on?", "program": "BOX0=LOC(image=IMAGE,object='standing person')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the person standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2705, "imageId": "n507149", "question": "Is the sand in front of the mountain both beige and fine?", "program": "BOX0=LOC(image=IMAGE,object='mountain')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sand')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the sand?')\nANSWER3=VQA(image=IMAGE0,question='What texture is the sand?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'beige' and {ANSWER3} == 'fine' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 2706, "imageId": "n181355", "question": "What is the man to the left of the pillow holding?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2707, "imageId": "n119944", "question": "Are there both notebooks and cans in the scene?", "program": "BOX0=LOC(image=IMAGE,object='notebook')\nBOX1=LOC(image=IMAGE,object='can')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2708, "imageId": "n111390", "question": "Who is standing behind the cake?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing behind the cake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2709, "imageId": "n181355", "question": "Who is sitting in front of the pillow that is to the left of the Wii controller?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='Wii controller')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is sitting in front of the pillow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2710, "imageId": "n127705", "question": "Is the ground smooth or rough?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the ground smooth or rough?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2711, "imageId": "n223750", "question": "Who is in front of the green bushes?", "program": "BOX0=LOC(image=IMAGE,object='green bushes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the green bushes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2712, "imageId": "n181355", "question": "Is the man to the left of the woman sitting in front of a pillow?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='pillow')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2713, "imageId": "n181355", "question": "What is the man to the left of the woman sitting in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the man sitting in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2714, "imageId": "n386682", "question": "Is the faucet in front of the white tiles?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white tiles')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2715, "imageId": "n140421", "question": "Is wood used to make the chairs that look small?", "program": "BOX0=LOC(image=IMAGE,object='small chairs')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material are the chairs made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2716, "imageId": "n386682", "question": "What is in front of the white tiles?", "program": "BOX0=LOC(image=IMAGE,object='white tiles')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the white tiles?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2717, "imageId": "n386682", "question": "What is the faucet in front of?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the faucet in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2718, "imageId": "n470920", "question": "What is the woman to the right of the bag wearing?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the woman wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2719, "imageId": "n513429", "question": "Is the black speaker both little and narrow?", "program": "BOX0=LOC(image=IMAGE,object='black speaker')\nANSWER0=VQA(image=IMAGE,question='Is the black speaker little?')\nANSWER1=VQA(image=IMAGE,question='Is the black speaker narrow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2720, "imageId": "n470920", "question": "Is the woman that is staring wearing goggles?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the woman wearing goggles?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2721, "imageId": "n143935", "question": "What's in front of the house?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2722, "imageId": "n143935", "question": "What is in front of the house the barn is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='barn')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the barn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2723, "imageId": "n143935", "question": "Is the lush tree behind a house?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lush tree')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2724, "imageId": "n6309", "question": "Are there girls to the left of the horse that is attached to the cart?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cart')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='girls')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2725, "imageId": "n92308", "question": "Are the trousers short and dark?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the trousers short?')\nANSWER1=VQA(image=IMAGE,question='What color are the trousers?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'short' and {ANSWER1} == 'dark' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2726, "imageId": "n88933", "question": "What is the happy girl sitting in?", "program": "BOX0=LOC(image=IMAGE,object='happy girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the happy girl sitting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2727, "imageId": "n54424", "question": "What is the boy playing with?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the boy playing with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2728, "imageId": "n578564", "question": "What is under the pan?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the pan?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2729, "imageId": "n499081", "question": "The rug is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The rug is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2730, "imageId": "n499081", "question": "What is in front of the cabinet?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the cabinet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2731, "imageId": "n369313", "question": "Are there red tables or ottomen?", "program": "BOX0=LOC(image=IMAGE,object='red table')\nBOX1=LOC(image=IMAGE,object='ottomen')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2732, "imageId": "n578564", "question": "Is the cutting board in the bottom part of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cutting board')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2733, "imageId": "n499081", "question": "What is the rug in front of?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the rug in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2734, "imageId": "n411121", "question": "Does the person to the right of the van look female?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2735, "imageId": "n334278", "question": "The umpire to the right of the player is standing where?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umpire')\nANSWER0=VQA(image=IMAGE0,question='Where is the umpire standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2736, "imageId": "n95904", "question": "What do the umbrella and the fence post have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the umbrella and the fence post have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2737, "imageId": "n89148", "question": "Is the doll to the right of the ladder made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='ladder')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='doll')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2738, "imageId": "n160664", "question": "Does the fence have round shape?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the fence?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2739, "imageId": "n51002", "question": "In which part of the picture is the computer monitor?", "program": "BOX0=LOC(image=IMAGE,object='computer monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In which part of the picture is the computer monitor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2740, "imageId": "n16936", "question": "Who are the spectators watching?", "program": "BOX0=LOC(image=IMAGE,object='spectators')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who are the spectators watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2741, "imageId": "n16936", "question": "The people that are waiting are watching who?", "program": "BOX0=LOC(image=IMAGE,object='waiting people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The people that are waiting are watching who?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2742, "imageId": "n16936", "question": "Who is watching the skateboarder on the left side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the skateboarder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2743, "imageId": "n98540", "question": "Does the jersey have the same color as the cap?", "program": "BOX0=LOC(image=IMAGE,object='jersey')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cap')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the jersey?')\nANSWER1=VQA(image=IMAGE1,question='What color is the cap?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2744, "imageId": "n97485", "question": "Is the chair tan or red?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=VQA(image=IMAGE,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'tan' or {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2745, "imageId": "n386682", "question": "Are there toilets next to the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2746, "imageId": "n58220", "question": "Are there green hats in the photo?", "program": "BOX0=LOC(image=IMAGE,object='green hat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2747, "imageId": "n335542", "question": "Is the picture frame that is not small decorated with a bear?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nBOX1=LOC(image=IMAGE,object='small')\nBOX2=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2748, "imageId": "n260521", "question": "Is the fence behind a car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2749, "imageId": "n470920", "question": "In which part are the glasses, the top or the bottom?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glasses')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2750, "imageId": "n202379", "question": "What is the fence made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2751, "imageId": "n573460", "question": "Do the shorts have gray color and short length?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE0,question='What is the length of the shorts?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2752, "imageId": "n437064", "question": "Is the utensil in front of the cake clean and metallic?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='Is the utensil clean and metallic?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 2753, "imageId": "n4777", "question": "Of what color is the table the woman is sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=VQA(image=IMAGE0,question='Of what color is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2754, "imageId": "n357784", "question": "What do you think is located on top of the bottle made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='bottle made of plastic')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is located on top of the bottle made of plastic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2755, "imageId": "n326988", "question": "Do the shelves look brown and short?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shelves?')\nANSWER1=VQA(image=IMAGE0,question='Are the shelves short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2756, "imageId": "n16378", "question": "How wide are the black jeans?", "program": "BOX0=LOC(image=IMAGE,object='black jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How wide are the black jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2757, "imageId": "n413002", "question": "What type of animal is the Caucasian person looking at?", "program": "BOX0=LOC(image=IMAGE,object='Caucasian person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of animal is the person looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2758, "imageId": "n326988", "question": "How tall are the shelves?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nANSWER0=MEASURE(box=BOX0,property='height')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2759, "imageId": "n4777", "question": "How big is the table that the stroller is parked beside?", "program": "BOX0=LOC(image=IMAGE,object='stroller')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=SIZE(box=BOX1)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2760, "imageId": "n390187", "question": "Is the jacket that is not short sleeved pink and clean?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE0,question='Is the jacket clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'pink' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2761, "imageId": "n382416", "question": "Is the coat white and long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the coat?')\nANSWER1=VQA(image=IMAGE0,question='Are the sleeves of the coat long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2762, "imageId": "n554880", "question": "Does the shirt look open or closed?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2763, "imageId": "n560243", "question": "What is in front of the plants?", "program": "BOX0=LOC(image=IMAGE,object='plants')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the plants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2764, "imageId": "n65885", "question": "Are there any tables or lamps that are not metallic?", "program": "BOX0=LOC(image=IMAGE,object='table')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2765, "imageId": "n65866", "question": "Do you see any toilets to the left of the drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2766, "imageId": "n460556", "question": "Is the backpack large and dark?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the backpack large?')\nANSWER1=VQA(image=IMAGE0,question='Is the backpack dark?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2767, "imageId": "n187961", "question": "Are the trees near the rock short and green?", "program": "BOX0=LOC(image=IMAGE,object='rock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='short trees')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='green trees')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 2768, "imageId": "n187961", "question": "Who is wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2769, "imageId": "n527290", "question": "Which side are the shelves on?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2770, "imageId": "n527589", "question": "Does the basket look narrow?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the basket look narrow?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'narrow' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2771, "imageId": "n511913", "question": "Do you see chairs to the left of the books?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2772, "imageId": "n357784", "question": "Is the bottle cap on top of a wine glass?", "program": "BOX0=LOC(image=IMAGE,object='wine glass')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle cap')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2773, "imageId": "n46510", "question": "Is the sky clear?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sky clear?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'clear' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2774, "imageId": "n441859", "question": "What color is the hat the person is wearing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2775, "imageId": "n162148", "question": "Does the dress shirt look orange and striped?", "program": "BOX0=LOC(image=IMAGE,object='dress shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the dress shirt?')\nANSWER1=VQA(image=IMAGE0,question='Is the dress shirt striped?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2776, "imageId": "n4777", "question": "What is the bag hanging from?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bag hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2777, "imageId": "n24526", "question": "Who is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2778, "imageId": "n24526", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2779, "imageId": "n357784", "question": "Is the curtain to the left of a pillow?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtain')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2780, "imageId": "n262920", "question": "What is the man looking at?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2781, "imageId": "n79078", "question": "Is the sign on top of the pole white and metallic?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=VQA(image=IMAGE0,question='What color is the sign?')\nANSWER1=VQA(image=IMAGE0,question='What material is the sign made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2782, "imageId": "n117888", "question": "Is the ball on the right side?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2783, "imageId": "n222915", "question": "What food is tan?", "program": "BOX0=LOC(image=IMAGE,object='tan')\nANSWER0=VQA(image=IMAGE,question='What food is tan?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2784, "imageId": "n233607", "question": "What is under the person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2785, "imageId": "n413319", "question": "Does the polo shirt look white and short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='polo shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the polo shirt?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the polo shirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'short sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2786, "imageId": "n150962", "question": "On which side of the image is the mat?", "program": "BOX0=LOC(image=IMAGE,object='mat')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2787, "imageId": "n116329", "question": "What is the window made of?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the window made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2788, "imageId": "n262920", "question": "What is the name of the piece of furniture that is shown in this picture?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the name of the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2789, "imageId": "n89148", "question": "Which kind of toy is to the right of the ladder?", "program": "BOX0=LOC(image=IMAGE,object='ladder')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of toy is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2790, "imageId": "n216553", "question": "What length is the tail?", "program": "BOX0=LOC(image=IMAGE,object='tail')\nANSWER0=LENGTH(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2791, "imageId": "n355339", "question": "Which material is the laptop near the glass made of?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which material is the laptop made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2792, "imageId": "n545516", "question": "Where is the airplane?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nANSWER0=VQA(image=IMAGE,question='Where is the airplane?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2793, "imageId": "n319845", "question": "Do the chairs to the right of the vase look dark brown?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2794, "imageId": "n367944", "question": "Is the chair on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2795, "imageId": "n184385", "question": "Is the appliance beside the wall metallic and black?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='metallic')\nIMAGE1=CROP(image=IMAGE0,box=BOX2)\nBOX3=LOC(image=IMAGE1,object='black')\nANSWER2=COUNT(box=BOX3)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 2796, "imageId": "n554880", "question": "Is the chair light brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'light brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2797, "imageId": "n473688", "question": "What is the soap dispenser sitting on?", "program": "BOX0=LOC(image=IMAGE,object='soap dispenser')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the soap dispenser sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2798, "imageId": "n204894", "question": "Are there cats or toys?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nBOX1=LOC(image=IMAGE,object='toy')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2799, "imageId": "n565418", "question": "Are the windows foggy and dark?", "program": "BOX0=LOC(image=IMAGE,object='windows')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the windows foggy?')\nANSWER1=VQA(image=IMAGE0,question='Are the windows dark?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2800, "imageId": "n249639", "question": "Is there any towel near the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towel')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2801, "imageId": "n249639", "question": "On which side of the picture is the white towel?", "program": "BOX0=LOC(image=IMAGE,object='white towel')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2802, "imageId": "n565418", "question": "Are the windows dark or white?", "program": "BOX0=LOC(image=IMAGE,object='window')\nANSWER0=VQA(image=IMAGE,question='What color are the windows?')\nANSWER1=EVAL(expr=\"'dark' if 'dark' in {ANSWER0} else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2803, "imageId": "n89148", "question": "Does the toy above the girl look small and white?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color is the toy?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'white' else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 2804, "imageId": "n431447", "question": "What is filled with the pizza?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is filled with the pizza?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2805, "imageId": "n66756", "question": "Are the bat and the mask made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='mask')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the bat made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the mask made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2806, "imageId": "n431447", "question": "What is the container in front of the container filled with?", "program": "BOX0=LOC(image=IMAGE,object='container filled with')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the container in front of the container filled with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2807, "imageId": "n429961", "question": "Is the vehicle dirty?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=VQA(image=IMAGE,question='Is the vehicle dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2808, "imageId": "n240973", "question": "What piece of furniture is the laptop sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is the laptop sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2809, "imageId": "n240666", "question": "What do the faucet and the light fixture have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the faucet and the light fixture have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2810, "imageId": "n16378", "question": "What is the woman pulling?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman pulling?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2811, "imageId": "n6908", "question": "What is hanging off the picture frame?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging off the picture frame?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2812, "imageId": "n6908", "question": "What's the Christmas light hanging off of?", "program": "BOX0=LOC(image=IMAGE,object='Christmas light')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the Christmas light hanging off of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2813, "imageId": "n318684", "question": "Is there an umbrella to the right of the man the hair is on top of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hair')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='umbrella')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2814, "imageId": "n6908", "question": "Which kind of furniture is the Christmas light behind of?", "program": "BOX0=LOC(image=IMAGE,object='Christmas light')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the Christmas light behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2815, "imageId": "n470920", "question": "What is located on top of the woman in the middle?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is located on top of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2816, "imageId": "n159802", "question": "Are there women to the right of the small cell phone?", "program": "BOX0=LOC(image=IMAGE,object='small cell phone')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='women')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2817, "imageId": "n480253", "question": "Is the vehicle that looks brown parked in front of a tractor?", "program": "BOX0=LOC(image=IMAGE,object='brown vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tractor')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2818, "imageId": "n312206", "question": "Is the knife on the left?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2819, "imageId": "n296467", "question": "Are the orange vegetables and the beans near the cookies both fresh?", "program": "BOX0=LOC(image=IMAGE,object='orange vegetables')\nBOX1=LOC(image=IMAGE,object='beans')\nBOX2=LOC(image=IMAGE,object='cookies')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nIMAGE1=CROP_NEAR(image=IMAGE,box=BOX1)\nIMAGE2=CROP_NEAR(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE0,question='Are the orange vegetables fresh?')\nANSWER1=VQA(image=IMAGE1,question='Are the beans fresh?')\nANSWER2=VQA(image=IMAGE2,question='Are the cookies fresh?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 2820, "imageId": "n548534", "question": "Is that countertop below a dishwasher?", "program": "BOX0=LOC(image=IMAGE,object='dishwasher')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='countertop')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2821, "imageId": "n275148", "question": "Are there beds or lamps in the picture?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2822, "imageId": "n153293", "question": "Are the towels made of cloth short or long?", "program": "BOX0=LOC(image=IMAGE,object='towels')\nANSWER0=VQA(image=IMAGE,question='What material are the towels made of?')\nANSWER1=EVAL(expr=\"'short' if {ANSWER0} == 'cloth' else 'long'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2823, "imageId": "n548534", "question": "Is the counter top below the light fixture?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='counter top')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2824, "imageId": "n243701", "question": "Is the man wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2825, "imageId": "n187544", "question": "Does the building have a different color than the field?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='field')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the building?')\nANSWER1=VQA(image=IMAGE1,question='What color is the field?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2826, "imageId": "n187544", "question": "Are the shorts the same color as the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shoes')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE1,question='What color are the shoes?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2827, "imageId": "n233607", "question": "Is she to the left or to the right of the pillow that looks soft?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soft')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='she')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2828, "imageId": "n429961", "question": "Is the vehicle that is not dirty red and metallic?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nANSWER1=VQA(image=IMAGE0,question='What material is the vehicle made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2829, "imageId": "n520071", "question": "What device is not open?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='What device is not open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2830, "imageId": "n6309", "question": "What vehicle is to the right of the cart?", "program": "BOX0=LOC(image=IMAGE,object='cart')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What vehicle is to the right of the cart?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2831, "imageId": "n222297", "question": "Is the water both blue and wet?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the water?')\nANSWER1=VQA(image=IMAGE,question='Is the water wet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2832, "imageId": "n16936", "question": "On which side of the image is the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2833, "imageId": "n49438", "question": "What item of furniture is not small?", "program": "BOX0=LOC(image=IMAGE,object='small')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is not small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2834, "imageId": "n57848", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2835, "imageId": "n67005", "question": "Is the bag large?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2836, "imageId": "n118102", "question": "How tall do you think is the stove behind the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stove')\nANSWER0=VQA(image=IMAGE0,question='How tall is the stove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2837, "imageId": "n556604", "question": "Which side is the metal lamp on?", "program": "BOX0=LOC(image=IMAGE,object='metal lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2838, "imageId": "n200692", "question": "What kind of appliance is powerful?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of appliance is powerful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2839, "imageId": "n298104", "question": "How big is the flower on the surfboard?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flower')\nANSWER0=SIZE(box=BOX1)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2840, "imageId": "n200907", "question": "Is the electric power line above the sturdy fence?", "program": "BOX0=LOC(image=IMAGE,object='sturdy fence')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='electric power line')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2841, "imageId": "n126891", "question": "Do the gloves look blue?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the gloves?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2842, "imageId": "n171169", "question": "What vehicle are the trees behind of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'unknown' if {ANSWER0} == 0 else 'yes'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2843, "imageId": "n171169", "question": "What is the vehicle that the trees are behind of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'unknown' if {ANSWER0} == 0 else 'yes'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2844, "imageId": "n171169", "question": "Are the green trees behind the vehicle the man is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='green trees')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2845, "imageId": "n264887", "question": "Is the mouse to the left of a keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mouse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2846, "imageId": "n579928", "question": "Do you see either a large window or door?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2847, "imageId": "n25275", "question": "Who do you think is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nANSWER0=VQA(image=IMAGE,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2848, "imageId": "n283587", "question": "Is the cupboard different in shape than the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='cupboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='coffee table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What shape is the cupboard?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the coffee table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2849, "imageId": "n367944", "question": "Is the napkin in the top part or in the bottom of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='napkin')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2850, "imageId": "n485969", "question": "Who is wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2851, "imageId": "n151768", "question": "Are there any men to the left of the vegetable that is not rotten?", "program": "BOX0=LOC(image=IMAGE,object='vegetable')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='men')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2852, "imageId": "n485969", "question": "What is the young person wearing?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the young person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2853, "imageId": "n318684", "question": "What color is the umbrella on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nANSWER0=VQA(image=IMAGE0,question='What color is the umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2854, "imageId": "n477702", "question": "What's the sofa made of?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sofa made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2855, "imageId": "n477702", "question": "What type of material makes up the sofa?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of material makes up the sofa?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2856, "imageId": "n278312", "question": "Does the appliance to the left of the knife block look dirty and dark?", "program": "BOX0=LOC(image=IMAGE,object='knife block')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='Does the appliance look dirty and dark?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'dirty and dark' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2857, "imageId": "n28572", "question": "What are the flowers in front of?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the flowers in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2858, "imageId": "n278312", "question": "What is the color of the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the stove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2859, "imageId": "n282607", "question": "Do you see any fences behind him?", "program": "BOX0=LOC(image=IMAGE,object='him')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fences')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2860, "imageId": "n477702", "question": "Is the brown sofa both soft and wooden?", "program": "BOX0=LOC(image=IMAGE,object='brown sofa')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the sofa soft?')\nANSWER1=VQA(image=IMAGE0,question='Is the sofa wooden?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2861, "imageId": "n475030", "question": "Does the horse that is to the right of the other horse look white and healthy?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horse')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the horse?')\nANSWER1=VQA(image=IMAGE1,question='Is the horse healthy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2862, "imageId": "n540852", "question": "Is the shoe black and open?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shoe?')\nANSWER1=VQA(image=IMAGE0,question='Is the shoe open?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2863, "imageId": "n68769", "question": "Is the color of the ceiling different than the plate?", "program": "BOX0=LOC(image=IMAGE,object='ceiling')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='plate')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the ceiling?')\nANSWER1=VQA(image=IMAGE1,question='What color is the plate?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2864, "imageId": "n413002", "question": "Are there bears to the right of the bananas?", "program": "BOX0=LOC(image=IMAGE,object='bananas')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bears')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2865, "imageId": "n473688", "question": "What is the faucet mounted on?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the faucet mounted on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2866, "imageId": "n411121", "question": "What is the weight of the bike?", "program": "There is no specific module mentioned in the examples that can directly answer the question about the weight of the bike. Therefore, the given program cannot be used to answer this question."}, {"index": 2867, "imageId": "n195925", "question": "Does the sailboat to the right of the boat look white and large?", "program": "BOX0=LOC(image=IMAGE,object='boat')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sailboat')\nANSWER0=VQA(image=IMAGE0,question='What color is the sailboat?')\nANSWER1=VQA(image=IMAGE0,question='Is the sailboat large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2868, "imageId": "n534106", "question": "How does the short sleeved shirt look, white or blue?", "program": "BOX0=LOC(image=IMAGE,object='short sleeved shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How does the short sleeved shirt look, white or blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2869, "imageId": "n403734", "question": "Does the notebook which is to the left of the napkin look black and closed?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='notebook')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the notebook?')\nANSWER1=VQA(image=IMAGE1,question='Is the notebook closed?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2870, "imageId": "n534106", "question": "Is the shirt short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt short sleeved?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'short sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2871, "imageId": "n546616", "question": "How long is the marker next to the cup?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='marker')\nANSWER0=LENGTH(box=BOX1)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2872, "imageId": "n14087", "question": "Is the color of the wall different than the dog?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='dog')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the wall?')\nANSWER1=VQA(image=IMAGE1,question='What color is the dog?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2873, "imageId": "n393305", "question": "Which kind of sign is the girl in front of?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=VQA(image=IMAGE0,question='Which kind of sign is the girl in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2874, "imageId": "n382416", "question": "Are there both a cabinet and a freezer in this image?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nBOX1=LOC(image=IMAGE,object='freezer')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2875, "imageId": "n574498", "question": "What is the fence made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2876, "imageId": "n186491", "question": "Is the tea to the right of the sandwich dry or wet?", "program": "BOX0=LOC(image=IMAGE,object='sandwich')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the tea dry or wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2877, "imageId": "n272313", "question": "Is the huge building behind the tree that is not short?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not short')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='huge building')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2878, "imageId": "n367944", "question": "What device is not white?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='What color is the device?')\nANSWER1=EVAL(expr=\"'not white' if {ANSWER0} != 'white' else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2879, "imageId": "n64959", "question": "Which side of the picture is the plastic appliance on?", "program": "BOX0=LOC(image=IMAGE,object='plastic appliance')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='plastic appliance')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2880, "imageId": "n526228", "question": "What kind of furniture is not long?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is not long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2881, "imageId": "n246334", "question": "Is there a computer or a Wii controller in this photo?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nBOX1=LOC(image=IMAGE,object='Wii controller')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2882, "imageId": "n398257", "question": "Is the red book thin or thick?", "program": "BOX0=LOC(image=IMAGE,object='red book')\nANSWER0=VQA(image=IMAGE,question='Is the red book thin or thick?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2883, "imageId": "n398429", "question": "Which kind of appliance is to the right of the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is to the right of the stove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2884, "imageId": "n500308", "question": "What kind of furniture is flat?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is flat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2885, "imageId": "n526228", "question": "Which kind of furniture is made of leather?", "program": "BOX0=LOC(image=IMAGE,object='leather')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is made of leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2886, "imageId": "n222297", "question": "What is the frisbee inside of?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP_INSIDE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the frisbee inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2887, "imageId": "n526228", "question": "What kind of furniture is long?", "program": "BOX0=LOC(image=IMAGE,object='long')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2888, "imageId": "n472825", "question": "Does the skateboarder that is to the right of the lamp seem to be male and skinny?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboarder')\nANSWER0=VQA(image=IMAGE0,question='Does the skateboarder seem to be male and skinny?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2889, "imageId": "n411121", "question": "Is the poster that looks dull both rectangular and brown?", "program": "BOX0=LOC(image=IMAGE,object='poster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the poster?')\nANSWER1=VQA(image=IMAGE0,question='What color is the poster?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rectangular' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2890, "imageId": "n472825", "question": "How fat is the skateboarder that is not male?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How fat is the skateboarder?')\nANSWER1=VQA(image=IMAGE0,question='Is the skateboarder male?')\nANSWER2=EVAL(expr=\"'not fat' if {ANSWER1} == 'no' else {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2891, "imageId": "n260762", "question": "Which color is the headband the player is wearing?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='headband')\nANSWER0=VQA(image=IMAGE0,question='Which color is the headband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2892, "imageId": "n411121", "question": "Does the green poster look dull?", "program": "BOX0=LOC(image=IMAGE,object='green poster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the green poster look dull?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'dull' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2893, "imageId": "n472825", "question": "What is the gender of the skateboarder to the right of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboarder')\nANSWER0=VQA(image=IMAGE0,question='What is the gender of the skateboarder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2894, "imageId": "n324644", "question": "Are the vertical windows tall and black?", "program": "BOX0=LOC(image=IMAGE,object='vertical windows')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the vertical windows tall?')\nANSWER1=VQA(image=IMAGE0,question='What color are the vertical windows?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'tall' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2895, "imageId": "n497789", "question": "Is the small vehicle on the left side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2896, "imageId": "n173807", "question": "What is the chimney sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='chimney')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the chimney sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2897, "imageId": "n433692", "question": "What color is the small animal?", "program": "BOX0=LOC(image=IMAGE,object='small animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the small animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2898, "imageId": "n173807", "question": "What is sitting on top of the houses?", "program": "BOX0=LOC(image=IMAGE,object='houses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=VQA(image=IMAGE0,question='What is sitting on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2899, "imageId": "n219840", "question": "What animal stands at the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal stands at the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2900, "imageId": "n219840", "question": "What animal stands at the grass the trees above?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nANSWER0=VQA(image=IMAGE1,question='What animal stands at the grass the trees above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2901, "imageId": "n497789", "question": "What are the animals to the left of the people?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animals')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2902, "imageId": "n219840", "question": "What is under the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2903, "imageId": "n281241", "question": "Is the shirt both long sleeved and beige?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the shirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'beige' and {ANSWER1} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2904, "imageId": "n219840", "question": "Where does the deer that to the right of the horses stand?", "program": "BOX0=LOC(image=IMAGE,object='horses')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='deer')\nANSWER0=VQA(image=IMAGE0,question='Where does the deer stand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2905, "imageId": "n54180", "question": "What is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2906, "imageId": "n54180", "question": "What do you think is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2907, "imageId": "n79078", "question": "What is the man standing behind of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man standing behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2908, "imageId": "n192021", "question": "What is the color of the curtain that is to the left of the pillows?", "program": "BOX0=LOC(image=IMAGE,object='pillows')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtain')\nANSWER0=VQA(image=IMAGE0,question='What color is the curtain?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2909, "imageId": "n98540", "question": "What's the belt holding onto?", "program": "BOX0=LOC(image=IMAGE,object='belt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's the belt holding onto?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2910, "imageId": "n398257", "question": "Is the color of the keyboard the same as the color of the plant?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='plant')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the keyboard?')\nANSWER1=VQA(image=IMAGE1,question='What color is the plant?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2911, "imageId": "n79078", "question": "Who is standing behind the trash can?", "program": "BOX0=LOC(image=IMAGE,object='trash can')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing behind the trash can?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2912, "imageId": "n398257", "question": "Does the plant pot under the plant look full and brown?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plant pot')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='full')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='brown')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 2913, "imageId": "n98540", "question": "What is holding onto the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is holding onto the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2914, "imageId": "n415215", "question": "Is the toilet brush black and clean?", "program": "BOX0=LOC(image=IMAGE,object='toilet brush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet brush?')\nANSWER1=VQA(image=IMAGE0,question='Is the toilet brush clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2915, "imageId": "n179136", "question": "Of which color is the murky water?", "program": "BOX0=LOC(image=IMAGE,object='murky water')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Of which color is the murky water?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2916, "imageId": "n206358", "question": "What is the color of the road near the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='road')\nIMAGE1=CROP_NEAR(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the road?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2917, "imageId": "n206358", "question": "Is the road near the building dark and narrow?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the road?')\nANSWER1=VQA(image=IMAGE0,question='What is the width of the road?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' and {ANSWER1} == 'narrow' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2918, "imageId": "n415215", "question": "What color is the toilet brush on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet brush')\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet brush?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2919, "imageId": "n65230", "question": "Which kind of furniture is patterned?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is patterned?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2920, "imageId": "n206785", "question": "What clothing item is long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved')\nANSWER0=VQA(image=IMAGE,question='What clothing item is long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2921, "imageId": "n437064", "question": "What is in front of the fruit that the bowl is behind of?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruit')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the fruit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2922, "imageId": "n119886", "question": "Is the faucet both clean and small?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the faucet clean?')\nANSWER1=VQA(image=IMAGE0,question='Is the faucet small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2923, "imageId": "n437064", "question": "The whipped cream is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='whipped cream')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The whipped cream is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2924, "imageId": "n470920", "question": "Is the bag that looks brown made of leather or paper?", "program": "BOX0=LOC(image=IMAGE,object='brown bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the bag made of?')\nANSWER1=EVAL(expr=\"'leather' if {ANSWER0} == 'leather' else 'paper'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2925, "imageId": "n119944", "question": "Does the talking person near the baskets look old?", "program": "BOX0=LOC(image=IMAGE,object='baskets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='talking person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2926, "imageId": "n119944", "question": "What is the young man wearing?", "program": "BOX0=LOC(image=IMAGE,object='young man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the young man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2927, "imageId": "n347706", "question": "What is that child wearing?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the child wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2928, "imageId": "n527589", "question": "What is the bag to the left of the shelves called?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='What is the bag called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2929, "imageId": "n435808", "question": "Which kind of device is the keyboard sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is the keyboard sitting next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2930, "imageId": "n69237", "question": "Is the pillow to the right of the books made of paper?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2931, "imageId": "n69237", "question": "Is the pillow to the right or to the left of the books?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2932, "imageId": "n92308", "question": "The person to the left of the bicyclist is riding what?", "program": "BOX0=LOC(image=IMAGE,object='bicyclist')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The person to the left of the bicyclist is riding what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2933, "imageId": "n470920", "question": "Are there men to the left of the fruits that are sitting atop the blanket?", "program": "BOX0=LOC(image=IMAGE,object='fruits')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blanket')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='men')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2934, "imageId": "n95369", "question": "What color is the shower that is in the bathroom?", "program": "BOX0=LOC(image=IMAGE,object='bathroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shower')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the shower?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2935, "imageId": "n299528", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2936, "imageId": "n470920", "question": "What do you think does the man to the left of the berries sit atop?", "program": "BOX0=LOC(image=IMAGE,object='berries')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What does the man sit atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2937, "imageId": "n16656", "question": "Is the shoe red or gray?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shoe?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'gray'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2938, "imageId": "n119886", "question": "Does the shelf to the right of the other shelf have white color?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the shelf?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2939, "imageId": "n119944", "question": "Is there an elephant to the left of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='elephant')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2940, "imageId": "n283587", "question": "Is there either a pillow or a sofa in the picture?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nBOX1=LOC(image=IMAGE,object='sofa')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2941, "imageId": "n514467", "question": "Do you see fire hydrants on top of the sidewalk that is not dry?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fire hydrant')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='dry')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2942, "imageId": "n508733", "question": "Is the long sleeved shirt black or light blue?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the long sleeved shirt?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'light blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2943, "imageId": "n283587", "question": "Behind what is the window, a sofa or a bed?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sofa')\nBOX2=LOC(image=IMAGE0,object='bed')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'sofa' if {ANSWER0} > 0 else 'bed'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2944, "imageId": "n283587", "question": "Behind what kind of furniture is the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Behind what kind of furniture is the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2945, "imageId": "n313060", "question": "Is the sweatshirt black and open?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sweatshirt?')\nANSWER1=VQA(image=IMAGE0,question='Is the sweatshirt open?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2946, "imageId": "n275148", "question": "Is the black device on the right or on the left side?", "program": "BOX0=LOC(image=IMAGE,object='black device')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2947, "imageId": "n501951", "question": "What is the driver driving?", "program": "BOX0=LOC(image=IMAGE,object='driver')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the driver driving?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2948, "imageId": "n536256", "question": "On which side of the image is the metal lamp?", "program": "BOX0=LOC(image=IMAGE,object='metal lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2949, "imageId": "n579256", "question": "Does the refrigerator that looks white look new?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the refrigerator?')\nANSWER1=VQA(image=IMAGE0,question='Does the refrigerator look new?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2950, "imageId": "n579256", "question": "What is inside the refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the refrigerator?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2951, "imageId": "n579256", "question": "What is inside the large appliance?", "program": "BOX0=LOC(image=IMAGE,object='large appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the large appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2952, "imageId": "n579256", "question": "What is the food that is inside the freezer?", "program": "BOX0=LOC(image=IMAGE,object='freezer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the food inside the freezer?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2953, "imageId": "n117888", "question": "Is the bat that looks gray and red made of wood?", "program": "BOX0=LOC(image=IMAGE,object='bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bat?')\nANSWER1=VQA(image=IMAGE0,question='What material is the bat made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray and red' and {ANSWER1} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2954, "imageId": "n151768", "question": "Which color do the pants have?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nANSWER0=VQA(image=IMAGE,question='Which color do the pants have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2955, "imageId": "n202379", "question": "Who is wearing a uniform?", "program": "BOX0=LOC(image=IMAGE,object='uniform')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2956, "imageId": "n202379", "question": "Who is wearing the uniform?", "program": "BOX0=LOC(image=IMAGE,object='uniform')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2957, "imageId": "n293477", "question": "Does the white bed look small and soft?", "program": "BOX0=LOC(image=IMAGE,object='white bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the bed look small?')\nANSWER1=VQA(image=IMAGE0,question='Does the bed look soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2958, "imageId": "n219840", "question": "What kind of animal is standing next to the concrete path?", "program": "BOX0=LOC(image=IMAGE,object='concrete path')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is standing next to the concrete path?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2959, "imageId": "n432591", "question": "Are these pillows or towels?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nBOX1=LOC(image=IMAGE,object='towel')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'pillows' if {ANSWER0} > {ANSWER1} else 'towels'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2960, "imageId": "n131634", "question": "What color does the mirror that is on the motorbike have?", "program": "BOX0=LOC(image=IMAGE,object='motorbike')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=VQA(image=IMAGE0,question='What color is the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2961, "imageId": "n390187", "question": "Do the helmet and the glove have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='glove')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the helmet?')\nANSWER1=VQA(image=IMAGE1,question='What color is the glove?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2962, "imageId": "n350766", "question": "Is that drawer below a counter?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drawer')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2963, "imageId": "n319845", "question": "Does the rug look dark and large?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the rug?')\nANSWER1=VQA(image=IMAGE0,question='Is the rug large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2964, "imageId": "n279173", "question": "Does the animal on the street seem to be black?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What color is the animal?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2965, "imageId": "n511913", "question": "Do you think the person that looks young is blond or brunette?", "program": "BOX0=LOC(image=IMAGE,object='person that looks young')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the person\\'s hair?')\nANSWER1=EVAL(expr=\"'blond' if {ANSWER0} == 'blond' else 'brunette'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2966, "imageId": "n95313", "question": "How large is the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2967, "imageId": "n413761", "question": "What is the vehicle that is in front of the hill that is in front of the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hill')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'unknown' if {ANSWER0} == 0 else 'yes'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2968, "imageId": "n116329", "question": "Which kind of material is used to make the large door?", "program": "BOX0=LOC(image=IMAGE,object='large door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of material is used to make the large door?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2969, "imageId": "n413761", "question": "What is the car in front of?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the car in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2970, "imageId": "n382416", "question": "Does the suitcase that is not big look square?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the suitcase square?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2971, "imageId": "n324644", "question": "Is the light fixture made of the same material as the stop sign?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='stop sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the light fixture made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the stop sign made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2972, "imageId": "n437064", "question": "Are there both a strawberry and a plate in the picture?", "program": "BOX0=LOC(image=IMAGE,object='strawberry')\nBOX1=LOC(image=IMAGE,object='plate')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2973, "imageId": "n52544", "question": "Does the thin man face a lamp?", "program": "BOX0=LOC(image=IMAGE,object='thin man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2974, "imageId": "n52544", "question": "Who faces the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who faces the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2975, "imageId": "n296467", "question": "What is inside the container made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='container made of plastic')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2976, "imageId": "n52544", "question": "Is the person that is not fat holding a camera?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='camera')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2977, "imageId": "n95369", "question": "How big is the bath tub?", "program": "BOX0=LOC(image=IMAGE,object='bath tub')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the bath tub?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2978, "imageId": "n296467", "question": "What type of food is inside the container to the left of the beans?", "program": "BOX0=LOC(image=IMAGE,object='beans')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='container')\nANSWER0=VQA(image=IMAGE0,question='What type of food is inside the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2979, "imageId": "n278312", "question": "What is the floor made of, stone or hardwood?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the floor made of?')\nANSWER1=EVAL(expr=\"'stone' if 'stone' in {ANSWER0} else 'hardwood'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2980, "imageId": "n52544", "question": "What is the material of the bucket to the right of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bucket')\nANSWER0=VQA(image=IMAGE0,question='What is the material of the bucket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2981, "imageId": "n207893", "question": "What is going through the grass the zebras are standing in?", "program": "BOX0=LOC(image=IMAGE,object='zebras')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nANSWER0=VQA(image=IMAGE0,question='What is going through the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2982, "imageId": "n326988", "question": "What kind of device do you think is to the left of the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is to the left of the glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2983, "imageId": "n24526", "question": "What material is the road, asphalt or cobblestone?", "program": "BOX0=LOC(image=IMAGE,object='road')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the road?')\nANSWER1=EVAL(expr=\"'asphalt' if {ANSWER0} == 'asphalt' else 'cobblestone'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2984, "imageId": "n256120", "question": "What size are the tree leaves that are behind the pole?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tree leaves')\nANSWER0=VQA(image=IMAGE0,question='What size are the tree leaves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2985, "imageId": "n207893", "question": "What's the fence going through?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence going through?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2986, "imageId": "n207893", "question": "Is the fence going through the grass that is not short?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='not short')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2987, "imageId": "n4777", "question": "What does the woman sit next to?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the woman sit next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2988, "imageId": "n200225", "question": "What color is the container made of cardboard?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the container?')\nANSWER1=EVAL(expr=\"'cardboard' if {ANSWER0} == 'brown' else 'not cardboard'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2989, "imageId": "n531731", "question": "Is the towel in the top or in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towel')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2990, "imageId": "n146555", "question": "What is the person that is standing leaning against?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person leaning against?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2991, "imageId": "n146555", "question": "What is the man leaning against?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man leaning against?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2992, "imageId": "n531731", "question": "On which side is the blue bag?", "program": "BOX0=LOC(image=IMAGE,object='blue bag')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 2993, "imageId": "n162108", "question": "What is the toilet paper in front of?", "program": "BOX0=LOC(image=IMAGE,object='toilet paper')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the toilet paper in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2994, "imageId": "n4777", "question": "Are there both bottles and cups in the picture?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nBOX1=LOC(image=IMAGE,object='cup')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2995, "imageId": "n64959", "question": "What is the color of the appliance made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic')\nANSWER0=VQA(image=IMAGE0,question='What is the color of the plastic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2996, "imageId": "n356822", "question": "On which side of the photo is the boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 2997, "imageId": "n64959", "question": "Is the appliance that is made of plastic orange and round?", "program": "BOX0=LOC(image=IMAGE,object='plastic')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the appliance?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the appliance?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2998, "imageId": "n296467", "question": "What type of food is rainbow colored, the cupcakes or the carrots?", "program": "BOX0=LOC(image=IMAGE,object='cupcakes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='carrots')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What type of food is rainbow colored?')\nANSWER1=VQA(image=IMAGE1,question='What type of food is rainbow colored?')\nANSWER2=EVAL(expr=\"'cupcakes' if {ANSWER0} == 'rainbow colored' else 'carrots'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 2999, "imageId": "n44249", "question": "Are the green trees lush or leafless?", "program": "BOX0=LOC(image=IMAGE,object='green trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the green trees lush or leafless?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3000, "imageId": "n199758", "question": "Is the tall person holding the remote on the left side of the image?", "program": "BOX0=LOC(image=IMAGE,object='tall person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"},{"index": 3001, "imageId": "n296467", "question": "What dessert is fresh?", "program": "BOX0=LOC(image=IMAGE,object='dessert')\nANSWER0=VQA(image=IMAGE,question='What dessert is fresh?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3002, "imageId": "n551964", "question": "What is the person to the right of the girl sitting on?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3003, "imageId": "n309148", "question": "Does the flag that is to the left of the bucket have large size and blue color?", "program": "BOX0=LOC(image=IMAGE,object='bucket')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flag')\nANSWER0=VQA(image=IMAGE0,question='What size is the flag?')\nANSWER1=VQA(image=IMAGE0,question='What color is the flag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3004, "imageId": "n54424", "question": "What is in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3005, "imageId": "n309148", "question": "Is the flag that is to the left of the bucket white or blue?", "program": "BOX0=LOC(image=IMAGE,object='bucket')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flag')\nANSWER0=VQA(image=IMAGE0,question='What color is the flag?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3006, "imageId": "n296467", "question": "Which kind of food is not rainbow colored?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is not rainbow colored?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3007, "imageId": "n357784", "question": "What do you think is plugged into the outlets that are made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood outlets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is plugged into the outlets?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3008, "imageId": "n195249", "question": "Does this woman wear a wetsuit?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does this woman wear a wetsuit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3009, "imageId": "n566028", "question": "Does the shirt that looks black look sleeveless or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='black shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look sleeveless or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3010, "imageId": "n262920", "question": "Where is the man standing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3011, "imageId": "n125122", "question": "Are the paintings above a bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='paintings')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3012, "imageId": "n357784", "question": "Do the cords look white?", "program": "BOX0=LOC(image=IMAGE,object='cords')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the cords?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3013, "imageId": "n445353", "question": "Does the person to the left of the other person seem to be talking or posing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the person seem to be talking or posing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3014, "imageId": "n95904", "question": "What is the pattern of the shirt that looks white and dark?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pattern of the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3015, "imageId": "n95904", "question": "What is the pattern of the shirt?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the pattern of the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3016, "imageId": "n207708", "question": "Is the bookcase full and white?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the bookcase full?')\nANSWER1=VQA(image=IMAGE0,question='What color is the bookcase?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3017, "imageId": "n319845", "question": "Is the apron the same color as the vase?", "program": "BOX0=LOC(image=IMAGE,object='apron')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='vase')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the apron?')\nANSWER1=VQA(image=IMAGE1,question='What color is the vase?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3018, "imageId": "n319845", "question": "Are both the vase and the ceiling the same color?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='ceiling')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the vase?')\nANSWER1=VQA(image=IMAGE1,question='What color is the ceiling?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3019, "imageId": "n62458", "question": "Is there a pot beside the motorbike that is above the stone?", "program": "BOX0=LOC(image=IMAGE,object='stone')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorbike')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='pot')\nIMAGE2=CROP_BESIDE(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3020, "imageId": "n315887", "question": "Is the speaker to the left of the device that is above the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='speaker')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3021, "imageId": "n393305", "question": "What color is the hydrant on the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hydrant')\nANSWER0=VQA(image=IMAGE0,question='What color is the hydrant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3022, "imageId": "n12404", "question": "Is the fire hydrant to the left or to the right of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fire hydrant')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3023, "imageId": "n315887", "question": "Is the speaker to the left or to the right of the device that is not small?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='speaker')\nBOX2=LOC(image=IMAGE0,object='small')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'left' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3024, "imageId": "n503626", "question": "What material is the urinal that is white and silver?", "program": "BOX0=LOC(image=IMAGE,object='white')\nBOX1=LOC(image=IMAGE,object='silver')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='urinal')\nBOX3=LOC(image=IMAGE1,object='urinal')\nANSWER0=COUNT(box=BOX2)\nANSWER1=COUNT(box=BOX3)\nANSWER2=EVAL(expr=\"'white' if {ANSWER0} > 0 else 'silver'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3025, "imageId": "n513429", "question": "Which kind of device is not electronic?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of device is not electronic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3026, "imageId": "n513429", "question": "What kind of device is not electronic, the monitor or the keyboard?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of device is the monitor?')\nANSWER1=VQA(image=IMAGE,question='What kind of device is the keyboard?')\nANSWER2=EVAL(expr=\"'monitor' if {ANSWER0} != 'electronic' else 'keyboard'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3027, "imageId": "n214497", "question": "Does the window that is not narrow look gray?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='narrow')\nIMAGE1=CROP_NOT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the window?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3028, "imageId": "n513429", "question": "What kind of device is electronic?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='What kind of device is electronic?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'electronic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3029, "imageId": "n355339", "question": "Is there a keyboard on top of the device which is to the right of the drink?", "program": "BOX0=LOC(image=IMAGE,object='drink')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='keyboard')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3030, "imageId": "n489699", "question": "Do the trousers look orange and long?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the trousers?')\nANSWER1=VQA(image=IMAGE,question='Are the trousers long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3031, "imageId": "n65885", "question": "Is the teddy bear brown?", "program": "BOX0=LOC(image=IMAGE,object='teddy bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the teddy bear?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3032, "imageId": "n68769", "question": "Are there chairs underneath the light fixture that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood light fixture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3033, "imageId": "n532191", "question": "Is the color of the chair blue?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3034, "imageId": "n68769", "question": "What is the piece of furniture underneath the light fixture?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3035, "imageId": "n65885", "question": "What toy is stuffed?", "program": "BOX0=LOC(image=IMAGE,object='stuffed')\nANSWER0=VQA(image=IMAGE,question='What toy is stuffed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3036, "imageId": "n68769", "question": "What is the item of furniture below the light fixture near the curtain?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtain')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='item of furniture')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3037, "imageId": "n298104", "question": "What is the thin person standing behind of?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the thin person standing behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3038, "imageId": "n167164", "question": "Is the truck to the left or to the right of the vehicle the traffic light is above?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='truck')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3039, "imageId": "n126891", "question": "Who is wearing a jersey?", "program": "BOX0=LOC(image=IMAGE,object='jersey')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a jersey?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3040, "imageId": "n126891", "question": "Who is wearing the jersey?", "program": "BOX0=LOC(image=IMAGE,object='jersey')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the jersey?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3041, "imageId": "n154160", "question": "Is the pitcher on the mound wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='mound')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pitcher')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='glove')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3042, "imageId": "n95313", "question": "On which side of the image is the bookshelf?", "program": "BOX0=LOC(image=IMAGE,object='bookshelf')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3043, "imageId": "n526228", "question": "Of what race is the man the skateboard is to the right of?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='Of what race is the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3044, "imageId": "n501951", "question": "Which side of the picture is the male person on?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3045, "imageId": "n475030", "question": "What color is the horse's tail?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the horse\\'s tail?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3046, "imageId": "n154856", "question": "Which shape is the glass window?", "program": "ANSWER0=VQA(image=IMAGE,question='Which shape is the glass window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3047, "imageId": "n258500", "question": "Where are the speakers, on the left or on the right of the image?", "program": "BOX0=LOC(image=IMAGE,object='speakers')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3048, "imageId": "n475030", "question": "Do you see a zebra or a giraffe there?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nBOX1=LOC(image=IMAGE,object='giraffe')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3049, "imageId": "n326988", "question": "On which side is the doll?", "program": "BOX0=LOC(image=IMAGE,object='doll')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3050, "imageId": "n329479", "question": "What do both the tshirt and the bike have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the tshirt and the bike have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3051, "imageId": "n314630", "question": "How hard is the metal appliance?", "program": "BOX0=LOC(image=IMAGE,object='metal appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How hard is the metal appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3052, "imageId": "n219840", "question": "What animal is standing behind the animals that are standing next to the path?", "program": "BOX0=LOC(image=IMAGE,object='path')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animals')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nIMAGE2=CROP_BEHIND(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What animal is standing behind?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3053, "imageId": "n71728", "question": "The man that is not sad is sitting beside who?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3054, "imageId": "n66756", "question": "Are there umpires behind the person that is wearing a mask?", "program": "BOX0=LOC(image=IMAGE,object='person wearing mask')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umpires')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3055, "imageId": "n71728", "question": "Who is sitting beside the boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting beside the boy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3056, "imageId": "n71728", "question": "Who is sitting beside the person that is young?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is young?')\nBOX1=LOC(image=IMAGE0,object=ANSWER0)\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='Who is sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3057, "imageId": "n25275", "question": "Where is the trash can?", "program": "BOX0=LOC(image=IMAGE,object='trash can')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3058, "imageId": "n71728", "question": "Is the happy man to the right or to the left of the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='happy man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3059, "imageId": "n208458", "question": "Is the dock wooden and long?", "program": "BOX0=LOC(image=IMAGE,object='dock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the dock made of?')\nANSWER1=VQA(image=IMAGE0,question='Is the dock long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3060, "imageId": "n25275", "question": "Is the garbage can to the left of a chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='garbage can')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3061, "imageId": "n219840", "question": "What animal is standing behind the horses?", "program": "BOX0=LOC(image=IMAGE,object='horses')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is standing behind the horses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3062, "imageId": "n55058", "question": "What kind of meat is on top of the cutting board?", "program": "BOX0=LOC(image=IMAGE,object='cutting board')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='meat')\nANSWER0=VQA(image=IMAGE0,question='What kind of meat is on top of the cutting board?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3063, "imageId": "n55058", "question": "What is the meat on top of the cooking utensil made of wood?", "program": "BOX0=LOC(image=IMAGE,object='cooking utensil')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='meat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the meat made of?')\nANSWER1=EVAL(expr=\"'wood' if {ANSWER0} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3064, "imageId": "n6908", "question": "What's around the picture?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nIMAGE0=CROP_AROUND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is around the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3065, "imageId": "n164272", "question": "Are the trees brown and abundant?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX1=LOC(image=IMAGE,object='brown trees')\nANSWER2=COUNT(box=BOX1)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 3066, "imageId": "n259002", "question": "Which gender is the soccer player that is standing on the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer player')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which gender is the soccer player?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3067, "imageId": "n6908", "question": "What is around the dark picture?", "program": "BOX0=LOC(image=IMAGE,object='dark picture')\nIMAGE0=CROP_AROUND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is around the dark picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3068, "imageId": "n527589", "question": "What are the fruits on top of the basket?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruits')\nANSWER0=VQA(image=IMAGE0,question='What are the fruits?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3069, "imageId": "n65230", "question": "How hard are the tan walls?", "program": "ANSWER0=VQA(image=IMAGE,question='How hard are the tan walls?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3070, "imageId": "n285391", "question": "In which part of the picture is the rope, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='rope')\nBOX1=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='rope')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3071, "imageId": "n204894", "question": "Are the toy and the chair made of the same material?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the toy made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the chair made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3072, "imageId": "n264887", "question": "What device is the mouse pad in front of?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is the mouse pad in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3073, "imageId": "n299528", "question": "Who rides on the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who rides on the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3074, "imageId": "n497789", "question": "What is the name of the animals to the left of the white vehicle?", "program": "BOX0=LOC(image=IMAGE,object='white vehicle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the animals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3075, "imageId": "n434283", "question": "How does the tire that looks round look, new or old?", "program": "BOX0=LOC(image=IMAGE,object='round tire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How does the tire look, new or old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3076, "imageId": "n501609", "question": "Is the red oven below a microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='red oven')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3077, "imageId": "n55058", "question": "What are the fries inside of?", "program": "BOX0=LOC(image=IMAGE,object='fries')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the fries inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3078, "imageId": "n471866", "question": "What is the policeman to the left of the man sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='man sitting atop')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='policeman')\nANSWER0=VQA(image=IMAGE0,question='What is the policeman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3079, "imageId": "n471866", "question": "Who is sitting atop the motorbike on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorbike')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is sitting atop the motorbike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3080, "imageId": "n352479", "question": "Is the jacket blue and long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the jacket have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3081, "imageId": "n544255", "question": "Do the trees below the sky look tall or short?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Do the trees look tall or short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3082, "imageId": "n567860", "question": "What animal is white?", "program": "BOX0=LOC(image=IMAGE,object='white')\nANSWER0=VQA(image=IMAGE,question='What animal is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3083, "imageId": "n554880", "question": "What device is behind the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is behind the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3084, "imageId": "n380113", "question": "Is the folding chair in the top part or in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='folding chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3085, "imageId": "n433532", "question": "What is larger than the drink that is in the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drink')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is larger than the drink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3086, "imageId": "n314171", "question": "What is the small room holding?", "program": "BOX0=LOC(image=IMAGE,object='small room')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the small room holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3087, "imageId": "n433532", "question": "Does the oil near the shelf seem to be thin or thick?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='oil')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the oil seem to be thin or thick?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3088, "imageId": "n282436", "question": "Is it outdoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it outdoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3089, "imageId": "n6908", "question": "What is sitting next to the flowers?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting next to the flowers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3090, "imageId": "n282436", "question": "Which room is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which room is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3091, "imageId": "n433532", "question": "What is the oil bigger than?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the oil bigger than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3092, "imageId": "n77818", "question": "What is the pepper shaker made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the pepper shaker made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3093, "imageId": "n526228", "question": "Who is the coffee table in front of?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the coffee table in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3094, "imageId": "n302387", "question": "Is the tall shelf on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tall shelf')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3095, "imageId": "n497789", "question": "Are all the animals zebras?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == TOTAL_OBJECTS else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3096, "imageId": "n344136", "question": "What's in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3097, "imageId": "n498712", "question": "Does that luggage look still?", "program": "BOX0=LOC(image=IMAGE,object='luggage')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the luggage look still?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3098, "imageId": "n222915", "question": "Which side of the image is the empty mug on?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='empty mug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3099, "imageId": "n417401", "question": "What material is the toilet near the toilet paper?", "program": "BOX0=LOC(image=IMAGE,object='toilet paper')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the toilet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3100, "imageId": "n500308", "question": "What's the floor made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the floor made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3101, "imageId": "n262920", "question": "On what's the backpack hanging?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hanging')\nANSWER0=VQA(image=IMAGE0,question='On what is the backpack hanging?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3102, "imageId": "n514467", "question": "Is the color of the coat different than the color of the garbage bin?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='garbage bin')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the coat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the garbage bin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3103, "imageId": "n500308", "question": "Is the floor rough and black?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the texture of the floor?')\nANSWER1=VQA(image=IMAGE0,question='What color is the floor?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rough' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3104, "imageId": "n500308", "question": "The floor is what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3105, "imageId": "n500308", "question": "Do you see refrigerators in the photo?", "program": "BOX0=LOC(image=IMAGE,object='refrigerators')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3106, "imageId": "n357126", "question": "How clean is the window?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3107, "imageId": "n243701", "question": "Who in this photograph is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3108, "imageId": "n398257", "question": "What's the sweatshirt in front of?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sweatshirt in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3109, "imageId": "n55058", "question": "How large is the onion to the left of the serving dish?", "program": "BOX0=LOC(image=IMAGE,object='serving dish')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='onion')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the onion?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3110, "imageId": "n398257", "question": "What kind of furniture is the sweatshirt hanging from?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the sweatshirt hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3111, "imageId": "n55058", "question": "In which part of the image is the mug, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3112, "imageId": "n357126", "question": "Is that window silver and tinted?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the window?')\nANSWER1=VQA(image=IMAGE0,question='Is the window tinted?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3113, "imageId": "n98544", "question": "Is this toilet open or closed?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the toilet open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3114, "imageId": "n23762", "question": "Are there bottles on the wood table?", "program": "BOX0=LOC(image=IMAGE,object='wood table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottles')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3115, "imageId": "n262929", "question": "Do the shoes look dark?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the shoes look dark?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3116, "imageId": "n501609", "question": "What do the cupboards and the cabinets have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the cupboards and the cabinets have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3117, "imageId": "n390187", "question": "Does the person wear jeans?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3118, "imageId": "n89148", "question": "What is the color of the ladder?", "program": "BOX0=LOC(image=IMAGE,object='ladder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the ladder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3119, "imageId": "n240666", "question": "Is the soap to the left of the tap underneath the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tap')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='soap')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3120, "imageId": "n238266", "question": "Do you see brown chairs or cakes?", "program": "BOX0=LOC(image=IMAGE,object='brown chair')\nBOX1=LOC(image=IMAGE,object='cake')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3121, "imageId": "n119944", "question": "What's the elephant doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the elephant doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3122, "imageId": "n326988", "question": "What items of furniture are behind the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What items of furniture are behind the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3123, "imageId": "n195249", "question": "Does the blue hat have large size?", "program": "BOX0=LOC(image=IMAGE,object='blue hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the blue hat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3124, "imageId": "n240666", "question": "Are there chairs or blankets in the scene?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='blanket')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3125, "imageId": "n298104", "question": "What is on the surfboard behind the sign?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surfboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3126, "imageId": "n95313", "question": "Does the rug look small and colorful?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the rug look small and colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3127, "imageId": "n124651", "question": "Which kind of sign is on the road?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of sign is on the road?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3128, "imageId": "n350766", "question": "Do you see a wood door or window?", "program": "BOX0=LOC(image=IMAGE,object='door')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3129, "imageId": "n469156", "question": "Is this a skateboarder or a snowboarder?", "program": "ANSWER0=VQA(image=IMAGE,question='Is this a skateboarder or a snowboarder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3130, "imageId": "n469156", "question": "Who is wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='glove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a glove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3131, "imageId": "n14", "question": "Does the motorbike look smooth?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the motorbike look smooth?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3132, "imageId": "n469156", "question": "Who is wearing the glove?", "program": "BOX0=LOC(image=IMAGE,object='glove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the glove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3133, "imageId": "n69237", "question": "How big is the chair that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3134, "imageId": "n240973", "question": "What device is on?", "program": "ANSWER0=VQA(image=IMAGE,question='What device is on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3135, "imageId": "n342511", "question": "Are there light bulbs or tents?", "program": "BOX0=LOC(image=IMAGE,object='light bulb')\nBOX1=LOC(image=IMAGE,object='tent')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3136, "imageId": "n329479", "question": "Are there both mannequins and bikes in the picture?", "program": "BOX0=LOC(image=IMAGE,object='mannequin')\nBOX1=LOC(image=IMAGE,object='bike')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3137, "imageId": "n240973", "question": "The wood shelves that are sitting on top of the desk are of what color?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood shelves')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color are the wood shelves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3138, "imageId": "n578564", "question": "What are the canisters that are to the left of the toaster made of?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='canisters')\nANSWER0=VQA(image=IMAGE0,question='What are the canisters made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3139, "imageId": "n356822", "question": "Who is the boy sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the boy sitting next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3140, "imageId": "n14087", "question": "What's the couch in front of?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the couch in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3141, "imageId": "n14087", "question": "Do you see a bed in front of the white curtains?", "program": "BOX0=LOC(image=IMAGE,object='white curtains')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3142, "imageId": "n209843", "question": "Is the mirror on the left side of the photo?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nANSWER0=EVAL(expr=\"'yes' if {BOX0}['x'] < {IMAGE}['width']/2 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3143, "imageId": "n326988", "question": "Is the person that is to the left of the shelves playing at a cell phone?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelves')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='person')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='Is the person playing at a cell phone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3144, "imageId": "n119944", "question": "What animal does the child look at?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal does the child look at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3145, "imageId": "n119944", "question": "What is the animal that the male person looks at?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal that the male person looks at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3146, "imageId": "n356822", "question": "Is the boy to the right or to the left of the person the man is sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='boy')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3147, "imageId": "n346247", "question": "What place is shown?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is shown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3148, "imageId": "n272313", "question": "What is in front of the huge building?", "program": "BOX0=LOC(image=IMAGE,object='huge building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the huge building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3149, "imageId": "n264887", "question": "Is the mouse pad to the right of the cups on the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cups')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='mouse pad')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3150, "imageId": "n494918", "question": "Are the short shorts orange or black?", "program": "BOX0=LOC(image=IMAGE,object='short shorts')\nANSWER0=VQA(image=IMAGE,question='What color are the short shorts?')\nANSWER1=EVAL(expr=\"'orange' if {ANSWER0} == 'orange' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3151, "imageId": "n513100", "question": "What kind of furniture is underneath the white table?", "program": "BOX0=LOC(image=IMAGE,object='white table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is underneath the white table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3152, "imageId": "n513100", "question": "Which kind of furniture is underneath the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is underneath the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3153, "imageId": "n272313", "question": "Who is the knee pad worn on?", "program": "BOX0=LOC(image=IMAGE,object='knee pad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the knee pad worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3154, "imageId": "n565418", "question": "How big is the brown dirt?", "program": "BOX0=LOC(image=IMAGE,object='brown dirt')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3155, "imageId": "n455563", "question": "Do you see a child near the person behind the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='child')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3156, "imageId": "n290409", "question": "Is this a truck or a bus?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nBOX1=LOC(image=IMAGE,object='bus')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'truck' if {ANSWER0} > 0 else 'bus'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3157, "imageId": "n570181", "question": "Who wears trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3158, "imageId": "n541854", "question": "Does the fork look hard and silver?", "program": "ANSWER0=VQA(image=IMAGE,question='What does the fork look like?')\nANSWER1=EVAL(expr=\"'yes' if 'hard' in {ANSWER0} and 'silver' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3159, "imageId": "n351318", "question": "What's the tape on?", "program": "BOX0=LOC(image=IMAGE,object='tape')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tape on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3160, "imageId": "n546884", "question": "What kind of furniture is this, a bookcase or a table?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is this?')\nANSWER1=EVAL(expr=\"'bookcase' if {ANSWER0} == 'bookcase' else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3161, "imageId": "n143935", "question": "What do the abundant trees surround?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the abundant trees surround?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3162, "imageId": "n282607", "question": "Are there any women?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3163, "imageId": "n282607", "question": "How clean is the t-shirt?", "program": "BOX0=LOC(image=IMAGE,object='t-shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the t-shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3164, "imageId": "n58220", "question": "Does this flag look red?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the flag?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3165, "imageId": "n86120", "question": "Does the person near the wall look tall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3166, "imageId": "n54424", "question": "What does the boy play with?", "program": "ANSWER0=VQA(image=IMAGE,question='What does the boy play with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3167, "imageId": "n256120", "question": "Is the machine on top of a bookcase?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='machine')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3168, "imageId": "n54424", "question": "He plays with what?", "program": "ANSWER0=VQA(image=IMAGE,question='He plays with what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3169, "imageId": "n256120", "question": "What's located on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3170, "imageId": "n54424", "question": "Who plays with the Wii controller?", "program": "BOX0=LOC(image=IMAGE,object='Wii controller')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who plays with the Wii controller?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3171, "imageId": "n578564", "question": "Is there a microwave to the right of the toaster?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='microwave')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3172, "imageId": "n538039", "question": "Is the man on the grass happy and old?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the man on the grass happy?')\nANSWER1=VQA(image=IMAGE,question='Is the man on the grass old?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3173, "imageId": "n538039", "question": "Does the man on the grass look young?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the man on the grass look young?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3174, "imageId": "n160664", "question": "Who is the giraffe looking down at?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the giraffe looking down at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3175, "imageId": "n411121", "question": "Do you see any people to the right of the dog?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3176, "imageId": "n571179", "question": "Who in this photograph is skiing?", "program": "BOX0=LOC(image=IMAGE,object='skiing')\nANSWER0=VQA(image=IMAGE,question='Who is skiing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3177, "imageId": "n223750", "question": "Does the necklace look large and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the necklace look large and blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3178, "imageId": "n531731", "question": "Does the field look orange?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the field look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3179, "imageId": "n531731", "question": "What does the player on the field wear?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='player')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What does the player wear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3180, "imageId": "n271392", "question": "Is the blue car to the right or to the left of the bench made of metal?", "program": "BOX0=LOC(image=IMAGE,object='bench made of metal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blue car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3181, "imageId": "n579256", "question": "Is she to the left or to the right of the bottle that looks heavy?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='heavy')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='she')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3182, "imageId": "n531731", "question": "What is the player on the field wearing?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='player')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the player wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3183, "imageId": "n223750", "question": "Does the necklace look large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the necklace look large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3184, "imageId": "n400036", "question": "What are the vehicles that the woman is behind of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3185, "imageId": "n100991", "question": "Does the knife on top of the napkin look green and thin?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knife')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the knife?')\nANSWER1=VQA(image=IMAGE1,question='Is the knife thin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3186, "imageId": "n315887", "question": "Does the speaker have the same color as the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='speaker')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the keyboard?')\nANSWER1=VQA(image=IMAGE1,question='What color is the speaker?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3187, "imageId": "n400036", "question": "What vehicles is the woman behind of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3188, "imageId": "n357784", "question": "Is the cat in the top part or in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3189, "imageId": "n199097", "question": "Does the street sign look small and red?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the street sign look small and red?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3190, "imageId": "n335542", "question": "Do the animals all have the same type?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the animals all have the same type?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3191, "imageId": "n133585", "question": "Does the person to the left of the boy look fat?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Does the person look fat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3192, "imageId": "n318370", "question": "What do the bottle and the drink have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the bottle and the drink have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3193, "imageId": "n202379", "question": "Do you think this fence is straight?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='Do you think this fence is straight?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3194, "imageId": "n412144", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3195, "imageId": "n202379", "question": "Is the fence straight and long?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the fence straight?')\nANSWER1=VQA(image=IMAGE,question='Is the fence long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3196, "imageId": "n437064", "question": "What is the spoon made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the spoon made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3197, "imageId": "n52544", "question": "What is the color of the knit shirt near the glass?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knit shirt')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the knit shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3198, "imageId": "n260762", "question": "What kind of vehicle is this, a truck or a bus?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nBOX1=LOC(image=IMAGE,object='bus')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'truck' if {ANSWER0} > 0 else 'bus'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3199, "imageId": "n527290", "question": "What is the pattern of the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pattern of the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3200, "imageId": "n187961", "question": "Does the animal in front of the kid look brown and short?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the animal?')\nANSWER1=VQA(image=IMAGE1,question='What is the height of the animal?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3201, "imageId": "n483840", "question": "Does the American flag look high?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the American flag look high?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3202, "imageId": "n382416", "question": "Is the coat short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the coat short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3203, "imageId": "n382416", "question": "Is the coat that is not short sleeved black or white?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the coat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' or {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3204, "imageId": "n309148", "question": "Is that a fire truck or a tractor?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nBOX1=LOC(image=IMAGE,object='tractor')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'fire truck' if {ANSWER0} > 0 else 'tractor'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3205, "imageId": "n65866", "question": "What do you think the bath tub is made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think the bath tub is made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3206, "imageId": "n65866", "question": "What is the bathtub made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the bathtub made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3207, "imageId": "n257997", "question": "Do you see any hats that are blue?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3208, "imageId": "n162108", "question": "Is there a bottle or a mug that is made of glass?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nBOX1=LOC(image=IMAGE,object='mug')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3209, "imageId": "n117888", "question": "How big is the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nANSWER0=VQA(image=IMAGE,question='How big is the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3210, "imageId": "n531731", "question": "Is the blue bag to the right of the towel?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blue bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3211, "imageId": "n525901", "question": "The covered window is what size?", "program": "BOX0=LOC(image=IMAGE,object='covered window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the covered window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3212, "imageId": "n527589", "question": "On which side of the image are the shelves?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3213, "imageId": "n575770", "question": "Is the rug below the suitcase gray and dirty?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the rug?')\nANSWER1=VQA(image=IMAGE1,question='Is the rug dirty?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3214, "imageId": "n575770", "question": "Which side of the picture is the rug on?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3215, "imageId": "n324908", "question": "Is the dry pasture larger than a zebra?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='dry pasture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the dry pasture larger than a zebra?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3216, "imageId": "n140421", "question": "On which side are the colorful plates?", "program": "BOX0=LOC(image=IMAGE,object='colorful plates')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3217, "imageId": "n412144", "question": "Do you see either a kid or a skateboarder there?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nBOX1=LOC(image=IMAGE,object='skateboarder')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3218, "imageId": "n162148", "question": "What is the shirt worn on?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the shirt worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3219, "imageId": "n162148", "question": "What's the shirt worn on?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the shirt worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3220, "imageId": "n162148", "question": "Is the white shirt worn on the undershirt the woman is wearing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='undershirt')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='white shirt')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3221, "imageId": "n313060", "question": "Are there either any tall men or women?", "program": "BOX0=LOC(image=IMAGE,object='man')\nBOX1=LOC(image=IMAGE,object='woman')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3222, "imageId": "n499081", "question": "Are the towels on the left side or on the right?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towels')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3223, "imageId": "n441859", "question": "What is the gender of the person that wears a hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the gender of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3224, "imageId": "n162148", "question": "What is the color of the undershirt?", "program": "BOX0=LOC(image=IMAGE,object='undershirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the undershirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3225, "imageId": "n283587", "question": "Does the side table have long length?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the side table have long length?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3226, "imageId": "n575770", "question": "What kind of clothing is gray?", "program": "BOX0=LOC(image=IMAGE,object='gray clothing')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is gray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3227, "imageId": "n357784", "question": "Does the curtain look thin and closed?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the curtain look thin and closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3228, "imageId": "n118102", "question": "Is the knife to the left of the girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knife')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3229, "imageId": "n119886", "question": "Is the pipe that looks white tall and thin?", "program": "BOX0=LOC(image=IMAGE,object='white pipe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the pipe tall and thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3230, "imageId": "n473688", "question": "Is the toothbrush the same material as the faucet?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='faucet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the toothbrush made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the faucet made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3231, "imageId": "n257997", "question": "Who is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3232, "imageId": "n257997", "question": "Who is before the crowd?", "program": "BOX0=LOC(image=IMAGE,object='crowd')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is before the crowd?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3233, "imageId": "n172618", "question": "Is the short girl to the right or to the left of the kite?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short girl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3234, "imageId": "n55058", "question": "Do you see any serving trays to the right of the mug that is round?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='round')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='serving trays')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3235, "imageId": "n71728", "question": "Is the round bowl to the left or to the right of the man on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='bowl')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3236, "imageId": "n222915", "question": "What fruits are sitting on the leafy vegetables?", "program": "BOX0=LOC(image=IMAGE,object='leafy vegetables')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruits')\nANSWER0=VQA(image=IMAGE0,question='What fruits are sitting on the leafy vegetables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3237, "imageId": "n382416", "question": "Does the box have tan color?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the box?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'tan' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3238, "imageId": "n117888", "question": "Is there a small ball or frisbee?", "program": "BOX0=LOC(image=IMAGE,object='small ball')\nBOX1=LOC(image=IMAGE,object='frisbee')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3239, "imageId": "n159284", "question": "Is the skateboard red and long?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the skateboard?')\nANSWER1=VQA(image=IMAGE0,question='How long is the skateboard?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3240, "imageId": "n398429", "question": "What is in front of the bench that is to the right of the coffee maker?", "program": "BOX0=LOC(image=IMAGE,object='coffee maker')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3241, "imageId": "n398429", "question": "What is the table in front of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the table in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3242, "imageId": "n350766", "question": "What cooking utensil is above the drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3243, "imageId": "n6908", "question": "Are the glass and the picture frame made of the same material?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the glass made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the picture frame made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3244, "imageId": "n548534", "question": "Is there any dishwasher to the right of the sharp knives that are sitting on the countertop?", "program": "BOX0=LOC(image=IMAGE,object='sharp knives')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='countertop')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='dishwasher')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3245, "imageId": "n6908", "question": "Is the picture frame made of the same material as the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='picture frame')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the picture frame made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3246, "imageId": "n355339", "question": "What is the device above the table that is in front of the people?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='people')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nANSWER0=VQA(image=IMAGE1,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3247, "imageId": "n331357", "question": "Is the white animal small or large?", "program": "BOX0=LOC(image=IMAGE,object='white animal')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} < 0.5 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3248, "imageId": "n355339", "question": "What device is the laptop behind of?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is the laptop behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3249, "imageId": "n450919", "question": "How clean is the mud near the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mud')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How clean is the mud?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3250, "imageId": "n37274", "question": "What kind of appliance is sitting atop the crate?", "program": "BOX0=LOC(image=IMAGE,object='crate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of appliance is sitting atop the crate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3251, "imageId": "n554880", "question": "What is the piece of furniture to the left of the cell phone?", "program": "BOX0=LOC(image=IMAGE,object='cell phone')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3252, "imageId": "n207708", "question": "Does the appliance to the left of the bookcase look large and black?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What color is the appliance?')\nANSWER1=VQA(image=IMAGE0,question='Does the appliance look large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3253, "imageId": "n486200", "question": "Is there a truck in the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='truck')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3254, "imageId": "n543966", "question": "Are the elephants standing behind the rocks?", "program": "BOX0=LOC(image=IMAGE,object='rocks')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='elephants')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3255, "imageId": "n543966", "question": "What are the large animals standing behind of?", "program": "BOX0=LOC(image=IMAGE,object='large animals')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the large animals standing behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3256, "imageId": "n543966", "question": "What animal is standing behind the rocks?", "program": "BOX0=LOC(image=IMAGE,object='rocks')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is standing behind the rocks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3257, "imageId": "n543966", "question": "What are the animals that are standing behind the rocks that are not small?", "program": "BOX0=LOC(image=IMAGE,object='rocks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animals')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='not small')\nANSWER0=VQA(image=IMAGE1,question='What are the animals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3258, "imageId": "n511913", "question": "Is the wine bottle on top of a cabinet?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wine bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3259, "imageId": "n28792", "question": "What is the color of the umbrella to the left of the other umbrella?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nANSWER0=VQA(image=IMAGE0,question='What is the color of the umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3260, "imageId": "n16378", "question": "Is the happy woman using a laptop?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3261, "imageId": "n89148", "question": "Is that girl below a stuffed bear?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stuffed bear')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3262, "imageId": "n543966", "question": "What animal is in front of the yellow flowers?", "program": "BOX0=LOC(image=IMAGE,object='yellow flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the yellow flowers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3263, "imageId": "n543966", "question": "What animal is in front of the flowers?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the flowers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3264, "imageId": "n159802", "question": "What is the woman wearing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3265, "imageId": "n312206", "question": "On which side of the image is the fork?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3266, "imageId": "n312206", "question": "Do you see any forks on top of the white napkin?", "program": "BOX0=LOC(image=IMAGE,object='white napkin')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='forks')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3267, "imageId": "n159802", "question": "Who is wearing a blouse?", "program": "BOX0=LOC(image=IMAGE,object='blouse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a blouse?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3268, "imageId": "n243701", "question": "The traffic signal has what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the traffic signal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3269, "imageId": "n317260", "question": "On which side is the umpire, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3270, "imageId": "n133585", "question": "Are the shorts long and black?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE0,question='Are the shorts long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3271, "imageId": "n573460", "question": "Is the umpire to the left or to the right of the person that holds the racket?", "program": "BOX0=LOC(image=IMAGE,object='person with racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umpire')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3272, "imageId": "n573460", "question": "Who is in front of the white shoes?", "program": "BOX0=LOC(image=IMAGE,object='white shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the white shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3273, "imageId": "n274905", "question": "Are the pants that look white soft and thin?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the pants that look white soft and thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3274, "imageId": "n326988", "question": "What are the glasses inside of?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the glasses inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3275, "imageId": "n195249", "question": "Does the cotton shirt look dark blue and short?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the cotton shirt?')\nANSWER1=VQA(image=IMAGE,question='Is the cotton shirt short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3276, "imageId": "n24526", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3277, "imageId": "n326988", "question": "Are the glasses that are to the right of the remote control black or gold?", "program": "BOX0=LOC(image=IMAGE,object='remote control')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glasses')\nANSWER0=VQA(image=IMAGE0,question='What color are the glasses?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'gold'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3278, "imageId": "n117888", "question": "Is the shallow sand underneath the athlete?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shallow sand')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3279, "imageId": "n195249", "question": "What color is the shirt made of cotton?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='What material is the shirt made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'cotton' and {ANSWER0} != 'none' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3280, "imageId": "n16936", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3281, "imageId": "n233607", "question": "Is she to the left or to the right of the computer that is not closed?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nBOX1=LOC(image=IMAGE,object='not closed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='she')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3282, "imageId": "n477215", "question": "Do the wildflowers look ugly?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the wildflowers look ugly?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3283, "imageId": "n293477", "question": "Which material is the white bed made of, cloth or leather?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material is the white bed made of, cloth or leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3284, "imageId": "n543966", "question": "How large are the gray rocks?", "program": "BOX0=LOC(image=IMAGE,object='gray rocks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How large are the gray rocks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3285, "imageId": "n485969", "question": "How heavy is the baseball that is not big?", "program": "BOX0=LOC(image=IMAGE,object='baseball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How heavy is the baseball?')\nANSWER1=EVAL(expr=\"'not big' if {ANSWER0} != 'big' else 'big'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3286, "imageId": "n280089", "question": "What do you think is sitting in the utensil holder?", "program": "BOX0=LOC(image=IMAGE,object='utensil holder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting in the utensil holder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3287, "imageId": "n137182", "question": "Which side of the image is the man on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3288, "imageId": "n386682", "question": "Which kind of furniture is rectangular?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is rectangular?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3289, "imageId": "n534106", "question": "Is the fried food in the top or in the bottom part?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fried food')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3290, "imageId": "n159802", "question": "Is the person to the left of the hair clip Asian and adult?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Is the person Asian?')\nANSWER1=VQA(image=IMAGE0,question='Is the person an adult?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3291, "imageId": "n67005", "question": "What color is the small bag?", "program": "BOX0=LOC(image=IMAGE,object='small bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the small bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3292, "imageId": "n124651", "question": "How wide is that road?", "program": "BOX0=LOC(image=IMAGE,object='road')\nANSWER0=VQA(image=IMAGE,question='How wide is the road?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3293, "imageId": "n279581", "question": "What is the batter on?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the batter on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3294, "imageId": "n97485", "question": "What piece of furniture is above the spices?", "program": "BOX0=LOC(image=IMAGE,object='spices')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is above the spices?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3295, "imageId": "n118102", "question": "Does the appliance behind the table have black color?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the appliance?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3296, "imageId": "n355567", "question": "Does the person to the left of the lady look happy and modern?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Does the person look happy?')\nANSWER1=VQA(image=IMAGE0,question='Does the person look modern?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3297, "imageId": "n97485", "question": "Are there any mirrors above the granite countertop?", "program": "BOX0=LOC(image=IMAGE,object='granite countertop')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3298, "imageId": "n565418", "question": "Are there any doors?", "program": "BOX0=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3299, "imageId": "n184551", "question": "What's the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3300, "imageId": "n314171", "question": "Is the drink that is to the right of the blender made of glass?", "program": "BOX0=LOC(image=IMAGE,object='blender')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drink')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the drink made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'glass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3301, "imageId": "n310625", "question": "Is the sink below a mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sink')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3302, "imageId": "n39114", "question": "Who is wearing the sneakers?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the sneakers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3303, "imageId": "n264887", "question": "What is the name of the device that is to the right of the white cups?", "program": "BOX0=LOC(image=IMAGE,object='white cups')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3304, "imageId": "n37274", "question": "Who is wearing the watch?", "program": "BOX0=LOC(image=IMAGE,object='watch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the watch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3305, "imageId": "n538684", "question": "Is the catcher to the right or to the left of the batter that is standing?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='catcher')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3306, "imageId": "n579928", "question": "Are there both a door and a window in the picture?", "program": "BOX0=LOC(image=IMAGE,object='door')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3307, "imageId": "n450919", "question": "The hat is what size?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The hat is what size?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3308, "imageId": "n51658", "question": "Is the man to the left or to the right of the tennis racket on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='man')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3309, "imageId": "n187544", "question": "Do you think the shirt is red?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3310, "imageId": "n450919", "question": "Is the hat blue and small?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE0,question='How big is the hat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3311, "imageId": "n206785", "question": "What is pulled by the person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is pulled by the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3312, "imageId": "n206785", "question": "Is the necktie pulled by a person?", "program": "BOX0=LOC(image=IMAGE,object='necktie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3313, "imageId": "n471866", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3314, "imageId": "n124651", "question": "The hospital has what size?", "program": "ANSWER0=VQA(image=IMAGE,question='The hospital has what size?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3315, "imageId": "n542609", "question": "What are the people walking on?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the people walking on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3316, "imageId": "n411121", "question": "How large is the bike the person rides on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bike')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the bike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3317, "imageId": "n542609", "question": "The people are walking on what?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The people are walking on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3318, "imageId": "n381072", "question": "Are there both a plate and a cake?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='cake')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3319, "imageId": "n473688", "question": "Are there either any chickens or trash cans in this picture?", "program": "BOX0=LOC(image=IMAGE,object='chicken')\nBOX1=LOC(image=IMAGE,object='trash can')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3320, "imageId": "n473688", "question": "Is the chrome faucet on the left side or on the right of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chrome faucet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3321, "imageId": "n403734", "question": "Is the black notebook open or closed?", "program": "BOX0=LOC(image=IMAGE,object='black notebook')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the black notebook open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3322, "imageId": "n554880", "question": "What type of device is to the left of the person that is wearing a watch?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watch')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of device is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3323, "imageId": "n513100", "question": "What is the item of furniture to the right of the bird?", "program": "BOX0=LOC(image=IMAGE,object='bird')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3324, "imageId": "n513100", "question": "Is there a chair underneath the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3325, "imageId": "n298104", "question": "What is the flower on?", "program": "BOX0=LOC(image=IMAGE,object='flower')\nANSWER0=VQA(image=IMAGE,question='What is the flower on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3326, "imageId": "n28996", "question": "Are there either spoons or containers?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nBOX1=LOC(image=IMAGE,object='container')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3327, "imageId": "n513100", "question": "What piece of furniture is to the right of the bird?", "program": "BOX0=LOC(image=IMAGE,object='bird')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is to the right of the bird?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3328, "imageId": "n579928", "question": "What vehicle is on the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is on the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3329, "imageId": "n200907", "question": "Is the shirt made of cotton short sleeved and blue?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the shirt made of?')\nANSWER1=VQA(image=IMAGE0,question='Are the sleeves of the shirt short?')\nANSWER2=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'cotton' and {ANSWER1} == 'yes' and {ANSWER2} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 3330, "imageId": "n250715", "question": "Is the chair to the right or to the left of the white device?", "program": "BOX0=LOC(image=IMAGE,object='white device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3331, "imageId": "n200907", "question": "What color is the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3332, "imageId": "n143935", "question": "What type of animal is small?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of animal is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3333, "imageId": "n143935", "question": "Which kind of animal is small?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3334, "imageId": "n415215", "question": "Is the male person Asian or Caucasian?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the male person Asian or Caucasian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3335, "imageId": "n469525", "question": "Is there either a giraffe or a fence in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3336, "imageId": "n153293", "question": "Does the floor look clean and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the floor look clean?')\nANSWER1=VQA(image=IMAGE,question='What color is the floor?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'clean' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3337, "imageId": "n324644", "question": "Do the tall windows have white color?", "program": "BOX0=LOC(image=IMAGE,object='tall windows')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the tall windows?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3338, "imageId": "n578564", "question": "Does the glass window look closed and rectangular?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the glass window look closed?')\nANSWER1=VQA(image=IMAGE,question='Does the glass window look rectangular?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3339, "imageId": "n153293", "question": "Does the clean floor look blue?", "program": "BOX0=LOC(image=IMAGE,object='clean floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color does the clean floor look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3340, "imageId": "n534106", "question": "Is this a bed or a couch?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='couch')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'bed' if {ANSWER0} > 0 else 'couch'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3341, "imageId": "n433692", "question": "How big is the animal in the middle of the image?", "program": "BOX0=LOC(image=IMAGE,object='middle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3342, "imageId": "n500209", "question": "Are both the jar and the shelf made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='jar')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shelf')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the jar made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the shelf made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3343, "imageId": "n98544", "question": "Which color do you think the floor has?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color do you think the floor has?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3344, "imageId": "n386688", "question": "Are there any kites?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3345, "imageId": "n23762", "question": "How fat is the tall person?", "program": "BOX0=LOC(image=IMAGE,object='tall person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How fat is the tall person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3346, "imageId": "n481655", "question": "Is the catcher on the right or on the left?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3347, "imageId": "n488874", "question": "Is the surfer unhealthy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the surfer unhealthy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3348, "imageId": "n240666", "question": "How large is the toilet paper?", "program": "BOX0=LOC(image=IMAGE,object='toilet paper')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3349, "imageId": "n312206", "question": "Are the napkin and the plate the same color?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='plate')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the napkin?')\nANSWER1=VQA(image=IMAGE1,question='What color is the plate?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3350, "imageId": "n98540", "question": "How tall is the grass that he is jumping over?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How tall is the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3351, "imageId": "n192021", "question": "Is the window that looks square clear and tinted?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the window clear?')\nANSWER1=VQA(image=IMAGE0,question='Is the window tinted?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3352, "imageId": "n289376", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3353, "imageId": "n290409", "question": "Does the basket behind the truck look light blue and new?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='basket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the basket?')\nANSWER1=VQA(image=IMAGE1,question='Is the basket new?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'light blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3354, "imageId": "n206785", "question": "Is the bag made of the same material as the door frame?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='door frame')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the bag made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the door frame made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3355, "imageId": "n415215", "question": "Of what material the toilet brush?", "program": "BOX0=LOC(image=IMAGE,object='toilet brush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Of what material is the toilet brush?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3356, "imageId": "n296467", "question": "What kind of furniture is wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3357, "imageId": "n118102", "question": "What is in front of the appliance that is to the right of the girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nIMAGE2=CROP_FRONT(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What is in front of the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3358, "imageId": "n437064", "question": "Are the utensil that looks silver and the utensil in front of the cake both metallic?", "program": "BOX0=LOC(image=IMAGE,object='silver utensil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='utensil in front of cake')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the silver utensil made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the utensil in front of the cake made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'metallic' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3359, "imageId": "n119886", "question": "On which side is the small faucet?", "program": "BOX0=LOC(image=IMAGE,object='small faucet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3360, "imageId": "n283587", "question": "What piece of furniture is to the right of the sofa?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is to the right of the sofa?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3361, "imageId": "n485969", "question": "Does the grassy field look brown?", "program": "BOX0=LOC(image=IMAGE,object='grassy field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color does the grassy field look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3362, "imageId": "n209843", "question": "Are there either any cabinets or shelves?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nBOX1=LOC(image=IMAGE,object='shelf')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3363, "imageId": "n264887", "question": "Is the white keyboard to the left or to the right of the cup that is made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='keyboard')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3364, "imageId": "n209843", "question": "What is the towel on?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the towel on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3365, "imageId": "n410476", "question": "What place is this picture in?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is this picture in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3366, "imageId": "n530733", "question": "Is the counter tan?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the counter?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'tan' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3367, "imageId": "n309148", "question": "Are the flag and the fire truck the same color?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fire truck')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the flag?')\nANSWER1=VQA(image=IMAGE1,question='What color is the fire truck?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3368, "imageId": "n171169", "question": "What animal is in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3369, "imageId": "n171169", "question": "What is the horse in front of?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the horse in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3370, "imageId": "n527290", "question": "What is the piece of furniture on top of the rug in the bottom of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the piece of furniture on top of the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3371, "imageId": "n342511", "question": "What animal is sitting atop the seat that looks orange?", "program": "BOX0=LOC(image=IMAGE,object='seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='orange')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is sitting atop the seat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3372, "imageId": "n527290", "question": "Is the table on top of the beige rug that is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='beige rug')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='table')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3373, "imageId": "n234683", "question": "Which kind of clothing isn't fancy?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing isn't fancy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3374, "imageId": "n498712", "question": "What is the young person wearing?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the young person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3375, "imageId": "n498712", "question": "What is the girl wearing?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the girl wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3376, "imageId": "n498712", "question": "Who is wearing the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3377, "imageId": "n92308", "question": "What is the color of the path?", "program": "BOX0=LOC(image=IMAGE,object='path')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the path?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3378, "imageId": "n432591", "question": "What is the lamp sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='top')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3379, "imageId": "n184385", "question": "Do you see either a spoon or a fork that are made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nBOX1=LOC(image=IMAGE,object='fork')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3380, "imageId": "n184385", "question": "Is the small utensil made of plastic or stainless steel?", "program": "BOX0=LOC(image=IMAGE,object='small utensil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the small utensil made of?')\nANSWER1=EVAL(expr=\"'plastic' if {ANSWER0} == 'plastic' else 'stainless steel'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3381, "imageId": "n313060", "question": "Which kind of clothing is warm?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is warm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3382, "imageId": "n313060", "question": "How is the clothing item that is open called?", "program": "BOX0=LOC(image=IMAGE,object='open clothing item')\nANSWER0=VQA(image=IMAGE,question='How is the clothing item called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3383, "imageId": "n313060", "question": "What clothing item is open?", "program": "BOX0=LOC(image=IMAGE,object='clothing item')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What clothing item is open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3384, "imageId": "n313060", "question": "What clothing item is comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='What clothing item is comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3385, "imageId": "n208458", "question": "Does the clear sky look blue?", "program": "BOX0=LOC(image=IMAGE,object='clear sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the clear sky?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3386, "imageId": "n536256", "question": "Is the lamp white and tall?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the lamp?')\nANSWER1=VQA(image=IMAGE0,question='Is the lamp tall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3387, "imageId": "n238266", "question": "What is on the cupcake?", "program": "BOX0=LOC(image=IMAGE,object='cupcake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the cupcake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3388, "imageId": "n52544", "question": "What kind of furniture is pictured?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is pictured?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3389, "imageId": "n54180", "question": "Is the man using a speaker?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='speaker')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3390, "imageId": "n538039", "question": "Where is the truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nANSWER0=VQA(image=IMAGE,question='Where is the truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3391, "imageId": "n497658", "question": "Do the trees appear to be green?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the trees appear to be green?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3392, "imageId": "n528403", "question": "Where is the young person standing on?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the young person standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3393, "imageId": "n12404", "question": "What is the woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3394, "imageId": "n12404", "question": "Is the woman in front of a fence?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3395, "imageId": "n275857", "question": "Does the goal have a different color than the building?", "program": "BOX0=LOC(image=IMAGE,object='goal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='building')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the goal?')\nANSWER1=VQA(image=IMAGE1,question='What color is the building?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3396, "imageId": "n9856", "question": "Is the fence in the top part of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3397, "imageId": "n222297", "question": "Which shape is the swimming pool below the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='swimming pool')\nANSWER0=VQA(image=IMAGE0,question='Which shape is the swimming pool?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3398, "imageId": "n355567", "question": "How large is the wire net?", "program": "BOX0=LOC(image=IMAGE,object='wire net')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3399, "imageId": "n194179", "question": "What is on the shoes?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3400, "imageId": "n79078", "question": "What is worn on the happy person?", "program": "BOX0=LOC(image=IMAGE,object='happy person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is worn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3401, "imageId": "n433692", "question": "Are the books to the right of the pens that look small?", "program": "BOX0=LOC(image=IMAGE,object='pens')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3402, "imageId": "n244826", "question": "Does the soccer player next to the other soccer player look small?", "program": "BOX0=LOC(image=IMAGE,object='soccer player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other soccer player')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the soccer player look small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3403, "imageId": "n216553", "question": "What animal is standing against the fence made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is standing against the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3404, "imageId": "n35676", "question": "Are the drawers to the left of the clean oven?", "program": "BOX0=LOC(image=IMAGE,object='clean oven')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drawers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3405, "imageId": "n90294", "question": "What type of device is not on?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='What type of device is not on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3406, "imageId": "n90294", "question": "Which kind of device is not on?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='Which kind of device is not on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3407, "imageId": "n187544", "question": "Is the shirt the same color as the building?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='building')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the building?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3408, "imageId": "n319845", "question": "How big is the red apron?", "program": "BOX0=LOC(image=IMAGE,object='red apron')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the red apron?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3409, "imageId": "n125122", "question": "How is the piece of furniture below the mirror the television is to the right of called?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='television')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How is the piece of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3410, "imageId": "n390187", "question": "Are the trousers red or blue?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the trousers?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3411, "imageId": "n90294", "question": "Does the device that looks little look blue?", "program": "BOX0=LOC(image=IMAGE,object='little')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the device?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3412, "imageId": "n336443", "question": "How is the meat on the plate that is sitting atop the table called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the meat on the plate that is sitting atop the table called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3413, "imageId": "n336443", "question": "Does the meat on the plate look roasted?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the meat on the plate look roasted?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3414, "imageId": "n162148", "question": "Which kind of device does the woman hold onto?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of device does the woman hold onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3415, "imageId": "n413761", "question": "Is the road rocky?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the road rocky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3416, "imageId": "n137182", "question": "What is the young person doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the young person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3417, "imageId": "n137182", "question": "Who is walking?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3418, "imageId": "n181210", "question": "Are there either any tablecloths or forks?", "program": "BOX0=LOC(image=IMAGE,object='tablecloth')\nBOX1=LOC(image=IMAGE,object='fork')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3419, "imageId": "n35676", "question": "Is the appliance above the oven old or new?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='Is the appliance old or new?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3420, "imageId": "n97485", "question": "Does the cabinet to the left of the other cabinet look clean?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other cabinet')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the cabinet look clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3421, "imageId": "n278312", "question": "What is the width of the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nANSWER0=VQA(image=IMAGE,question='What is the width of the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3422, "imageId": "n479092", "question": "Do the metal utensils next to the forks look hard?", "program": "BOX0=LOC(image=IMAGE,object='forks')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='metal utensils')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3423, "imageId": "n54424", "question": "What shape is the Wii controller to the right of the Wii remotes?", "program": "BOX0=LOC(image=IMAGE,object='Wii remotes')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='Wii controller')\nANSWER0=VQA(image=IMAGE0,question='What shape is the Wii controller?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3424, "imageId": "n479092", "question": "Do the utensils next to the forks look black and hard?", "program": "BOX0=LOC(image=IMAGE,object='forks')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensils')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3425, "imageId": "n28572", "question": "Is this a little table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='Is this a little table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3426, "imageId": "n483840", "question": "Is the car on the right side?", "program": "BOX0=LOC(image=IMAGE,object='car')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3427, "imageId": "n483840", "question": "What is the jacket made of, cloth or leather?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the jacket made of, cloth or leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3428, "imageId": "n133585", "question": "Does the boy to the right of the person appear to be standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3429, "imageId": "n262920", "question": "Are there screens to the right of the backpack?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='screens')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3430, "imageId": "n386682", "question": "Which size are those cabinets, large or small?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which size are the cabinets?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3431, "imageId": "n346247", "question": "Are there any mirrors or cars?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nBOX1=LOC(image=IMAGE,object='car')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3432, "imageId": "n334278", "question": "Is the fence in the bottom or in the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3433, "imageId": "n507959", "question": "Is there a pink umbrella in the picture?", "program": "BOX0=LOC(image=IMAGE,object='pink umbrella')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3434, "imageId": "n507959", "question": "What is the color of the umbrella that is sitting behind the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nANSWER0=VQA(image=IMAGE0,question='What color is the umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3435, "imageId": "n296467", "question": "Do the dessert next to the carrots look baked?", "program": "BOX0=LOC(image=IMAGE,object='carrots')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nANSWER0=VQA(image=IMAGE0,question='Does the dessert look baked?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3436, "imageId": "n77818", "question": "Is the DVD player short and black?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the DVD player?')\nANSWER1=VQA(image=IMAGE,question='What is the height of the DVD player?')\nANSWER2=VQA(image=IMAGE,question='What is the width of the DVD player?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 3437, "imageId": "n250821", "question": "What is falling off the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is falling off the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3438, "imageId": "n211324", "question": "Which kind of sign is on the walkway?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of sign is on the walkway?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3439, "imageId": "n350732", "question": "Are both the chair and the soccer ball the same color?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='soccer ball')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=VQA(image=IMAGE1,question='What color is the soccer ball?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3440, "imageId": "n44249", "question": "What kind of animal are the trees behind of, a sheep or an elephant?", "program": "BOX0=LOC(image=IMAGE,object='sheep')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'sheep' if {ANSWER0} > 0 else 'elephant'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3441, "imageId": "n398429", "question": "Is there a train to the left of the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='train')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3442, "imageId": "n211324", "question": "How large is the traffic sign?", "program": "BOX0=LOC(image=IMAGE,object='traffic sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How large is the traffic sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3443, "imageId": "n111390", "question": "Is the table to the left or to the right of the lady that is standing behind the cake?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lady')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='table')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3444, "imageId": "n28572", "question": "Is the color of the saucer different than the napkin?", "program": "BOX0=LOC(image=IMAGE,object='saucer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='napkin')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the saucer?')\nANSWER1=VQA(image=IMAGE1,question='What color is the napkin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3445, "imageId": "n403734", "question": "Is the color of the bottle different than the napkin?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='napkin')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bottle?')\nANSWER1=VQA(image=IMAGE1,question='What color is the napkin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3446, "imageId": "n403734", "question": "Does the napkin have the same color as the notebook?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='notebook')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the napkin?')\nANSWER1=VQA(image=IMAGE1,question='What color is the notebook?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3447, "imageId": "n494918", "question": "What's the boy looking at?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the boy looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3448, "imageId": "n357784", "question": "Are there either any small mirrors or nightstands?", "program": "BOX0=LOC(image=IMAGE,object='small mirrors')\nBOX1=LOC(image=IMAGE,object='nightstands')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3449, "imageId": "n272098", "question": "How is that food called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is that food called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3450, "imageId": "n272098", "question": "What kind of baked good is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of baked good is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3451, "imageId": "n272098", "question": "How is the glazed food called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the glazed food called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3452, "imageId": "n68769", "question": "Is the plate both round and silver?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the plate round?')\nANSWER1=VQA(image=IMAGE,question='What color is the plate?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'silver' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3453, "imageId": "n259002", "question": "Is the color of the ball the same as that of the trash can?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='trash can')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the ball?')\nANSWER1=VQA(image=IMAGE1,question='What color is the trash can?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3454, "imageId": "n315887", "question": "Is there any speaker in the picture that is not white?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nANSWER0=VQA(image=IMAGE,question='What color is the speaker?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3455, "imageId": "n319845", "question": "What is around the table the ceiling is above?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ceiling')\nIMAGE1=CROP_AROUND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is around the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3456, "imageId": "n546884", "question": "Is the cup on a plate?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3457, "imageId": "n23181", "question": "Is the bed still?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nANSWER0=VQA(image=IMAGE,question='Is the bed still?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3458, "imageId": "n71728", "question": "Is the table made of the same material as the bench?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bench')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the bench made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3459, "imageId": "n168412", "question": "Is the ground dry?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the ground dry?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3460, "imageId": "n95313", "question": "What color is the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3461, "imageId": "n446242", "question": "Who wears shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nANSWER0=VQA(image=IMAGE,question='Who wears shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3462, "imageId": "n429961", "question": "Is the round vegetable to the right or to the left of the purple cabbage?", "program": "BOX0=LOC(image=IMAGE,object='purple cabbage')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='round vegetable')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3463, "imageId": "n95313", "question": "What kind of clothing is hanging?", "program": "BOX0=LOC(image=IMAGE,object='hanging')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of clothing is hanging?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3464, "imageId": "n455563", "question": "Does the spray bottle look white and small?", "program": "BOX0=LOC(image=IMAGE,object='spray bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the spray bottle?')\nANSWER1=VQA(image=IMAGE0,question='What size is the spray bottle?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3465, "imageId": "n503626", "question": "What is mounted on the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is mounted on the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3466, "imageId": "n90944", "question": "Are the tall buildings behind the sand that is not dirty?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tall buildings')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='dirty')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3467, "imageId": "n355339", "question": "Is there any mouse or keyboard that is not made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='mouse')\nBOX1=LOC(image=IMAGE,object='keyboard')\nANSWER0=VQA(image=IMAGE,question='What material is the mouse made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the keyboard made of?')\nANSWER2=EVAL(expr=\"'yes' if ({ANSWER0} != 'plastic' or {ANSWER1} != 'plastic') else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3468, "imageId": "n275148", "question": "Are there couches near the storage box?", "program": "BOX0=LOC(image=IMAGE,object='storage box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couches')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3469, "imageId": "n172618", "question": "Is the kite to the right of the girl round and small?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='kite')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3470, "imageId": "n200225", "question": "Is the green spinach to the left or to the right of the food the sausage is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='sausage')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='green spinach')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3471, "imageId": "n489699", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3472, "imageId": "n88366", "question": "Who is skiing?", "program": "BOX0=LOC(image=IMAGE,object='skiing')\nANSWER0=VQA(image=IMAGE,question='Who is skiing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3473, "imageId": "n200225", "question": "Is the leafy vegetable to the left of the yellow food?", "program": "BOX0=LOC(image=IMAGE,object='yellow food')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='leafy vegetable')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3474, "imageId": "n167164", "question": "What vehicle is to the right of the SUV?", "program": "BOX0=LOC(image=IMAGE,object='SUV')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is to the right?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3475, "imageId": "n37274", "question": "Is the man to the left of the crate holding beer?", "program": "BOX0=LOC(image=IMAGE,object='crate')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the man holding?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'beer' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3476, "imageId": "n126891", "question": "Who is wearing the gloves?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the gloves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3477, "imageId": "n150962", "question": "Which kind of clothing is warm?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is warm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3478, "imageId": "n150962", "question": "What kind of clothing is hanging?", "program": "BOX0=LOC(image=IMAGE,object='hanging')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of clothing is hanging?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3479, "imageId": "n126891", "question": "Who is wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing gloves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3480, "imageId": "n150962", "question": "What item of furniture is below the light fixture that is below the sign?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light fixture')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nANSWER0=VQA(image=IMAGE1,question='What item of furniture is below the light fixture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3481, "imageId": "n126891", "question": "Is the young boy wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='young boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the young boy wearing a jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3482, "imageId": "n520071", "question": "What is the animal that looks orange doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the animal that looks orange doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3483, "imageId": "n329514", "question": "What shape does the chimney that the window is below have?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chimney')\nANSWER0=VQA(image=IMAGE0,question='What shape does the chimney have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3484, "imageId": "n283587", "question": "What type of furniture is to the left of the side table that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of furniture is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3485, "imageId": "n540852", "question": "What kind of clothing is black?", "program": "BOX0=LOC(image=IMAGE,object='black clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3486, "imageId": "n329514", "question": "On which side is the chimney?", "program": "BOX0=LOC(image=IMAGE,object='chimney')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3487, "imageId": "n258500", "question": "Who in the picture is looking down?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3488, "imageId": "n314171", "question": "What appliance is to the left of the alcohol?", "program": "BOX0=LOC(image=IMAGE,object='alcohol')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is to the left of the alcohol?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3489, "imageId": "n314630", "question": "Do you think the toaster is rounded?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do you think the toaster is rounded?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3490, "imageId": "n200225", "question": "Do both the black vegetable and the pepper look cooked?", "program": "ANSWER0=VQA(image=IMAGE,question='Do both the black vegetable and the pepper look cooked?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3491, "imageId": "n532191", "question": "Is the charger white?", "program": "BOX0=LOC(image=IMAGE,object='charger')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the charger?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3492, "imageId": "n100552", "question": "What is the container made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the container made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3493, "imageId": "n336443", "question": "What piece of furniture is the plate sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is the plate sitting atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3494, "imageId": "n434283", "question": "What is the vehicle that is large?", "program": "BOX0=LOC(image=IMAGE,object='large')\nBOX1=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3495, "imageId": "n434283", "question": "Which kind of vehicle is large?", "program": "BOX0=LOC(image=IMAGE,object='large')\nANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3496, "imageId": "n126891", "question": "Is the baseball jersey short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='baseball jersey')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the baseball jersey short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3497, "imageId": "n455563", "question": "How large do you think is the bottle near the mug?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the bottle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3498, "imageId": "n334278", "question": "Is the leather belt both black and thick?", "program": "BOX0=LOC(image=IMAGE,object='leather belt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the leather belt?')\nANSWER1=VQA(image=IMAGE0,question='Is the leather belt thick?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3499, "imageId": "n398429", "question": "Is the red bench below a painting?", "program": "BOX0=LOC(image=IMAGE,object='painting')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='red bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3500, "imageId": "n324908", "question": "Which color is the horse, dark brown or tan?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the horse, dark brown or tan?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3501, "imageId": "n95313", "question": "What type of furniture is the bed in front of?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is the bed in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3502, "imageId": "n12404", "question": "What's the fire hydrant in front of?", "program": "BOX0=LOC(image=IMAGE,object='fire hydrant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fire hydrant in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3503, "imageId": "n12404", "question": "What is the fire hydrant in front of?", "program": "BOX0=LOC(image=IMAGE,object='fire hydrant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fire hydrant in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3504, "imageId": "n460385", "question": "Does the pizza beside the drink have orange color and round shape?", "program": "BOX0=LOC(image=IMAGE,object='drink')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pizza')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the pizza?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the pizza?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3505, "imageId": "n350732", "question": "What is the ethnicity of the man near the plants?", "program": "BOX0=LOC(image=IMAGE,object='plants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the ethnicity of the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3506, "imageId": "n326988", "question": "Which kind of furniture is to the right of the statue?", "program": "BOX0=LOC(image=IMAGE,object='statue')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is to the right of the statue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3507, "imageId": "n336443", "question": "Is the bowl to the left of the plate the fork is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nIMAGE1=CROP_LEFTOF(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE,object='fork')\nIMAGE2=CROP_LEFTOF(image=IMAGE,box=BOX2)\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3508, "imageId": "n204894", "question": "How old is the person that is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How old is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3509, "imageId": "n567860", "question": "What is the kitten doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the kitten doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3510, "imageId": "n264887", "question": "Are there either cabinets or chairs in this photo?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3511, "imageId": "n39114", "question": "Do the pants look beige and wet?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the pants?')\nANSWER1=VQA(image=IMAGE,question='Do the pants look wet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'beige' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3512, "imageId": "n501609", "question": "Is the oven to the left or to the right of the appliance the cabinets are below?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='oven')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3513, "imageId": "n310828", "question": "Is the mousepad different in color than the shirt?", "program": "BOX0=LOC(image=IMAGE,object='mousepad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the mousepad?')\nANSWER1=VQA(image=IMAGE1,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3514, "imageId": "n133585", "question": "Are there any helmets?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3515, "imageId": "n200225", "question": "Which kind of food is on the pizza?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is on the pizza?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3516, "imageId": "n49310", "question": "Does the sweater look blue?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sweater?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3517, "imageId": "n159802", "question": "Is the device to the left of the water bottle small and black?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the device?')\nANSWER3=VQA(image=IMAGE0,question='What size is the device?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'black' and {ANSWER3} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 3518, "imageId": "n433692", "question": "Are there any dogs near the pens to the right of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pens')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='dogs')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3519, "imageId": "n380113", "question": "Does the folding chair look still?", "program": "BOX0=LOC(image=IMAGE,object='folding chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the folding chair look still?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3520, "imageId": "n501951", "question": "What item of furniture is on top of the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is on top of the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3521, "imageId": "n317260", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3522, "imageId": "n501951", "question": "Are there any beds on top of the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='beds')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3523, "imageId": "n275148", "question": "What is the item of furniture that is made of same material as the storage box that is not empty called?", "program": "BOX0=LOC(image=IMAGE,object='storage box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the storage box made of?')\nBOX1=LOC(image=IMAGE,object='furniture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='What material is the furniture made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} and {ANSWER0} != 'empty' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3524, "imageId": "n556604", "question": "What is the lamp made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the lamp made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3525, "imageId": "n83784", "question": "What is the chair made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the chair made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3526, "imageId": "n534106", "question": "How long are the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long are the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3527, "imageId": "n69237", "question": "What is on the soft bed?", "program": "BOX0=LOC(image=IMAGE,object='soft bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the soft bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3528, "imageId": "n222915", "question": "Is the empty mug colorful or black and white?", "program": "BOX0=LOC(image=IMAGE,object='empty mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the empty mug colorful or black and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3529, "imageId": "n173807", "question": "Are there fences to the right of the bus in the middle of the picture?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='fences')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3530, "imageId": "n275148", "question": "What do both the floor and the TV stand have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the floor and the TV stand have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3531, "imageId": "n222915", "question": "Are there any mugs or bottles that are not empty?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nBOX1=LOC(image=IMAGE,object='bottle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3532, "imageId": "n500308", "question": "Is the window made of the same material as the table?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the window made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3533, "imageId": "n500308", "question": "Is the floor the same material as the table?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the floor made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3534, "imageId": "n500308", "question": "Are both the fridge and the door made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='fridge')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='door')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the fridge made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the door made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3535, "imageId": "n192021", "question": "What shape is the chair that looks white?", "program": "BOX0=LOC(image=IMAGE,object='white chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3536, "imageId": "n498140", "question": "Does the person above the grill look calm and male?", "program": "BOX0=LOC(image=IMAGE,object='grill')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Does the person look calm?')\nANSWER3=VQA(image=IMAGE1,question='Is the person male?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 3537, "imageId": "n498140", "question": "Does the person that is not female look calm?", "program": "BOX0=LOC(image=IMAGE,object='female')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='person')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the person look calm?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3538, "imageId": "n262920", "question": "Is the desk light brown or black?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light')\nANSWER0=VQA(image=IMAGE0,question='What color is the desk?')\nANSWER1=VQA(image=IMAGE0,question='What color is the light?')\nANSWER2=EVAL(expr=\"'brown' if {ANSWER0} == 'brown' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3539, "imageId": "n143672", "question": "Does the ground near the forest have brown color?", "program": "BOX0=LOC(image=IMAGE,object='forest')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ground')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the ground?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3540, "imageId": "n469525", "question": "Does the grass that looks light brown look tall?", "program": "BOX0=LOC(image=IMAGE,object='light brown grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the grass look tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3541, "imageId": "n279581", "question": "Which side is the helmet on?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3542, "imageId": "n23762", "question": "Do the flowers look white?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the flowers?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3543, "imageId": "n497789", "question": "Is the vehicle behind donkeys?", "program": "BOX0=LOC(image=IMAGE,object='donkeys')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3544, "imageId": "n445353", "question": "Is the glass vase in the top part or in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass vase')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3545, "imageId": "n98544", "question": "Are there trash cans next to the toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trash cans')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3546, "imageId": "n290409", "question": "Which kind of vehicle is in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3547, "imageId": "n119944", "question": "Does the elephant appear to be walking?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nANSWER0=VQA(image=IMAGE,question='Does the elephant appear to be walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3548, "imageId": "n23762", "question": "What is in the vase?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in the vase?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3549, "imageId": "n214497", "question": "Is the light fixture below the high windows?", "program": "BOX0=LOC(image=IMAGE,object='high windows')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light fixture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3550, "imageId": "n69237", "question": "What kind of appliance is to the left of the draperies that look green?", "program": "BOX0=LOC(image=IMAGE,object='draperies')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of appliance is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3551, "imageId": "n69237", "question": "Which kind of appliance is to the left of the drapes?", "program": "BOX0=LOC(image=IMAGE,object='drapes')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is to the left of the drapes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3552, "imageId": "n280089", "question": "What is sitting in front of the wall the artwork is leaning against?", "program": "BOX0=LOC(image=IMAGE,object='artwork')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wall')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is sitting in front of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3553, "imageId": "n390187", "question": "What's the person riding?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3554, "imageId": "n390187", "question": "The person is riding what?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The person is riding what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3555, "imageId": "n501609", "question": "What are the items of furniture above the cabinets?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3556, "imageId": "n429961", "question": "Is the vehicle in the top or in the bottom of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3557, "imageId": "n501609", "question": "What is the shape of the cupboards above the cabinets?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cupboards')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the shape of the cupboards?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3558, "imageId": "n170941", "question": "What is the name of the food that has the same shape as the coffee mug?", "program": "BOX0=LOC(image=IMAGE,object='coffee mug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3559, "imageId": "n28996", "question": "Is the cheese that is to the right of the spoon small and round?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cheese')\nANSWER0=VQA(image=IMAGE0,question='Is the cheese small and round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3560, "imageId": "n390187", "question": "Is the person wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3561, "imageId": "n507959", "question": "Who is looking down?", "program": "BOX0=LOC(image=IMAGE,object='down')\nANSWER0=VQA(image=IMAGE,question='Who is looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3562, "imageId": "n557666", "question": "Are the jeans long and dark?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the jeans long?')\nANSWER1=VQA(image=IMAGE,question='Are the jeans dark?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3563, "imageId": "n501609", "question": "Are the cabinets below the cupboards that are shown in this image?", "program": "BOX0=LOC(image=IMAGE,object='cupboards')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabinets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3564, "imageId": "n192021", "question": "What is on the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3565, "imageId": "n196058", "question": "Which kind of animal is small?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3566, "imageId": "n296467", "question": "What kind of vegetable is to the left of the cookies?", "program": "BOX0=LOC(image=IMAGE,object='cookies')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetable')\nANSWER0=VQA(image=IMAGE0,question='What kind of vegetable is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3567, "imageId": "n196058", "question": "Does the zebra to the right of the other zebras look small and striped?", "program": "BOX0=LOC(image=IMAGE,object='zebras')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='zebra')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the zebra look small and striped?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3568, "imageId": "n469156", "question": "Which color does the glove the skateboarder is wearing have?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glove')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which color does the glove have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3569, "imageId": "n329479", "question": "Do the shoes have white color?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shoes?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3570, "imageId": "n470920", "question": "Are there men to the right of the woman that is wearing trousers?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trousers')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='man')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3571, "imageId": "n143935", "question": "Is the pasture open and grassy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the pasture open?')\nANSWER1=VQA(image=IMAGE,question='Is the pasture grassy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3572, "imageId": "n234722", "question": "What kind of food is on the pizza?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food is on the pizza?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3573, "imageId": "n143935", "question": "Is the pasture that is not closed green or brown?", "program": "BOX0=LOC(image=IMAGE,object='pasture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='closed pasture')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the closed pasture?')\nANSWER1=EVAL(expr=\"'green' if {ANSWER0} == 'green' else 'brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3574, "imageId": "n222915", "question": "Is the plate different in shape than the bowl?", "program": "ANSWER0=VQA(image=IMAGE,question='What shape is the plate?')\nANSWER1=VQA(image=IMAGE,question='What shape is the bowl?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3575, "imageId": "n278312", "question": "The microwave oven that is to the right of the refrigerator is of which shape?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='microwave oven')\nANSWER0=VQA(image=IMAGE0,question='The microwave oven is of which shape?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3576, "imageId": "n429883", "question": "What are the items of furniture to the right of the man that is wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='man wearing glasses')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3577, "imageId": "n470920", "question": "Who do you think wears glasses?", "program": "ANSWER0=VQA(image=IMAGE,question='Who wears glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3578, "imageId": "n209843", "question": "Are there any lamps above the white counter?", "program": "BOX0=LOC(image=IMAGE,object='white counter')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3579, "imageId": "n119944", "question": "Are there either plates or cans that are not round?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='can')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3580, "imageId": "n525029", "question": "Is the car the same color as the train?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='train')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the car?')\nANSWER1=VQA(image=IMAGE1,question='What color is the train?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3581, "imageId": "n119944", "question": "Does the tin can look round and orange?", "program": "BOX0=LOC(image=IMAGE,object='tin can')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the tin can?')\nANSWER1=VQA(image=IMAGE0,question='What color is the tin can?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3582, "imageId": "n66756", "question": "What's the batter holding onto?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the batter holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3583, "imageId": "n525029", "question": "Are both the window and the train the same color?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='train')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the window?')\nANSWER1=VQA(image=IMAGE1,question='What color is the train?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3584, "imageId": "n181355", "question": "What is the device that the man to the right of the pillow is holding?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the device that the man is holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3585, "imageId": "n181355", "question": "What is the man to the right of the pillow holding?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3586, "imageId": "n574498", "question": "Are there mirrors in the picture?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3587, "imageId": "n317189", "question": "Is the hat white and clean?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE,question='Is the hat clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3588, "imageId": "n14", "question": "What sign is metallic?", "program": "BOX0=LOC(image=IMAGE,object='metallic sign')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'metallic sign' if {ANSWER0} > 0 else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3589, "imageId": "n210269", "question": "Are there toilets near the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3590, "imageId": "n181355", "question": "Is the man to the right of the pillow holding the Wii remotes to the right of the pillow?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='Wii remotes')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3591, "imageId": "n546884", "question": "Does that basket look white and large?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the basket?')\nANSWER1=VQA(image=IMAGE0,question='How large is the basket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3592, "imageId": "n153293", "question": "Is the faucet on the right?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nANSWER0=EVAL(expr=\"'yes' if {BOX0}.x > IMAGE.width/2 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3593, "imageId": "n526228", "question": "What kind of furniture is to the left of the man that is wearing a shoe?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shoe')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of furniture is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3594, "imageId": "n546884", "question": "How big is the white basket?", "program": "BOX0=LOC(image=IMAGE,object='white basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the white basket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3595, "imageId": "n318684", "question": "Do you see fences in front of the bench that the man is sitting on?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='fences')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3596, "imageId": "n315859", "question": "Is the airplane small and wooden?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the airplane small?')\nANSWER1=VQA(image=IMAGE,question='Is the airplane wooden?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3597, "imageId": "n318684", "question": "What's the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3598, "imageId": "n318684", "question": "What is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3599, "imageId": "n513429", "question": "Is the bowl to the left of a keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3600, "imageId": "n187961", "question": "Are both the animals goats?", "program": "ANSWER0=VQA(image=IMAGE,question='Are both the animals goats?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3601, "imageId": "n314171", "question": "Is there any red table or bottle?", "program": "BOX0=LOC(image=IMAGE,object='table')\nBOX1=LOC(image=IMAGE,object='bottle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3602, "imageId": "n187961", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3603, "imageId": "n556604", "question": "Is the young man to the right or to the left of the device the woman is holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='man')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nANSWER0=LOC_LEFTOF(image=IMAGE2,box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3604, "imageId": "n556604", "question": "Are there both men and women in the scene?", "program": "BOX0=LOC(image=IMAGE,object='man')\nBOX1=LOC(image=IMAGE,object='woman')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3605, "imageId": "n160664", "question": "What is the animal that is hanging above the walkway that is presented in the picture?", "program": "BOX0=LOC(image=IMAGE,object='walkway')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3606, "imageId": "n157375", "question": "What place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3607, "imageId": "n160664", "question": "What animal is hanging above the brick walkway?", "program": "BOX0=LOC(image=IMAGE,object='brick walkway')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is hanging?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3608, "imageId": "n572716", "question": "What kind of aircraft is blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of aircraft is blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3609, "imageId": "n160664", "question": "What is the long animal in front of the forest hanging above?", "program": "BOX0=LOC(image=IMAGE,object='forest')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the long animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3610, "imageId": "n160664", "question": "What animal is looking down at the man that wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shirt')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nANSWER0=VQA(image=IMAGE1,question='What animal is looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3611, "imageId": "n68769", "question": "Are there any cups or wine glasses that are not tall?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nBOX1=LOC(image=IMAGE,object='wine glass')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3612, "imageId": "n59676", "question": "Are there small doors or windows?", "program": "BOX0=LOC(image=IMAGE,object='door')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3613, "imageId": "n400036", "question": "Is she kicking a frisbee?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='frisbee')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3614, "imageId": "n14", "question": "What is the cyclist riding?", "program": "BOX0=LOC(image=IMAGE,object='cyclist')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cyclist riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3615, "imageId": "n100991", "question": "Are there pizzas or knives that are thin?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nBOX1=LOC(image=IMAGE,object='knife')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3616, "imageId": "n207708", "question": "Does the door have the same color as the bookcase?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bookcase')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the door?')\nANSWER1=VQA(image=IMAGE1,question='What color is the bookcase?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3617, "imageId": "n210269", "question": "Does the black logo look straight?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the black logo look straight?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3618, "imageId": "n400036", "question": "What is she kicking?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is she kicking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3619, "imageId": "n400036", "question": "Who is kicking the soccer ball?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is kicking the soccer ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3620, "imageId": "n210269", "question": "Does the logo look white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the logo?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3621, "imageId": "n526228", "question": "Are there beds or paintings in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='painting')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3622, "imageId": "n264887", "question": "Do the monitor and the plant have the same color?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='plant')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the monitor?')\nANSWER1=VQA(image=IMAGE1,question='What color is the plant?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3623, "imageId": "n310828", "question": "Which side of the picture are the papers on?", "program": "BOX0=LOC(image=IMAGE,object='papers')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3624, "imageId": "n412144", "question": "What kind of clothing is long?", "program": "BOX0=LOC(image=IMAGE,object='long')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3625, "imageId": "n167552", "question": "Which side of the photo is the shelf on?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3626, "imageId": "n470131", "question": "What rests on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What rests on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3627, "imageId": "n470131", "question": "What rests on the yellow table?", "program": "BOX0=LOC(image=IMAGE,object='yellow table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What rests on the yellow table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3628, "imageId": "n181210", "question": "What is the name of the food that is light brown?", "program": "BOX0=LOC(image=IMAGE,object='light brown food')\nANSWER0=VQA(image=IMAGE,question='What is the name of the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3629, "imageId": "n52544", "question": "Are the glasses to the left of the man both black and small?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glasses')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color are the glasses?')\nANSWER3=VQA(image=IMAGE1,question='What size are the glasses?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'black' and {ANSWER3} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 3630, "imageId": "n470920", "question": "Is the woman to the right of the glasses covered by an umbrella?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='umbrella')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3631, "imageId": "n356822", "question": "On which side is the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3632, "imageId": "n313060", "question": "What is the coffee made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the coffee made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3633, "imageId": "n4777", "question": "Is the woman standing?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=POSE(image=IMAGE,box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'standing' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3634, "imageId": "n4777", "question": "Do you see a chair that is brown?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3635, "imageId": "n88933", "question": "What type of furniture is the happy girl sitting in, a sofa or a desk?", "program": "BOX0=LOC(image=IMAGE,object='happy girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is the girl sitting in?')\nANSWER1=EVAL(expr=\"'sofa' if {ANSWER0} == 'sofa' else 'desk'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3636, "imageId": "n413002", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3637, "imageId": "n279173", "question": "Is he on a snowboard?", "program": "BOX0=LOC(image=IMAGE,object='snowboard')\nBOX1=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3638, "imageId": "n257997", "question": "Is the man wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3639, "imageId": "n460556", "question": "On which side of the image is the bicycle?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3640, "imageId": "n470920", "question": "Is the woman to the right of the berries holding a baby?", "program": "BOX0=LOC(image=IMAGE,object='berries')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3641, "imageId": "n579256", "question": "Is that woman short or is she tall?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=VQA(image=IMAGE,question='Is the woman short or tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3642, "imageId": "n557666", "question": "Do the jeans look blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the jeans look blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3643, "imageId": "n216553", "question": "Is the ground smooth or rough?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the ground smooth or rough?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3644, "imageId": "n527290", "question": "What color is the striped shirt?", "program": "BOX0=LOC(image=IMAGE,object='striped shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the striped shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3645, "imageId": "n295771", "question": "What rests on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What rests on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3646, "imageId": "n527589", "question": "How are the pieces of furniture on top of the floor called?", "program": "ANSWER0=VQA(image=IMAGE,question='How are the pieces of furniture on top of the floor called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3647, "imageId": "n400036", "question": "Is the large building behind or in front of the trees next to the cars?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cars')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='large building')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'behind' if {ANSWER0} > 0 else 'in front'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3648, "imageId": "n400036", "question": "Is the tall building in front of the trees next to the cars?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cars')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='tall building')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3649, "imageId": "n460556", "question": "Do you see bicycles or scooters that are not gray?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nBOX1=LOC(image=IMAGE,object='scooter')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3650, "imageId": "n318370", "question": "What gender is the sitting person next to the bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What gender is the sitting person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3651, "imageId": "n449058", "question": "The truck to the right of the police officer is what color?", "program": "BOX0=LOC(image=IMAGE,object='police officer')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='truck')\nANSWER0=VQA(image=IMAGE0,question='What color is the truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3652, "imageId": "n496803", "question": "What's larger than the wristband?", "program": "ANSWER0=VQA(image=IMAGE,question='What\\'s larger than the wristband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3653, "imageId": "n460385", "question": "Who is wearing the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3654, "imageId": "n546616", "question": "What is the food on top of the cake that is to the left of the baby called?", "program": "BOX0=LOC(image=IMAGE,object='baby')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cake')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nANSWER0=VQA(image=IMAGE1,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3655, "imageId": "n530733", "question": "Where in this photograph is the trash can, on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='trash can')\nBOX1=LOC(image=IMAGE,object='LEFT')\nBOX2=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'left' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 3656, "imageId": "n499081", "question": "How hard are the towels that are not wet?", "program": "BOX0=LOC(image=IMAGE,object='towels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wet')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='towels',exclude=BOX1)\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='How hard are the towels?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3657, "imageId": "n250715", "question": "Does the logo have the same color as the telephone?", "program": "BOX0=LOC(image=IMAGE,object='telephone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='logo')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the telephone?')\nANSWER1=VQA(image=IMAGE1,question='What color is the logo?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3658, "imageId": "n499081", "question": "Are the towels wet and soft?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the towels wet?')\nANSWER1=VQA(image=IMAGE,question='Are the towels soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3659, "imageId": "n477702", "question": "Is the smiling man sitting on a bench?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3660, "imageId": "n499081", "question": "Are the towels that are not wet brown or white?", "program": "BOX0=LOC(image=IMAGE,object='towels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wet')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='brown')\nBOX3=LOC(image=IMAGE0,object='white')\nANSWER0=COUNT(box=BOX2)\nANSWER1=COUNT(box=BOX3)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3661, "imageId": "n71728", "question": "Is the bowl to the right of the bench square and smooth?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Is the bowl square and smooth?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 3662, "imageId": "n222915", "question": "Is the food next to the broccoli round and tan?", "program": "BOX0=LOC(image=IMAGE,object='broccoli')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the food?')\nANSWER3=VQA(image=IMAGE0,question='What shape is the food?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'tan' and {ANSWER3} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 3663, "imageId": "n25275", "question": "Who kicks the soccer ball?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who kicks the soccer ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3664, "imageId": "n25275", "question": "The boy to the left of the soccer ball is playing where?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boy')\nANSWER0=VQA(image=IMAGE0,question='Where is the boy playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3665, "imageId": "n262920", "question": "What is the man wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3666, "imageId": "n154160", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3667, "imageId": "n154160", "question": "What is the umpire doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the umpire doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3668, "imageId": "n115614", "question": "Which color is the car on the left of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nANSWER0=VQA(image=IMAGE0,question='Which color is the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3669, "imageId": "n130638", "question": "What place do you think was the image taken at, a beach or a field?", "program": "ANSWER0=VQA(image=IMAGE,question='What place do you think was the image taken at, a beach or a field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3670, "imageId": "n89148", "question": "How tall are the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nANSWER0=VQA(image=IMAGE,question='How tall are the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3671, "imageId": "n450919", "question": "What animal is in the mud?", "program": "BOX0=LOC(image=IMAGE,object='mud')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is in the mud?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3672, "imageId": "n450919", "question": "What animal is in the brown mud?", "program": "BOX0=LOC(image=IMAGE,object='brown mud')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is in the brown mud?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3673, "imageId": "n578564", "question": "Do you see rolling pins or microwaves in this scene?", "program": "BOX0=LOC(image=IMAGE,object='rolling pins')\nBOX1=LOC(image=IMAGE,object='microwaves')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3674, "imageId": "n450919", "question": "Is there an elephant in the mud?", "program": "BOX0=LOC(image=IMAGE,object='mud')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='elephant')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3675, "imageId": "n162148", "question": "Which ethnicity do you think the person the hair is on top of is?", "program": "ANSWER0=VQA(image=IMAGE,question='Which ethnicity do you think the person the hair is on top of is?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3676, "imageId": "n181210", "question": "On which side of the photo is the cup?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3677, "imageId": "n432591", "question": "Are there either red blankets or towels?", "program": "BOX0=LOC(image=IMAGE,object='blankets')\nBOX1=LOC(image=IMAGE,object='towels')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3678, "imageId": "n319845", "question": "How clean are the windows near the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='windows')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How clean are the windows?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3679, "imageId": "n355339", "question": "The table the people are sitting around is of what color?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3680, "imageId": "n16656", "question": "What animal is in front of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is in front of the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3681, "imageId": "n319845", "question": "What kind of furniture is the statue behind of?", "program": "BOX0=LOC(image=IMAGE,object='statue')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is behind the statue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3682, "imageId": "n431447", "question": "Is the man eating a donut?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man eating a donut?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3683, "imageId": "n249639", "question": "Is the material of the table the same as the trash can?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='trash can')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the trash can made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3684, "imageId": "n296467", "question": "What is the dip inside of?", "program": "BOX0=LOC(image=IMAGE,object='dip')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the dip inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3685, "imageId": "n233607", "question": "Is the computer on the left?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3686, "imageId": "n386688", "question": "Are there large houses or sailboats?", "program": "BOX0=LOC(image=IMAGE,object='large houses')\nBOX1=LOC(image=IMAGE,object='sailboats')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3687, "imageId": "n141939", "question": "Are there both candles and soaps in the picture?", "program": "BOX0=LOC(image=IMAGE,object='candles')\nBOX1=LOC(image=IMAGE,object='soaps')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3688, "imageId": "n89148", "question": "What is the toy that the small person is holding?", "program": "BOX0=LOC(image=IMAGE,object='small person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the toy that the small person is holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3689, "imageId": "n500209", "question": "Is the container made of glass sitting on top of the shelf that is in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='container')\nIMAGE2=CROP_ABOVE(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3690, "imageId": "n166008", "question": "Who is eating the sandwich?", "program": "BOX0=LOC(image=IMAGE,object='sandwich')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is eating the sandwich?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3691, "imageId": "n28792", "question": "Does the wet umbrella look brown or green?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the wet umbrella look?')\nANSWER1=EVAL(expr=\"'brown' if {ANSWER0} == 'brown' else 'green'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3692, "imageId": "n435808", "question": "What device is underneath the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is underneath the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3693, "imageId": "n473688", "question": "Is the sink mounted on the countertop?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='countertop')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3694, "imageId": "n317260", "question": "Who is standing on the sand?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing on the sand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3695, "imageId": "n317260", "question": "Is the person behind the home plate wearing a uniform?", "program": "BOX0=LOC(image=IMAGE,object='home plate')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3696, "imageId": "n83784", "question": "What is the piece of furniture that the black and white animal sits atop called?", "program": "BOX0=LOC(image=IMAGE,object='black and white animal')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3697, "imageId": "n88933", "question": "Who is eating the food?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is eating the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3698, "imageId": "n317260", "question": "The person in front of the umpire is standing where?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'in front' if {ANSWER0} > 0 else 'behind'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3699, "imageId": "n312206", "question": "Is this a chocolate ice cream?", "program": "ANSWER0=VQA(image=IMAGE,question='Is this a chocolate ice cream?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3700, "imageId": "n35676", "question": "Are there both dishwashers and ovens in the picture?", "program": "BOX0=LOC(image=IMAGE,object='dishwasher')\nBOX1=LOC(image=IMAGE,object='oven')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3701, "imageId": "n70461", "question": "Is there a yellow traffic light or fire hydrant?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nBOX1=LOC(image=IMAGE,object='fire hydrant')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3702, "imageId": "n274905", "question": "Is the tennis player holding the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='tennis player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3703, "imageId": "n25275", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3704, "imageId": "n344136", "question": "What kind of furniture is made of the same material as the window frame that looks white?", "program": "BOX0=LOC(image=IMAGE,object='window frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the window frame?')\nBOX1=LOC(image=IMAGE,object='furniture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='What kind of furniture is made of the same material as the window frame that looks white?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3705, "imageId": "n24526", "question": "What type of vehicle is she in front of, a bus or a car?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nBOX2=LOC(image=IMAGE0,object='car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'bus' if {ANSWER0} > 0 else 'car'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3706, "imageId": "n24526", "question": "What kind of vehicle is the woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is the woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3707, "imageId": "n195249", "question": "Is the person that is staring holding the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3708, "imageId": "n24526", "question": "What is the woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3709, "imageId": "n24526", "question": "This woman is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='This woman is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3710, "imageId": "n445353", "question": "Which side of the picture are the tall boxes on?", "program": "BOX0=LOC(image=IMAGE,object='tall boxes')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3711, "imageId": "n229548", "question": "Is the sun large and orange?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sun large?')\nANSWER1=VQA(image=IMAGE,question='What color is the sun?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3712, "imageId": "n141939", "question": "What do both the floor and the mirror have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the floor and the mirror have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3713, "imageId": "n200225", "question": "What color is the cooked cheese?", "program": "BOX0=LOC(image=IMAGE,object='cooked cheese')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cooked cheese?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3714, "imageId": "n229548", "question": "What is the color of the sun that is not small?", "program": "BOX0=LOC(image=IMAGE,object='sun')\nBOX1=LOC(image=IMAGE,object='small')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the sun?')\nANSWER1=VQA(image=IMAGE1,question='What is the color of the small object?')\nANSWER2=EVAL(expr=\"{ANSWER0} if {ANSWER1} != 'small' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3715, "imageId": "n501609", "question": "Is the oven to the left of the stove red and square?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='oven')\nANSWER0=VQA(image=IMAGE0,question='What color is the oven?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the oven?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3716, "imageId": "n233607", "question": "What does the person hold?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the person hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3717, "imageId": "n310828", "question": "On which side of the image is the empty box?", "program": "BOX0=LOC(image=IMAGE,object='empty box')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='empty box')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3718, "imageId": "n51002", "question": "Does the device in front of the computer monitor have white color?", "program": "BOX0=LOC(image=IMAGE,object='computer monitor')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the device?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3719, "imageId": "n263180", "question": "What is the vehicle that is to the left of the building that is made of brick called?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brick')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3720, "imageId": "n148872", "question": "Are there any girls to the right of the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3721, "imageId": "n279581", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3722, "imageId": "n279581", "question": "Who is wearing the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3723, "imageId": "n67005", "question": "What is the door made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the door made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3724, "imageId": "n532213", "question": "What sits next to the street that is made of asphalt?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='asphalt')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What sits next to the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3725, "imageId": "n355567", "question": "What is the color of the lady that is about to hit the tennis ball?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lady')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the lady?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3726, "imageId": "n49438", "question": "Is the boy to the right or to the left of the curtain?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3727, "imageId": "n49438", "question": "Are there any boys to the right of the tall dresser near the bed?", "program": "BOX0=LOC(image=IMAGE,object='tall dresser')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='boys')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3728, "imageId": "n279581", "question": "What is the batter holding?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the batter holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3729, "imageId": "n455563", "question": "Are there any chairs or mugs that are black?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='mug')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3730, "imageId": "n314171", "question": "What is common to the balloon and the bracelet?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the balloon and the bracelet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3731, "imageId": "n204894", "question": "Is the yellow crown in the bottom or in the top of the picture?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='yellow crown')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3732, "imageId": "n494918", "question": "Are the trees behind a frisbee?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3733, "imageId": "n315887", "question": "What kind of device is to the right of the speaker?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is to the right of the speaker?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3734, "imageId": "n574498", "question": "Do the shorts look black and checkered?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE,question='Are the shorts checkered?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3735, "imageId": "n480253", "question": "How is the vehicle to the left of the ambulance called?", "program": "BOX0=LOC(image=IMAGE,object='ambulance')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='How is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3736, "imageId": "n264887", "question": "Do you think the keyboard is white?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the keyboard?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3737, "imageId": "n263180", "question": "Which kind of vehicle is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='metal')\nANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is made of metal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3738, "imageId": "n263180", "question": "Which kind of vehicle is metallic?", "program": "BOX0=LOC(image=IMAGE,object='metallic')\nANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3739, "imageId": "n489190", "question": "What is the material of the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='What is the material of the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3740, "imageId": "n151768", "question": "What is the man that looks old holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3741, "imageId": "n151768", "question": "What is the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3742, "imageId": "n184551", "question": "What does the woman hold?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the woman hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3743, "imageId": "n151768", "question": "Does the old person to the left of the vegetable wear shorts?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetable')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='old person')\nANSWER0=VQA(image=IMAGE1,question='Does the old person wear shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3744, "imageId": "n184551", "question": "Is the bag that is to the right of the man blue and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the bag?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the bag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3745, "imageId": "n184551", "question": "Who holds the umbrella the man under of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nANSWER0=VQA(image=IMAGE0,question='Who holds the umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3746, "imageId": "n470131", "question": "Are there cookies that are not baked?", "program": "BOX0=LOC(image=IMAGE,object='cookies')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the cookies baked?')\nANSWER1=EVAL(expr=\"'yes' if 'not' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3747, "imageId": "n470131", "question": "What is in front of the orange thing that is on the wall?", "program": "BOX0=LOC(image=IMAGE,object='orange thing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wall')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the orange thing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3748, "imageId": "n51658", "question": "Is the wristband small?", "program": "BOX0=LOC(image=IMAGE,object='wristband')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the wristband small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3749, "imageId": "n470131", "question": "What is the food in front of the orange tape?", "program": "BOX0=LOC(image=IMAGE,object='orange tape')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3750, "imageId": "n470131", "question": "What's in front of the tape?", "program": "BOX0=LOC(image=IMAGE,object='tape')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the tape?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3751, "imageId": "n278312", "question": "Which kind of appliance is the tea kettle on?", "program": "BOX0=LOC(image=IMAGE,object='tea kettle')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is the tea kettle on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3752, "imageId": "n470131", "question": "The cookie is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='cookie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The cookie is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3753, "imageId": "n278312", "question": "What kind of cooking utensil is on the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of cooking utensil is on the stove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3754, "imageId": "n278312", "question": "What is the tea kettle on?", "program": "BOX0=LOC(image=IMAGE,object='tea kettle')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tea kettle on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3755, "imageId": "n46510", "question": "What is the sticker stuck on?", "program": "BOX0=LOC(image=IMAGE,object='sticker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sticker stuck on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3756, "imageId": "n256120", "question": "Does the black jacket look light and comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the black jacket look light and comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3757, "imageId": "n309148", "question": "What is the vehicle that is in front of the pedestrian called?", "program": "BOX0=LOC(image=IMAGE,object='pedestrian')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3758, "imageId": "n309148", "question": "What is in front of the person in the bottom part of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3759, "imageId": "n417401", "question": "Which color is the toilet seat that is not big?", "program": "BOX0=LOC(image=IMAGE,object='toilet seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not big')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which color is the toilet seat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3760, "imageId": "n14087", "question": "What kind of animal is white?", "program": "BOX0=LOC(image=IMAGE,object='white')\nANSWER0=VQA(image=IMAGE,question='What kind of animal is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3761, "imageId": "n19152", "question": "What is the vehicle that is sitting atop the stone road which is lying next to the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stone road')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3762, "imageId": "n319845", "question": "Is the vase blue and square?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the vase?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the vase?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3763, "imageId": "n534106", "question": "What is the woman doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the woman doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3764, "imageId": "n473688", "question": "Which side of the photo is the toilet on?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3765, "imageId": "n62458", "question": "Do the wall and the motorbike have the same color?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='motorbike')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the wall?')\nANSWER1=VQA(image=IMAGE1,question='What color is the motorbike?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3766, "imageId": "n403734", "question": "Is there a plate to the left of the napkin the purse is to the right of?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='purse')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='plate')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3767, "imageId": "n282436", "question": "What animal is calm?", "program": "ANSWER0=VQA(image=IMAGE,question='What animal is calm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3768, "imageId": "n437192", "question": "Does the bear that looks tan look large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the bear that looks tan look large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3769, "imageId": "n380113", "question": "Who is holding the soccer ball that looks red?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the soccer ball?')\nANSWER1=VQA(image=IMAGE0,question='What color is the soccer ball?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if '{ANSWER1}' == 'red' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3770, "imageId": "n200907", "question": "Is the car that is to the right of the other car metallic and white?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the car?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'metallic and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3771, "imageId": "n500308", "question": "Which kind of material is the table made of?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of material is the table made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3772, "imageId": "n302387", "question": "How large is the luggage?", "program": "BOX0=LOC(image=IMAGE,object='luggage')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3773, "imageId": "n37274", "question": "What kind of drink is to the left of the cup?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drink')\nANSWER0=VQA(image=IMAGE0,question='What kind of drink is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3774, "imageId": "n415215", "question": "What is the male person doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the male person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3775, "imageId": "n234722", "question": "Which kind of cooking utensil is below the pizza?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=VQA(image=IMAGE0,question='Which kind of cooking utensil is below the pizza?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3776, "imageId": "n153293", "question": "Is the closed toilet on the left?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='closed toilet')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3777, "imageId": "n199286", "question": "What is the size of the shorts made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='cloth')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shorts')\nANSWER0=VQA(image=IMAGE0,question='What is the size of the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3778, "imageId": "n315859", "question": "Is the propeller black and narrow?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the propeller?')\nANSWER1=VQA(image=IMAGE,question='Is the propeller narrow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3779, "imageId": "n118102", "question": "Does the cake which is to the right of the girl look brown and round?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cake')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the cake?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the cake?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3780, "imageId": "n314630", "question": "On which side of the image are the metal utensils?", "program": "BOX0=LOC(image=IMAGE,object='metal utensils')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3781, "imageId": "n518912", "question": "Are the curtains white and short?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the curtains?')\nANSWER1=VQA(image=IMAGE0,question='Are the curtains short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3782, "imageId": "n98544", "question": "How clean is the floor?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3783, "imageId": "n433692", "question": "What is this cat lying on?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cat lying on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3784, "imageId": "n433692", "question": "What is the animal that is lying on the mousepad called?", "program": "BOX0=LOC(image=IMAGE,object='mousepad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3785, "imageId": "n314630", "question": "Do the knives look black and metallic?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the knives?')\nANSWER1=VQA(image=IMAGE,question='What material are the knives made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3786, "imageId": "n379991", "question": "Does the table seem to be wooden?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the table seem to be wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3787, "imageId": "n315887", "question": "Does the telephone to the right of the mouse look black?", "program": "BOX0=LOC(image=IMAGE,object='mouse')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='telephone')\nANSWER0=VQA(image=IMAGE0,question='What color is the telephone?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3788, "imageId": "n262929", "question": "Is the bag small and dark?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the bag small?')\nANSWER1=VQA(image=IMAGE,question='Is the bag dark?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3789, "imageId": "n100991", "question": "Is the round plate on top of the square tray?", "program": "BOX0=LOC(image=IMAGE,object='square tray')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='round plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3790, "imageId": "n100991", "question": "What vegetables are in this image?", "program": "BOX0=LOC(image=IMAGE,object='vegetables')\nANSWER0=VQA(image=IMAGE,question='What vegetables are in this image?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3791, "imageId": "n100991", "question": "What vegetables are it?", "program": "ANSWER0=VQA(image=IMAGE,question='What vegetables are it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3792, "imageId": "n37274", "question": "What drink is to the left of the blender?", "program": "BOX0=LOC(image=IMAGE,object='blender')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drink')\nANSWER0=VQA(image=IMAGE0,question='What drink is to the left of the blender?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3793, "imageId": "n9181", "question": "Is the brown cowboy hat below the small sign?", "program": "BOX0=LOC(image=IMAGE,object='small sign')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown cowboy hat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3794, "imageId": "n100991", "question": "What is the food that is on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3795, "imageId": "n500308", "question": "Does that door look thin and wooden?", "program": "ANSWER0=VQA(image=IMAGE,question='Does that door look thin and wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3796, "imageId": "n398257", "question": "Does the keyboard look white and curved?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the keyboard look?')\nANSWER1=VQA(image=IMAGE,question='Does the keyboard look curved?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3797, "imageId": "n544255", "question": "Does the shirt look gold and long sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE,question='Are the sleeves of the shirt long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gold' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3798, "imageId": "n244826", "question": "What is the color of the field the soccer ball is on?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='field')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3799, "imageId": "n118102", "question": "What color are the candles?", "program": "BOX0=LOC(image=IMAGE,object='candles')\nANSWER0=VQA(image=IMAGE,question='What color are the candles?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3800, "imageId": "n65230", "question": "Is there a cat in the clean bathroom?", "program": "BOX0=LOC(image=IMAGE,object='clean bathroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3801, "imageId": "n437064", "question": "Is the red strawberry behind the whipped cream?", "program": "BOX0=LOC(image=IMAGE,object='whipped cream')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='red strawberry')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3802, "imageId": "n437064", "question": "What fruit is behind the whipped cream?", "program": "BOX0=LOC(image=IMAGE,object='whipped cream')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruit')\nANSWER0=VQA(image=IMAGE0,question='What fruit is behind the whipped cream?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3803, "imageId": "n92308", "question": "Is the bicycle to the left or to the right of the person that is wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='person wearing jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bicycle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3804, "imageId": "n560243", "question": "Does the racket look metallic and round?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the racket look metallic?')\nANSWER1=VQA(image=IMAGE,question='Does the racket look round?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3805, "imageId": "n83784", "question": "On which side of the photo is the small side table?", "program": "BOX0=LOC(image=IMAGE,object='small side table')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3806, "imageId": "n119886", "question": "What shape is the floor the sink is above?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3807, "imageId": "n486200", "question": "Does the new vehicle look metallic?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the new vehicle look metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3808, "imageId": "n560243", "question": "What material makes up the tennis racket to the right of the athlete?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material makes up the tennis racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3809, "imageId": "n264887", "question": "Is there a keyboard to the right of the computer mouse?", "program": "BOX0=LOC(image=IMAGE,object='computer mouse')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='keyboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3810, "imageId": "n146522", "question": "Are both the ball to the right of the other balls and the black helmet made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nBOX1=LOC(image=IMAGE,object='black helmet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the ball made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the black helmet made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' and {ANSWER1} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3811, "imageId": "n530733", "question": "Is that a mirror or a sofa?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nBOX1=LOC(image=IMAGE,object='sofa')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'mirror' if {ANSWER0} > 0 else 'sofa'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3812, "imageId": "n310828", "question": "Is that mousepad white?", "program": "BOX0=LOC(image=IMAGE,object='mousepad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the mousepad?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3813, "imageId": "n542609", "question": "Is the long train to the left of the people below the sign?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='train')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3814, "imageId": "n573460", "question": "Which color do you think the shorts are?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color do you think the shorts are?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3815, "imageId": "n181355", "question": "What color is this coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the coffee table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3816, "imageId": "n513100", "question": "Does the chair below the table look white?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3817, "imageId": "n298104", "question": "Is the sky cloudy and bright?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sky cloudy?')\nANSWER1=VQA(image=IMAGE,question='Is the sky bright?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3818, "imageId": "n544255", "question": "Is the man on a motorcycle?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorcycle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3819, "imageId": "n315859", "question": "What is the pier surrounded by?", "program": "BOX0=LOC(image=IMAGE,object='pier')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pier surrounded by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3820, "imageId": "n234683", "question": "Does the suit appear to be clean?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the suit appear to be clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3821, "imageId": "n233607", "question": "Which kind of furniture is not brown, the shelf or the table?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shelf?')\nANSWER1=VQA(image=IMAGE1,question='What color is the table?')\nANSWER2=EVAL(expr=\"'shelf' if {ANSWER0} != 'brown' else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3822, "imageId": "n544255", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3823, "imageId": "n195925", "question": "Is the water blue and still?", "program": "BOX0=LOC(image=IMAGE,object='water')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the water?')\nANSWER1=VQA(image=IMAGE0,question='Is the water still?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3824, "imageId": "n305495", "question": "Is there a open window or door?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3825, "imageId": "n305495", "question": "Does the window look open or closed?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the window look open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3826, "imageId": "n305495", "question": "Is the window behind a fan?", "program": "BOX0=LOC(image=IMAGE,object='fan')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3827, "imageId": "n184385", "question": "How big is the utensil to the right of the pot?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3828, "imageId": "n500209", "question": "Is the closed book in the top or in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='closed book')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3829, "imageId": "n125122", "question": "What is the name of the piece of furniture to the right of the phone that is on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='piece of furniture')\nANSWER0=VQA(image=IMAGE1,question='What is the name of the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3830, "imageId": "n536256", "question": "Is that lamp blue or white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the lamp?')\nANSWER1=EVAL(expr=\"'blue' if {ANSWER0} == 'blue' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3831, "imageId": "n195249", "question": "Is the tank top light blue or yellow?", "program": "BOX0=LOC(image=IMAGE,object='tank top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tank top?')\nANSWER1=EVAL(expr=\"'light blue' if {ANSWER0} == 'blue' else 'yellow'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3832, "imageId": "n271392", "question": "What vehicle is in front of the men?", "program": "BOX0=LOC(image=IMAGE,object='men')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is in front of the men?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3833, "imageId": "n125122", "question": "What kind of furniture is to the left of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is to the left of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3834, "imageId": "n238266", "question": "In which part of the picture is the silver knife, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='silver knife')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3835, "imageId": "n250821", "question": "Is there a cat in the scene that is healthy?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nANSWER0=VQA(image=IMAGE,question='Is the cat healthy?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'healthy' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3836, "imageId": "n346247", "question": "What's the school made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the school made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3837, "imageId": "n549922", "question": "Is the colorful toy both black and soft?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the colorful toy black?')\nANSWER1=VQA(image=IMAGE,question='Is the colorful toy soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3838, "imageId": "n202379", "question": "What is the color of the shirt the boy is wearing?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3839, "imageId": "n485969", "question": "Is the baseball mitt made of leather closed or open?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the baseball mitt made of leather?')\nANSWER1=VQA(image=IMAGE0,question='Is the baseball mitt closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3840, "imageId": "n77818", "question": "Are there any towels next to the cat that the book is to the right of?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='book')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='towels')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3841, "imageId": "n12404", "question": "Who is wearing a shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3842, "imageId": "n469156", "question": "Is the helmet that is to the left of the skateboard colorful and hard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='helmet')\nANSWER0=VQA(image=IMAGE0,question='What color is the helmet?')\nANSWER1=VQA(image=IMAGE0,question='Is the helmet hard?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'colorful' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3843, "imageId": "n344136", "question": "Are there any bookcases next to the window frame that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='window frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='bookcases')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3844, "imageId": "n350766", "question": "What is the color of the garbage bin?", "program": "BOX0=LOC(image=IMAGE,object='garbage bin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the garbage bin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3845, "imageId": "n331357", "question": "Are there any cows near the stones?", "program": "BOX0=LOC(image=IMAGE,object='stones')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3846, "imageId": "n111390", "question": "Does the brown window look wooden and large?", "program": "ANSWER0=VQA(image=IMAGE,question='What material does the brown window look like?')\nANSWER1=VQA(image=IMAGE,question='Does the brown window look large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3847, "imageId": "n119944", "question": "Does the green shirt look bright and short sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the green shirt look bright and short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3848, "imageId": "n279173", "question": "What color does the license plate have?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the license plate have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3849, "imageId": "n518912", "question": "Does the table look long and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the table look long and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3850, "imageId": "n501951", "question": "Is there a short table or lamp?", "program": "BOX0=LOC(image=IMAGE,object='short table')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3851, "imageId": "n382416", "question": "What kind of clothing is white?", "program": "BOX0=LOC(image=IMAGE,object='white clothing')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3852, "imageId": "n69237", "question": "Are there either red pillows or blankets?", "program": "BOX0=LOC(image=IMAGE,object='pillows')\nBOX1=LOC(image=IMAGE,object='blankets')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3853, "imageId": "n196058", "question": "Is the brush behind horses?", "program": "BOX0=LOC(image=IMAGE,object='horses')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brush')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3854, "imageId": "n4777", "question": "What device is black?", "program": "BOX0=LOC(image=IMAGE,object='black')\nANSWER0=VQA(image=IMAGE,question='What device is black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3855, "imageId": "n4777", "question": "Are there laptops or phones that are not black?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nBOX1=LOC(image=IMAGE,object='phone')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3856, "imageId": "n181210", "question": "Is the fork covered?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the fork covered?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3857, "imageId": "n514467", "question": "Is the coat long sleeved and black?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the coat long sleeved?')\nANSWER1=VQA(image=IMAGE,question='What color is the coat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3858, "imageId": "n382416", "question": "What type of clothing is white?", "program": "BOX0=LOC(image=IMAGE,object='white clothing')\nANSWER0=VQA(image=IMAGE,question='What type of clothing is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3859, "imageId": "n556604", "question": "How hard is the skate park the man is skating on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skate park')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How hard is the skate park?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3860, "imageId": "n181210", "question": "In which part of the photo is the fork, the top or the bottom?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3861, "imageId": "n54424", "question": "Does the Wii controller that looks oval have small size and white color?", "program": "BOX0=LOC(image=IMAGE,object='Wii controller')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the Wii controller?')\nANSWER1=VQA(image=IMAGE0,question='What size is the Wii controller?')\nANSWER2=VQA(image=IMAGE0,question='What color is the Wii controller?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'oval' and {ANSWER1} == 'small' and {ANSWER2} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 3862, "imageId": "n483840", "question": "On which side is the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3863, "imageId": "n499081", "question": "Does the rug look brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the rug look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3864, "imageId": "n289376", "question": "Do you see any street signs that are blue?", "program": "BOX0=LOC(image=IMAGE,object='street sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the street sign?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3865, "imageId": "n35676", "question": "How clean is the microwave?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the microwave?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3866, "imageId": "n356822", "question": "Is the jacket black and long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the jacket have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3867, "imageId": "n499081", "question": "Does the rug in front of the cabinet look soft and blue?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the rug?')\nANSWER3=VQA(image=IMAGE0,question='Does the rug look soft?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'blue' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 3868, "imageId": "n531731", "question": "Is the player on the right side?", "program": "BOX0=LOC(image=IMAGE,object='player')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3869, "imageId": "n210269", "question": "Do all the animals have the same type?", "program": "BOX0=LOC(image=IMAGE,object='animal')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 1 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3870, "imageId": "n68769", "question": "Is the curtain to the right or to the left of the woman that is below the ceiling?", "program": "BOX0=LOC(image=IMAGE,object='ceiling')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='curtain')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3871, "imageId": "n16936", "question": "Do you see either any snowboarders or skateboarders that are jumping?", "program": "BOX0=LOC(image=IMAGE,object='snowboarder')\nBOX1=LOC(image=IMAGE,object='skateboarder')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3872, "imageId": "n16936", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3873, "imageId": "n579256", "question": "Do the jeans look skinny and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the jeans look skinny?')\nANSWER1=VQA(image=IMAGE,question='Do the jeans look blue?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3874, "imageId": "n335542", "question": "Is the grass green?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the grass?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3875, "imageId": "n259002", "question": "How clean is the small vehicle?", "program": "BOX0=LOC(image=IMAGE,object='small vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the small vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3876, "imageId": "n429961", "question": "What is the shape of the vegetable near the cabbage?", "program": "BOX0=LOC(image=IMAGE,object='cabbage')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetable')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the shape of the vegetable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3877, "imageId": "n507959", "question": "Are there umbrellas to the left of the person that is to the left of the palm?", "program": "BOX0=LOC(image=IMAGE,object='palm')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='umbrellas')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3878, "imageId": "n296467", "question": "Are there any knives to the right of the vegetables near the rice?", "program": "BOX0=LOC(image=IMAGE,object='rice')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetables')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='knives')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3879, "imageId": "n6908", "question": "What's the glass made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the glass made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3880, "imageId": "n551964", "question": "Which side of the image is the blond woman on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blond woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3881, "imageId": "n507959", "question": "Is the umbrella to the left of the palm tree closed or open?", "program": "BOX0=LOC(image=IMAGE,object='palm tree')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the umbrella closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3882, "imageId": "n6908", "question": "Is the glass both large and clear?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the glass large?')\nANSWER1=VQA(image=IMAGE,question='Is the glass clear?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3883, "imageId": "n35676", "question": "Are the cabinets to the right of the drawers open and wooden?", "program": "BOX0=LOC(image=IMAGE,object='drawers')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabinets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What material are the cabinets made of?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 3884, "imageId": "n525901", "question": "Is the shelf to the right or to the left of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3885, "imageId": "n211324", "question": "What type of place is pictured?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of place is pictured?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3886, "imageId": "n54424", "question": "What kind of furniture is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown furniture')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3887, "imageId": "n390187", "question": "Does the mirror to the left of the person look brown and small?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=VQA(image=IMAGE0,question='What color is the mirror?')\nANSWER1=VQA(image=IMAGE0,question='How big is the mirror?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3888, "imageId": "n54424", "question": "Which kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3889, "imageId": "n16656", "question": "What animal is staring?", "program": "BOX0=LOC(image=IMAGE,object='staring')\nANSWER0=VQA(image=IMAGE,question='What animal is staring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3890, "imageId": "n222915", "question": "What vegetable is the fork sitting under?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetable')\nANSWER0=VQA(image=IMAGE0,question='What vegetable is the fork sitting under?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3891, "imageId": "n172618", "question": "Is the grass below the kite dry and brown?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the grass?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'dry and brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3892, "imageId": "n403734", "question": "What do the umbrella and the ipod have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the umbrella and the ipod have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3893, "imageId": "n494918", "question": "Do the shorts made out of cotton look orange and long?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material are the shorts made of?')\nANSWER1=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER2=VQA(image=IMAGE0,question='Are the shorts long?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'cotton' and {ANSWER1} == 'orange' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 3894, "imageId": "n68769", "question": "Is there either a rectangular plate or table in the picture?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3895, "imageId": "n355339", "question": "Who is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3896, "imageId": "n272098", "question": "Is the box different in color than the hat?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hat')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the box?')\nANSWER1=VQA(image=IMAGE1,question='What color is the hat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3897, "imageId": "n429961", "question": "What kind of vegetable isn't round?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vegetable isn't round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3898, "imageId": "n62458", "question": "Are there motorcycles on the square stone?", "program": "BOX0=LOC(image=IMAGE,object='square stone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorcycles')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3899, "imageId": "n62458", "question": "What's the motorcycle on?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surface')\nANSWER0=VQA(image=IMAGE0,question='What is the motorcycle on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3900, "imageId": "n62458", "question": "What is on the stone?", "program": "BOX0=LOC(image=IMAGE,object='stone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the stone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3901, "imageId": "n260521", "question": "What color is the coat?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the coat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3902, "imageId": "n413761", "question": "What is in front of the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3903, "imageId": "n429961", "question": "What kind of vegetable is round?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vegetable is round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3904, "imageId": "n413761", "question": "What is the hill in front of?", "program": "BOX0=LOC(image=IMAGE,object='hill')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the hill in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3905, "imageId": "n299528", "question": "Does the sign made of metal look high?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the sign made of metal look high?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3906, "imageId": "n551964", "question": "What is the color of the fence made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3907, "imageId": "n573460", "question": "Who is looking up?", "program": "BOX0=LOC(image=IMAGE,object='up')\nANSWER0=VQA(image=IMAGE,question='Who is looking up?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3908, "imageId": "n573460", "question": "What is the umpire doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the umpire doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3909, "imageId": "n275148", "question": "What is in front of the speaker on the right side?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='front')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the speaker?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3910, "imageId": "n551964", "question": "Do you see fences in this photo that are not brown?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the fence?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3911, "imageId": "n573460", "question": "What is the umpire to the left of the player doing, looking up or waiting?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umpire')\nANSWER0=VQA(image=IMAGE0,question='What is the umpire doing?')\nANSWER1=EVAL(expr=\"'looking up' if {ANSWER0} == 'looking up' else 'waiting'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3912, "imageId": "n88366", "question": "Who is wearing trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3913, "imageId": "n88366", "question": "Who is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3914, "imageId": "n314630", "question": "Which kind of appliance is metallic?", "program": "BOX0=LOC(image=IMAGE,object='metallic')\nANSWER0=VQA(image=IMAGE,question='Which kind of appliance is metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3915, "imageId": "n314630", "question": "Which kind of appliance is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is made of metal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3916, "imageId": "n88366", "question": "Is the person that is skiing wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='person skiing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3917, "imageId": "n88366", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3918, "imageId": "n314630", "question": "What appliance is silver?", "program": "BOX0=LOC(image=IMAGE,object='silver')\nANSWER0=VQA(image=IMAGE,question='What appliance is silver?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3919, "imageId": "n413319", "question": "Is the player wearing a jersey?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the player wearing a jersey?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3920, "imageId": "n413319", "question": "Is the male player swinging a tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='male player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3921, "imageId": "n98540", "question": "What does the man hold?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the man hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3922, "imageId": "n233607", "question": "Is there a door or a window that is not made of glass?", "program": "BOX0=LOC(image=IMAGE,object='door')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3923, "imageId": "n126891", "question": "Who is in front of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3924, "imageId": "n146555", "question": "Is the cow small and still?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the cow small?')\nANSWER1=VQA(image=IMAGE,question='Is the cow still?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3925, "imageId": "n141939", "question": "Is the bath towel near the toilet white and short?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bath towel')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the bath towel?')\nANSWER1=VQA(image=IMAGE1,question='What is the length of the bath towel?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3926, "imageId": "n126891", "question": "Who is in front of the old person?", "program": "BOX0=LOC(image=IMAGE,object='old person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the old person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3927, "imageId": "n527290", "question": "On which side of the picture is the happy woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3928, "imageId": "n257997", "question": "Does the shirt have a different color than the hat?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hat')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the hat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3929, "imageId": "n150962", "question": "What's in front of the door?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the door?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3930, "imageId": "n150962", "question": "What is in front of the closed door?", "program": "BOX0=LOC(image=IMAGE,object='closed door')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the closed door?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3931, "imageId": "n311910", "question": "What sign is on top of the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What sign is on top of the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3932, "imageId": "n222915", "question": "What is the fork sitting under?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fork sitting under?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3933, "imageId": "n311910", "question": "What sign is on top of the side walk?", "program": "BOX0=LOC(image=IMAGE,object='side walk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What sign is on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3934, "imageId": "n97485", "question": "Do you see either any cans or mats there?", "program": "BOX0=LOC(image=IMAGE,object='cans')\nBOX1=LOC(image=IMAGE,object='mats')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3935, "imageId": "n520071", "question": "What is the animal to the left of the books near the water bottle?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='water bottle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nANSWER0=VQA(image=IMAGE1,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3936, "imageId": "n258500", "question": "Who rides on the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who rides on the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3937, "imageId": "n541482", "question": "What color is the scarf?", "program": "BOX0=LOC(image=IMAGE,object='scarf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the scarf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3938, "imageId": "n258500", "question": "Who rides on a skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who rides on a skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3939, "imageId": "n566028", "question": "What is the height of the person that is standing by the other person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the height of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3940, "imageId": "n204894", "question": "What is the chair made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the chair made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3941, "imageId": "n204894", "question": "What type of material is the chair near the toy made of?", "program": "BOX0=LOC(image=IMAGE,object='toy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of material is the chair made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3942, "imageId": "n66756", "question": "On which side of the image is the umpire?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3943, "imageId": "n532191", "question": "What is the charger plugged into?", "program": "BOX0=LOC(image=IMAGE,object='charger')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the charger plugged into?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3944, "imageId": "n363445", "question": "What are the vegetables above the dessert on the right of the photo?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vegetables')\nANSWER0=VQA(image=IMAGE1,question='What are the vegetables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3945, "imageId": "n532191", "question": "Which kind of device is plugged into the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is plugged into the laptop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3946, "imageId": "n451187", "question": "What is the color of the jacket that is not short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short sleeved')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='jacket')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the jacket?')\nANSWER1=VQA(image=IMAGE2,question='What is the color of the jacket?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if {ANSWER0} != 'short sleeved' else '{ANSWER1}'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3947, "imageId": "n532191", "question": "What's plugged into the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is plugged into the laptop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3948, "imageId": "n324908", "question": "What animal is the horse walking by?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is the horse walking by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3949, "imageId": "n382416", "question": "What is the bag to the left of the person next to the suitcase?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='suitcase')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='bag')\nANSWER0=VQA(image=IMAGE1,question='What is the bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3950, "imageId": "n434283", "question": "Is the old vehicle in front of the building small or large?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='old vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} > 0 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3951, "imageId": "n382416", "question": "Is there any purse to the left of the woman the suitcase is to the right of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='suitcase')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='purse')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3952, "imageId": "n243701", "question": "Which color does the shirt that is not short sleeved have?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short sleeved')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='shirt',exclude=BOX1)\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='Which color does the shirt have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3953, "imageId": "n170941", "question": "How is the food that is brown called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the food that is brown called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3954, "imageId": "n513429", "question": "Are there screens to the right of the monitor that is not off?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='screen')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3955, "imageId": "n170941", "question": "What food is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown food')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3956, "imageId": "n124651", "question": "Is the traffic sign running?", "program": "BOX0=LOC(image=IMAGE,object='traffic sign')\nANSWER0=VQA(image=IMAGE,question='Is the traffic sign running?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3957, "imageId": "n51002", "question": "What is in front of the computer monitor?", "program": "BOX0=LOC(image=IMAGE,object='computer monitor')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the computer monitor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3958, "imageId": "n170941", "question": "Which kind of food is round?", "program": "BOX0=LOC(image=IMAGE,object='food')\nANSWER0=VQA(image=IMAGE,question='Which kind of food is round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3959, "imageId": "n243701", "question": "Does the shirt look long sleeved or sleeveless?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look long sleeved or sleeveless?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3960, "imageId": "n334278", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3961, "imageId": "n334278", "question": "Who is watching the pitcher?", "program": "BOX0=LOC(image=IMAGE,object='pitcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the pitcher?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3962, "imageId": "n69237", "question": "What color do you think are the drapes that are hang from the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the drapes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3963, "imageId": "n534106", "question": "Which kind of clothing is white?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of clothing is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3964, "imageId": "n507959", "question": "What is the bag that is not large hanging from?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bag hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3965, "imageId": "n65866", "question": "What is the item of furniture on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3966, "imageId": "n352479", "question": "What clothing items are beige?", "program": "BOX0=LOC(image=IMAGE,object='beige clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3967, "imageId": "n538684", "question": "Who is staring?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is staring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3968, "imageId": "n538684", "question": "What's the umpire doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the umpire doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3969, "imageId": "n434283", "question": "Is the dirty trash below a tie?", "program": "BOX0=LOC(image=IMAGE,object='tie')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dirty trash')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3970, "imageId": "n141939", "question": "How big is the clean shower near the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clean shower')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the clean shower?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3971, "imageId": "n573460", "question": "Who is the shirt worn on?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the shirt worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3972, "imageId": "n471866", "question": "Is there a motorcycle to the left of the policeman on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='policeman')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='motorcycle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3973, "imageId": "n293477", "question": "What is the food that is the same color as the hair clip that is lying on top of the bed called?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hair clip')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the hair clip?')\nBOX2=LOC(image=IMAGE0,object='food')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER1=VQA(image=IMAGE2,question='What is the food called?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3974, "imageId": "n293477", "question": "Does the bed have the same color as the book?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='book')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bed?')\nANSWER1=VQA(image=IMAGE1,question='What color is the book?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3975, "imageId": "n28996", "question": "Is the dessert to the left of the candy sitting inside the container that is not small?", "program": "BOX0=LOC(image=IMAGE,object='candy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='container',size='not small')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3976, "imageId": "n200225", "question": "What sits atop the pizza box?", "program": "BOX0=LOC(image=IMAGE,object='pizza box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What sits atop the pizza box?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3977, "imageId": "n520071", "question": "Does the bookcase near the lamp look tall and empty?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bookcase')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the bookcase look tall and empty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3978, "imageId": "n92308", "question": "Is the sky cloudy and huge?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sky cloudy?')\nANSWER1=VQA(image=IMAGE,question='Is the sky huge?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3979, "imageId": "n6908", "question": "Which kind of furniture is stuffed?", "program": "BOX0=LOC(image=IMAGE,object='stuffed')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is stuffed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3980, "imageId": "n6908", "question": "What is the name of the comfortable item of furniture?", "program": "BOX0=LOC(image=IMAGE,object='comfortable item of furniture')\nANSWER0=VQA(image=IMAGE,question='What is the name of the comfortable item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3981, "imageId": "n88366", "question": "Are there any soap dishes or dish drainers?", "program": "BOX0=LOC(image=IMAGE,object='soap dish')\nBOX1=LOC(image=IMAGE,object='dish drainer')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3982, "imageId": "n429961", "question": "What vegetable is on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What vegetable is on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3983, "imageId": "n513429", "question": "What kind of furniture is smooth?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is smooth?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3984, "imageId": "n520071", "question": "What is the color of the device near the lamps?", "program": "BOX0=LOC(image=IMAGE,object='lamps')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3985, "imageId": "n501951", "question": "Is there a bench near the tool?", "program": "BOX0=LOC(image=IMAGE,object='tool')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3986, "imageId": "n380113", "question": "What is the color of the field?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the color of the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3987, "imageId": "n173807", "question": "How big are the heavy wheels?", "program": "BOX0=LOC(image=IMAGE,object='heavy wheels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big are the heavy wheels?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3988, "imageId": "n83784", "question": "What is located on top of the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3989, "imageId": "n278453", "question": "Does the sandwich on the plate look rotten?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the sandwich on the plate look rotten?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3990, "imageId": "n281241", "question": "Does this man look young and Asian?", "program": "ANSWER0=VQA(image=IMAGE,question='Does this man look young?')\nANSWER1=VQA(image=IMAGE,question='Does this man look Asian?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3991, "imageId": "n324908", "question": "Does the long tail look bushy and black?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the long tail look bushy and black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3992, "imageId": "n207893", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3993, "imageId": "n28996", "question": "Is there a plate or a pizza in the picture?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='pizza')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3994, "imageId": "n126891", "question": "Is the folding chair to the right of the boy white or red?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='folding chair')\nANSWER0=VQA(image=IMAGE0,question='What color is the folding chair?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'red'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3995, "imageId": "n315887", "question": "What is in front of the computer that looks tall?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tall')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the computer?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 3996, "imageId": "n500308", "question": "Is the window the same material as the freezer?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='freezer')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the window made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the freezer made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 3997, "imageId": "n278312", "question": "Does the tea kettle look rounded and white?", "program": "ANSWER0=VQA(image=IMAGE,question='What does the tea kettle look like?')\nANSWER1=EVAL(expr=\"'yes' if 'rounded' in {ANSWER0} and 'white' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 3998, "imageId": "n507959", "question": "Is the table to the left of the guitar black and covered?", "program": "BOX0=LOC(image=IMAGE,object='guitar')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the table?')\nANSWER3=VQA(image=IMAGE0,question='Is the table covered?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'black' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 3999, "imageId": "n367944", "question": "What kind of furniture is square?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is square?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4000, "imageId": "n271392", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4001, "imageId": "n507959", "question": "Are there clocks in the picture?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4002, "imageId": "n49438", "question": "Is the dresser on the right side or on the left?", "program": "BOX0=LOC(image=IMAGE,object='dresser')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4003, "imageId": "n200692", "question": "Which kind of food is not round?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is not round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4004, "imageId": "n39114", "question": "Who is standing on the mound that is not clean?", "program": "BOX0=LOC(image=IMAGE,object='mound')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not clean')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is standing on the mound?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4005, "imageId": "n59147", "question": "Is there an ottoman or a bed in the image?", "program": "BOX0=LOC(image=IMAGE,object='ottoman')\nBOX1=LOC(image=IMAGE,object='bed')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4006, "imageId": "n195249", "question": "Does the wrist band that is not Adidas appear to be blue or black?", "program": "BOX0=LOC(image=IMAGE,object='Adidas wrist band')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='wrist band')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the Adidas wrist band?')\nANSWER1=VQA(image=IMAGE1,question='What color is the wrist band?')\nANSWER2=EVAL(expr=\"'blue' if {ANSWER1} == 'blue' and {ANSWER0} != 'blue' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4007, "imageId": "n126087", "question": "What place is this image in?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is this image in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4008, "imageId": "n126087", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4009, "imageId": "n126087", "question": "Are both the courtyard and the wristband the same color?", "program": "BOX0=LOC(image=IMAGE,object='courtyard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='wristband')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the courtyard?')\nANSWER1=VQA(image=IMAGE1,question='What color is the wristband?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4010, "imageId": "n271392", "question": "What do the sign post and the street have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the sign post and the street have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4011, "imageId": "n119944", "question": "What animal is staring?", "program": "BOX0=LOC(image=IMAGE,object='staring')\nANSWER0=VQA(image=IMAGE,question='What animal is staring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4012, "imageId": "n28572", "question": "Is the saucer large and white?", "program": "BOX0=LOC(image=IMAGE,object='saucer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the size of the saucer?')\nANSWER1=VQA(image=IMAGE0,question='What color is the saucer?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4013, "imageId": "n259949", "question": "Which color is the parking lot?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the parking lot?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4014, "imageId": "n14", "question": "Who is the building in front of?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the building in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4015, "imageId": "n579928", "question": "What animal is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What animal is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4016, "imageId": "n162108", "question": "What is that mat in front of?", "program": "BOX0=LOC(image=IMAGE,object='mat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the mat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4017, "imageId": "n100991", "question": "What is common to the egg and the plate?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the egg and the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4018, "imageId": "n199286", "question": "What animal is standing on the green grass?", "program": "BOX0=LOC(image=IMAGE,object='green grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is standing on the green grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4019, "imageId": "n100991", "question": "What type of food has the same shape as the plate that is on top of the tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of food has the same shape as the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4020, "imageId": "n222915", "question": "Is the bowl on the left part or on the right?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4021, "imageId": "n488874", "question": "What are the sparse trees growing on?", "program": "BOX0=LOC(image=IMAGE,object='sparse trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the sparse trees growing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4022, "imageId": "n536256", "question": "Is the TV stand on the right?", "program": "BOX0=LOC(image=IMAGE,object='TV stand')\nANSWER0=EVAL(expr=\"'yes' if {BOX0} == 'RIGHT' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4023, "imageId": "n206358", "question": "What's located on top of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4024, "imageId": "n166008", "question": "Do the customers appear to be waiting?", "program": "BOX0=LOC(image=IMAGE,object='customers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do the customers appear to be waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4025, "imageId": "n166008", "question": "Who is waiting?", "program": "BOX0=LOC(image=IMAGE,object='waiting')\nANSWER0=VQA(image=IMAGE,question='Who is waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4026, "imageId": "n166008", "question": "Is there any beer in this photo?", "program": "BOX0=LOC(image=IMAGE,object='beer')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4027, "imageId": "n97485", "question": "Which kind of furniture isn't small?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is small?')\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} == 'table' else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4028, "imageId": "n317189", "question": "Are the shoes large and white?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shoes?')\nANSWER1=VQA(image=IMAGE0,question='How large are the shoes?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'large' and {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4029, "imageId": "n208302", "question": "How large is the tall apartment building?", "program": "BOX0=LOC(image=IMAGE,object='apartment building')\nANSWER0=VQA(image=IMAGE,question='How large is the apartment building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4030, "imageId": "n393305", "question": "Which kind of sign is behind the girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=VQA(image=IMAGE0,question='Which kind of sign is behind the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4031, "imageId": "n545516", "question": "Does the device below the airplane have black color?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the device?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4032, "imageId": "n209843", "question": "What is the shape of the counter the bottles are on?", "program": "BOX0=LOC(image=IMAGE,object='bottles')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='counter')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the shape of the counter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4033, "imageId": "n249903", "question": "What is the length of the poster?", "program": "BOX0=LOC(image=IMAGE,object='poster')\nANSWER0=VQA(image=IMAGE,question='What is the length of the poster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4034, "imageId": "n524855", "question": "Do the mountains that are not short look grassy or rocky?", "program": "BOX0=LOC(image=IMAGE,object='mountains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='grassy')\nBOX3=LOC(image=IMAGE1,object='rocky')\nANSWER0=COUNT(box=BOX2)\nANSWER1=COUNT(box=BOX3)\nANSWER2=EVAL(expr=\"'grassy' if {ANSWER0} > {ANSWER1} else 'rocky'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4035, "imageId": "n572716", "question": "How do the green trees look, dense or sparse?", "program": "ANSWER0=VQA(image=IMAGE,question='How do the green trees look, dense or sparse?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4036, "imageId": "n398257", "question": "The plant is in what?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nANSWER0=VQA(image=IMAGE,question='The plant is in what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4037, "imageId": "n565418", "question": "Are there any buses or trucks in the image?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nBOX1=LOC(image=IMAGE,object='truck')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4038, "imageId": "n565418", "question": "Does the tire look round and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the tire look round and large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4039, "imageId": "n507959", "question": "Does the palm tree to the left of the flag look blue?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='palm tree')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the palm tree?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4040, "imageId": "n398257", "question": "What's the plant in?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nANSWER0=VQA(image=IMAGE,question='What is the plant in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4041, "imageId": "n282607", "question": "What color is the floor that looks smooth?", "program": "BOX0=LOC(image=IMAGE,object='smooth floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4042, "imageId": "n513429", "question": "Does the bowl that is not small look square and clear?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the bowl?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the bowl?')\nANSWER2=VQA(image=IMAGE0,question='What color is the bowl?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} != 'small' and {ANSWER1} == 'square' and {ANSWER2} == 'clear' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 4043, "imageId": "n433692", "question": "Is the mouse on top of a desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mouse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4044, "imageId": "n556604", "question": "Does the man that is to the right of the camera appear to be young and Asian?", "program": "BOX0=LOC(image=IMAGE,object='camera')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='Does the man appear to be young?')\nANSWER1=VQA(image=IMAGE0,question='Does the man appear to be Asian?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4045, "imageId": "n98544", "question": "Which color is the toilet paper on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet paper')\nANSWER0=VQA(image=IMAGE0,question='Which color is the toilet paper?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4046, "imageId": "n344136", "question": "What item of furniture is not comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='What item of furniture is not comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4047, "imageId": "n344136", "question": "Is this a couch or a table?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'couch' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4048, "imageId": "n59676", "question": "What rests on the cooking utensil the plate beside of?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=VQA(image=IMAGE0,question='What rests on the cooking utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4049, "imageId": "n59676", "question": "What rests on the pan?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What rests on the pan?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4050, "imageId": "n59676", "question": "What is the name of the cooking utensil that rests on the pan that the plate beside of?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='cooking utensil')\nANSWER0=VQA(image=IMAGE1,question='What is the name of the cooking utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4051, "imageId": "n302358", "question": "Is there any small scooter or motorcycle in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='scooter')\nBOX1=LOC(image=IMAGE,object='motorcycle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4052, "imageId": "n160664", "question": "Is the long fence metallic or wooden?", "program": "BOX0=LOC(image=IMAGE,object='long fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the fence made of?')\nANSWER1=EVAL(expr=\"'metallic' if {ANSWER0} == 'metal' else 'wooden'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4053, "imageId": "n223750", "question": "How long is the skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4054, "imageId": "n314630", "question": "Is the house made of the same material as the toaster?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='toaster')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the house made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the toaster made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4055, "imageId": "n68769", "question": "Are there any wine glasses next to the plate in the bottom of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='wine glass')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4056, "imageId": "n314630", "question": "What is common to the electric outlet and the switch?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the electric outlet and the switch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4057, "imageId": "n151768", "question": "What tone does the skirt have?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What tone does the skirt have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4058, "imageId": "n347706", "question": "Does the wide street look open?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the wide street look open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4059, "imageId": "n329479", "question": "What is he jumping off of?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is he jumping off of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4060, "imageId": "n151768", "question": "Does the vegetable that is not rotten have round shape?", "program": "BOX0=LOC(image=IMAGE,object='rotten vegetable')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='vegetable')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What shape is the vegetable?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4061, "imageId": "n526228", "question": "What is the couch in front of?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the couch in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4062, "imageId": "n347706", "question": "Does the wide street look clean and open?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the wide street look clean and open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4063, "imageId": "n318370", "question": "What makes up the drink to the left of the bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What makes up the drink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4064, "imageId": "n318370", "question": "What is the drink made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the drink made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4065, "imageId": "n412144", "question": "What is the gender of the person that is holding the video camera?", "program": "BOX0=LOC(image=IMAGE,object='video camera')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the gender of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4066, "imageId": "n573460", "question": "What are this items of furniture called?", "program": "ANSWER0=VQA(image=IMAGE,question='What are these items of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4067, "imageId": "n573460", "question": "Which kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4068, "imageId": "n412144", "question": "Are there people to the right of the skateboarder that is on the right?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4069, "imageId": "n412144", "question": "The person that holds the video camera is which ethnicity?", "program": "BOX0=LOC(image=IMAGE,object='video camera')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The person that holds the video camera is which ethnicity?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4070, "imageId": "n167552", "question": "Do the tree and the ornament have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='ornament')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the tree?')\nANSWER1=VQA(image=IMAGE1,question='What color is the ornament?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4071, "imageId": "n573460", "question": "The shirt is worn on who?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The shirt is worn on who?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4072, "imageId": "n437064", "question": "Is this fork on top of a napkin?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fork')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4073, "imageId": "n167552", "question": "Do the dog and the rug have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='rug')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the dog?')\nANSWER1=VQA(image=IMAGE1,question='What color is the rug?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4074, "imageId": "n470920", "question": "Is the jacket blue?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4075, "imageId": "n262929", "question": "How big is the hat above the tie?", "program": "BOX0=LOC(image=IMAGE,object='tie')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4076, "imageId": "n313060", "question": "What is the color of the drink in the middle?", "program": "BOX0=LOC(image=IMAGE,object='middle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the drink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4077, "imageId": "n181355", "question": "Is this a couch or a bookcase?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nBOX1=LOC(image=IMAGE,object='bookcase')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'couch' if {ANSWER0} > 0 else 'bookcase'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4078, "imageId": "n356822", "question": "What kind of clothing is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4079, "imageId": "n313060", "question": "Is there any black coffee or tea?", "program": "BOX0=LOC(image=IMAGE,object='coffee')\nBOX1=LOC(image=IMAGE,object='tea')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4080, "imageId": "n356822", "question": "What type of clothing is brown, the sweater or the baseball mitt?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='baseball mitt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the sweater?')\nANSWER1=VQA(image=IMAGE1,question='What color is the baseball mitt?')\nANSWER2=EVAL(expr=\"'sweater' if {ANSWER0} == 'brown' else 'baseball mitt'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4081, "imageId": "n356822", "question": "What kind of clothing is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown clothing')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4082, "imageId": "n356822", "question": "Which kind of clothing is made of leather?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is made of leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4083, "imageId": "n65866", "question": "How big is the bathtub that is made of porcelain?", "program": "BOX0=LOC(image=IMAGE,object='porcelain bathtub')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the bathtub?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4084, "imageId": "n285391", "question": "What animal is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What animal is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4085, "imageId": "n250715", "question": "What item of furniture is metallic?", "program": "BOX0=LOC(image=IMAGE,object='metallic')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4086, "imageId": "n470920", "question": "What are the fruits that are to the left of the woman that is holding the umbrella?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='fruits')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4087, "imageId": "n527290", "question": "On which side of the image is the handbag?", "program": "BOX0=LOC(image=IMAGE,object='handbag')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4088, "imageId": "n541854", "question": "How clean do you think is the knife?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean do you think is the knife?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4089, "imageId": "n575770", "question": "Is this a red suitcase?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the suitcase?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4090, "imageId": "n318370", "question": "How big is the donut the person holds?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='donut')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the donut?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4091, "imageId": "n151768", "question": "Is the cane hard?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the cane hard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4092, "imageId": "n37274", "question": "What is the cup full of?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cup full of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4093, "imageId": "n460385", "question": "The woman is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The woman is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4094, "imageId": "n460385", "question": "Who is in front of the wood shelf?", "program": "BOX0=LOC(image=IMAGE,object='wood shelf')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the wood shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4095, "imageId": "n184385", "question": "What is the cooking utensil to the right of the pot?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=VQA(image=IMAGE0,question='What is the cooking utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4096, "imageId": "n4777", "question": "What is the white object to the left of the laptop made of, paper or glass?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white object')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the white object made of?')\nANSWER1=EVAL(expr=\"'paper' if {ANSWER0} == 'paper' else 'glass'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4097, "imageId": "n181355", "question": "Which kind of furniture is behind the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is behind the coffee table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4098, "imageId": "n181355", "question": "Which material is the couch made of, cloth or leather?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material is the couch made of, cloth or leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4099, "imageId": "n25275", "question": "How old is the boy to the right of the other boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boy')\nANSWER0=VQA(image=IMAGE0,question='How old is the boy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4100, "imageId": "n347706", "question": "What is the color of the shirt made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the shirt?')\nANSWER1=EVAL(expr=\"'cloth' if {ANSWER0} != 'unknown' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4101, "imageId": "n369595", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4102, "imageId": "n347706", "question": "Is the cloth shirt short sleeved and gray?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the shirt short sleeved?')\nANSWER1=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4103, "imageId": "n25275", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4104, "imageId": "n116329", "question": "Is the window made of glass round and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the window made of glass?')\nANSWER1=VQA(image=IMAGE,question='Is the window round?')\nANSWER2=VQA(image=IMAGE,question='Is the window large?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 4105, "imageId": "n382416", "question": "Is the square box in the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='square box')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4106, "imageId": "n435808", "question": "Is the computer rectangular and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the computer rectangular?')\nANSWER1=VQA(image=IMAGE,question='What color is the computer?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4107, "imageId": "n235859", "question": "Is the little drink in the bottom part or in the top of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='little drink')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4108, "imageId": "n115614", "question": "What is located on top of the pole?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the pole?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4109, "imageId": "n160664", "question": "Are the fence and the sign made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the fence made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the sign made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4110, "imageId": "n115614", "question": "Are there either any scrub brushes or umbrellas?", "program": "BOX0=LOC(image=IMAGE,object='scrub brushes')\nBOX1=LOC(image=IMAGE,object='umbrellas')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4111, "imageId": "n115614", "question": "What do you think is the red sign mounted on?", "program": "BOX0=LOC(image=IMAGE,object='red sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is the red sign mounted on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4112, "imageId": "n450919", "question": "Are there both mud and grass in this image?", "program": "BOX0=LOC(image=IMAGE,object='mud')\nBOX1=LOC(image=IMAGE,object='grass')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4113, "imageId": "n545516", "question": "Is the plane above a camera?", "program": "BOX0=LOC(image=IMAGE,object='camera')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plane')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4114, "imageId": "n331357", "question": "On which side of the image is the large mother, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='large mother')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4115, "imageId": "n146522", "question": "Who is playing with the ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is playing with the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4116, "imageId": "n431447", "question": "Where is the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4117, "imageId": "n167164", "question": "Is that wire thin and gray?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the wire?')\nANSWER1=VQA(image=IMAGE,question='Is the wire thin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4118, "imageId": "n16656", "question": "Which kind of animal is behind the shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is behind the shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4119, "imageId": "n264887", "question": "Is the keyboard in front of the device that is to the left of the speaker?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='keyboard')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4120, "imageId": "n160664", "question": "Is that man comfortable and young?", "program": "ANSWER0=VQA(image=IMAGE,question='Is that man comfortable?')\nANSWER1=VQA(image=IMAGE,question='Is that man young?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4121, "imageId": "n146522", "question": "Is the young boy playing with a frisbee?", "program": "BOX0=LOC(image=IMAGE,object='young boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='frisbee')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4122, "imageId": "n187544", "question": "Where is the lamp post?", "program": "BOX0=LOC(image=IMAGE,object='lamp post')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4123, "imageId": "n141939", "question": "Is the garbage can to the left of the radiator tall and black and white?", "program": "BOX0=LOC(image=IMAGE,object='radiator')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='garbage can')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color is the garbage can?')\nANSWER3=VQA(image=IMAGE1,question='What is the height of the garbage can?')\nANSWER4=VQA(image=IMAGE1,question='What is the width of the garbage can?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER2} == 'black and white' and {ANSWER3} == 'tall' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 4124, "imageId": "n95313", "question": "Are both the bookshelf and the chair made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='bookshelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='chair')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the bookshelf made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the chair made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4125, "imageId": "n511913", "question": "How large are the books to the right of the wine bottle?", "program": "BOX0=LOC(image=IMAGE,object='wine bottle')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large are the books?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4126, "imageId": "n141939", "question": "Does the garbage can look black and white?", "program": "BOX0=LOC(image=IMAGE,object='garbage can')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the garbage can?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4127, "imageId": "n511913", "question": "Does the man look young?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the man look young?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4128, "imageId": "n95313", "question": "Do the jacket and the tray have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='tray')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE1,question='What color is the tray?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4129, "imageId": "n511913", "question": "Are the small books on the right side or on the left?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4130, "imageId": "n95313", "question": "Is the color of the blanket different than that of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blanket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bed?')\nANSWER1=VQA(image=IMAGE1,question='What color is the blanket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4131, "imageId": "n159802", "question": "Who is the woman playing with?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the woman playing with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4132, "imageId": "n16378", "question": "What's the woman looking down at?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman looking down at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4133, "imageId": "n412144", "question": "What is the material of the skateboard to the right of the skateboarder?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the material of the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4134, "imageId": "n16378", "question": "Is the person behind the papers looking down at the luggage cart?", "program": "BOX0=LOC(image=IMAGE,object='papers')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='luggage cart')\nANSWER0=COUNT(box=BOX2)\nANSWER1=VQA(image=IMAGE1,question='Is the person looking down at the luggage cart?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4135, "imageId": "n312206", "question": "Is the chocolate dessert on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chocolate dessert')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4136, "imageId": "n496803", "question": "Is the crowd that is sitting down watching the athlete?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='crowd')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4137, "imageId": "n97485", "question": "What type of furniture is above the shelves?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is above the shelves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4138, "imageId": "n312206", "question": "Is the glass empty or full?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the glass empty or full?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4139, "imageId": "n35676", "question": "Is the new oven to the left or to the right of the drawers?", "program": "BOX0=LOC(image=IMAGE,object='drawers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='new oven')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4140, "imageId": "n244826", "question": "What is in front of the soccer player that wears a shoe?", "program": "BOX0=LOC(image=IMAGE,object='soccer player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shoe')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the soccer player?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4141, "imageId": "n526228", "question": "What is common to the remote and the phone?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the remote and the phone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4142, "imageId": "n525901", "question": "Which piece of furniture is not tall, the shelf or the office chair?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nBOX1=LOC(image=IMAGE,object='office chair')\nANSWER0=VQA(image=IMAGE,question='How tall is the shelf?')\nANSWER1=VQA(image=IMAGE,question='How tall is the office chair?')\nANSWER2=EVAL(expr=\"'shelf' if {ANSWER0} < {ANSWER1} else 'office chair'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4143, "imageId": "n235859", "question": "What color is that watch?", "program": "BOX0=LOC(image=IMAGE,object='watch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the watch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4144, "imageId": "n525901", "question": "What piece of furniture is tall?", "program": "BOX0=LOC(image=IMAGE,object='tall')\nANSWER0=VQA(image=IMAGE,question='What piece of furniture is tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4145, "imageId": "n526228", "question": "What type of device is made of the same material as the remote the man is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of device is made of the same material as the remote?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4146, "imageId": "n525901", "question": "What item of furniture is not tall?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is not tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4147, "imageId": "n86120", "question": "Do the shirt and the wall have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='wall')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the wall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4148, "imageId": "n24526", "question": "What is she doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is she doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4149, "imageId": "n274905", "question": "Who is wearing the tank top?", "program": "BOX0=LOC(image=IMAGE,object='tank top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the tank top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4150, "imageId": "n24526", "question": "Does the person to the right of the umbrella appear to be skating?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Does the person appear to be skating?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4151, "imageId": "n274905", "question": "Who is wearing a tank top?", "program": "BOX0=LOC(image=IMAGE,object='tank top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a tank top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4152, "imageId": "n477215", "question": "What is the name of this animals?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the name of these animals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4153, "imageId": "n477215", "question": "What animals are it?", "program": "BOX0=LOC(image=IMAGE,object='animals')\nANSWER0=VQA(image=IMAGE,question='What animals are it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4154, "imageId": "n520071", "question": "What device is portable?", "program": "ANSWER0=VQA(image=IMAGE,question='What device is portable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4155, "imageId": "n324908", "question": "What is resting on the mountains?", "program": "ANSWER0=VQA(image=IMAGE,question='What is resting on the mountains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4156, "imageId": "n477215", "question": "Is there a bird in the picture that is not large?", "program": "BOX0=LOC(image=IMAGE,object='bird')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='large bird')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4157, "imageId": "n6309", "question": "Are the cart and the fence made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='cart')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fence')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the cart made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the fence made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4158, "imageId": "n6309", "question": "Is the color of the fence different than the car?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='car')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the fence?')\nANSWER1=VQA(image=IMAGE1,question='What color is the car?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4159, "imageId": "n216553", "question": "What is common to the bag and the sky?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the bag and the sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4160, "imageId": "n520071", "question": "What device is not off?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='What device is not off?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4161, "imageId": "n324908", "question": "Is the snow bright and white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the snow?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'bright and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4162, "imageId": "n296467", "question": "Are the fresh carrots to the right of the bowl that is to the left of the cookies?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cookies')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='bowl')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='carrots')\nANSWER0=COUNT(box=BOX3)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4163, "imageId": "n148872", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4164, "imageId": "n367944", "question": "Is there a bag that is not white?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nANSWER0=VQA(image=IMAGE,question='What color is the bag?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4165, "imageId": "n118102", "question": "What appliance is tall?", "program": "BOX0=LOC(image=IMAGE,object='tall')\nANSWER0=VQA(image=IMAGE,question='What appliance is tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4166, "imageId": "n118102", "question": "What is the white appliance called?", "program": "BOX0=LOC(image=IMAGE,object='white appliance')\nANSWER0=VQA(image=IMAGE,question='What is the white appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4167, "imageId": "n200225", "question": "What food is not greasy?", "program": "ANSWER0=VQA(image=IMAGE,question='What food is not greasy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4168, "imageId": "n211324", "question": "Does the baby to the right of the bicycle look small and beautiful?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='baby')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4169, "imageId": "n88366", "question": "Does the mountain side have a different color than the jacket?", "program": "BOX0=LOC(image=IMAGE,object='mountain side')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='jacket')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the mountain side?')\nANSWER1=VQA(image=IMAGE1,question='What color is the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4170, "imageId": "n16378", "question": "Are there any bags or cars?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nBOX1=LOC(image=IMAGE,object='car')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4171, "imageId": "n473688", "question": "Which side of the picture is the soap dispenser on?", "program": "BOX0=LOC(image=IMAGE,object='soap dispenser')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4172, "imageId": "n310625", "question": "What color is the mug?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the mug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4173, "imageId": "n554880", "question": "Is the person to the left of the laptop sitting beside the gift that is next to the man?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='man')\nIMAGE2=CROP_RIGHTOF(image=IMAGE,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='gift')\nIMAGE3=CROP(image=IMAGE2,box=BOX3)\nANSWER0=EVAL(expr=\"'yes' if {IMAGE1} == {IMAGE3} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4174, "imageId": "n554880", "question": "What is the person to the left of the chair sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4175, "imageId": "n554880", "question": "What is the woman sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4176, "imageId": "n554880", "question": "Who is sitting beside the gift?", "program": "BOX0=LOC(image=IMAGE,object='gift')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting beside the gift?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4177, "imageId": "n116329", "question": "Is the metal fence on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='metal fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4178, "imageId": "n250715", "question": "What is the pilot doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the pilot doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4179, "imageId": "n250715", "question": "What is the person to the right of the device doing?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4180, "imageId": "n369313", "question": "Which kind of clothing is white?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of clothing is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4181, "imageId": "n310828", "question": "What kind of furniture is full?", "program": "BOX0=LOC(image=IMAGE,object='full')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is full?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4182, "imageId": "n369313", "question": "What do you think is the name of the white clothing item in the picture?", "program": "BOX0=LOC(image=IMAGE,object='white clothing item')\nANSWER0=VQA(image=IMAGE,question='What do you think is the name of the white clothing item?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4183, "imageId": "n51658", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4184, "imageId": "n489190", "question": "Is the fence in front or behind the trees that are green and brown?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green')\nBOX2=LOC(image=IMAGE0,object='brown')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nBOX3=LOC(image=IMAGE,object='fence')\nIMAGE3=CROP_FRONT(image=IMAGE,box=BOX3)\nANSWER0=EVAL(expr=\"'front' if {IMAGE3} == {IMAGE1} or {IMAGE3} == {IMAGE2} else 'behind'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4185, "imageId": "n310828", "question": "Which kind of furniture is long?", "program": "BOX0=LOC(image=IMAGE,object='long')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4186, "imageId": "n310828", "question": "What kind of furniture is long?", "program": "BOX0=LOC(image=IMAGE,object='long')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4187, "imageId": "n278312", "question": "What type of cooking utensil is to the left of the knife block in the middle of the picture?", "program": "BOX0=LOC(image=IMAGE,object='knife block')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=VQA(image=IMAGE0,question='What type of cooking utensil is to the left of the knife block?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4188, "imageId": "n538039", "question": "Are the people male?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Are the people male?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4189, "imageId": "n309148", "question": "Is there any taxi behind the sticker?", "program": "BOX0=LOC(image=IMAGE,object='sticker')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='taxi')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4190, "imageId": "n258500", "question": "Is the hair band both white and small?", "program": "BOX0=LOC(image=IMAGE,object='hair band')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hair band?')\nANSWER1=VQA(image=IMAGE0,question='How big is the hair band?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4191, "imageId": "n309148", "question": "What is the vehicle behind the sticker?", "program": "BOX0=LOC(image=IMAGE,object='sticker')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4192, "imageId": "n309148", "question": "Is there a traffic light in front of the bridge that is crossing the street?", "program": "BOX0=LOC(image=IMAGE,object='bridge')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic light')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4193, "imageId": "n195925", "question": "What kind of watercraft is to the right of the boat near the bridge?", "program": "BOX0=LOC(image=IMAGE,object='boat')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watercraft')\nANSWER0=VQA(image=IMAGE0,question='What kind of watercraft is to the right of the boat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4194, "imageId": "n19152", "question": "Is the large vehicle yellow or black?", "program": "BOX0=LOC(image=IMAGE,object='large vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the large vehicle?')\nANSWER1=EVAL(expr=\"'yellow' if {ANSWER0} == 'yellow' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4195, "imageId": "n473688", "question": "Which kind of clothing is thin?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4196, "imageId": "n154856", "question": "Is the lamp made of the same material as the van?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the van made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the lamp made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4197, "imageId": "n19152", "question": "What is sitting beside the tall building?", "program": "BOX0=LOC(image=IMAGE,object='tall building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='beside')\nANSWER0=VQA(image=IMAGE0,question='What is sitting beside the tall building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4198, "imageId": "n159802", "question": "Are both the dress shirt that looks gray and the black blouse striped?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the dress shirt striped?')\nANSWER1=VQA(image=IMAGE,question='Is the black blouse striped?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4199, "imageId": "n208302", "question": "Does the grass look tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the grass look tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4200, "imageId": "n554880", "question": "Does the mobile phone to the right of the chair look old and white?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mobile phone')\nANSWER0=VQA(image=IMAGE0,question='What color is the mobile phone?')\nANSWER1=VQA(image=IMAGE0,question='Is the mobile phone old?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4201, "imageId": "n54424", "question": "Which kind of device is the boy playing with?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of device is the boy playing with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4202, "imageId": "n187544", "question": "Is the frisbee made of the same material as the street light?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='street light')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the frisbee made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the street light made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4203, "imageId": "n187544", "question": "Is the tree made of the same material as the streetlight?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='streetlight')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the tree made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the streetlight made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4204, "imageId": "n229548", "question": "What is the ship made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the ship made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4205, "imageId": "n380113", "question": "Who is wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing gloves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4206, "imageId": "n200907", "question": "What is growing behind the fence made of metal?", "program": "BOX0=LOC(image=IMAGE,object='metal fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='growing')\nANSWER0=VQA(image=IMAGE0,question='What is growing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4207, "imageId": "n16378", "question": "Who is holding onto the papers to the left of the bag?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='papers')\nANSWER0=VQA(image=IMAGE0,question='Who is holding onto the papers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4208, "imageId": "n380113", "question": "Who is standing on the field?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing on the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4209, "imageId": "n380113", "question": "Where is the soccer player that is bending standing on?", "program": "BOX0=LOC(image=IMAGE,object='bending soccer player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the soccer player standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4210, "imageId": "n398257", "question": "Do you see rugs behind the sweatshirt?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rugs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4211, "imageId": "n210269", "question": "Is the concrete pavement below the horses that are not little?", "program": "BOX0=LOC(image=IMAGE,object='horses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not little')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='concrete pavement')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4212, "imageId": "n437192", "question": "Are there any white bears or horses?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nBOX1=LOC(image=IMAGE,object='horse')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4213, "imageId": "n140421", "question": "How clean is the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4214, "imageId": "n524855", "question": "Are there any cows or goats that are walking?", "program": "BOX0=LOC(image=IMAGE,object='cow')\nBOX1=LOC(image=IMAGE,object='goat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4215, "imageId": "n28996", "question": "Which kind of food is not cut, the grapes or the sandwiches?", "program": "BOX0=LOC(image=IMAGE,object='grapes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sandwiches')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Is the food cut?')\nANSWER1=VQA(image=IMAGE1,question='Is the food cut?')\nANSWER2=EVAL(expr=\"'grapes' if {ANSWER0} == 'no' else 'sandwiches'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4216, "imageId": "n398257", "question": "On which side of the image is the red book?", "program": "BOX0=LOC(image=IMAGE,object='red book')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4217, "imageId": "n97485", "question": "Are there cups or breads in this picture?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nBOX1=LOC(image=IMAGE,object='bread')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4218, "imageId": "n433692", "question": "What is the color of the pot?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the pot?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4219, "imageId": "n498712", "question": "Which seems to be younger, the woman or the girl?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='girl')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='How old is the woman?')\nANSWER1=VQA(image=IMAGE1,question='How old is the girl?')\nANSWER2=EVAL(expr=\"'woman' if {ANSWER0} < {ANSWER1} else 'girl'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4220, "imageId": "n314630", "question": "What is the color of the knives that are reflected in the toaster?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knives')\nANSWER0=VQA(image=IMAGE0,question='What is the color of the knives?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4221, "imageId": "n100991", "question": "Is the plate to the left or to the right of the knife?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4222, "imageId": "n498712", "question": "What is common to the backpack and the poster?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the backpack and the poster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4223, "imageId": "n481655", "question": "Is the umpire on the right?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4224, "imageId": "n315887", "question": "Is the black phone on the left of the image?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black phone')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4225, "imageId": "n39114", "question": "Who is in front of the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4226, "imageId": "n233607", "question": "What is sitting atop the metal shelf?", "program": "BOX0=LOC(image=IMAGE,object='metal shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting atop the metal shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4227, "imageId": "n39114", "question": "Is the young person in front of the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4228, "imageId": "n39114", "question": "Who wears the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4229, "imageId": "n355567", "question": "Is the tennis net rectangular and small?", "program": "BOX0=LOC(image=IMAGE,object='tennis net')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the tennis net rectangular?')\nANSWER1=VQA(image=IMAGE0,question='Is the tennis net small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4230, "imageId": "n97485", "question": "What is the height of the chair that is underneath the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the height of the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4231, "imageId": "n415215", "question": "Is the purple hair long and straight?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the purple hair long?')\nANSWER1=VQA(image=IMAGE,question='Is the purple hair straight?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4232, "imageId": "n92308", "question": "Does the blue sky look clear?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the blue sky look clear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4233, "imageId": "n411121", "question": "Is the animal in the backpack brown and small?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What color is the animal?')\nANSWER1=VQA(image=IMAGE0,question='What size is the animal?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4234, "imageId": "n437064", "question": "Are there tablecloths or gourds in the photo?", "program": "BOX0=LOC(image=IMAGE,object='tablecloth')\nBOX1=LOC(image=IMAGE,object='gourd')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4235, "imageId": "n153118", "question": "What kind of vehicle is metallic?", "program": "BOX0=LOC(image=IMAGE,object='metallic')\nANSWER0=VQA(image=IMAGE,question='What kind of vehicle is metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4236, "imageId": "n153118", "question": "Which kind of vehicle is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='metal')\nANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is made of metal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4237, "imageId": "n479092", "question": "On which side are the silver forks?", "program": "BOX0=LOC(image=IMAGE,object='silver forks')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4238, "imageId": "n560243", "question": "What color do you think are the shorts that are worn on the athlete?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shorts')\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4239, "imageId": "n479092", "question": "Are the pants below a couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pants')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4240, "imageId": "n283587", "question": "What is the material of the staircase?", "program": "BOX0=LOC(image=IMAGE,object='staircase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the material of the staircase?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4241, "imageId": "n536256", "question": "Do both the device that is white and the on TV to the right of the lamp look small?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TV')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='device')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='Does the device look small?')\nANSWER1=VQA(image=IMAGE1,question='Does the TV look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4242, "imageId": "n210269", "question": "What is located on top of the horses that the window is over?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horses')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is located on top of the horses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4243, "imageId": "n283587", "question": "Which kind of furniture is the staircase behind of?", "program": "BOX0=LOC(image=IMAGE,object='staircase')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is behind the staircase?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4244, "imageId": "n283587", "question": "Is the steep staircase behind the chairs next to the cupboard?", "program": "BOX0=LOC(image=IMAGE,object='cupboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='staircase')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4245, "imageId": "n393305", "question": "What is the sidewalk made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sidewalk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4246, "imageId": "n39114", "question": "Is the bench rectangular and full?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nANSWER0=VQA(image=IMAGE,question='Is the bench rectangular?')\nANSWER1=VQA(image=IMAGE,question='Is the bench full?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4247, "imageId": "n192021", "question": "Does the pillow that is to the left of the couch look round and red?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What shape is the pillow?')\nANSWER1=VQA(image=IMAGE1,question='What color is the pillow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4248, "imageId": "n88933", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4249, "imageId": "n211324", "question": "Is the garden colorful?", "program": "BOX0=LOC(image=IMAGE,object='garden')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the garden colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4250, "imageId": "n545516", "question": "Is the color of the airplane different than that of the shirt?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the airplane?')\nANSWER1=VQA(image=IMAGE1,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4251, "imageId": "n500308", "question": "Is the table long?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='Is the table long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4252, "imageId": "n470920", "question": "What is covering the woman that is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pants')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is covering the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4253, "imageId": "n289376", "question": "What sits beside the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='beside')\nANSWER0=VQA(image=IMAGE0,question='What sits beside the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4254, "imageId": "n526228", "question": "What item of furniture does the white man below the frame sit on?", "program": "BOX0=LOC(image=IMAGE,object='frame')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What item of furniture does the white man sit on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4255, "imageId": "n184385", "question": "What is the appliance that the utensil made of stainless steel is sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='utensil made of stainless steel')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4256, "imageId": "n187961", "question": "Is that goat white and small?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the goat?')\nANSWER1=VQA(image=IMAGE,question='What size is the goat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4257, "imageId": "n184385", "question": "Is the spoon sitting atop a stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='spoon')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4258, "imageId": "n184385", "question": "What is the spoon sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the spoon sitting atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4259, "imageId": "n216553", "question": "Is the bag near the fence closed or open?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='Is the bag closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4260, "imageId": "n489190", "question": "What is common to the fence and the light fixture?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the fence and the light fixture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4261, "imageId": "n500209", "question": "Do you think that picture frame is standing?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nANSWER0=EVAL(expr=\"'yes' if {BOX0} == 'standing' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4262, "imageId": "n278453", "question": "How big is the bottle that looks yellow?", "program": "BOX0=LOC(image=IMAGE,object='yellow bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the bottle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4263, "imageId": "n500209", "question": "Which shape is the picture frame?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nANSWER0=VQA(image=IMAGE,question='Which shape is the picture frame?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4264, "imageId": "n83784", "question": "Does the carpet beneath the side table look green?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='carpet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4265, "imageId": "n283587", "question": "Does the window look large and dark?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the window look large and dark?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4266, "imageId": "n250821", "question": "What animal is sitting at the bedroom that looks dirty?", "program": "BOX0=LOC(image=IMAGE,object='bedroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dirty')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4267, "imageId": "n125122", "question": "Are there sinks in front of the mirror that is to the left of the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='sink')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4268, "imageId": "n494677", "question": "That elephant is where?", "program": "ANSWER0=VQA(image=IMAGE,question='That elephant is where?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4269, "imageId": "n526228", "question": "Does the man below the frame sit on a couch?", "program": "BOX0=LOC(image=IMAGE,object='frame')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='couch')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4270, "imageId": "n494677", "question": "Is there any elephant on the field?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='elephant')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4271, "imageId": "n494677", "question": "Are there any elephants below the blue sky?", "program": "BOX0=LOC(image=IMAGE,object='blue sky')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='elephants')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4272, "imageId": "n238266", "question": "Are there black knives or spoons?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nBOX1=LOC(image=IMAGE,object='spoon')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4273, "imageId": "n299528", "question": "Who rides on a skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who rides on a skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4274, "imageId": "n192021", "question": "What item of furniture is on the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is on the carpet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4275, "imageId": "n279173", "question": "Are there taxis on the street that is made of cement?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='taxi')\nBOX2=LOC(image=IMAGE0,object='cement')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4276, "imageId": "n406334", "question": "Which kind of vehicle is in front of the buildings?", "program": "BOX0=LOC(image=IMAGE,object='buildings')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is in front of the buildings?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4277, "imageId": "n125122", "question": "Is the wood chair on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4278, "imageId": "n244826", "question": "Does the soccer ball look round and red?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the soccer ball look round and red?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4279, "imageId": "n77818", "question": "On which side are the towels?", "program": "BOX0=LOC(image=IMAGE,object='towels')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4280, "imageId": "n433692", "question": "Does the laptop computer next to the cat look modern?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the laptop computer next to the cat look modern?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4281, "imageId": "n356822", "question": "What is the piece of clothing that is not white called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the piece of clothing that is not white called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4282, "imageId": "n356822", "question": "Which kind of clothing is not white?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is not white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4283, "imageId": "n187961", "question": "What kind of animal is in front of the child?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of animal is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4284, "imageId": "n154856", "question": "What is the vehicle that that van is in front of?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle that the van is in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4285, "imageId": "n356822", "question": "Which kind of clothing is white?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of clothing is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4286, "imageId": "n119944", "question": "Do the shorts that are made of jeans look short and blue?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shorts')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE1,question='Are the shorts short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4287, "imageId": "n315887", "question": "Are there any computers near the tape?", "program": "BOX0=LOC(image=IMAGE,object='tape')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='computer')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4288, "imageId": "n356822", "question": "Which kind of clothing is not white, the baseball mitt or the sweater?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sweater')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the baseball mitt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sweater?')\nANSWER2=EVAL(expr=\"'baseball mitt' if {ANSWER0} != 'white' else 'sweater'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4289, "imageId": "n501609", "question": "Is the stove black?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the stove?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4290, "imageId": "n501609", "question": "Does the stove seem to be off or on?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nANSWER0=VQA(image=IMAGE,question='Does the stove seem to be off or on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4291, "imageId": "n125122", "question": "Is there a mirror to the right of the paintings above the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='paintings')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='mirror')\nIMAGE2=CROP_RIGHTOF(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4292, "imageId": "n90294", "question": "Is the ground made of brick rough or smooth?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the ground made of brick rough or smooth?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4293, "imageId": "n565418", "question": "Does the vehicle to the right of the fence look silver and small?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nANSWER1=VQA(image=IMAGE0,question='How big is the vehicle?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4294, "imageId": "n498712", "question": "The woman is in front of who?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The woman is in front of who?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4295, "imageId": "n240973", "question": "Is that a white desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the desk?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4296, "imageId": "n273901", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4297, "imageId": "n562105", "question": "Is the huge stadium empty or full?", "program": "BOX0=LOC(image=IMAGE,object='stadium')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the stadium empty or full?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4298, "imageId": "n342511", "question": "What is the old person leaning against?", "program": "BOX0=LOC(image=IMAGE,object='old person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the old person leaning against?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4299, "imageId": "n342511", "question": "What's the man leaning against?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man leaning against?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4300, "imageId": "n143935", "question": "Does the barn appear to be large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the barn appear to be large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4301, "imageId": "n143935", "question": "Does the barn seem to be wooden and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the barn seem to be wooden?')\nANSWER1=VQA(image=IMAGE,question='Does the barn seem to be large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4302, "imageId": "n572716", "question": "Does the jet have blue color?", "program": "BOX0=LOC(image=IMAGE,object='jet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4303, "imageId": "n310828", "question": "What is the person touching?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person touching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4304, "imageId": "n313060", "question": "Are the striped tank top and the black sweatshirt both on?", "program": "BOX0=LOC(image=IMAGE,object='striped tank top')\nBOX1=LOC(image=IMAGE,object='black sweatshirt')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4305, "imageId": "n313060", "question": "Which kind of clothing is striped?", "program": "BOX0=LOC(image=IMAGE,object='striped clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4306, "imageId": "n313060", "question": "What is the article of clothing that is striped called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the article of clothing that is striped called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4307, "imageId": "n54424", "question": "What are the striped clothing items in this photo?", "program": "BOX0=LOC(image=IMAGE,object='striped clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'no'\")\nANSWER2=EVAL(expr=\"'pants' if {ANSWER0} > 0 else 'no'\")\nANSWER3=EVAL(expr=\"'skirt' if {ANSWER0} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'dress' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1, var=ANSWER2, var=ANSWER3, var=ANSWER4)"}, {"index": 4308, "imageId": "n125122", "question": "Is the pillow to the left of the bed gray and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color is the pillow?')\nANSWER3=VQA(image=IMAGE1,question='What shape is the pillow?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'gray' and {ANSWER3} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 4309, "imageId": "n309148", "question": "What is located on top of the fire truck?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4310, "imageId": "n309148", "question": "What is located on top of the fire truck that is not dirty?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dirty')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='TOP')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What is located on top of the fire truck?')\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 'dirty' else {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4311, "imageId": "n28572", "question": "What kind of furniture isn't large?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is large?')\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} == 'table' else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4312, "imageId": "n411121", "question": "Is the parked vehicle to the left of the person small or large?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='parked vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} > 0 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4313, "imageId": "n411121", "question": "Is the parked vehicle near the person silver and large?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='parked vehicle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the parked vehicle?')\nANSWER1=VQA(image=IMAGE1,question='How large is the parked vehicle?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4314, "imageId": "n574498", "question": "Do the ball and the tennis racket have the same color?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='tennis racket')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the ball?')\nANSWER1=VQA(image=IMAGE1,question='What color is the tennis racket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4315, "imageId": "n65202", "question": "Who is wearing the wristwatch?", "program": "BOX0=LOC(image=IMAGE,object='wristwatch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the wristwatch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4316, "imageId": "n65202", "question": "Who is wearing sneakers?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing sneakers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4317, "imageId": "n100991", "question": "Which side is the ripe fruit on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ripe fruit')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4318, "imageId": "n526228", "question": "Is the happy man Caucasian or Asian?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man Caucasian or Asian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4319, "imageId": "n386682", "question": "What is the name of this items of furniture?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the name of this items of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4320, "imageId": "n386682", "question": "What items of furniture are it?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What items of furniture are it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4321, "imageId": "n296467", "question": "Is there any pasta next to the food on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='pasta')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4322, "imageId": "n579256", "question": "Which kind of clothing is blue?", "program": "BOX0=LOC(image=IMAGE,object='blue')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4323, "imageId": "n386682", "question": "Which kind of furniture is large?", "program": "BOX0=LOC(image=IMAGE,object='large furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4324, "imageId": "n274905", "question": "Is the fence behind a girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4325, "imageId": "n579256", "question": "Is the wall different in color than the freezer?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='freezer')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the wall?')\nANSWER1=VQA(image=IMAGE1,question='What color is the freezer?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4326, "imageId": "n219840", "question": "Behind what animal is the zebra standing?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='Behind what animal is the zebra standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4327, "imageId": "n54424", "question": "Does the couch have white color?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the couch?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4328, "imageId": "n499081", "question": "The small sink has which shape?", "program": "BOX0=LOC(image=IMAGE,object='small sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The small sink has which shape?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4329, "imageId": "n51002", "question": "Is the leather couch to the left or to the right of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='leather couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4330, "imageId": "n51002", "question": "Is the leather couch to the right of a desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='leather couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4331, "imageId": "n68769", "question": "Do you see books on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4332, "imageId": "n28572", "question": "Does the plate look large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the plate look large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4333, "imageId": "n538039", "question": "Which color is the car to the right of the truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nANSWER0=VQA(image=IMAGE0,question='Which color is the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4334, "imageId": "n243701", "question": "Are there any girls beside the traffic signal in the top part of the picture?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic signal')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='girls')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4335, "imageId": "n400036", "question": "What size is the backpack near the tree?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='backpack')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What size is the backpack?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4336, "imageId": "n272098", "question": "How do the food to the left of the rope look, white or dark brown?", "program": "BOX0=LOC(image=IMAGE,object='rope')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How does the food look?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'dark brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4337, "imageId": "n296467", "question": "Does the food to the right of the cupcakes seem to be black and white and rotten?", "program": "BOX0=LOC(image=IMAGE,object='cupcakes')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What color is the food?')\nANSWER1=VQA(image=IMAGE0,question='Is the food rotten?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black and white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4338, "imageId": "n9856", "question": "Are there either any fences or buckets?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='bucket')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4339, "imageId": "n62458", "question": "On which side of the photo are the clay pots?", "program": "BOX0=LOC(image=IMAGE,object='clay pots')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4340, "imageId": "n527589", "question": "What is the sign hanging from?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hanging')\nANSWER0=VQA(image=IMAGE0,question='What is the sign hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4341, "imageId": "n259002", "question": "What is the vehicle that the trash bin is in front of called?", "program": "BOX0=LOC(image=IMAGE,object='trash bin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4342, "imageId": "n137182", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4343, "imageId": "n429961", "question": "Is this broccoli or lettuce?", "program": "BOX0=LOC(image=IMAGE,object='broccoli')\nBOX1=LOC(image=IMAGE,object='lettuce')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'broccoli' if {ANSWER0} > 0 else 'lettuce'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4344, "imageId": "n204894", "question": "Who is wearing the jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4345, "imageId": "n531731", "question": "What is the baseball bat made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the baseball bat made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4346, "imageId": "n355339", "question": "Is the plastic keyboard to the left or to the right of the chair on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='plastic keyboard')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4347, "imageId": "n125122", "question": "What item of furniture is below the paintings?", "program": "BOX0=LOC(image=IMAGE,object='paintings')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is below the paintings?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4348, "imageId": "n88366", "question": "What is the skier riding on?", "program": "BOX0=LOC(image=IMAGE,object='skier')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skier riding on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4349, "imageId": "n125122", "question": "How is the item of furniture that is below the paintings in the picture called?", "program": "BOX0=LOC(image=IMAGE,object='paintings')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4350, "imageId": "n125122", "question": "What shape is the bed below the paintings?", "program": "BOX0=LOC(image=IMAGE,object='paintings')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What shape is the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4351, "imageId": "n88366", "question": "What is the person to the right of the helmet riding on?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person riding on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4352, "imageId": "n532191", "question": "The rug is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The rug is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4353, "imageId": "n532191", "question": "What is the rug in front of?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the rug in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4354, "imageId": "n172618", "question": "Who is wearing the skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4355, "imageId": "n532191", "question": "What kind of furniture is the rug in front of?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the rug in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4356, "imageId": "n413002", "question": "Are there elephants to the right of the bananas?", "program": "BOX0=LOC(image=IMAGE,object='bananas')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='elephants')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4357, "imageId": "n410476", "question": "What animal is in front of the animal in the middle?", "program": "BOX0=LOC(image=IMAGE,object='middle animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is in front?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4358, "imageId": "n413319", "question": "Who is about to hit the tennis ball?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is about to hit the tennis ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4359, "imageId": "n413319", "question": "Who is about to hit the tennis ball that is in the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis ball')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is about to hit the tennis ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4360, "imageId": "n98540", "question": "Who is wearing the baseball mitt?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the baseball mitt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4361, "imageId": "n279173", "question": "Is it an outdoors scene?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an outdoors scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4362, "imageId": "n414992", "question": "Is the heavy man wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4363, "imageId": "n414992", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4364, "imageId": "n414992", "question": "Are there men in front of the ocean?", "program": "BOX0=LOC(image=IMAGE,object='ocean')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4365, "imageId": "n414992", "question": "Is the heavy man looking at a cell phone?", "program": "BOX0=LOC(image=IMAGE,object='heavy man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cell phone')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4366, "imageId": "n528403", "question": "Who is wearing a skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4367, "imageId": "n150962", "question": "In which part of the picture is the pot, the top or the bottom?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nBOX1=LOC(image=IMAGE,object='TOP')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4368, "imageId": "n262920", "question": "What color are the laptops?", "program": "BOX0=LOC(image=IMAGE,object='laptops')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the laptops?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4369, "imageId": "n146555", "question": "Who is the large cow watching?", "program": "BOX0=LOC(image=IMAGE,object='large cow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the large cow watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4370, "imageId": "n314171", "question": "What kind of appliance are the spices in?", "program": "BOX0=LOC(image=IMAGE,object='spices')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of appliance are the spices in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4371, "imageId": "n398429", "question": "Is the sink that is silver on or off?", "program": "BOX0=LOC(image=IMAGE,object='silver sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the sink on or off?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4372, "imageId": "n51002", "question": "Are there both desks and laptops in this image?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nBOX1=LOC(image=IMAGE,object='laptop')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4373, "imageId": "n520071", "question": "What animal is to the right of the device near the lamps?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamps')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is to the right of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4374, "imageId": "n4777", "question": "Is the watch the same color as the laptop?", "program": "BOX0=LOC(image=IMAGE,object='watch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='laptop')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the watch?')\nANSWER1=VQA(image=IMAGE1,question='What color is the laptop?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4375, "imageId": "n334278", "question": "Do you think the uniform is blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the uniform?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4376, "imageId": "n146555", "question": "Who is the cow watching?", "program": "BOX0=LOC(image=IMAGE,object='cow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the cow watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4377, "imageId": "n314171", "question": "Are there knives or plates?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nBOX1=LOC(image=IMAGE,object='plate')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4378, "imageId": "n314171", "question": "What are the spices in?", "program": "BOX0=LOC(image=IMAGE,object='spices')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the spices in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4379, "imageId": "n314171", "question": "What are the condiments in?", "program": "BOX0=LOC(image=IMAGE,object='condiments')\nANSWER0=VQA(image=IMAGE,question='What are the condiments in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4380, "imageId": "n66756", "question": "Who is looking up?", "program": "BOX0=LOC(image=IMAGE,object='up')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking up?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4381, "imageId": "n145498", "question": "Which kind of furniture is comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4382, "imageId": "n145498", "question": "Which kind of furniture is long?", "program": "BOX0=LOC(image=IMAGE,object='long')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4383, "imageId": "n204894", "question": "Do you see a chair to the left of the toy that is made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='toy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nBOX2=LOC(image=IMAGE0,object='plastic')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4384, "imageId": "n204894", "question": "Does the phone to the left of the curtain look large and black?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='phone')\nANSWER0=VQA(image=IMAGE0,question='What color is the phone?')\nANSWER1=VQA(image=IMAGE0,question='Is the phone large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4385, "imageId": "n334278", "question": "Does the umpire behind the batter seem to be staring?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umpire')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4386, "imageId": "n95313", "question": "Is this an empty closet?", "program": "BOX0=LOC(image=IMAGE,object='closet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is this an empty closet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4387, "imageId": "n66756", "question": "What is the person to the left of the catcher doing?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4388, "imageId": "n66756", "question": "What is the umpire doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the umpire doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4389, "imageId": "n281241", "question": "Which shape does the picture near the chair have?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='picture')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which shape does the picture have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4390, "imageId": "n222915", "question": "Does this table look white and wooden?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the table?')\nANSWER1=VQA(image=IMAGE,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4391, "imageId": "n363445", "question": "Are the orange vegetables to the right of the food above the apples?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='apples')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='orange vegetables')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4392, "imageId": "n184385", "question": "What is the appliance to the left of the cutting board the potato is on?", "program": "BOX0=LOC(image=IMAGE,object='cutting board')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='potato')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4393, "imageId": "n310625", "question": "Is the toothpaste on the left side?", "program": "BOX0=LOC(image=IMAGE,object='toothpaste')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4394, "imageId": "n433532", "question": "Does the spoon look dirty?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the spoon look dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4395, "imageId": "n324908", "question": "What animal is walking near the goat that looks brown?", "program": "BOX0=LOC(image=IMAGE,object='goat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is walking near the goat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4396, "imageId": "n324908", "question": "Is that horse to the left of a lamb?", "program": "BOX0=LOC(image=IMAGE,object='lamb')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4397, "imageId": "n434283", "question": "Is this car old or new?", "program": "ANSWER0=VQA(image=IMAGE,question='Is this car old or new?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4398, "imageId": "n200907", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4399, "imageId": "n538684", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4400, "imageId": "n520071", "question": "What device is to the left of the computer?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the left of the computer?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4401, "imageId": "n528403", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4402, "imageId": "n406334", "question": "Which color is this bus?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is this bus?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4403, "imageId": "n513429", "question": "What is the flat device called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the flat device called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4404, "imageId": "n513429", "question": "What kind of device is flat?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of device is flat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4405, "imageId": "n243701", "question": "How wide is the black road?", "program": "BOX0=LOC(image=IMAGE,object='black road')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How wide is the black road?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4406, "imageId": "n531359", "question": "Who is in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4407, "imageId": "n150962", "question": "In which part of the image is the small chair, the top or the bottom?", "program": "BOX0=LOC(image=IMAGE,object='small chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4408, "imageId": "n164272", "question": "What animals are in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animals are in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4409, "imageId": "n65230", "question": "Is the shirt hanging above the table behind the shoes?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shoes')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='shirt')\nIMAGE2=CROP_ABOVE(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4410, "imageId": "n434283", "question": "What vehicle is the building behind of?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 0 else 'unknown' if {ANSWER0} > 1 else VQA(image=IMAGE0,question='What vehicle is it?')\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4411, "imageId": "n23181", "question": "What is common to the sculpture and the fireplace?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the sculpture and the fireplace?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4412, "imageId": "n501609", "question": "Does the oven have tan color?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the oven?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'tan' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4413, "imageId": "n164272", "question": "What animal is in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4414, "imageId": "n164272", "question": "What animal is in front of the red building?", "program": "BOX0=LOC(image=IMAGE,object='red building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the red building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4415, "imageId": "n164272", "question": "What are the animals that are in front of the large building?", "program": "BOX0=LOC(image=IMAGE,object='large building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animals')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4416, "imageId": "n554880", "question": "On which side of the image is the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4417, "imageId": "n28996", "question": "What shape is the food the cheese is below?", "program": "BOX0=LOC(image=IMAGE,object='cheese')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What shape is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4418, "imageId": "n293477", "question": "What device is made of the same material as the hair clip that is lying on top of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hair clip')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the hair clip made of?')\nANSWER1=VQA(image=IMAGE,question='What device is made of the same material?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4419, "imageId": "n335542", "question": "Is there a long giraffe or bear?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nBOX1=LOC(image=IMAGE,object='bear')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4420, "imageId": "n171169", "question": "Which kind of vehicle is right of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4421, "imageId": "n485969", "question": "Which kind of clothing is tight?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is tight?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4422, "imageId": "n435808", "question": "Which kind of furniture is made of wood, the desk or the chair?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='chair')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the desk made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the chair made of?')\nANSWER2=EVAL(expr=\"'desk' if {ANSWER0} == 'wood' else 'chair'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4423, "imageId": "n513429", "question": "What is the desk in front of?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the desk in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4424, "imageId": "n154856", "question": "What kind of vehicle isn't black?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=VQA(image=IMAGE,question='What color is the vehicle?')\nANSWER1=EVAL(expr=\"'car' if {ANSWER0} != 'black' else 'truck'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4425, "imageId": "n513429", "question": "What material is the flat desk in front of the curtain, plastic or wood?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flat desk')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the flat desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4426, "imageId": "n154856", "question": "What vehicle is black?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=VQA(image=IMAGE,question='What color is the vehicle?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4427, "imageId": "n154856", "question": "Which kind of vehicle is not black, the van or the car?", "program": "BOX0=LOC(image=IMAGE,object='van')\nBOX1=LOC(image=IMAGE,object='car')\nANSWER0=VQA(image=IMAGE,question='What color is the van?')\nANSWER1=VQA(image=IMAGE,question='What color is the car?')\nANSWER2=EVAL(expr=\"'van' if {ANSWER0} != 'black' else 'car'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4428, "imageId": "n513429", "question": "Which kind of furniture is in front of the curtain?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is in front of the curtain?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4429, "imageId": "n513429", "question": "What type of furniture is in front of the curtain that is to the left of the monitor?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='monitor')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nANSWER0=VQA(image=IMAGE1,question='What type of furniture is in front of the curtain?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4430, "imageId": "n513429", "question": "What is in front of the curtain?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the curtain?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4431, "imageId": "n173807", "question": "What do both the chimney and the street sign have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the chimney and the street sign have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4432, "imageId": "n271392", "question": "What devices are on the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What devices are on the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4433, "imageId": "n171169", "question": "Is the sign on a traffic light?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4434, "imageId": "n271392", "question": "Where are the phones?", "program": "BOX0=LOC(image=IMAGE,object='phones')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4435, "imageId": "n413002", "question": "Which kind of animal is to the right of the backpack?", "program": "BOX0=LOC(image=IMAGE,object='backpack')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is to the right of the backpack?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4436, "imageId": "n171169", "question": "What is that sign on?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nANSWER0=VQA(image=IMAGE,question='What is that sign on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4437, "imageId": "n171169", "question": "What is the sign on?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nANSWER0=VQA(image=IMAGE,question='What is the sign on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4438, "imageId": "n171169", "question": "Which kind of animal is large?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4439, "imageId": "n173807", "question": "How is the sign that is the same color as the chimney called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the sign that is the same color as the chimney called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4440, "imageId": "n28996", "question": "Of what color is the cheese that is inside the sandwiches?", "program": "BOX0=LOC(image=IMAGE,object='sandwiches')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cheese')\nANSWER0=VQA(image=IMAGE0,question='Of what color is the cheese?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4441, "imageId": "n181355", "question": "What is the remote made of plastic lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='plastic')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote')\nANSWER0=VQA(image=IMAGE0,question='What is the remote lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4442, "imageId": "n207893", "question": "Do the mountains look brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What color do the mountains look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4443, "imageId": "n538684", "question": "Are there any boys on the field that the spectators are below?", "program": "BOX0=LOC(image=IMAGE,object='spectators')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='field')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='boys')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4444, "imageId": "n181355", "question": "What device is lying on top of the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is lying on top of the coffee table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4445, "imageId": "n310828", "question": "Is there any helmet to the right of the person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='helmet')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4446, "imageId": "n310828", "question": "Are there computer desks near the papers to the left of the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='papers')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='computer desks')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4447, "imageId": "n507959", "question": "Are there knife blocks or diapers in this picture?", "program": "BOX0=LOC(image=IMAGE,object='knife block')\nBOX1=LOC(image=IMAGE,object='diaper')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4448, "imageId": "n413319", "question": "Who is wearing socks?", "program": "BOX0=LOC(image=IMAGE,object='socks')\nANSWER0=VQA(image=IMAGE,question='Who is wearing socks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4449, "imageId": "n367944", "question": "Is there either a black calculator or chair?", "program": "BOX0=LOC(image=IMAGE,object='calculator')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4450, "imageId": "n55058", "question": "In which part is the plate, the top or the bottom?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4451, "imageId": "n350732", "question": "What color is the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4452, "imageId": "n336443", "question": "Are there any lamps or tables that are made of metal?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4453, "imageId": "n355567", "question": "What is the lady that is not antique playing with?", "program": "BOX0=LOC(image=IMAGE,object='antique')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lady')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the lady playing with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4454, "imageId": "n355567", "question": "Who is playing with the tennis ball?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is playing with the tennis ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4455, "imageId": "n49438", "question": "What color is that dresser?", "program": "BOX0=LOC(image=IMAGE,object='dresser')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the dresser?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4456, "imageId": "n350732", "question": "Is the beige shirt short sleeved or maybe long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='beige shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4457, "imageId": "n546616", "question": "On which side are the blue plates?", "program": "BOX0=LOC(image=IMAGE,object='blue plates')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4458, "imageId": "n350732", "question": "Does the shirt look beige and short sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE,question='What type of sleeves does the shirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'beige' and {ANSWER1} == 'short sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4459, "imageId": "n64959", "question": "Is there a round door or window?", "program": "BOX0=LOC(image=IMAGE,object='door')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4460, "imageId": "n100991", "question": "Is the banana on top of a counter?", "program": "BOX0=LOC(image=IMAGE,object='banana')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='counter')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4461, "imageId": "n541688", "question": "Does the toothbrush to the left of the other toothbrush look small?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toothbrush')\nANSWER0=EVAL(expr=\"'yes' if {BOX1.width} < {BOX0.width} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4462, "imageId": "n496803", "question": "Is the athlete that is to the right of the racket male and tall?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='athlete')\nANSWER0=VQA(image=IMAGE0,question='Is the athlete male?')\nANSWER1=VQA(image=IMAGE0,question='Is the athlete tall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4463, "imageId": "n544255", "question": "Does the sky appear to be cloudy and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the sky appear to be cloudy?')\nANSWER1=VQA(image=IMAGE,question='What color is the sky?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4464, "imageId": "n497789", "question": "Where are the people?", "program": "BOX0=LOC(image=IMAGE,object='people')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4465, "imageId": "n326988", "question": "Where is the man playing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=VQA(image=IMAGE,question='Where is the man playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4466, "imageId": "n279173", "question": "Does the bag to the right of the flags look blue and large?", "program": "BOX0=LOC(image=IMAGE,object='flags')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='What color is the bag?')\nANSWER1=VQA(image=IMAGE0,question='How large is the bag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4467, "imageId": "n259949", "question": "What is before the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is before the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4468, "imageId": "n579928", "question": "What animal is calm?", "program": "ANSWER0=VQA(image=IMAGE,question='What animal is calm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4469, "imageId": "n259949", "question": "What is in front of the leafy trees?", "program": "BOX0=LOC(image=IMAGE,object='leafy trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the leafy trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4470, "imageId": "n273901", "question": "Is this a truck or a bus?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nBOX1=LOC(image=IMAGE,object='bus')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'truck' if {ANSWER0} > 0 else 'bus'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4471, "imageId": "n273901", "question": "Does the bus in front of the other bus have green color and rectangular shape?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the bus?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the bus?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4472, "imageId": "n196058", "question": "Is the gray rock sitting beside donkeys?", "program": "BOX0=LOC(image=IMAGE,object='donkeys')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gray rock')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4473, "imageId": "n273901", "question": "Does the bus in front of the other bus have white color?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the bus?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4474, "imageId": "n196058", "question": "What are the animals that the gray rock is sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='gray rock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animals')\nANSWER0=VQA(image=IMAGE0,question='What are the animals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4475, "imageId": "n507959", "question": "Are both the palm tree in front of the wall and the palm to the left of the flag brown?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='palm tree')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='flag')\nIMAGE2=CROP_LEFTOF(image=IMAGE,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='palm tree')\nIMAGE3=CROP(image=IMAGE2,box=BOX3)\nANSWER0=VQA(image=IMAGE1,question='What color is the palm tree?')\nANSWER1=VQA(image=IMAGE3,question='What color is the palm tree?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4476, "imageId": "n196058", "question": "What animal is the rock that is gray sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='rock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the rock sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4477, "imageId": "n526228", "question": "Is the man below the frame driving or looking down?", "program": "BOX0=LOC(image=IMAGE,object='frame')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='Is the man driving or looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4478, "imageId": "n572716", "question": "Is it cloudy in this photo?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it cloudy in this photo?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4479, "imageId": "n578564", "question": "Is the jar made of the same material as the hook?", "program": "BOX0=LOC(image=IMAGE,object='jar')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hook')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the jar made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the hook made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4480, "imageId": "n143935", "question": "What place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4481, "imageId": "n234683", "question": "Is there a old phone or TV in this picture?", "program": "BOX0=LOC(image=IMAGE,object='old phone')\nBOX1=LOC(image=IMAGE,object='TV')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4482, "imageId": "n578564", "question": "Are the cutting board and the hook made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='cutting board')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hook')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the cutting board made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the hook made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4483, "imageId": "n234683", "question": "Is the black phone old or new?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the black phone old or new?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4484, "imageId": "n143935", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4485, "imageId": "n429883", "question": "What is facing the man that is wearing a suit?", "program": "BOX0=LOC(image=IMAGE,object='man wearing suit')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is facing the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4486, "imageId": "n398429", "question": "Which color is the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4487, "imageId": "n494918", "question": "Do the shorts have short length?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the length of the shorts?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4488, "imageId": "n166008", "question": "What is underneath the glass?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the glass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4489, "imageId": "n186491", "question": "Is that a round table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='Is that a round table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4490, "imageId": "n393305", "question": "What is the sign that the girl is in front of called?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=VQA(image=IMAGE0,question='What is the sign called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4491, "imageId": "n246334", "question": "Is the pillow case red?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the pillow case?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4492, "imageId": "n210269", "question": "Is the door antique?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the door antique?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4493, "imageId": "n210269", "question": "Does the door next to the garage look modern and shut?", "program": "BOX0=LOC(image=IMAGE,object='garage')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='door')\nANSWER0=VQA(image=IMAGE0,question='Does the door look modern?')\nANSWER1=VQA(image=IMAGE0,question='Is the door shut?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4494, "imageId": "n574498", "question": "Is the metal fence in front or behind the man that is holding the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='metal fence')\nIMAGE2=CROP_FRONT(image=IMAGE,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'front' if {ANSWER0} > 0 else 'behind'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4495, "imageId": "n335542", "question": "Is the bear that is not little brown and tall?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bear?')\nANSWER1=VQA(image=IMAGE0,question='Is the bear little?')\nANSWER2=VQA(image=IMAGE0,question='Is the bear tall?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} != 'brown' and {ANSWER1} == 'no' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 4496, "imageId": "n98540", "question": "Are the white pants short or long?", "program": "BOX0=LOC(image=IMAGE,object='white pants')\nANSWER0=VQA(image=IMAGE,question='Are the white pants short or long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4497, "imageId": "n64959", "question": "What is the appliance that is to the right of the tap called?", "program": "BOX0=LOC(image=IMAGE,object='tap')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4498, "imageId": "n296467", "question": "Do the cookies look round and black?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the cookies look like?')\nANSWER1=EVAL(expr=\"'yes' if 'round' in {ANSWER0} and 'black' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4499, "imageId": "n58220", "question": "Do the hat and the jacket have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='jacket')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4500, "imageId": "n570181", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4501, "imageId": "n86120", "question": "What are the animals that she is petting?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the animals she is petting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4502, "imageId": "n58220", "question": "What place was the picture taken at?", "program": "ANSWER0=VQA(image=IMAGE,question='What place was the picture taken at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4503, "imageId": "n86120", "question": "What animal is the woman petting?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the woman petting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4504, "imageId": "n513429", "question": "On which side of the photo is the bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4505, "imageId": "n206785", "question": "Is the person standing in front of a desk?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='desk')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4506, "imageId": "n315859", "question": "Are the words red?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the words?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4507, "imageId": "n86120", "question": "Who is petting the goats?", "program": "BOX0=LOC(image=IMAGE,object='goats')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is petting the goats?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4508, "imageId": "n437064", "question": "On which side is the red fruit?", "program": "BOX0=LOC(image=IMAGE,object='red fruit')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4509, "imageId": "n54424", "question": "Are there both Wii controllers and blinds in this photo?", "program": "BOX0=LOC(image=IMAGE,object='Wii controllers')\nBOX1=LOC(image=IMAGE,object='blinds')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4510, "imageId": "n59676", "question": "How large do you think is that window?", "program": "ANSWER0=VQA(image=IMAGE,question='How large do you think is that window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4511, "imageId": "n356822", "question": "Is the boy to the right of the man happy and old?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Is the boy happy?')\nANSWER3=VQA(image=IMAGE1,question='Is the boy old?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 4512, "imageId": "n379991", "question": "Which kind of cooking utensil is flat?", "program": "BOX0=LOC(image=IMAGE,object='flat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of cooking utensil is flat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4513, "imageId": "n379991", "question": "How is this cooking utensil called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is this cooking utensil called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4514, "imageId": "n379991", "question": "What cooking utensil is it?", "program": "BOX0=LOC(image=IMAGE,object='cooking utensil')\nANSWER0=VQA(image=IMAGE,question='What cooking utensil is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4515, "imageId": "n357126", "question": "Where is the streetlight?", "program": "BOX0=LOC(image=IMAGE,object='streetlight')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4516, "imageId": "n68769", "question": "What is the wine glass in front of?", "program": "BOX0=LOC(image=IMAGE,object='wine glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the wine glass in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4517, "imageId": "n68769", "question": "What is before the silverware?", "program": "BOX0=LOC(image=IMAGE,object='silverware')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is before the silverware?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4518, "imageId": "n68769", "question": "What's the wine glass in front of?", "program": "BOX0=LOC(image=IMAGE,object='wine glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the wine glass in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4519, "imageId": "n329479", "question": "What is the man using?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4520, "imageId": "n400036", "question": "What color is the tall person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tall person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4521, "imageId": "n150962", "question": "Is the chair to the left or to the right of the pot below the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pot')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='chair')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4522, "imageId": "n526228", "question": "What item of furniture is to the right of the telephone?", "program": "BOX0=LOC(image=IMAGE,object='telephone')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is to the right of the telephone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4523, "imageId": "n527589", "question": "Do the fruits on top of the basket have large size and green color?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruits')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the size of the fruits?')\nANSWER1=VQA(image=IMAGE1,question='What is the color of the fruits?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4524, "imageId": "n429961", "question": "Is the cabbage to the left of the other cabbage leafy and purple?", "program": "BOX0=LOC(image=IMAGE,object='cabbage')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabbage')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE,box=BOX0)\nANSWER2=VQA(image=IMAGE1,question='What color is the cabbage?')\nANSWER3=VQA(image=IMAGE1,question='Is the cabbage leafy?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'purple' and {ANSWER3} == 'yes' else 'no'\")\nANSWER5=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER4} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 4525, "imageId": "n433532", "question": "Does the hair look thick?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the hair look thick?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4526, "imageId": "n400036", "question": "Are there blond men or women?", "program": "BOX0=LOC(image=IMAGE,object='blond men')\nBOX1=LOC(image=IMAGE,object='blond women')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4527, "imageId": "n433532", "question": "Does the hair look long and gray?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the hair look long and gray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4528, "imageId": "n262929", "question": "Do you see a scooter in front of the bag the boy is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='scooter')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4529, "imageId": "n58220", "question": "On which side is the flag?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4530, "imageId": "n498712", "question": "On which side is the blue bag?", "program": "BOX0=LOC(image=IMAGE,object='blue bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4531, "imageId": "n58220", "question": "Does the flag look calm and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the flag?')\nANSWER1=VQA(image=IMAGE,question='Does the flag look calm?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4532, "imageId": "n58220", "question": "Does this flag look calm?", "program": "ANSWER0=VQA(image=IMAGE,question='Does this flag look calm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4533, "imageId": "n431447", "question": "Does the chair in the restaurant look white?", "program": "BOX0=LOC(image=IMAGE,object='restaurant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4534, "imageId": "n289376", "question": "What is the name of the sign that is standing in the lawn?", "program": "BOX0=LOC(image=IMAGE,object='lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=VQA(image=IMAGE0,question='What is the name of the sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4535, "imageId": "n260762", "question": "Are there hats or gloves that are not blue?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nBOX1=LOC(image=IMAGE,object='gloves')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4536, "imageId": "n313060", "question": "Are there both coffee and food in this image?", "program": "BOX0=LOC(image=IMAGE,object='coffee')\nBOX1=LOC(image=IMAGE,object='food')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4537, "imageId": "n313060", "question": "Is the building behind a fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='building')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4538, "imageId": "n541688", "question": "On which side of the image is the blue picture?", "program": "BOX0=LOC(image=IMAGE,object='blue picture')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4539, "imageId": "n541688", "question": "Are there any TVs or magazines in the picture?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nBOX1=LOC(image=IMAGE,object='magazine')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4540, "imageId": "n97485", "question": "Which kind of furniture is underneath the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is underneath the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4541, "imageId": "n318370", "question": "Are there any donuts?", "program": "BOX0=LOC(image=IMAGE,object='donut')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4542, "imageId": "n243701", "question": "Does the bag have black color and large size?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bag?')\nANSWER1=VQA(image=IMAGE0,question='How large is the bag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4543, "imageId": "n259002", "question": "Do you see frisbees on the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='frisbees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4544, "imageId": "n548534", "question": "Is the cloth towel in the bottom part of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cloth towel')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4545, "imageId": "n575770", "question": "What are the clothes in?", "program": "BOX0=LOC(image=IMAGE,object='clothes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the clothes in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4546, "imageId": "n579256", "question": "What's the poster hang from?", "program": "BOX0=LOC(image=IMAGE,object='poster')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hang')\nANSWER0=VQA(image=IMAGE0,question='What is the poster hang from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4547, "imageId": "n12404", "question": "What is the person in front of the safety cone doing?", "program": "BOX0=LOC(image=IMAGE,object='safety cone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4548, "imageId": "n12404", "question": "Who is playing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4549, "imageId": "n16378", "question": "Do you see children in this image?", "program": "BOX0=LOC(image=IMAGE,object='children')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4550, "imageId": "n263180", "question": "What color is the large mirror?", "program": "BOX0=LOC(image=IMAGE,object='large mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4551, "imageId": "n184385", "question": "Is there a kettle on the stove top that is black?", "program": "BOX0=LOC(image=IMAGE,object='stove top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='kettle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the kettle?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4552, "imageId": "n140421", "question": "Are there any cups to the left of the clock that looks white?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cups')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4553, "imageId": "n184385", "question": "What is the pot on?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surface')\nANSWER0=VQA(image=IMAGE0,question='What is the pot on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4554, "imageId": "n184385", "question": "What is that pot on?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pot on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4555, "imageId": "n317260", "question": "Do you see a fence or a bike there?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='bike')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4556, "imageId": "n51002", "question": "Is the material of the computer monitor the same as the TV?", "program": "BOX0=LOC(image=IMAGE,object='computer monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='TV')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the computer monitor made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the TV made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4557, "imageId": "n319845", "question": "What kind of furniture is the person in front of?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the person in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4558, "imageId": "n125122", "question": "Are the white pillows to the left or to the right of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white pillows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4559, "imageId": "n125122", "question": "What shape are the pillows that look red and white?", "program": "BOX0=LOC(image=IMAGE,object='red pillows')\nBOX1=LOC(image=IMAGE,object='white pillows')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What shape are the red pillows?')\nANSWER1=VQA(image=IMAGE1,question='What shape are the white pillows?')\nANSWER2=EVAL(expr=\"'{ANSWER0} and {ANSWER1}'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4560, "imageId": "n315887", "question": "Are both the tape and the keyboard made of the same material?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the tape made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the keyboard made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4561, "imageId": "n324644", "question": "What is hang from the cables?", "program": "BOX0=LOC(image=IMAGE,object='cables')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the cables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4562, "imageId": "n400036", "question": "What bag has the same shape as the soccer ball that is not large?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the soccer ball?')\nBOX1=LOC(image=IMAGE,object='bag')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='What shape is the bag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} and {ANSWER1} != 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4563, "imageId": "n116329", "question": "On which side of the photo is the calm man?", "program": "BOX0=LOC(image=IMAGE,object='calm man')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='calm man')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4564, "imageId": "n117888", "question": "Are there any red rackets or bats?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nBOX1=LOC(image=IMAGE,object='bat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What color is the racket?')\nANSWER4=VQA(image=IMAGE,question='What color is the bat?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} == 'red' or {ANSWER4} == 'red' else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 4565, "imageId": "n154160", "question": "How clean are the trousers the catcher is wearing?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trousers')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How clean are the trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4566, "imageId": "n324644", "question": "Which kind of sign are the traffic lights hanging above?", "program": "BOX0=LOC(image=IMAGE,object='traffic lights')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=VQA(image=IMAGE0,question='Which kind of sign is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4567, "imageId": "n413761", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4568, "imageId": "n413761", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4569, "imageId": "n541854", "question": "What shape is the table that is large, round or square?", "program": "BOX0=LOC(image=IMAGE,object='large table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4570, "imageId": "n77818", "question": "Are there puppies behind the wall made of brick?", "program": "BOX0=LOC(image=IMAGE,object='brick wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='puppies')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4571, "imageId": "n235859", "question": "Do you see any black wine or coffee?", "program": "BOX0=LOC(image=IMAGE,object='wine')\nBOX1=LOC(image=IMAGE,object='coffee')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4572, "imageId": "n486200", "question": "Does the traffic sign that is not antique look small and metallic?", "program": "BOX0=LOC(image=IMAGE,object='traffic sign')\nBOX1=LOC(image=IMAGE,object='antique')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the traffic sign look like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small and metallic' and {BOX1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4573, "imageId": "n160664", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4574, "imageId": "n77818", "question": "What is the animal behind the wall made of brick?", "program": "BOX0=LOC(image=IMAGE,object='brick wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4575, "imageId": "n77818", "question": "Which kind of animal is behind the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is behind the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4576, "imageId": "n146522", "question": "Who is wearing an athletic shoe?", "program": "BOX0=LOC(image=IMAGE,object='athletic shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing an athletic shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4577, "imageId": "n331357", "question": "The small animal is drinking from who?", "program": "BOX0=LOC(image=IMAGE,object='small animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the small animal drinking from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4578, "imageId": "n451187", "question": "What is the street made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the street made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4579, "imageId": "n331357", "question": "What animal is drinking from the mother?", "program": "BOX0=LOC(image=IMAGE,object='mother')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is drinking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4580, "imageId": "n331357", "question": "What is the animal that is drinking from the mom that is not small?", "program": "BOX0=LOC(image=IMAGE,object='mom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What is the animal?')\nANSWER1=VQA(image=IMAGE0,question='Is the animal small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'no' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4581, "imageId": "n4777", "question": "Is the table behind the chair wooden and small?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE0,question='How big is the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4582, "imageId": "n4777", "question": "Is the container that looks brown made of paper?", "program": "BOX0=LOC(image=IMAGE,object='brown container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the container made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'paper' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4583, "imageId": "n431447", "question": "Who is the restaurant filled with?", "program": "BOX0=LOC(image=IMAGE,object='restaurant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the restaurant filled with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4584, "imageId": "n431447", "question": "Who is the large restaurant filled with?", "program": "ANSWER0=VQA(image=IMAGE,question='Who is the large restaurant filled with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4585, "imageId": "n488874", "question": "What is the colorful watercraft called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the colorful watercraft called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4586, "imageId": "n59676", "question": "Which side of the image is the plate on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4587, "imageId": "n460385", "question": "What clothing item is worn?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What clothing item is worn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4588, "imageId": "n511913", "question": "On which side is the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4589, "imageId": "n164272", "question": "Are there large cows or zebras?", "program": "BOX0=LOC(image=IMAGE,object='cow')\nBOX1=LOC(image=IMAGE,object='zebra')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4590, "imageId": "n79078", "question": "Is the gray shirt short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='gray shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4591, "imageId": "n157375", "question": "Are there both airplanes and trucks in the picture?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nBOX1=LOC(image=IMAGE,object='truck')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4592, "imageId": "n501609", "question": "The appliance that is on the floor has what color?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What color is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4593, "imageId": "n480253", "question": "What is connected to the utility pole made of wood?", "program": "BOX0=LOC(image=IMAGE,object='utility pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nANSWER0=VQA(image=IMAGE0,question='What is connected to the utility pole?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4594, "imageId": "n480253", "question": "The wire is connected to what?", "program": "BOX0=LOC(image=IMAGE,object='wire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The wire is connected to what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4595, "imageId": "n480253", "question": "To what is the wire connected?", "program": "BOX0=LOC(image=IMAGE,object='wire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='To what is the wire connected?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4596, "imageId": "n310828", "question": "Are there people to the left of the mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4597, "imageId": "n548534", "question": "Is the floor beige or dark brown?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the floor?')\nANSWER1=EVAL(expr=\"'beige' if {ANSWER0} == 'beige' else 'dark brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4598, "imageId": "n513429", "question": "Is the turned-on laptop on the desk closed and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the laptop closed?')\nANSWER1=VQA(image=IMAGE1,question='Is the laptop rectangular?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4599, "imageId": "n65202", "question": "Who is wearing a wristwatch?", "program": "BOX0=LOC(image=IMAGE,object='wristwatch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a wristwatch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4600, "imageId": "n140421", "question": "Are there vases to the right of the curtains?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vases')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4601, "imageId": "n445353", "question": "What is the vase on?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the vase on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4602, "imageId": "n489699", "question": "Who is looking up?", "program": "BOX0=LOC(image=IMAGE,object='up')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking up?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4603, "imageId": "n489699", "question": "What is the standing child to the left of the helmet doing?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='standing child')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the standing child doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4604, "imageId": "n256120", "question": "Is the flag behind the van square and green?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the flag square?')\nANSWER1=VQA(image=IMAGE1,question='What color is the flag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4605, "imageId": "n493357", "question": "Is the park that looks green large or small?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the park that looks green large or small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4606, "imageId": "n489699", "question": "Who in the picture is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4607, "imageId": "n140421", "question": "Is the white clock to the right or to the left of the appliance that is in front of the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='white clock')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4608, "imageId": "n445353", "question": "What is on the table made of wood?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the table made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4609, "imageId": "n445353", "question": "What is on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4610, "imageId": "n357784", "question": "Do you see either any bottle or cup that are not made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nBOX1=LOC(image=IMAGE,object='cup')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4611, "imageId": "n403734", "question": "Are there briefcases or purses that are made of leather?", "program": "BOX0=LOC(image=IMAGE,object='briefcase')\nBOX1=LOC(image=IMAGE,object='purse')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What material is the briefcase made of?')\nANSWER4=VQA(image=IMAGE,question='What material is the purse made of?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} == 'leather' or {ANSWER4} == 'leather' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 4612, "imageId": "n367944", "question": "What device is white?", "program": "BOX0=LOC(image=IMAGE,object='white')\nANSWER0=VQA(image=IMAGE,question='What device is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4613, "imageId": "n357784", "question": "What is the bottle made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the bottle made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4614, "imageId": "n117888", "question": "Is the sand thick?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sand thick?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4615, "imageId": "n522733", "question": "Is the building the same material as the pole?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pole')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the building made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the pole made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4616, "imageId": "n263180", "question": "Is the building that is made of brick both rectangular and white?", "program": "BOX0=LOC(image=IMAGE,object='brick building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the building rectangular?')\nANSWER1=VQA(image=IMAGE0,question='What color is the building?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4617, "imageId": "n263180", "question": "Is the apartment building rectangular?", "program": "BOX0=LOC(image=IMAGE,object='apartment building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the apartment building rectangular?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4618, "imageId": "n475030", "question": "Are the people skiing?", "program": "BOX0=LOC(image=IMAGE,object='ski')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4619, "imageId": "n16936", "question": "Who is standing on the skateboard that looks black?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is standing on the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4620, "imageId": "n534106", "question": "What is the item of furniture that is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4621, "imageId": "n51002", "question": "What is the color of the fireplace the TV is above?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fireplace')\nANSWER0=VQA(image=IMAGE0,question='What is the color of the fireplace?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4622, "imageId": "n344136", "question": "On which side are the thin books?", "program": "BOX0=LOC(image=IMAGE,object='thin books')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4623, "imageId": "n148872", "question": "Which color is the shirt the girl is standing next to?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shirt')\nANSWER0=VQA(image=IMAGE0,question='Which color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4624, "imageId": "n477702", "question": "Are there any glasses or laptops?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nBOX1=LOC(image=IMAGE,object='laptop')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4625, "imageId": "n570181", "question": "Are both the face mask that looks red and the black face mask metallic?", "program": "BOX0=LOC(image=IMAGE,object='red face mask')\nBOX1=LOC(image=IMAGE,object='black face mask')\nANSWER0=VQA(image=IMAGE,question='Is the red face mask metallic?')\nANSWER1=VQA(image=IMAGE,question='Is the black face mask metallic?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4626, "imageId": "n355339", "question": "What is the device that is not on?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='What is the device that is not on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4627, "imageId": "n500209", "question": "What is the vegetable that is sitting inside the green bowls?", "program": "BOX0=LOC(image=IMAGE,object='green bowls')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the vegetable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4628, "imageId": "n167552", "question": "What is the person near the shoes wearing?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4629, "imageId": "n167552", "question": "What is the person wearing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4630, "imageId": "n69237", "question": "What does the pillow lean against?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the pillow lean against?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4631, "imageId": "n500209", "question": "What is the squash sitting inside of?", "program": "BOX0=LOC(image=IMAGE,object='squash')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the squash sitting inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4632, "imageId": "n500209", "question": "Is the squash that looks big sitting inside the green bowls?", "program": "BOX0=LOC(image=IMAGE,object='green bowls')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='squash')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4633, "imageId": "n534106", "question": "What is located on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4634, "imageId": "n16378", "question": "Are there any papers to the left of the man that is walking behind the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='papers')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4635, "imageId": "n473688", "question": "What is in front of the bath tub?", "program": "BOX0=LOC(image=IMAGE,object='bath tub')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the bath tub?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4636, "imageId": "n473688", "question": "What's in front of the bathtub?", "program": "BOX0=LOC(image=IMAGE,object='bathtub')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the bathtub?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4637, "imageId": "n125122", "question": "What is in front of the curtains that look white?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the curtains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4638, "imageId": "n543966", "question": "Do the animals that are standing look gray and wet?", "program": "BOX0=LOC(image=IMAGE,object='standing animals')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the standing animals?')\nANSWER1=VQA(image=IMAGE0,question='Do the standing animals look wet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4639, "imageId": "n546884", "question": "Is the receipt on an ottoman?", "program": "BOX0=LOC(image=IMAGE,object='ottoman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='receipt')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4640, "imageId": "n246334", "question": "Is the pillow on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4641, "imageId": "n250715", "question": "How old is the pilot that is to the right of the device?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pilot')\nANSWER0=VQA(image=IMAGE0,question='How old is the pilot?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4642, "imageId": "n187544", "question": "Is there a frisbee to the left of the person in the middle?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='frisbee')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4643, "imageId": "n543966", "question": "Are the elephants wet or dry?", "program": "BOX0=LOC(image=IMAGE,object='elephants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the elephants wet or dry?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4644, "imageId": "n51658", "question": "What is the man holding onto?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4645, "imageId": "n51658", "question": "The person below the tennis ball is holding onto what?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4646, "imageId": "n489190", "question": "Do the trees in front of the fence look green and abundant?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color are the trees?')\nANSWER3=VQA(image=IMAGE0,question='Do the trees look abundant?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'green' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 4647, "imageId": "n51658", "question": "Is the standing person below the tennis ball holding onto the tennis racket on the right?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='standing person')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='tennis racket')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4648, "imageId": "n500308", "question": "Is the floor made of the same material as the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='floor')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the wall made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the floor made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4649, "imageId": "n167552", "question": "What is the black dog doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the black dog doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4650, "imageId": "n23181", "question": "What color is the couch on the left of the photo?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=VQA(image=IMAGE0,question='What color is the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4651, "imageId": "n258500", "question": "Are there rackets in the picture?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4652, "imageId": "n326988", "question": "Which kind of furniture is not brown?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is not brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4653, "imageId": "n326988", "question": "What pieces of furniture are wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='What pieces of furniture are wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4654, "imageId": "n70461", "question": "What color is the vehicle to the left of the traffic signal?", "program": "BOX0=LOC(image=IMAGE,object='traffic signal')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4655, "imageId": "n326988", "question": "What items of furniture are made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nANSWER0=VQA(image=IMAGE,question='What items of furniture are made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4656, "imageId": "n244826", "question": "Who is the soccer ball in front of?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the soccer ball in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4657, "imageId": "n55058", "question": "Do you see any cups or glasses in this photo?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nBOX1=LOC(image=IMAGE,object='glass')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4658, "imageId": "n324908", "question": "Are these animals of different species?", "program": "ANSWER0=VQA(image=IMAGE,question='Are these animals of different species?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4659, "imageId": "n324908", "question": "What place could this be?", "program": "ANSWER0=VQA(image=IMAGE,question='What place could this be?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4660, "imageId": "n324908", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4661, "imageId": "n232810", "question": "Is the silver lamp on the right side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='silver lamp')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4662, "imageId": "n500308", "question": "What material is the smooth floor?", "program": "BOX0=LOC(image=IMAGE,object='smooth floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the smooth floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4663, "imageId": "n238266", "question": "What material is the cake stand, metal or glass?", "program": "BOX0=LOC(image=IMAGE,object='cake stand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the cake stand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4664, "imageId": "n469525", "question": "What color is the tall grass?", "program": "BOX0=LOC(image=IMAGE,object='tall grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tall grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4665, "imageId": "n437192", "question": "Which size is the bear on top of the other bear, small or large?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bear')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} > 0 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4666, "imageId": "n28996", "question": "What is the food below the round fruits?", "program": "BOX0=LOC(image=IMAGE,object='round fruits')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4667, "imageId": "n380113", "question": "Are there soccer players to the left of the person in the top part?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='soccer player')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4668, "imageId": "n511913", "question": "Is there a table in front of the person that is wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='jeans')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='table')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4669, "imageId": "n355567", "question": "Do you see any stainless steel clocks or faucets?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nBOX1=LOC(image=IMAGE,object='faucet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4670, "imageId": "n310625", "question": "What is leaning against the faucet on the right of the image?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='faucet')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is leaning against the faucet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4671, "imageId": "n140421", "question": "On which side of the picture is the large refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='large refrigerator')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4672, "imageId": "n111390", "question": "Who is sitting at the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting at the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4673, "imageId": "n314630", "question": "What is the appliance that the sharp knives are reflected in?", "program": "BOX0=LOC(image=IMAGE,object='sharp knives')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4674, "imageId": "n315887", "question": "Which kind of device is the phone in front of?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is the phone in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4675, "imageId": "n285391", "question": "Does the pillow on top of the other pillow look uncomfortable and soft?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the pillow on top of the other pillow look uncomfortable and soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4676, "imageId": "n315887", "question": "What is the phone in front of?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the phone in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4677, "imageId": "n315887", "question": "What device is in front of the computer?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is in front of the computer?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4678, "imageId": "n315887", "question": "What's the phone in front of?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the phone in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4679, "imageId": "n100991", "question": "What vegetables are to the left of the fork?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetables')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4680, "imageId": "n143672", "question": "Is the ground near the forest snowy or bare?", "program": "BOX0=LOC(image=IMAGE,object='forest')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ground')\nANSWER0=VQA(image=IMAGE0,question='What is the condition of the ground?')\nANSWER1=EVAL(expr=\"'snowy' if 'snow' in {ANSWER0} else 'bare'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4681, "imageId": "n39114", "question": "Does he wear a jersey?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does he wear a jersey?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4682, "imageId": "n39114", "question": "Who wears the glove?", "program": "BOX0=LOC(image=IMAGE,object='glove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the glove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4683, "imageId": "n477702", "question": "Which kind of furniture is wide?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is wide?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4684, "imageId": "n477702", "question": "Is this a coffee table or a sofa?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nBOX1=LOC(image=IMAGE,object='sofa')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'coffee table' if {ANSWER0} > 0 else 'sofa'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4685, "imageId": "n259949", "question": "Are there skateboards in the image?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4686, "imageId": "n477702", "question": "What piece of furniture is soft?", "program": "ANSWER0=VQA(image=IMAGE,question='What piece of furniture is soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4687, "imageId": "n172618", "question": "Does the long hair look curly?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the long hair look curly?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4688, "imageId": "n256120", "question": "Does the beige jacket have light weight?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the weight of the beige jacket?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'light' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4689, "imageId": "n546616", "question": "Does the marker look red and long?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the marker?')\nANSWER1=VQA(image=IMAGE,question='What is the length of the marker?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4690, "imageId": "n243701", "question": "Is the woman to the left or to the right of the person that wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='person that wears a shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4691, "imageId": "n119886", "question": "How long is the toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nANSWER0=VQA(image=IMAGE,question='How long is the toilet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4692, "imageId": "n486200", "question": "Is the new vehicle on the right or on the left side?", "program": "BOX0=LOC(image=IMAGE,object='new vehicle')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4693, "imageId": "n159802", "question": "Is the person that is to the left of the water bottle both young and Asian?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Is the person young?')\nANSWER3=VQA(image=IMAGE1,question='Is the person Asian?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 4694, "imageId": "n534106", "question": "Who do you think is eating the donut?", "program": "BOX0=LOC(image=IMAGE,object='donut')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is eating the donut?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4695, "imageId": "n479092", "question": "What is the plate made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the plate made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4696, "imageId": "n219840", "question": "What animal stands at the green grass?", "program": "BOX0=LOC(image=IMAGE,object='green grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal stands at the green grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4697, "imageId": "n578564", "question": "What is the appliance to the left of the jar in this photo?", "program": "BOX0=LOC(image=IMAGE,object='jar')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4698, "imageId": "n497789", "question": "What is the color of the lush trees below the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lush trees')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the lush trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4699, "imageId": "n513100", "question": "What kind of furniture is the fence behind of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is behind the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4700, "imageId": "n298104", "question": "Is the flower on the surfboard large and white?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flower')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='flower')\nIMAGE1=CROP(image=IMAGE0,box=BOX2)\nANSWER2=VQA(image=IMAGE1,question='What color is the flower?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'white' else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 4701, "imageId": "n513100", "question": "Which kind of furniture is the fence behind of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is behind the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4702, "imageId": "n280089", "question": "Are the jars to the right of the mugs that are sitting on top of the stove?", "program": "BOX0=LOC(image=IMAGE,object='mugs')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stove')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='jars')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4703, "imageId": "n398257", "question": "Is the shelf full and stainless steel?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shelf full?')\nANSWER1=VQA(image=IMAGE0,question='What material is the shelf made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'stainless steel' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4704, "imageId": "n272313", "question": "Who do you think is on the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is on the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4705, "imageId": "n51658", "question": "Who is holding onto the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding onto the tennis racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4706, "imageId": "n398257", "question": "Is the full shelf made of steel?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the shelf made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'steel' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4707, "imageId": "n500308", "question": "Is there any cabinet to the left of the appliance next to the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='cabinet')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4708, "imageId": "n274905", "question": "Who is holding the tennis racket that looks yellow and gray?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the tennis racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4709, "imageId": "n296467", "question": "Which side are the chocolate cookies on?", "program": "BOX0=LOC(image=IMAGE,object='chocolate cookies')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4710, "imageId": "n98544", "question": "Is the toilet white and dirty?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet?')\nANSWER1=VQA(image=IMAGE0,question='Is the toilet dirty?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4711, "imageId": "n433692", "question": "What is the pot made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the pot made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4712, "imageId": "n235859", "question": "Who is the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4713, "imageId": "n187961", "question": "Do you see both sheep and goats?", "program": "BOX0=LOC(image=IMAGE,object='sheep')\nBOX1=LOC(image=IMAGE,object='goat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4714, "imageId": "n214497", "question": "What is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4715, "imageId": "n214497", "question": "The man is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The man is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4716, "imageId": "n278453", "question": "Does the person wear glasses?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the person wear glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4717, "imageId": "n28792", "question": "What is the bald man holding?", "program": "BOX0=LOC(image=IMAGE,object='bald man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bald man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4718, "imageId": "n264887", "question": "Which kind of furniture is large?", "program": "BOX0=LOC(image=IMAGE,object='large furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4719, "imageId": "n255161", "question": "What sign is written?", "program": "ANSWER0=VQA(image=IMAGE,question='What sign is written?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4720, "imageId": "n150962", "question": "Are there mattresses or carts?", "program": "BOX0=LOC(image=IMAGE,object='mattress')\nBOX1=LOC(image=IMAGE,object='cart')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4721, "imageId": "n173807", "question": "What kind of vehicle is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='metal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is made of metal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4722, "imageId": "n255161", "question": "What is the written sign?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the written sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4723, "imageId": "n173807", "question": "What is the name of the vehicle that is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='metal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4724, "imageId": "n255161", "question": "What sign is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What sign is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4725, "imageId": "n390187", "question": "What is the color of the dirty sneakers?", "program": "BOX0=LOC(image=IMAGE,object='dirty sneakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the dirty sneakers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4726, "imageId": "n187961", "question": "What animal do you think is to the left of the person that is on the right of the photo?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4727, "imageId": "n195249", "question": "Is the wristband Nike and orange?", "program": "BOX0=LOC(image=IMAGE,object='wristband')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What brand is the wristband?')\nANSWER1=VQA(image=IMAGE0,question='What color is the wristband?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'Nike' and {ANSWER1} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4728, "imageId": "n546884", "question": "What is the cup on?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cup on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4729, "imageId": "n508641", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4730, "imageId": "n95313", "question": "What kind of furniture is behind the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is behind the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4731, "imageId": "n508641", "question": "Is the man near the catcher wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_NEAR(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the man wearing?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4732, "imageId": "n229548", "question": "What is that aircraft called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is that aircraft called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4733, "imageId": "n77818", "question": "Which shape does the tissue box have?", "program": "BOX0=LOC(image=IMAGE,object='tissue box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which shape does the tissue box have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4734, "imageId": "n77818", "question": "What animal is the tissue box behind of?", "program": "BOX0=LOC(image=IMAGE,object='tissue box')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the tissue box behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4735, "imageId": "n98544", "question": "What is in the bathroom?", "program": "ANSWER0=VQA(image=IMAGE,question='What is in the bathroom?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4736, "imageId": "n119944", "question": "Who is the fat woman looking at?", "program": "BOX0=LOC(image=IMAGE,object='fat woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the fat woman looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4737, "imageId": "n111390", "question": "How big is the window the telephone is sitting at?", "program": "BOX0=LOC(image=IMAGE,object='telephone')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4738, "imageId": "n119944", "question": "Who is looking at the man that is not old?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking at the man that is not old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4739, "imageId": "n95313", "question": "Which kind of furniture is the bed in front of?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the bed in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4740, "imageId": "n119944", "question": "Is the fat woman wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='fat woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gloves')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4741, "imageId": "n151768", "question": "Do the boxes have a different shape than the steps?", "program": "BOX0=LOC(image=IMAGE,object='boxes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='steps')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What shape are the boxes?')\nANSWER1=VQA(image=IMAGE1,question='What shape are the steps?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4742, "imageId": "n302387", "question": "Are there bottles or tables in this scene?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4743, "imageId": "n518912", "question": "Is the floor low and green?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the floor?')\nANSWER1=VQA(image=IMAGE0,question='Is the floor low?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4744, "imageId": "n88366", "question": "Does the jacket have red color?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4745, "imageId": "n210269", "question": "Does the fence near the wall have black color?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the fence?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4746, "imageId": "n151768", "question": "Are the cane and the barrier made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='cane')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='barrier')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the cane made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the barrier made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4747, "imageId": "n565418", "question": "Is the parking lot clean?", "program": "BOX0=LOC(image=IMAGE,object='parking lot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the parking lot clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4748, "imageId": "n23181", "question": "Are the draperies thin?", "program": "BOX0=LOC(image=IMAGE,object='draperies')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the draperies thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4749, "imageId": "n562105", "question": "What is the color of the bat that is holding onto the other bat?", "program": "BOX0=LOC(image=IMAGE,object='bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other bat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the bat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4750, "imageId": "n520071", "question": "How clean are the books that are not horizontal?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horizontal books')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How clean are the books?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4751, "imageId": "n111390", "question": "Does the gray coat appear to be thick?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the gray coat appear to be thick?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4752, "imageId": "n367944", "question": "Which kind of device is not on?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='Which kind of device is not on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4753, "imageId": "n367944", "question": "Which kind of device is not on, the calculator or the laptop?", "program": "BOX0=LOC(image=IMAGE,object='calculator')\nBOX1=LOC(image=IMAGE,object='laptop')\nANSWER0=VQA(image=IMAGE,question='Is the calculator on?')\nANSWER1=VQA(image=IMAGE,question='Is the laptop on?')\nANSWER2=EVAL(expr=\"'calculator' if {ANSWER0} == 'no' else 'laptop'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4754, "imageId": "n415215", "question": "Do both the toilet brush near the toilet and the tool have black color?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet brush')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='tool')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='What color is the toilet brush?')\nANSWER1=VQA(image=IMAGE2,question='What color is the tool?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4755, "imageId": "n199758", "question": "Does the skinny person look tall or short?", "program": "BOX0=LOC(image=IMAGE,object='skinny person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the skinny person look tall or short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4756, "imageId": "n570181", "question": "Who is wearing the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4757, "imageId": "n570181", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4758, "imageId": "n143935", "question": "What color is the cow on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cow')\nANSWER0=VQA(image=IMAGE0,question='What color is the cow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4759, "imageId": "n479092", "question": "Is the napkin on the right?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4760, "imageId": "n499081", "question": "How large is the shower?", "program": "BOX0=LOC(image=IMAGE,object='shower')\nANSWER0=VQA(image=IMAGE,question='How large is the shower?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4761, "imageId": "n54424", "question": "Is the color of the pillow the same as that of the shuttle?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shuttle')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the pillow?')\nANSWER1=VQA(image=IMAGE1,question='What color is the shuttle?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4762, "imageId": "n346736", "question": "Is the branch lying next to a train?", "program": "BOX0=LOC(image=IMAGE,object='train')\nIMAGE0=CROP_NEXTTO(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='branch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4763, "imageId": "n24526", "question": "Is the car on the left of the picture?", "program": "BOX0=LOC(image=IMAGE,object='car')\nANSWER0=EVAL(expr=\"'yes' if {BOX0} < 0.5 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4764, "imageId": "n528403", "question": "Who is flying the flying kite above the tree?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flying kite')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is flying the flying kite?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4765, "imageId": "n16936", "question": "What's the skateboarder standing on?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skateboarder standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4766, "imageId": "n363445", "question": "What are the fruits in this photograph called?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the fruits in this photograph called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4767, "imageId": "n363445", "question": "Which kind of fruit is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fruit is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4768, "imageId": "n16936", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4769, "imageId": "n199097", "question": "Is the old man wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='old man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4770, "imageId": "n117888", "question": "What is underneath the athlete that is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shorts')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is underneath the athlete?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4771, "imageId": "n12404", "question": "Is the person to the right of the traffic cone standing beside the dirt that looks wet?", "program": "BOX0=LOC(image=IMAGE,object='traffic cone')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='wet dirt')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4772, "imageId": "n59627", "question": "Is the large blanket to the right or to the left of the man in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='blanket')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4773, "imageId": "n44249", "question": "Does the animal beside the fence have small size?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What size is the animal?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4774, "imageId": "n274905", "question": "What color is the metal fence?", "program": "BOX0=LOC(image=IMAGE,object='metal fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the metal fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4775, "imageId": "n69237", "question": "Is the bedroom that is not dirty both white and small?", "program": "BOX0=LOC(image=IMAGE,object='dirty')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bedroom')\nANSWER0=VQA(image=IMAGE0,question='What color is the bedroom?')\nANSWER1=VQA(image=IMAGE0,question='What size is the bedroom?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4776, "imageId": "n172618", "question": "How long is the straight hair?", "program": "BOX0=LOC(image=IMAGE,object='straight hair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the straight hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4777, "imageId": "n531359", "question": "Which side are the tables on?", "program": "BOX0=LOC(image=IMAGE,object='tables')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4778, "imageId": "n125122", "question": "Are there both a chair and a lamp in this photo?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4779, "imageId": "n35676", "question": "Do you see either bowls or cabinets in the photo?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nBOX1=LOC(image=IMAGE,object='cabinet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4780, "imageId": "n534106", "question": "What is the piece of furniture that is long called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the piece of furniture that is long called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4781, "imageId": "n433692", "question": "Is the mouse pad gray and square?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the mouse pad?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the mouse pad?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4782, "imageId": "n90294", "question": "Does the device next to the laptop computer look short and white?", "program": "BOX0=LOC(image=IMAGE,object='laptop computer')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What color is the device?')\nANSWER1=VQA(image=IMAGE0,question='Does the device look short?')\nANSWER2=VQA(image=IMAGE0,question='Does the device look white?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 4783, "imageId": "n470131", "question": "Is the sweet dessert sitting beside the food in front of the tape?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tape')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='sweet dessert')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4784, "imageId": "n243701", "question": "Is the young person to the right or to the left of the bag the man is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='young person')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4785, "imageId": "n272098", "question": "What food is frosted?", "program": "BOX0=LOC(image=IMAGE,object='frosted')\nANSWER0=VQA(image=IMAGE,question='What food is frosted?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4786, "imageId": "n518912", "question": "Do you see any chair on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4787, "imageId": "n470131", "question": "Is the tape white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the tape?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4788, "imageId": "n295771", "question": "Which kind of furniture is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4789, "imageId": "n259002", "question": "Are there trash cans to the left of the soccer player that is kicking the ball?", "program": "BOX0=LOC(image=IMAGE,object='soccer player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ball')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='trash cans')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4790, "imageId": "n546884", "question": "What is the cup made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the cup made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4791, "imageId": "n546884", "question": "What is the cup to the right of the donut made of?", "program": "BOX0=LOC(image=IMAGE,object='donut')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cup')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the cup made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4792, "imageId": "n414992", "question": "What is the man that looks happy wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4793, "imageId": "n23181", "question": "Are the drapes closed or open?", "program": "BOX0=LOC(image=IMAGE,object='drapes')\nANSWER0=VQA(image=IMAGE,question='Are the drapes closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4794, "imageId": "n260521", "question": "What is the tall person reading?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tall person reading?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4795, "imageId": "n511913", "question": "What kind of device is to the right of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is to the right of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4796, "imageId": "n37274", "question": "Who is wearing the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4797, "imageId": "n446242", "question": "What do you think is the shape of the picture?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is the shape of the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4798, "imageId": "n70461", "question": "Does the shopping center look large or small?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the shopping center look large or small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4799, "imageId": "n451187", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4800, "imageId": "n88366", "question": "Does the mountain side appear to be white?", "program": "BOX0=LOC(image=IMAGE,object='mountain')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the mountain side?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4801, "imageId": "n380113", "question": "Is the hair band white and round?", "program": "BOX0=LOC(image=IMAGE,object='hair band')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hair band?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the hair band?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4802, "imageId": "n88366", "question": "Does the mountain side that looks white look snowy?", "program": "BOX0=LOC(image=IMAGE,object='white mountain side')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the mountain side look snowy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4803, "imageId": "n282436", "question": "Is there a green couch or table?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4804, "imageId": "n310625", "question": "On which side is the blue toothbrush?", "program": "BOX0=LOC(image=IMAGE,object='blue toothbrush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4805, "imageId": "n271392", "question": "Who is sitting on the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting on the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4806, "imageId": "n65885", "question": "Which kind of animal is this, a dog or a bird?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is this, a dog or a bird?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4807, "imageId": "n414992", "question": "Is the shirt both irregular and black?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE,question='Is the shirt irregular?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4808, "imageId": "n150962", "question": "Do the coats look thin?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the coats look thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4809, "imageId": "n310828", "question": "What color is the device that she works on?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4810, "imageId": "n150962", "question": "Is the white sign above the light fixture that is above the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light fixture')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='white sign')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4811, "imageId": "n170941", "question": "What do both the pancake and the coffee mug have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the pancake and the coffee mug have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4812, "imageId": "n528403", "question": "Does the skirt look black and small?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the skirt?')\nANSWER1=VQA(image=IMAGE,question='Does the skirt look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4813, "imageId": "n520071", "question": "How tall is the lamp which is to the right of the computer?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=VQA(image=IMAGE0,question='How tall is the lamp?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4814, "imageId": "n507959", "question": "Behind what is the person that is to the left of the palm sitting?", "program": "BOX0=LOC(image=IMAGE,object='palm')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='sitting')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'behind the palm' if {ANSWER0} > 0 else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4815, "imageId": "n151768", "question": "Is the open umbrella to the right or to the left of the person on the right?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='open umbrella')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4816, "imageId": "n357126", "question": "What color is the house, brown or white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the house?')\nANSWER1=EVAL(expr=\"'brown' if {ANSWER0} == 'brown' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4817, "imageId": "n4777", "question": "What is common to the bag and the lid?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the bag and the lid?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4818, "imageId": "n271392", "question": "Who is sitting on the long bench?", "program": "BOX0=LOC(image=IMAGE,object='long bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting on the long bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4819, "imageId": "n46510", "question": "Which kind of sign is walking?", "program": "BOX0=LOC(image=IMAGE,object='walking sign')\nANSWER0=VQA(image=IMAGE,question='Which kind of sign is walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4820, "imageId": "n579256", "question": "What do you think is in the large appliance?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is in the large appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4821, "imageId": "n579256", "question": "What is in the refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in the refrigerator?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4822, "imageId": "n46510", "question": "What is the yellow sign in this photo?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the yellow sign in this photo?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4823, "imageId": "n579256", "question": "What's the sauce in?", "program": "BOX0=LOC(image=IMAGE,object='sauce')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sauce in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4824, "imageId": "n240973", "question": "Where in the photo is the laptop, on the right or on the left?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='laptop')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4825, "imageId": "n532191", "question": "Is that sweater blue or tan?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sweater?')\nANSWER1=EVAL(expr=\"'blue' if {ANSWER0} == 'blue' else 'tan'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4826, "imageId": "n494918", "question": "What is the color of the frisbee that flies above the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='frisbee')\nANSWER0=VQA(image=IMAGE0,question='What is the color of the frisbee?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4827, "imageId": "n363445", "question": "What is the food in the picture called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the food in the picture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4828, "imageId": "n363445", "question": "Which kind of fast food is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fast food is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4829, "imageId": "n100991", "question": "What kind of food is to the left of the egg?", "program": "BOX0=LOC(image=IMAGE,object='egg')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What kind of food is to the left of the egg?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4830, "imageId": "n527589", "question": "Is the woman Caucasian or Asian?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the woman Caucasian or Asian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4831, "imageId": "n546616", "question": "What food is on top of the cake?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What food is on top of the cake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4832, "imageId": "n546616", "question": "Is the chocolate on top of a cake?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chocolate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4833, "imageId": "n363445", "question": "Which kind of fast food is pink?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fast food is pink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4834, "imageId": "n250715", "question": "How clean is the brown shirt?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the brown shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4835, "imageId": "n23762", "question": "Is it indoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it indoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4836, "imageId": "n315887", "question": "Does the tape behind the coffee cup look small or large?", "program": "BOX0=LOC(image=IMAGE,object='coffee cup')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tape')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} > 0 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4837, "imageId": "n318684", "question": "Is the man to the left of the glasses holding onto the umbrella to the right of the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='umbrella')\nIMAGE2=CROP_RIGHTOF(image=IMAGE0,box=BOX2)\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4838, "imageId": "n318684", "question": "Who do you think is holding onto the umbrella to the right of the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is holding onto the umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4839, "imageId": "n344136", "question": "Are both the bookcase and the window frame made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='window frame')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the bookcase made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the window frame made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4840, "imageId": "n318684", "question": "Is the man to the left of the glasses wearing a tie?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the man wearing a tie?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4841, "imageId": "n479092", "question": "What are the forks made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the forks made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4842, "imageId": "n275148", "question": "What's the desk made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the desk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4843, "imageId": "n275148", "question": "What is the desk made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the desk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4844, "imageId": "n573460", "question": "Who holds the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who holds the tennis racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4845, "imageId": "n573460", "question": "What does the professional person hold?", "program": "BOX0=LOC(image=IMAGE,object='professional person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the professional person hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4846, "imageId": "n283587", "question": "What item of furniture is behind the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is behind the coffee table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4847, "imageId": "n283587", "question": "What kind of furniture is the sofa behind of?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is behind the sofa?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4848, "imageId": "n283587", "question": "Which kind of furniture is below the light fixture?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is below the light fixture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4849, "imageId": "n167164", "question": "Does the car seem to be small and gray?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the car?')\nANSWER1=VQA(image=IMAGE0,question='Does the car seem small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4850, "imageId": "n25275", "question": "Is the soccer ball yellow and round?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the soccer ball?')\nANSWER1=VQA(image=IMAGE,question='What shape is the soccer ball?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4851, "imageId": "n207708", "question": "Which kind of furniture is the door behind of?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is behind the door?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4852, "imageId": "n207708", "question": "What is the item of furniture that the door is behind of?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4853, "imageId": "n6309", "question": "Which kind of animal is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4854, "imageId": "n380113", "question": "What color is the head band?", "program": "BOX0=LOC(image=IMAGE,object='head band')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the head band?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4855, "imageId": "n216553", "question": "Which animal is this, a horse or a pig?", "program": "ANSWER0=VQA(image=IMAGE,question='Which animal is this, a horse or a pig?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4856, "imageId": "n311910", "question": "What is the sidewalk made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sidewalk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4857, "imageId": "n446242", "question": "Is the silver mirror on the right side or on the left?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='silver')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4858, "imageId": "n159802", "question": "What device is to the left of the water bottle made of stainless steel?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What material is the device made of?')\nANSWER1=EVAL(expr=\"'stainless steel' if {ANSWER0} == 'yes' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4859, "imageId": "n520071", "question": "Is the radio both modern and black?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the radio modern?')\nANSWER1=VQA(image=IMAGE,question='What color is the radio?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4860, "imageId": "n485969", "question": "Does the leather belt look thin and red?", "program": "ANSWER0=VQA(image=IMAGE,question='What does the leather belt look like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'thin and red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4861, "imageId": "n578564", "question": "What is the appliance below the chalkboard near the artwork?", "program": "BOX0=LOC(image=IMAGE,object='chalkboard')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='artwork')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4862, "imageId": "n493357", "question": "Is the park different in color than the hill side?", "program": "BOX0=LOC(image=IMAGE,object='park')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hill side')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the park?')\nANSWER1=VQA(image=IMAGE1,question='What color is the hill side?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4863, "imageId": "n262920", "question": "Is the poster large or small?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the poster large or small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4864, "imageId": "n525901", "question": "Are there large laptops or cats?", "program": "BOX0=LOC(image=IMAGE,object='laptop', size='large')\nBOX1=LOC(image=IMAGE,object='cat', size='large')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4865, "imageId": "n493357", "question": "Are the animals of different types?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the animals of different types?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4866, "imageId": "n51658", "question": "Are the people that are to the left of the tennis ball watching a kite?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis ball')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='people')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='Are the people watching a kite?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4867, "imageId": "n208458", "question": "How large are the sparse clouds?", "program": "BOX0=LOC(image=IMAGE,object='sparse clouds')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How large are the sparse clouds?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4868, "imageId": "n207893", "question": "Is the green grass below the green mountains?", "program": "BOX0=LOC(image=IMAGE,object='green mountains')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green grass')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4869, "imageId": "n16378", "question": "What clothing item is blue?", "program": "BOX0=LOC(image=IMAGE,object='blue')\nANSWER0=VQA(image=IMAGE,question='What clothing item is blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4870, "imageId": "n126891", "question": "Do the jeans and the gloves have the same color?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='gloves')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the jeans?')\nANSWER1=VQA(image=IMAGE1,question='What color are the gloves?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4871, "imageId": "n259002", "question": "Who is looking down at the ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking down at the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4872, "imageId": "n259002", "question": "Who is looking down at the ball on the grass?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking down at the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4873, "imageId": "n527290", "question": "Does she appear to be happy and Caucasian?", "program": "ANSWER0=VQA(image=IMAGE,question='Does she appear to be happy?')\nANSWER1=VQA(image=IMAGE,question='Does she appear to be Caucasian?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4874, "imageId": "n259002", "question": "Does the soccer player to the left of the ball appear to be playing?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer player')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4875, "imageId": "n310828", "question": "Which kind of clothing is warm?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is warm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4876, "imageId": "n263180", "question": "How big is the green bus?", "program": "BOX0=LOC(image=IMAGE,object='green bus')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4877, "imageId": "n525901", "question": "What is the name of the device above the white device?", "program": "BOX0=LOC(image=IMAGE,object='white device')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4878, "imageId": "n390187", "question": "Is the small mirror on the motorcycle?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4879, "imageId": "n256120", "question": "Does the girl to the right of the person wear jeans?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the girl wear jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4880, "imageId": "n311910", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4881, "imageId": "n311910", "question": "What place is shown?", "program": "ANSWER0=VQA(image=IMAGE,question='What place is shown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4882, "imageId": "n159802", "question": "Is the sweatshirt that looks soft small and black?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sweatshirt?')\nANSWER1=VQA(image=IMAGE0,question='Is the sweatshirt small?')\nANSWER2=VQA(image=IMAGE0,question='Does the sweatshirt look soft?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 4883, "imageId": "n256120", "question": "Who wears jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nANSWER0=VQA(image=IMAGE,question='Who wears jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4884, "imageId": "n97485", "question": "Does the table have small size and square shape?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the size of the table?')\nANSWER1=VQA(image=IMAGE0,question='What is the shape of the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'small' and {ANSWER1} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4885, "imageId": "n279581", "question": "Is the black net made of mesh?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the black net made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'mesh' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4886, "imageId": "n49438", "question": "Is the dresser to the left of the curtain above the bed?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='dresser')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4887, "imageId": "n160664", "question": "In front of what is the giraffe?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In front of what is the giraffe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4888, "imageId": "n16378", "question": "What article of clothing is light?", "program": "ANSWER0=VQA(image=IMAGE,question='What article of clothing is light?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4889, "imageId": "n94074", "question": "Are there either any women or men that are sitting?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nBOX1=LOC(image=IMAGE,object='man')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4890, "imageId": "n350732", "question": "Where is the soccer ball?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4891, "imageId": "n39114", "question": "Is the grass short and lush?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the grass short?')\nANSWER1=VQA(image=IMAGE,question='Is the grass lush?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4892, "imageId": "n59147", "question": "Do you think the bag to the left of the vase is empty or full?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='Is the bag empty or full?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4893, "imageId": "n259002", "question": "Which side is the male spectator on?", "program": "BOX0=LOC(image=IMAGE,object='male spectator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4894, "imageId": "n240973", "question": "Is the chicken black or white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the chicken?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4895, "imageId": "n240973", "question": "What do you think is standing on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4896, "imageId": "n469156", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4897, "imageId": "n469156", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4898, "imageId": "n334278", "question": "What do you think is the batter in front of the umpire looking at?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='batter')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the batter looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4899, "imageId": "n143935", "question": "What is in front of the barn?", "program": "BOX0=LOC(image=IMAGE,object='barn')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the barn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4900, "imageId": "n49310", "question": "What color is the long bench?", "program": "BOX0=LOC(image=IMAGE,object='long bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the long bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4901, "imageId": "n234722", "question": "Is the sausage in the bottom part or in the top of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sausage')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4902, "imageId": "n522733", "question": "How big is the black vehicle?", "program": "BOX0=LOC(image=IMAGE,object='black vehicle')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4903, "imageId": "n234722", "question": "Does the sausage that is to the left of the pan look small and brown?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sausage')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the sausage?')\nANSWER1=VQA(image=IMAGE1,question='Does the sausage look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4904, "imageId": "n472825", "question": "Who is riding on a skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is riding on a skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4905, "imageId": "n556604", "question": "How tall is the lamp that is behind the tree?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How tall is the lamp?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4906, "imageId": "n472825", "question": "Who is wearing the jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4907, "imageId": "n472825", "question": "What is the skateboarder that is not female wearing?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skateboarder wearing?')\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 'female' else {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4908, "imageId": "n472825", "question": "Who is wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4909, "imageId": "n166008", "question": "What is the item of furniture underneath the water bottle?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4910, "imageId": "n94074", "question": "The dress made of lace has which color?", "program": "BOX0=LOC(image=IMAGE,object='dress made of lace')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the dress?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4911, "imageId": "n200225", "question": "What food is not greasy, the sausage or the pizza?", "program": "BOX0=LOC(image=IMAGE,object='sausage')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pizza')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Is the sausage greasy?')\nANSWER1=VQA(image=IMAGE1,question='Is the pizza greasy?')\nANSWER2=EVAL(expr=\"'sausage' if {ANSWER0} == 'no' else 'pizza'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4912, "imageId": "n278453", "question": "Which material was used to make the white plate?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material was used to make the white plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4913, "imageId": "n94074", "question": "Does the dress made of lace look white and short?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the lace dress?')\nANSWER1=VQA(image=IMAGE,question='Is the lace dress short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4914, "imageId": "n94074", "question": "What kind of clothing is not long?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of clothing is not long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4915, "imageId": "n98540", "question": "Is there any short grass in the picture?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nANSWER0=VQA(image=IMAGE,question='Is there any short grass in the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4916, "imageId": "n210269", "question": "Do you see lamps or pictures?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='picture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4917, "imageId": "n264887", "question": "What piece of furniture is shown?", "program": "ANSWER0=VQA(image=IMAGE,question='What piece of furniture is shown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4918, "imageId": "n500308", "question": "Is this a clean refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is this a clean refrigerator?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4919, "imageId": "n28996", "question": "What type of food is not cut?", "program": "BOX0=LOC(image=IMAGE,object='cut food')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'uncut' if {ANSWER0} == 0 else 'cut'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4920, "imageId": "n508641", "question": "Do the glove and the helmet have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='glove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='helmet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the glove?')\nANSWER1=VQA(image=IMAGE1,question='What color is the helmet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4921, "imageId": "n398257", "question": "What is under the device the computer monitor is above?", "program": "BOX0=LOC(image=IMAGE,object='computer monitor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is under the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4922, "imageId": "n406334", "question": "What is in front of the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4923, "imageId": "n282607", "question": "Who is watching the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4924, "imageId": "n398257", "question": "What is the shape of the desk that is below the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='desk')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the shape of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4925, "imageId": "n282607", "question": "Who is watching the person that holds the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4926, "imageId": "n480253", "question": "What vehicle is red?", "program": "BOX0=LOC(image=IMAGE,object='red')\nBOX1=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What vehicle is red?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4927, "imageId": "n335542", "question": "Does the man that is to the left of the bear look tall and old?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='Does the man look tall and old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4928, "imageId": "n437064", "question": "Is the table underneath a bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4929, "imageId": "n329514", "question": "Do the skateboard and the rooftop have the same material?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='rooftop')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the skateboard made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the rooftop made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4930, "imageId": "n262929", "question": "Is the necktie dark?", "program": "BOX0=LOC(image=IMAGE,object='necktie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the necktie?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4931, "imageId": "n329514", "question": "Are the concrete steps below the window that is below the chimney?", "program": "BOX0=LOC(image=IMAGE,object='chimney')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='concrete steps')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4932, "imageId": "n526228", "question": "What shape are the pillows that look big?", "program": "BOX0=LOC(image=IMAGE,object='big pillows')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape are the pillows?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4933, "imageId": "n290409", "question": "What animal is inside the truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is inside the truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4934, "imageId": "n100991", "question": "Does the paper napkin look square and white?", "program": "BOX0=LOC(image=IMAGE,object='paper napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the paper napkin?')\nANSWER1=VQA(image=IMAGE0,question='What color is the paper napkin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'square' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4935, "imageId": "n264887", "question": "Which kind of device is behind the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is behind the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4936, "imageId": "n541688", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4937, "imageId": "n290409", "question": "Does the dog inside the truck look black and happy?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dog')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the dog?')\nANSWER1=VQA(image=IMAGE1,question='Is the dog happy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4938, "imageId": "n336443", "question": "Does the bowl to the right of the plate look white and empty?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the bowl?')\nANSWER3=VQA(image=IMAGE0,question='Is the bowl empty?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 4939, "imageId": "n264887", "question": "What type of device is behind the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of device is behind the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4940, "imageId": "n272098", "question": "Is the white rope on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white rope')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4941, "imageId": "n12214", "question": "Which color is the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4942, "imageId": "n329479", "question": "What is he in front of?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is he in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4943, "imageId": "n329479", "question": "What do the bench and the skateboard have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the bench and the skateboard have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4944, "imageId": "n69237", "question": "How does the floor made of wood look, stained or clean?", "program": "ANSWER0=VQA(image=IMAGE,question='How does the floor made of wood look, stained or clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4945, "imageId": "n417401", "question": "What is the sink made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sink made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4946, "imageId": "n433532", "question": "On which side are the plates?", "program": "BOX0=LOC(image=IMAGE,object='plates')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4947, "imageId": "n125122", "question": "Is the wood chair behind the desk below the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='desk')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='wood chair')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4948, "imageId": "n66756", "question": "Who is standing beside the home plate?", "program": "BOX0=LOC(image=IMAGE,object='home plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing beside the home plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4949, "imageId": "n49310", "question": "What kind of clothing is striped?", "program": "BOX0=LOC(image=IMAGE,object='striped clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4950, "imageId": "n77818", "question": "Does that pepper shaker look round?", "program": "ANSWER0=VQA(image=IMAGE,question='Does that pepper shaker look round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4951, "imageId": "n14087", "question": "Which kind of furniture are the curtains behind of?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4952, "imageId": "n64959", "question": "The window near the switch has which shape?", "program": "BOX0=LOC(image=IMAGE,object='switch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nANSWER0=VQA(image=IMAGE1,question='The window near the switch has which shape?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4953, "imageId": "n313060", "question": "What is in the coffee?", "program": "ANSWER0=VQA(image=IMAGE,question='What is in the coffee?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4954, "imageId": "n313060", "question": "What is the straw in?", "program": "BOX0=LOC(image=IMAGE,object='straw')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the straw in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4955, "imageId": "n313060", "question": "What's the straw in?", "program": "BOX0=LOC(image=IMAGE,object='straw')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the straw in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4956, "imageId": "n417401", "question": "What kind of furniture is inside the small bathroom?", "program": "BOX0=LOC(image=IMAGE,object='small bathroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is inside the small bathroom?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4957, "imageId": "n209843", "question": "Is the white toilet to the left or to the right of the cabinet that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white toilet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4958, "imageId": "n290409", "question": "What vehicle is thin?", "program": "BOX0=LOC(image=IMAGE,object='thin')\nANSWER0=VQA(image=IMAGE,question='What vehicle is thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4959, "imageId": "n455563", "question": "Is it an outdoors or indoors picture?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an outdoors or indoors picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4960, "imageId": "n246334", "question": "Are there any black phones or monitors?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nBOX1=LOC(image=IMAGE,object='monitor')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4961, "imageId": "n66756", "question": "What is the door covered in?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the door covered in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4962, "imageId": "n579256", "question": "Is the bottle to the right or to the left of the person on the floor?", "program": "BOX0=LOC(image=IMAGE,object='person on the floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4963, "imageId": "n571179", "question": "Is the coat gray?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the coat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4964, "imageId": "n527290", "question": "Is the shirt long sleeved and striped?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the shirt long sleeved?')\nANSWER1=VQA(image=IMAGE,question='Is the shirt striped?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4965, "imageId": "n455563", "question": "What is common to the outlet and the bathroom?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the outlet and the bathroom?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4966, "imageId": "n485969", "question": "What color do you think the shirt is?", "program": "ANSWER0=VQA(image=IMAGE,question='What color do you think the shirt is?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4967, "imageId": "n12404", "question": "Is the machine behind a cone?", "program": "BOX0=LOC(image=IMAGE,object='cone')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='machine')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4968, "imageId": "n455563", "question": "On which side is the medicine cabinet?", "program": "BOX0=LOC(image=IMAGE,object='medicine cabinet')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4969, "imageId": "n398429", "question": "Is the bench behind the table that looks red?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4970, "imageId": "n276011", "question": "Which side of the image is the old picture on?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='old picture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4971, "imageId": "n283587", "question": "What is the color of the countertop that looks rectangular?", "program": "BOX0=LOC(image=IMAGE,object='rectangular countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4972, "imageId": "n207708", "question": "Does the plant have a different color than the bookcase?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bookcase')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the plant?')\nANSWER1=VQA(image=IMAGE1,question='What color is the bookcase?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4973, "imageId": "n500308", "question": "Is the color of the table different than the color of the floor?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='floor')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=VQA(image=IMAGE1,question='What color is the floor?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4974, "imageId": "n54424", "question": "Who is sitting on top of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting on top of the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4975, "imageId": "n12404", "question": "What is the color of the container?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4976, "imageId": "n14087", "question": "What is the item of furniture that the curtains are behind of?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4977, "imageId": "n116329", "question": "Are there chairs below the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4978, "imageId": "n541482", "question": "Is the grass brown or green?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nANSWER0=VQA(image=IMAGE,question='What color is the grass?')\nANSWER1=EVAL(expr=\"'green' if {ANSWER0} == 'green' else 'brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4979, "imageId": "n541482", "question": "Do you see either a kite or a lamp there?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4980, "imageId": "n477702", "question": "Who wears the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4981, "imageId": "n350766", "question": "Is there a toaster above the drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toaster')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4982, "imageId": "n9181", "question": "Is the motorcycle near the jacket black and metallic?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorcycle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the motorcycle?')\nANSWER3=VQA(image=IMAGE0,question='What material is the motorcycle made of?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'black' and {ANSWER3} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 4983, "imageId": "n235859", "question": "Who is the person that is posing holding?", "program": "BOX0=LOC(image=IMAGE,object='holding')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4984, "imageId": "n131634", "question": "Is the van in the top part or in the bottom of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='van')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4985, "imageId": "n432591", "question": "Is there a clock that is not on?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='on')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4986, "imageId": "n548534", "question": "Are there any ovens or cabinets that are black?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nBOX1=LOC(image=IMAGE,object='cabinet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What color is the oven?')\nANSWER4=VQA(image=IMAGE,question='What color is the cabinet?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} == 'black' or {ANSWER4} == 'black' else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 4987, "imageId": "n350766", "question": "What is the appliance above the drawer called?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4988, "imageId": "n477702", "question": "Does the cloth shirt have blue color?", "program": "BOX0=LOC(image=IMAGE,object='cloth shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cloth shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4989, "imageId": "n350766", "question": "What appliance is above the drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is above the drawer?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4990, "imageId": "n9181", "question": "Is the motorcycle on the right part?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorcycle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4991, "imageId": "n355567", "question": "Is the plastic bat Adidas and modern?", "program": "BOX0=LOC(image=IMAGE,object='plastic bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What brand is the plastic bat?')\nANSWER1=VQA(image=IMAGE0,question='Is the plastic bat modern?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'Adidas' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 4992, "imageId": "n216553", "question": "What is the animal that is on top of the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4993, "imageId": "n92308", "question": "What kind of animal is playing in the grass?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of animal is playing in the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4994, "imageId": "n274905", "question": "Are the trousers brown?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the trousers?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4995, "imageId": "n59676", "question": "Who is the plate in front of?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the plate in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4996, "imageId": "n518912", "question": "What is the man that is not young standing beside of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man standing beside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 4997, "imageId": "n455563", "question": "On which side of the picture is the small bottle, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='small bottle')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='small bottle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4998, "imageId": "n4777", "question": "Is the woman in the top part or in the bottom?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 4999, "imageId": "n386688", "question": "What type of watercraft is floating on the ocean?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of watercraft is floating on the ocean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5000, "imageId": "n520071", "question": "Is the water bottle full?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the water bottle full?')\nFINAL_RESULT=RESULT(var=ANSWER0)"},{"index": 5001, "imageId": "n116329", "question": "Is the metal fence to the right or to the left of the man the door is behind of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='door')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='metal fence')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5002, "imageId": "n127705", "question": "Are there white rackets in this image?", "program": "BOX0=LOC(image=IMAGE,object='rackets')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5003, "imageId": "n312206", "question": "Is the packet on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='packet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5004, "imageId": "n4777", "question": "Is the short bottle to the left of a cup?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5005, "imageId": "n296467", "question": "What vegetables are not orange?", "program": "BOX0=LOC(image=IMAGE,object='orange vegetables')\nANSWER0=VQA(image=IMAGE,question='What vegetables are not orange?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5006, "imageId": "n162148", "question": "Does the shirt have white color?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5007, "imageId": "n54424", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5008, "imageId": "n133585", "question": "What is the color of the hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5009, "imageId": "n317260", "question": "Who is waiting?", "program": "BOX0=LOC(image=IMAGE,object='waiting')\nANSWER0=VQA(image=IMAGE,question='Who is waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5010, "imageId": "n162148", "question": "What is worn on the undershirt?", "program": "BOX0=LOC(image=IMAGE,object='undershirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is worn on the undershirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5011, "imageId": "n223750", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5012, "imageId": "n493357", "question": "What is the animal to the right of the house?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5013, "imageId": "n256120", "question": "Are the large tents on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large tents')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5014, "imageId": "n493357", "question": "Where is the giraffe that looks yellow and brown eating from?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the giraffe eating from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5015, "imageId": "n145498", "question": "Does the table lamp have large size and white color?", "program": "BOX0=LOC(image=IMAGE,object='table lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the size of the table lamp?')\nANSWER1=VQA(image=IMAGE0,question='What color is the table lamp?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5016, "imageId": "n160664", "question": "Are there giraffes in front of the forest that is not sparse?", "program": "BOX0=LOC(image=IMAGE,object='forest')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='giraffes')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5017, "imageId": "n525901", "question": "Is the wood desk above the cords red or tan?", "program": "BOX0=LOC(image=IMAGE,object='cords')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood desk')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the wood desk?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'tan'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5018, "imageId": "n160664", "question": "The giraffe is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The giraffe is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5019, "imageId": "n293477", "question": "Which kind of furniture is the wallet lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='wallet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the wallet lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5020, "imageId": "n160664", "question": "Which kind of animal is in front of the forest?", "program": "BOX0=LOC(image=IMAGE,object='forest')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is in front of the forest?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5021, "imageId": "n445353", "question": "The chairs that are on the left of the photo have what tone?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nANSWER0=VQA(image=IMAGE0,question='What tone are the chairs?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5022, "imageId": "n167164", "question": "Is the traffic light above the SUV green or black?", "program": "BOX0=LOC(image=IMAGE,object='SUV')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic light')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the traffic light?')\nANSWER1=EVAL(expr=\"'green' if {ANSWER0} == 'green' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5023, "imageId": "n344136", "question": "Are there either curtains or blankets?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nBOX1=LOC(image=IMAGE,object='blankets')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5024, "imageId": "n302387", "question": "How thick are the books?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How thick are the books?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5025, "imageId": "n334278", "question": "Does the player that is to the right of the batter seem to be waiting?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='player')\nANSWER0=VQA(image=IMAGE0,question='Does the player seem to be waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5026, "imageId": "n326988", "question": "What is the woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5027, "imageId": "n554880", "question": "What is that man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is that man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5028, "imageId": "n441859", "question": "How large is the sand?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5029, "imageId": "n263180", "question": "Does the building behind the car look brown?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='building')\nANSWER0=VQA(image=IMAGE0,question='What color is the building?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5030, "imageId": "n355339", "question": "Is there either a laptop or a chair that is made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=VQA(image=IMAGE,question='What material is the laptop made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the chair made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' or {ANSWER1} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5031, "imageId": "n90944", "question": "Is the clear sky bright and white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE,question='Is the sky bright?')\nANSWER2=VQA(image=IMAGE,question='Is the sky white?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'clear' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 5032, "imageId": "n570181", "question": "How long is the baseball bat the batter is holding?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='baseball bat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How long is the baseball bat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5033, "imageId": "n217003", "question": "Who is riding on the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is riding on the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5034, "imageId": "n217003", "question": "Who is riding on a skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is riding on a skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5035, "imageId": "n217003", "question": "Who is jumping?", "program": "BOX0=LOC(image=IMAGE,object='jumping')\nANSWER0=VQA(image=IMAGE,question='Who is jumping?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5036, "imageId": "n507149", "question": "Is the sky both huge and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sky huge?')\nANSWER1=VQA(image=IMAGE,question='Is the sky white?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5037, "imageId": "n557666", "question": "Is the woman to the right of the person that is standing near the truck?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='truck')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='woman')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5038, "imageId": "n473688", "question": "Is the sink clean and blue?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the sink clean?')\nANSWER1=VQA(image=IMAGE0,question='What color is the sink?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'clean' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5039, "imageId": "n531731", "question": "Who is on the field?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is on the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5040, "imageId": "n167164", "question": "Do you think that house is blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Do you think that house is blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5041, "imageId": "n554880", "question": "Which kind of device is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5042, "imageId": "n357784", "question": "Does she wear a necklace?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does she wear a necklace?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5043, "imageId": "n445353", "question": "What is in front of the bricks?", "program": "BOX0=LOC(image=IMAGE,object='bricks')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the bricks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5044, "imageId": "n554880", "question": "What's the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5045, "imageId": "n554880", "question": "What is the device that the man is in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5046, "imageId": "n207708", "question": "Which color is the countertop made of granite?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the countertop made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5047, "imageId": "n546884", "question": "Is the lid that looks oval made of stainless steel?", "program": "BOX0=LOC(image=IMAGE,object='lid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape does the lid look like?')\nANSWER1=VQA(image=IMAGE0,question='What material is the lid made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'oval' and {ANSWER1} == 'stainless steel' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5048, "imageId": "n167164", "question": "Does the bright house have small size and blue color?", "program": "BOX0=LOC(image=IMAGE,object='bright house')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the size of the bright house?')\nANSWER1=VQA(image=IMAGE0,question='What is the color of the bright house?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'small' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5049, "imageId": "n119944", "question": "Is the small child on the left side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small child')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5050, "imageId": "n187544", "question": "Does the field look smooth and snowy?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the field look smooth?')\nANSWER1=VQA(image=IMAGE,question='Does the field look snowy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5051, "imageId": "n433692", "question": "What is the cat lying on?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cat lying on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5052, "imageId": "n141939", "question": "Are both the tissue box that looks square and the toilet white?", "program": "BOX0=LOC(image=IMAGE,object='tissue box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='toilet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What shape is the tissue box?')\nANSWER1=VQA(image=IMAGE1,question='What color is the toilet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'square' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5053, "imageId": "n540852", "question": "Is the happy man below the umbrella the woman is holding?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='happy man')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5054, "imageId": "n282607", "question": "Is the crowd sitting?", "program": "BOX0=LOC(image=IMAGE,object='crowd')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the crowd sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5055, "imageId": "n513429", "question": "What do both the keyboard and the desk have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the keyboard and the desk have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5056, "imageId": "n51002", "question": "Is the lamp to the left or to the right of the vase?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5057, "imageId": "n473688", "question": "Is the toilet dirty?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the toilet dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5058, "imageId": "n417401", "question": "What size is the toilet seat that is white?", "program": "BOX0=LOC(image=IMAGE,object='toilet seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the toilet seat?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'small' else 'not white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5059, "imageId": "n350732", "question": "The man is looking at what?", "program": "ANSWER0=VQA(image=IMAGE,question='The man is looking at what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5060, "imageId": "n326988", "question": "Which kind of furniture are the glasses inside of?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture are the glasses inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5061, "imageId": "n222915", "question": "What fruits are brown?", "program": "BOX0=LOC(image=IMAGE,object='brown fruit')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5062, "imageId": "n222915", "question": "What food is not sliced, the apples or the vegetables?", "program": "BOX0=LOC(image=IMAGE,object='apples')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='vegetables')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Are the apples sliced?')\nANSWER1=VQA(image=IMAGE1,question='Are the vegetables sliced?')\nANSWER2=EVAL(expr=\"'apples' if {ANSWER0} == 'no' else 'vegetables'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5063, "imageId": "n222915", "question": "What food isn't sliced?", "program": "BOX0=LOC(image=IMAGE,object='food')\nANSWER0=VQA(image=IMAGE,question='What food isn\\'t sliced?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5064, "imageId": "n222915", "question": "What is the food that is not sliced called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the food that is not sliced called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5065, "imageId": "n282436", "question": "Does that office look small and modern?", "program": "ANSWER0=VQA(image=IMAGE,question='Does that office look small?')\nANSWER1=VQA(image=IMAGE,question='Does that office look modern?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5066, "imageId": "n477215", "question": "What are the animals that are flying above the bridge called?", "program": "BOX0=LOC(image=IMAGE,object='bridge')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animals')\nANSWER0=VQA(image=IMAGE0,question='What are the animals called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5067, "imageId": "n477215", "question": "What animal is flying above the bridge?", "program": "BOX0=LOC(image=IMAGE,object='bridge')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is flying?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5068, "imageId": "n187544", "question": "Is the person playing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5069, "imageId": "n543966", "question": "Is the dark sky clear or cloudy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the dark sky clear or cloudy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5070, "imageId": "n153293", "question": "What is sitting inside the shelves?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting inside the shelves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5071, "imageId": "n477215", "question": "What are the birds flying above?", "program": "BOX0=LOC(image=IMAGE,object='birds')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the birds flying above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5072, "imageId": "n6309", "question": "Is the fence on the right of the image?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5073, "imageId": "n526228", "question": "How is the piece of furniture to the left of the couch that is in front of the mirror called?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='piece of furniture')\nANSWER0=VQA(image=IMAGE1,question='How is the piece of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5074, "imageId": "n154856", "question": "Which material is the bench which is to the left of the lamp made of, concrete or iron?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=VQA(image=IMAGE0,question='Which material is the bench made of?')\nANSWER1=EVAL(expr=\"'concrete' if {ANSWER0} == 'concrete' else 'iron'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5075, "imageId": "n315859", "question": "Are the glass windows round and dark?", "program": "BOX0=LOC(image=IMAGE,object='glass windows')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='round')\nANSWER1=COUNT(box=BOX1)\nBOX2=LOC(image=IMAGE,object='dark')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 and {ANSWER2} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 5076, "imageId": "n154856", "question": "What color is the bench made of cement?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bench made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5077, "imageId": "n382416", "question": "Who is wearing a coat?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a coat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5078, "imageId": "n382416", "question": "Is the tall person wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gloves')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5079, "imageId": "n314630", "question": "Are there any ovens or cabinets?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nBOX1=LOC(image=IMAGE,object='cabinet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5080, "imageId": "n44249", "question": "Is the woman to the right or to the left of the heavy person?", "program": "BOX0=LOC(image=IMAGE,object='heavy person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5081, "imageId": "n315887", "question": "What is the device to the right of the device that is gray and silver?", "program": "BOX0=LOC(image=IMAGE,object='gray and silver device')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5082, "imageId": "n310625", "question": "Is the toothbrush on the right side?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5083, "imageId": "n526228", "question": "Is the unlit lamp on the right or on the left side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='unlit lamp')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5084, "imageId": "n437064", "question": "How clean is the spoon?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the spoon?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5085, "imageId": "n264887", "question": "Is the white keyboard to the right or to the left of the mousepad?", "program": "BOX0=LOC(image=IMAGE,object='mousepad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='keyboard')\nBOX2=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5086, "imageId": "n58220", "question": "Is the man to the left of the flag?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5087, "imageId": "n412144", "question": "Does the skate park below the skateboarder look wooden and high?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skate park')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material does the skate park look like?')\nANSWER1=VQA(image=IMAGE1,question='Does the skate park look high?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5088, "imageId": "n282607", "question": "What's the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5089, "imageId": "n296467", "question": "What type of food is to the right of the container that is not open?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not open')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of food is to the right?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5090, "imageId": "n187544", "question": "How clean are the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean are the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5091, "imageId": "n470920", "question": "Are the metal glasses to the right or to the left of the man who is holding onto the sweater?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sweater')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='metal glasses')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5092, "imageId": "n54180", "question": "Is the tap silver and large?", "program": "BOX0=LOC(image=IMAGE,object='tap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tap?')\nANSWER1=VQA(image=IMAGE0,question='How large is the tap?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5093, "imageId": "n206785", "question": "What is the bag sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bag sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5094, "imageId": "n481777", "question": "What is the male person doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the male person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5095, "imageId": "n486200", "question": "Is the minivan new?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the minivan new?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5096, "imageId": "n222915", "question": "Which kind of food is not green?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is not green?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5097, "imageId": "n275148", "question": "Is there any speaker behind the couch near the wall?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='speaker')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5098, "imageId": "n209843", "question": "Do you see a mirror or an umbrella in this scene?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nBOX1=LOC(image=IMAGE,object='umbrella')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5099, "imageId": "n283587", "question": "Does the towel look thick?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the towel look thick?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5100, "imageId": "n222915", "question": "Which kind of food is not leafy?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is not leafy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5101, "imageId": "n153118", "question": "Is the vehicle in front of the trees metallic and short?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='metallic')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='short')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 5102, "imageId": "n573460", "question": "What is the small audience sitting on?", "program": "BOX0=LOC(image=IMAGE,object='small audience')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the small audience sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5103, "imageId": "n525029", "question": "What is parked near the buildings the sign post is across from?", "program": "BOX0=LOC(image=IMAGE,object='sign post')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='buildings')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is parked near the buildings?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5104, "imageId": "n14087", "question": "What is the animal in the picture?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the animal in the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5105, "imageId": "n23181", "question": "Is the mirror above the fireplace?", "program": "BOX0=LOC(image=IMAGE,object='fireplace')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5106, "imageId": "n398257", "question": "Which side of the image is the rug on?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5107, "imageId": "n228268", "question": "Does the shirt look short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5108, "imageId": "n159802", "question": "Is the man near the water bottle both Caucasian and adult?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the ethnicity of the man?')\nANSWER1=VQA(image=IMAGE0,question='What is the age of the man?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'Caucasian' and {ANSWER1} == 'adult' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5109, "imageId": "n398257", "question": "Is the rug behind the sweatshirt made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=VQA(image=IMAGE0,question='What material is the rug made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'cloth' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5110, "imageId": "n187961", "question": "What is the animal in front of the happy person that is in front of the goat?", "program": "BOX0=LOC(image=IMAGE,object='goat')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nANSWER0=VQA(image=IMAGE1,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5111, "imageId": "n187961", "question": "What animal is the person that is walking leading?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the person leading?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5112, "imageId": "n187961", "question": "Is the brown sheep in front of a person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown sheep')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5113, "imageId": "n386688", "question": "Which color are the sailboats that are below the boats?", "program": "BOX0=LOC(image=IMAGE,object='boats')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sailboats')\nANSWER0=VQA(image=IMAGE0,question='Which color are the sailboats?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5114, "imageId": "n187961", "question": "What is the animal that the person that is walking is leading?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal that the person is leading?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5115, "imageId": "n98544", "question": "How clean is the faucet?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the faucet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5116, "imageId": "n278453", "question": "What kind of clothing is tight?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of clothing is tight?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5117, "imageId": "n195249", "question": "Which type of clothing is not comfortable, the hat or the tank top?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nBOX1=LOC(image=IMAGE,object='tank top')\nANSWER0=VQA(image=IMAGE,question='Which type of clothing is not comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5118, "imageId": "n278453", "question": "What clothing items are blue?", "program": "BOX0=LOC(image=IMAGE,object='blue')\nANSWER0=VQA(image=IMAGE,question='What clothing items are blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5119, "imageId": "n281241", "question": "Are both the dress shirt and the jacket black?", "program": "BOX0=LOC(image=IMAGE,object='dress shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='jacket')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the dress shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5120, "imageId": "n195249", "question": "Which kind of clothing is light blue?", "program": "BOX0=LOC(image=IMAGE,object='light blue clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5121, "imageId": "n195249", "question": "What is the light blue clothing item?", "program": "BOX0=LOC(image=IMAGE,object='light blue clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the clothing item?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5122, "imageId": "n255161", "question": "What is the artwork on?", "program": "BOX0=LOC(image=IMAGE,object='artwork')\nANSWER0=VQA(image=IMAGE,question='What is the artwork on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5123, "imageId": "n195249", "question": "What kind of clothing is comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of clothing is comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5124, "imageId": "n544255", "question": "Do you think the trees below the sky are leafy or bare?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Do you think the trees are leafy or bare?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5125, "imageId": "n250821", "question": "Is the man drinking or staring?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the man drinking or staring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5126, "imageId": "n192021", "question": "Does the couch on the carpet look green?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the couch?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5127, "imageId": "n413761", "question": "What's the car in front of?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the car in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5128, "imageId": "n508641", "question": "Which part is the umpire in?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which part is the umpire in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5129, "imageId": "n14", "question": "On which side of the image is the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5130, "imageId": "n192021", "question": "Do you see couches or lamps that are not red?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What color is the couch?')\nANSWER4=VQA(image=IMAGE,question='What color is the lamp?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} != 'red' or {ANSWER4} != 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 5131, "imageId": "n398257", "question": "Is the keyboard black or is it white?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the keyboard?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5132, "imageId": "n299528", "question": "What's the bush in front of?", "program": "BOX0=LOC(image=IMAGE,object='bush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bush in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5133, "imageId": "n413002", "question": "What is she carrying?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is she carrying?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5134, "imageId": "n278312", "question": "Is it an outdoors scene?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an outdoors scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5135, "imageId": "n55058", "question": "Which kind of cooking utensil is curved?", "program": "BOX0=LOC(image=IMAGE,object='cooking utensil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of cooking utensil is curved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5136, "imageId": "n9181", "question": "What's the wheelchair in front of?", "program": "BOX0=LOC(image=IMAGE,object='wheelchair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the wheelchair in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5137, "imageId": "n9181", "question": "What is in front of the vest?", "program": "BOX0=LOC(image=IMAGE,object='vest')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the vest?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5138, "imageId": "n357784", "question": "Do the outlets and the wires have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='outlets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='wires')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the outlets?')\nANSWER1=VQA(image=IMAGE1,question='What color are the wires?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5139, "imageId": "n119944", "question": "Is the fat woman on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fat woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5140, "imageId": "n466319", "question": "Does the sky look blue and cloudless?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE,question='Are there any clouds in the sky?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5141, "imageId": "n393305", "question": "Who is in front of the sign that is on top of the pole?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is in front of the sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5142, "imageId": "n435808", "question": "Is the color of the chair the same as that of the computer?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='computer')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=VQA(image=IMAGE1,question='What color is the computer?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5143, "imageId": "n317189", "question": "Are there both helmets and gloves in the picture?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nBOX1=LOC(image=IMAGE,object='gloves')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5144, "imageId": "n48494", "question": "Are both the train station and the tunnel made out of the same material?", "program": "BOX0=LOC(image=IMAGE,object='train station')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='tunnel')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the train station made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the tunnel made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5145, "imageId": "n565418", "question": "How is the vehicle to the right of the fence called?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='How is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5146, "imageId": "n477702", "question": "How does the cotton shirt seem to be, long sleeved or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='cotton shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How does the cotton shirt seem to be, long sleeved or short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5147, "imageId": "n69237", "question": "Which kind of furniture is low?", "program": "BOX0=LOC(image=IMAGE,object='low')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is low?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5148, "imageId": "n318370", "question": "Does the male person appear to be sitting?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the person appear to be sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5149, "imageId": "n545516", "question": "What is the device that he holds?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the device he holds?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5150, "imageId": "n219840", "question": "Are the trees behind the path old and tall?", "program": "BOX0=LOC(image=IMAGE,object='path')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5151, "imageId": "n570181", "question": "Who is wearing the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5152, "imageId": "n570181", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5153, "imageId": "n153293", "question": "Are there shelves next to the wall the towels hang from?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towels')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='shelves')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5154, "imageId": "n234683", "question": "Which kind of clothing is ugly?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is ugly?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5155, "imageId": "n289376", "question": "Where is the street sign that looks white and green standing?", "program": "BOX0=LOC(image=IMAGE,object='street sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the street sign standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5156, "imageId": "n578564", "question": "What is the blue object above the flower pot hang from?", "program": "BOX0=LOC(image=IMAGE,object='flower pot')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blue object')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the blue object above the flower pot hang from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5157, "imageId": "n309148", "question": "What vehicle is white?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=VQA(image=IMAGE,question='What color is the vehicle?')\nANSWER1=EVAL(expr=\"'car' if {ANSWER0} == 'white' else 'truck'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5158, "imageId": "n479092", "question": "What's the tray made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the tray made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5159, "imageId": "n488874", "question": "Is the surf board both long and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the surf board long?')\nANSWER1=VQA(image=IMAGE,question='Is the surf board white?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5160, "imageId": "n296467", "question": "What is inside the container?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5161, "imageId": "n411121", "question": "Is the silver van to the left or to the right of the female person?", "program": "BOX0=LOC(image=IMAGE,object='female person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='silver van')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5162, "imageId": "n210269", "question": "Is the garage near the door open and yellow?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='garage')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the garage open?')\nANSWER1=VQA(image=IMAGE1,question='What color is the garage?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'open' and {ANSWER1} == 'yellow' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5163, "imageId": "n68769", "question": "Are there any women beside the green plant?", "program": "BOX0=LOC(image=IMAGE,object='green plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='women')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5164, "imageId": "n199097", "question": "How big is the man that is not young?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the man?')\nANSWER1=VQA(image=IMAGE0,question='Is the man young?')\nANSWER2=EVAL(expr=\"'not young' if {ANSWER1} == 'no' else 'young'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5165, "imageId": "n363445", "question": "Is the small lid above a dessert?", "program": "BOX0=LOC(image=IMAGE,object='dessert')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small lid')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5166, "imageId": "n250715", "question": "Which side is the white device on?", "program": "BOX0=LOC(image=IMAGE,object='white device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5167, "imageId": "n181210", "question": "Is the cup behind the orange closed or open?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the cup open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5168, "imageId": "n363445", "question": "Does the purple thing above the dessert look small?", "program": "BOX0=LOC(image=IMAGE,object='dessert')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='purple thing')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5169, "imageId": "n187544", "question": "What's the person doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What\\'s the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5170, "imageId": "n260521", "question": "Is the book above a bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='book')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5171, "imageId": "n470131", "question": "Is there a red bottle or can?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nBOX1=LOC(image=IMAGE,object='can')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5172, "imageId": "n318684", "question": "Does the bench seem to be rough and wooden?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the bench seem to be rough and wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5173, "imageId": "n460556", "question": "Are there both bicycles and chimneys?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nBOX1=LOC(image=IMAGE,object='chimney')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5174, "imageId": "n202379", "question": "Are the dark trees leafy or bare?", "program": "BOX0=LOC(image=IMAGE,object='dark trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the trees leafy or bare?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5175, "imageId": "n77818", "question": "Are both the tissue box behind the cat and the pepper shaker brown?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tissue box')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='pepper shaker')\nANSWER0=VQA(image=IMAGE1,question='What color is the tissue box?')\nANSWER1=VQA(image=IMAGE,question='What color is the pepper shaker?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5176, "imageId": "n59627", "question": "Are there either any small towels or blankets?", "program": "BOX0=LOC(image=IMAGE,object='small towels')\nBOX1=LOC(image=IMAGE,object='blankets')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5177, "imageId": "n235859", "question": "Are the smiling people that are to the left of the light bulb both old and fat?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light bulb')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='smiling people')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5178, "imageId": "n235859", "question": "Are there any chairs or students?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='student')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5179, "imageId": "n125122", "question": "What item of furniture is in front of the curtains?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is in front of the curtains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5180, "imageId": "n125122", "question": "Are there any round nightstands or lamps?", "program": "BOX0=LOC(image=IMAGE,object='nightstand')\nBOX1=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5181, "imageId": "n16378", "question": "What is the weight of the luggage cart?", "program": "BOX0=LOC(image=IMAGE,object='luggage cart')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the weight of the luggage cart?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5182, "imageId": "n160664", "question": "Are there either any benches or helmets?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nBOX1=LOC(image=IMAGE,object='helmet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5183, "imageId": "n160664", "question": "Is the man uncomfortable or comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the man uncomfortable or comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5184, "imageId": "n470131", "question": "Which kind of food is the tape behind of?", "program": "BOX0=LOC(image=IMAGE,object='tape')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of food is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5185, "imageId": "n470131", "question": "Is the tape behind the cookie?", "program": "BOX0=LOC(image=IMAGE,object='cookie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tape')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5186, "imageId": "n95904", "question": "What size is the blue backpack?", "program": "BOX0=LOC(image=IMAGE,object='blue backpack')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the blue backpack?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5187, "imageId": "n546884", "question": "What is in the basket?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in the basket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5188, "imageId": "n336443", "question": "Is the fork to the right or to the left of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fork')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5189, "imageId": "n66756", "question": "Who is wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='glove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a glove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5190, "imageId": "n406334", "question": "Is the large vehicle to the right or to the left of the vehicles near the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicles')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='large vehicle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5191, "imageId": "n150962", "question": "Do the chair and the pot have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pot')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=VQA(image=IMAGE1,question='What color is the pot?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5192, "imageId": "n68769", "question": "Which kind of furniture is not white?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is not white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5193, "imageId": "n23181", "question": "On which side are the draperies?", "program": "BOX0=LOC(image=IMAGE,object='draperies')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5194, "imageId": "n168412", "question": "On which side of the photo is the huge animal?", "program": "BOX0=LOC(image=IMAGE,object='huge animal')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5195, "imageId": "n429961", "question": "What is the broccoli in?", "program": "BOX0=LOC(image=IMAGE,object='broccoli')\nANSWER0=VQA(image=IMAGE,question='What is the broccoli in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5196, "imageId": "n429961", "question": "What kind of vegetable is to the left of the box?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetable')\nANSWER0=VQA(image=IMAGE0,question='What kind of vegetable is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5197, "imageId": "n4777", "question": "Does the person to the right of the cup appear to be sitting?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5198, "imageId": "n514467", "question": "Is he to the left of a trash can?", "program": "BOX0=LOC(image=IMAGE,object='trash can')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='he')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5199, "imageId": "n369313", "question": "Is that window triangular and clear?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the window triangular?')\nANSWER1=VQA(image=IMAGE0,question='Is the window clear?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5200, "imageId": "n572716", "question": "Does the mountain have the same color as the crane?", "program": "BOX0=LOC(image=IMAGE,object='mountain')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='crane')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the mountain?')\nANSWER1=VQA(image=IMAGE1,question='What color is the crane?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5201, "imageId": "n413319", "question": "What's the player doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What\\'s the player doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5202, "imageId": "n4777", "question": "Is the woman sitting on a bed?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5203, "imageId": "n451187", "question": "How wide is the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nANSWER0=VQA(image=IMAGE,question='How wide is the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5204, "imageId": "n264887", "question": "What is the name of the device on top of the desk made of wood?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the name of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5205, "imageId": "n532191", "question": "Which kind of furniture is patterned?", "program": "BOX0=LOC(image=IMAGE,object='patterned furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5206, "imageId": "n77818", "question": "Is that entertainment center full and wooden?", "program": "BOX0=LOC(image=IMAGE,object='entertainment center')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the entertainment center full?')\nANSWER1=VQA(image=IMAGE0,question='What material is the entertainment center made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5207, "imageId": "n130638", "question": "How old is the girl that is sitting-down?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sitting-down')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How old is the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5208, "imageId": "n55058", "question": "What is the cooking utensil that is made of same material as the rectangular table called?", "program": "BOX0=LOC(image=IMAGE,object='rectangular table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cooking utensil that is made of same material as the rectangular table called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5209, "imageId": "n55058", "question": "Is the cutting board made of the same material as the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cutting board')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the cutting board made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5210, "imageId": "n117888", "question": "Who is wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing gloves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5211, "imageId": "n117888", "question": "Who is wearing the gloves?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the gloves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5212, "imageId": "n222915", "question": "In which part of the image is the metal utensil, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='metal utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5213, "imageId": "n117888", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5214, "imageId": "n536256", "question": "What is inside the TV stand that stands against the wall?", "program": "BOX0=LOC(image=IMAGE,object='TV stand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the TV stand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5215, "imageId": "n140421", "question": "What are the cushioned items of furniture called?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the cushioned items of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5216, "imageId": "n334278", "question": "What do both the uniform and the fence have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the uniform and the fence have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5217, "imageId": "n4777", "question": "Is the bottle orange or blue?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bottle?')\nANSWER1=EVAL(expr=\"'orange' if {ANSWER0} == 'orange' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5218, "imageId": "n466319", "question": "Does the dark shirt look short sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the dark shirt look short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5219, "imageId": "n314171", "question": "How tall is the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='How tall is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5220, "imageId": "n100552", "question": "Is the container made of the same material as the fence?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fence')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the container made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the fence made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5221, "imageId": "n204894", "question": "Are there any phones?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5222, "imageId": "n66756", "question": "Does the door look closed?", "program": "BOX0=LOC(image=IMAGE,object='door')\nANSWER0=VQA(image=IMAGE,question='Does the door look closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5223, "imageId": "n363445", "question": "What is the color of the cut food that is above the apples?", "program": "BOX0=LOC(image=IMAGE,object='apples')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cut food')\nANSWER0=VQA(image=IMAGE0,question='What is the color of the cut food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5224, "imageId": "n146555", "question": "Which color do you think the shirt is?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color do you think the shirt is?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5225, "imageId": "n532191", "question": "On which side is the coffee cup?", "program": "BOX0=LOC(image=IMAGE,object='coffee cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5226, "imageId": "n532191", "question": "Does the coffee cup look brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the coffee cup look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5227, "imageId": "n363445", "question": "Which type of food is not cut, the carrots or the hot dogs?", "program": "BOX0=LOC(image=IMAGE,object='carrots')\nBOX1=LOC(image=IMAGE,object='hot dogs')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'carrots' if {ANSWER0} > {ANSWER1} else 'hot dogs'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5228, "imageId": "n116329", "question": "Is the woman on the right or on the left side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5229, "imageId": "n302358", "question": "Is the bench white or brown?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bench?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'brown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5230, "imageId": "n511913", "question": "Which kind of furniture is the woman before?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the woman before?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5231, "imageId": "n71728", "question": "Who do you think does the young person sit beside?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who does the young person sit beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5232, "imageId": "n116329", "question": "Do you see a woman that is not irregular?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='irregular')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5233, "imageId": "n511913", "question": "What type of furniture is the woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is the woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5234, "imageId": "n511913", "question": "What is this woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is this woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5235, "imageId": "n243701", "question": "Does the store look open and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the store look open?')\nANSWER1=VQA(image=IMAGE,question='Does the store look large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5236, "imageId": "n162148", "question": "What type of clothing is striped?", "program": "BOX0=LOC(image=IMAGE,object='striped clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5237, "imageId": "n243701", "question": "How large is the store?", "program": "ANSWER0=VQA(image=IMAGE,question='How large is the store?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5238, "imageId": "n548534", "question": "Do the oven and the refrigerator have the same color?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='refrigerator')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the oven?')\nANSWER1=VQA(image=IMAGE1,question='What color is the refrigerator?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5239, "imageId": "n170941", "question": "Is there any bacon in this picture that is long?", "program": "BOX0=LOC(image=IMAGE,object='bacon')\nBOX1=LOC(image=IMAGE,object='long')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5240, "imageId": "n575770", "question": "Does the white newspaper have small size?", "program": "BOX0=LOC(image=IMAGE,object='newspaper')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the newspaper?')\nANSWER1=VQA(image=IMAGE0,question='What size is the newspaper?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5241, "imageId": "n477215", "question": "How does the river look like, blue or brown?", "program": "ANSWER0=VQA(image=IMAGE,question='How does the river look like, blue or brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5242, "imageId": "n37274", "question": "How clean is the hat made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5243, "imageId": "n249639", "question": "How big is the mirror above the trash can?", "program": "BOX0=LOC(image=IMAGE,object='trash can')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5244, "imageId": "n207708", "question": "What is the color of the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5245, "imageId": "n23181", "question": "What is located on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5246, "imageId": "n538684", "question": "Who is in front of the dugout?", "program": "BOX0=LOC(image=IMAGE,object='dugout')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the dugout?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5247, "imageId": "n233607", "question": "Which kind of furniture isn't brown?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture isn\\'t brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5248, "imageId": "n538684", "question": "What is the batter in front of?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the batter in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5249, "imageId": "n293477", "question": "In which part of the image is the hair clip?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=EVAL(expr=\"'top' if {BOX1} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5250, "imageId": "n501951", "question": "On which side of the picture is the motorbike?", "program": "BOX0=LOC(image=IMAGE,object='motorbike')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5251, "imageId": "n151768", "question": "Which color are the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color are the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5252, "imageId": "n137182", "question": "On which side of the photo is the white boat?", "program": "BOX0=LOC(image=IMAGE,object='white boat')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5253, "imageId": "n485969", "question": "Which color is the belt?", "program": "BOX0=LOC(image=IMAGE,object='belt')\nANSWER0=VQA(image=IMAGE,question='Which color is the belt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5254, "imageId": "n311910", "question": "Are both the windows and the buildings made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='windows')\nBOX1=LOC(image=IMAGE,object='buildings')\nANSWER0=VQA(image=IMAGE,question='What material are the windows made of?')\nANSWER1=VQA(image=IMAGE,question='What material are the buildings made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5255, "imageId": "n6908", "question": "Is the chair in front of the Christmas light that is on the wall?", "program": "BOX0=LOC(image=IMAGE,object='Christmas light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5256, "imageId": "n24526", "question": "What is the woman carrying?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman carrying?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5257, "imageId": "n317260", "question": "How does the helmet to the left of the fence look, white or black?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='helmet')\nANSWER0=VQA(image=IMAGE0,question='How does the helmet look?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5258, "imageId": "n200692", "question": "What kind of appliance does the plate lie on top of?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of appliance does the plate lie on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5259, "imageId": "n520071", "question": "What is common to the bookcase and the desk?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the bookcase and the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5260, "imageId": "n200692", "question": "What does the plate lie on top of?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the plate lie on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5261, "imageId": "n35676", "question": "Is the electric dishwasher behind the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='electric dishwasher')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5262, "imageId": "n520071", "question": "Which room is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which room is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5263, "imageId": "n59147", "question": "Is the toilet that looks white rectangular or round?", "program": "BOX0=LOC(image=IMAGE,object='white toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the toilet rectangular or round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5264, "imageId": "n314171", "question": "Are there small bowls or blenders?", "program": "BOX0=LOC(image=IMAGE,object='small bowls')\nBOX1=LOC(image=IMAGE,object='blenders')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5265, "imageId": "n208458", "question": "The bright sun is shining through what?", "program": "ANSWER0=VQA(image=IMAGE,question='The bright sun is shining through what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5266, "imageId": "n171169", "question": "Is the polo shirt orange or white?", "program": "BOX0=LOC(image=IMAGE,object='polo shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the polo shirt?')\nANSWER1=EVAL(expr=\"'orange' if {ANSWER0} == 'orange' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5267, "imageId": "n208458", "question": "What is the sun shining through?", "program": "BOX0=LOC(image=IMAGE,object='sun')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sun shining through?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5268, "imageId": "n171169", "question": "Who is the polo shirt worn on?", "program": "BOX0=LOC(image=IMAGE,object='polo shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the polo shirt worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5269, "imageId": "n314171", "question": "What is the color of the balloon?", "program": "BOX0=LOC(image=IMAGE,object='balloon')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the balloon?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5270, "imageId": "n143672", "question": "Does the jacket that is not short sleeved look white or brown?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short sleeved')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='white')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nBOX3=LOC(image=IMAGE0,object='brown')\nIMAGE3=CROP(image=IMAGE0,box=BOX3)\nANSWER0=VQA(image=IMAGE1,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE2,question='What color is the jacket?')\nANSWER2=VQA(image=IMAGE3,question='What color is the jacket?')\nANSWER3=EVAL(expr=\"'white' if {ANSWER0} != 'white' and {ANSWER1} == 'white' else 'brown'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 5271, "imageId": "n507959", "question": "What is hanging from the tall pole?", "program": "BOX0=LOC(image=IMAGE,object='tall pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the tall pole?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5272, "imageId": "n234722", "question": "Is the chair in the top part of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5273, "imageId": "n51658", "question": "Who is this man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is this man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5274, "imageId": "n51658", "question": "Who is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5275, "imageId": "n367944", "question": "Are there both chairs and tables in this scene?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5276, "imageId": "n143672", "question": "Does the jacket look long sleeved and black?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the jacket look long sleeved?')\nANSWER1=VQA(image=IMAGE,question='What color is the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5277, "imageId": "n367944", "question": "What is the donut sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='donut')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the donut sitting atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5278, "imageId": "n192021", "question": "Is the ceiling the same color as the fan?", "program": "BOX0=LOC(image=IMAGE,object='ceiling')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fan')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the ceiling?')\nANSWER1=VQA(image=IMAGE1,question='What color is the fan?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5279, "imageId": "n49438", "question": "On which side of the photo is the curtain?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5280, "imageId": "n199286", "question": "Is the happy woman on the right side or on the left?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='happy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5281, "imageId": "n119944", "question": "Is the basket that is brown closed or open?", "program": "BOX0=LOC(image=IMAGE,object='brown basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the basket closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5282, "imageId": "n336443", "question": "How clean is the utensil that is to the right of the carrots?", "program": "BOX0=LOC(image=IMAGE,object='carrots')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How clean is the utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5283, "imageId": "n527290", "question": "What is located on top of the shelves that are to the right of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelves')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='TOP')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What is located on top of the shelves?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5284, "imageId": "n222915", "question": "What kind of food is round?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food is round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5285, "imageId": "n410476", "question": "Are the animals of different types?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the animals of different types?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5286, "imageId": "n54424", "question": "What is the name of the piece of furniture that is in front of the white wall?", "program": "BOX0=LOC(image=IMAGE,object='white wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5287, "imageId": "n350732", "question": "Are there either frisbees or soccer balls that are not white?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nBOX1=LOC(image=IMAGE,object='soccer ball')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5288, "imageId": "n531359", "question": "What is the color of the balloons?", "program": "BOX0=LOC(image=IMAGE,object='balloons')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the balloons?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5289, "imageId": "n19152", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5290, "imageId": "n298104", "question": "What does the happy person hold onto?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the person hold onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5291, "imageId": "n298104", "question": "Does the tall person hold onto the surf board the flower is on?", "program": "BOX0=LOC(image=IMAGE,object='tall person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surf board')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='flower')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5292, "imageId": "n298104", "question": "Who is wearing the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5293, "imageId": "n298104", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5294, "imageId": "n565418", "question": "Do you see a fence in front of the trees near the sign?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='fence')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5295, "imageId": "n259949", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5296, "imageId": "n48494", "question": "What is the tunnel above the railroad made of?", "program": "BOX0=LOC(image=IMAGE,object='railroad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tunnel')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the tunnel made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5297, "imageId": "n259949", "question": "Is the skater in the parking lot wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='parking lot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skater')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the skater wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5298, "imageId": "n259949", "question": "Who is riding on the skateboard?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is riding on the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5299, "imageId": "n579928", "question": "Which color is the horse?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the horse?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5300, "imageId": "n280089", "question": "What is the bowl sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bowl sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5301, "imageId": "n280089", "question": "What type of appliance is the bowl to the right of the mugs sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='mugs')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of appliance is the bowl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5302, "imageId": "n350766", "question": "Is the toaster different in color than the burner?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='burner')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the toaster?')\nANSWER1=VQA(image=IMAGE1,question='What color is the burner?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5303, "imageId": "n299528", "question": "How hard is the street?", "program": "ANSWER0=VQA(image=IMAGE,question='How hard is the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5304, "imageId": "n500308", "question": "How clean is the window behind the sign?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nANSWER0=VQA(image=IMAGE0,question='How clean is the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5305, "imageId": "n350766", "question": "What do the dish drainer and the garbage can have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the dish drainer and the garbage can have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5306, "imageId": "n133585", "question": "Are there any boys to the right of the fat person?", "program": "BOX0=LOC(image=IMAGE,object='fat person')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boys')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5307, "imageId": "n49310", "question": "What is the old woman sitting on?", "program": "BOX0=LOC(image=IMAGE,object='old woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the old woman sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5308, "imageId": "n228268", "question": "What is worn on the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is worn on the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5309, "imageId": "n240973", "question": "What is sitting on the tray that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on the tray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5310, "imageId": "n88933", "question": "Is there any plate to the left of the girl on the right of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='plate')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5311, "imageId": "n49310", "question": "Who is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5312, "imageId": "n199286", "question": "Is the grass green?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the grass?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5313, "imageId": "n329514", "question": "Is there a snowboarder below the rooftop that is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='rooftop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='snowboarder')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='metal')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5314, "imageId": "n222915", "question": "On which side is the round food?", "program": "BOX0=LOC(image=IMAGE,object='round food')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5315, "imageId": "n329514", "question": "Who is flying through the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is flying through the sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5316, "imageId": "n460385", "question": "Are there pizzas or sandwiches that are not white?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nBOX1=LOC(image=IMAGE,object='sandwich')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5317, "imageId": "n293477", "question": "Is the small device on the right or on the left of the photo?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5318, "imageId": "n94074", "question": "Which kind of clothing is white?", "program": "BOX0=LOC(image=IMAGE,object='white clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5319, "imageId": "n472825", "question": "Do you see a skateboarder that is not female?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nANSWER0=VQA(image=IMAGE,question='Is the skateboarder female?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5320, "imageId": "n200225", "question": "What is this pizza inside of?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is this pizza inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5321, "imageId": "n512257", "question": "Who wears the suit?", "program": "BOX0=LOC(image=IMAGE,object='suit')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the suit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5322, "imageId": "n494677", "question": "What is the color of the field?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the color of the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5323, "imageId": "n494918", "question": "Is the person that is not tall wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gloves')\nANSWER0=COUNT(box=BOX1)\nBOX2=LOC(image=IMAGE0,object='tall')\nIMAGE1=CROP(image=IMAGE0,box=BOX2)\nBOX3=LOC(image=IMAGE1,object='person')\nANSWER1=COUNT(box=BOX3)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} > 0 and {ANSWER0} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5324, "imageId": "n445353", "question": "Is the person in the top or in the bottom?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5325, "imageId": "n309148", "question": "Who is walking?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5326, "imageId": "n398257", "question": "How is the rectangular piece of furniture called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the rectangular piece of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5327, "imageId": "n28572", "question": "Is the empty glass in front of the menu?", "program": "BOX0=LOC(image=IMAGE,object='menu')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='empty glass')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5328, "imageId": "n153293", "question": "What hangs above the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What hangs above the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5329, "imageId": "n153293", "question": "What does the white ceiling hang above?", "program": "BOX0=LOC(image=IMAGE,object='ceiling')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the white ceiling hang above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5330, "imageId": "n335542", "question": "What is the large bear looking at?", "program": "BOX0=LOC(image=IMAGE,object='large bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the large bear looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5331, "imageId": "n282607", "question": "What do you think is in front of the man that is wearing a shoe?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shoe')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What do you think is in front of the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5332, "imageId": "n282607", "question": "Is the net above the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='net')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5333, "imageId": "n282607", "question": "What is in front of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='front')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5334, "imageId": "n216553", "question": "Is the man that is not old looking in the bag made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the bag made of?')\nANSWER1=VQA(image=IMAGE0,question='Is the man old?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'no' and {ANSWER0} == 'cloth' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5335, "imageId": "n305495", "question": "Who is in front of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the lamp?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5336, "imageId": "n379991", "question": "Is the baking pan silver and round?", "program": "BOX0=LOC(image=IMAGE,object='baking pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the baking pan?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the baking pan?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5337, "imageId": "n356822", "question": "Is the girl to the right or to the left of the boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5338, "imageId": "n567860", "question": "What kind of fruit is the white kitten playing with, an apple or a banana?", "program": "BOX0=LOC(image=IMAGE,object='white kitten')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='apple')\nBOX2=LOC(image=IMAGE0,object='banana')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'apple' if {ANSWER0} > 0 else 'banana'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5339, "imageId": "n532191", "question": "What is the piece of furniture that the rectangular device is sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='rectangular device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5340, "imageId": "n69237", "question": "How is the item of furniture that is made of same material as the floor called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the item of furniture that is made of same material as the floor called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5341, "imageId": "n398429", "question": "Which side of the photo is the stove on?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5342, "imageId": "n567860", "question": "What animal is lying on top of the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is lying on top of the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5343, "imageId": "n59147", "question": "Is the table to the right or to the left of the white toilet?", "program": "BOX0=LOC(image=IMAGE,object='white toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5344, "imageId": "n290409", "question": "Which kind of animal is to the left of the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is to the left of the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5345, "imageId": "n59147", "question": "Are there empty chairs or bags?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='bag')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5346, "imageId": "n262920", "question": "Where is the man that is not short standing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nBOX1=LOC(image=IMAGE,object='short')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX2[0]} < {BOX0[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5347, "imageId": "n290409", "question": "Does the brown dog sit inside a truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown dog')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5348, "imageId": "n100991", "question": "Is the fork on the left side of the image?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fork')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5349, "imageId": "n527589", "question": "What kind of fruit is small?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of fruit is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5350, "imageId": "n240973", "question": "What kind of furniture is the black towel sitting on?", "program": "BOX0=LOC(image=IMAGE,object='black towel')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the black towel sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5351, "imageId": "n527290", "question": "What color does that couch have?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does that couch have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5352, "imageId": "n318370", "question": "What size is the doughnut the person is eating?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='doughnut')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What size is the doughnut?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5353, "imageId": "n305495", "question": "Is the shirt dark and short?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='Is the shirt short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5354, "imageId": "n433532", "question": "Are there both food and wine in the picture?", "program": "BOX0=LOC(image=IMAGE,object='food')\nBOX1=LOC(image=IMAGE,object='wine')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5355, "imageId": "n498712", "question": "Is the luggage large or small?", "program": "BOX0=LOC(image=IMAGE,object='luggage')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'large' if {ANSWER0} > 0 else 'small'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5356, "imageId": "n140421", "question": "What kind of furniture contains the cups?", "program": "BOX0=LOC(image=IMAGE,object='cups')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture contains the cups?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5357, "imageId": "n140421", "question": "What does the cupboard contain?", "program": "ANSWER0=VQA(image=IMAGE,question='What does the cupboard contain?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5358, "imageId": "n140421", "question": "What contains cups?", "program": "BOX0=LOC(image=IMAGE,object='cups')\nANSWER0=VQA(image=IMAGE,question='What contains cups?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5359, "imageId": "n162586", "question": "Is there any soft bed or couch?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='couch')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5360, "imageId": "n259949", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5361, "imageId": "n393305", "question": "Is the traffic sign on top of the pole red or white?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic sign')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the traffic sign?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5362, "imageId": "n497658", "question": "Is the sky cloudy and bright?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sky cloudy?')\nANSWER1=VQA(image=IMAGE,question='Is the sky bright?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5363, "imageId": "n290409", "question": "How big is the truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nANSWER0=VQA(image=IMAGE,question='How big is the truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5364, "imageId": "n54180", "question": "How big is the mirror that is above the shelf?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=VQA(image=IMAGE0,question='How big is the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5365, "imageId": "n181355", "question": "Does the young woman seem to be adult and blond?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the young woman seem to be adult?')\nANSWER1=VQA(image=IMAGE,question='Does the young woman seem to be blond?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5366, "imageId": "n429961", "question": "The broccoli is in what?", "program": "BOX0=LOC(image=IMAGE,object='broccoli')\nANSWER0=VQA(image=IMAGE,question='The broccoli is in what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5367, "imageId": "n238266", "question": "What kind of food is on the table?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food is on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5368, "imageId": "n575770", "question": "Does the suitcase look large and yellow?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the suitcase look large and yellow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5369, "imageId": "n527290", "question": "Are there either any chairs or televisions that are black?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='television')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5370, "imageId": "n541854", "question": "What is the fruit on the tray that is shown in the picture?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fruit on the tray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5371, "imageId": "n541854", "question": "Which kind of fruit is on the tray?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fruit is on the tray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5372, "imageId": "n433692", "question": "On which side of the picture is the small monitor, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='small monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5373, "imageId": "n59676", "question": "Is there either any red can or cup?", "program": "BOX0=LOC(image=IMAGE,object='red can')\nBOX1=LOC(image=IMAGE,object='cup')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5374, "imageId": "n501609", "question": "What is the appliance to the right of the appliance that is below the microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5375, "imageId": "n562105", "question": "Does the dirt look empty and white?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the dirt look empty and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5376, "imageId": "n413761", "question": "How big is the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nANSWER0=VQA(image=IMAGE,question='How big is the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5377, "imageId": "n541482", "question": "Does the grass look green and tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the grass look green?')\nANSWER1=VQA(image=IMAGE,question='Does the grass look tall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5378, "imageId": "n235859", "question": "Where is the man sitting?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5379, "imageId": "n412144", "question": "Is the fence near the skateboarder open or closed?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=VQA(image=IMAGE0,question='Is the fence open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5380, "imageId": "n115614", "question": "In which part of the image are the cars, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5381, "imageId": "n216553", "question": "What is the horse doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the horse doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5382, "imageId": "n413002", "question": "What kind of fruit is to the left of the elephant in the middle of the photo?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of fruit is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5383, "imageId": "n181210", "question": "Are there peaches in front of the cup?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='peaches')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5384, "imageId": "n554880", "question": "Is there a chair on top of the floor made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5385, "imageId": "n35676", "question": "Do you see an oven near the cabinet to the left of the drawers?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drawers')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='oven')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5386, "imageId": "n331357", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5387, "imageId": "n355567", "question": "Which company made the bat, Adidas or Nike?", "program": "BOX0=LOC(image=IMAGE,object='bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which company made the bat, Adidas or Nike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5388, "imageId": "n315887", "question": "Are there both a keyboard and a desk in this image?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nBOX1=LOC(image=IMAGE,object='desk')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5389, "imageId": "n256120", "question": "Who is wearing the sneakers?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the sneakers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5390, "imageId": "n309148", "question": "How wide is the bucket?", "program": "BOX0=LOC(image=IMAGE,object='bucket')\nANSWER0=VQA(image=IMAGE,question='How wide is the bucket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5391, "imageId": "n148872", "question": "Is the tennis racket to the left of a ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5392, "imageId": "n256120", "question": "Who is wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5393, "imageId": "n525901", "question": "What do the laptop and the office chair have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the laptop and the office chair have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5394, "imageId": "n259002", "question": "What size do you think the ball is?", "program": "ANSWER0=VQA(image=IMAGE,question='What size do you think the ball is?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5395, "imageId": "n518912", "question": "Is the old man to the left or to the right of the chair that is to the left of the cups?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='cups')\nIMAGE2=CROP_LEFTOF(image=IMAGE1,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='old man')\nANSWER0=COUNT(box=BOX3)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5396, "imageId": "n470920", "question": "Are there any green blankets or towels?", "program": "BOX0=LOC(image=IMAGE,object='blanket')\nBOX1=LOC(image=IMAGE,object='towel')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5397, "imageId": "n200225", "question": "Which kind of food isn't melted?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food isn't melted?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5398, "imageId": "n259002", "question": "Is the jersey sleeveless?", "program": "BOX0=LOC(image=IMAGE,object='jersey')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the jersey sleeveless?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5399, "imageId": "n503626", "question": "What is mounted on the wall that looks beige and white?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='beige and white')\nANSWER0=VQA(image=IMAGE0,question='What is mounted on the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5400, "imageId": "n480253", "question": "Is the brown car on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5401, "imageId": "n296467", "question": "Which vegetables are not cylindrical, the beans or the carrots?", "program": "BOX0=LOC(image=IMAGE,object='beans')\nBOX1=LOC(image=IMAGE,object='carrots')\nANSWER0=VQA(image=IMAGE,question='What shape are the beans?')\nANSWER1=VQA(image=IMAGE,question='What shape are the carrots?')\nANSWER2=EVAL(expr=\"'beans' if {ANSWER0} != 'cylindrical' else 'carrots'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5402, "imageId": "n4777", "question": "Is the orange bottle to the left or to the right of the person that is sitting beside the table?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='orange bottle')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5403, "imageId": "n507959", "question": "Is the guitar small and black?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the guitar small?')\nANSWER1=VQA(image=IMAGE,question='What color is the guitar?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'small' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5404, "imageId": "n499081", "question": "Is the window small?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the window small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5405, "imageId": "n111390", "question": "Which side is the blue cake on, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='blue cake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5406, "imageId": "n35676", "question": "Which kind of furniture is to the left of the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is to the left of the oven?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5407, "imageId": "n256120", "question": "Which kind of vehicle are the tents behind of?", "program": "BOX0=LOC(image=IMAGE,object='tents')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle are the tents behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5408, "imageId": "n390187", "question": "Does the mirror on the motorbike look red or silver?", "program": "BOX0=LOC(image=IMAGE,object='motorbike')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the mirror?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'silver'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5409, "imageId": "n493357", "question": "Does the giraffe to the right of the house look skinny?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='giraffe')\nANSWER0=VQA(image=IMAGE0,question='Does the giraffe look skinny?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5410, "imageId": "n309148", "question": "Does the steel bridge look high and long?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the steel bridge look high and long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5411, "imageId": "n445353", "question": "What kind of furniture is to the left of the boxes?", "program": "BOX0=LOC(image=IMAGE,object='boxes')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is to the left of the boxes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5412, "imageId": "n489699", "question": "Who is wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5413, "imageId": "n68769", "question": "How long is the white table?", "program": "BOX0=LOC(image=IMAGE,object='white table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the white table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5414, "imageId": "n445353", "question": "What is the item of furniture in front of the old bricks?", "program": "BOX0=LOC(image=IMAGE,object='old bricks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5415, "imageId": "n28572", "question": "Is the mug in front of a cup?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5416, "imageId": "n489699", "question": "Does the parent that looks blonde look happy?", "program": "BOX0=LOC(image=IMAGE,object='parent')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blonde')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the parent look happy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5417, "imageId": "n357784", "question": "What animal is the mirror behind of?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the mirror behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5418, "imageId": "n494918", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5419, "imageId": "n329514", "question": "Who is traveling down the steps?", "program": "BOX0=LOC(image=IMAGE,object='steps')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is traveling down the steps?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5420, "imageId": "n357784", "question": "Is the clean mirror behind the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5421, "imageId": "n357784", "question": "What is the animal that this mirror is behind of called?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5422, "imageId": "n210269", "question": "Is the logo straight and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the logo straight?')\nANSWER1=VQA(image=IMAGE,question='What color is the logo?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5423, "imageId": "n167164", "question": "Which color is the traffic light in the middle?", "program": "BOX0=LOC(image=IMAGE,object='middle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic light')\nANSWER0=VQA(image=IMAGE0,question='Which color is the traffic light?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5424, "imageId": "n199097", "question": "Who is wearing a jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5425, "imageId": "n315887", "question": "Is the water bottle made of the same material as the desk?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='desk')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the water bottle made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the desk made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5426, "imageId": "n62458", "question": "What is in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5427, "imageId": "n199097", "question": "Who is wearing an umbrella?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing an umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5428, "imageId": "n9856", "question": "Are there any fences behind the tall tree?", "program": "BOX0=LOC(image=IMAGE,object='tall tree')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fences')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5429, "imageId": "n62458", "question": "What is in front of the green wall?", "program": "BOX0=LOC(image=IMAGE,object='green wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the green wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5430, "imageId": "n344136", "question": "The curtains have what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the curtains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5431, "imageId": "n570181", "question": "Are the blue shoes made of leather or rubber?", "program": "ANSWER0=VQA(image=IMAGE,question='What material are the blue shoes made of?')\nANSWER1=EVAL(expr=\"'leather' if {ANSWER0} == 'leather' else 'rubber'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5432, "imageId": "n344136", "question": "Are the curtains made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material are the curtains made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'cloth' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5433, "imageId": "n296467", "question": "Which kind of food is inside the container?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is inside the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5434, "imageId": "n67005", "question": "Is there a bag near the white bed?", "program": "BOX0=LOC(image=IMAGE,object='white bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5435, "imageId": "n64959", "question": "What appliance is to the right of the box?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is to the right of the box?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5436, "imageId": "n90944", "question": "Is the sand surrounded by the trees?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5437, "imageId": "n507149", "question": "What is in front of the sea foam?", "program": "BOX0=LOC(image=IMAGE,object='sea foam')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the sea foam?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5438, "imageId": "n507149", "question": "Is the wet sand in front of the sea foam that is not dry?", "program": "BOX0=LOC(image=IMAGE,object='sea foam')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wet sand')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5439, "imageId": "n507149", "question": "Is the sea foam behind the sand?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sea foam')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5440, "imageId": "n355339", "question": "Are there either any beige tables or couches?", "program": "BOX0=LOC(image=IMAGE,object='beige table')\nBOX1=LOC(image=IMAGE,object='couch')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5441, "imageId": "n551964", "question": "Is the young boy on the right?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5442, "imageId": "n16656", "question": "Is the Caucasian person in front of the tree the sky is behind of?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='Caucasian person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5443, "imageId": "n155555", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5444, "imageId": "n16656", "question": "What is the man behind of, a cat or a horse?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cat')\nBOX2=LOC(image=IMAGE0,object='horse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'cat' if {ANSWER0} > 0 else 'horse'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5445, "imageId": "n16656", "question": "What animal is the man behind of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is the man behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5446, "imageId": "n413002", "question": "Do the leaves have green color?", "program": "BOX0=LOC(image=IMAGE,object='leaves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the leaves?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5447, "imageId": "n471866", "question": "Is it indoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it indoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5448, "imageId": "n554880", "question": "What is the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5449, "imageId": "n257997", "question": "Who is in front of the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5450, "imageId": "n65885", "question": "Is the cabinet on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabinet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5451, "imageId": "n257997", "question": "Who is in front of the car that is presented in this scene?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5452, "imageId": "n433692", "question": "Does the lamp near the laptop computer look thin and tall?", "program": "BOX0=LOC(image=IMAGE,object='laptop computer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=VQA(image=IMAGE0,question='Does the lamp look thin and tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5453, "imageId": "n455563", "question": "Is she seen through a lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='she')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5454, "imageId": "n543966", "question": "What animals are huge?", "program": "BOX0=LOC(image=IMAGE,object='huge animals')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'elephants' if {ANSWER0} > 0 else 'no animals'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5455, "imageId": "n77818", "question": "Is the entertainment center on the right side or on the left of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='entertainment center')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5456, "imageId": "n141939", "question": "What kind of appliance is below the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of appliance is below the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5457, "imageId": "n141939", "question": "What is the tissue in?", "program": "BOX0=LOC(image=IMAGE,object='tissue')\nANSWER0=VQA(image=IMAGE,question='What is the tissue in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5458, "imageId": "n347706", "question": "Is the window clean and small?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the window clean?')\nANSWER1=VQA(image=IMAGE0,question='Is the window small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5459, "imageId": "n532213", "question": "What is the color of the traffic signal on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic signal')\nANSWER0=VQA(image=IMAGE0,question='What color is the traffic signal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5460, "imageId": "n540852", "question": "Who in the image is walking?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5461, "imageId": "n398429", "question": "Is the coffee machine to the left of the bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='coffee machine')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5462, "imageId": "n70461", "question": "Is the train large and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the train large?')\nANSWER1=VQA(image=IMAGE,question='What color is the train?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5463, "imageId": "n70461", "question": "Is this a train or a bus?", "program": "BOX0=LOC(image=IMAGE,object='train')\nBOX1=LOC(image=IMAGE,object='bus')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'train' if {ANSWER0} > 0 else 'bus'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5464, "imageId": "n68769", "question": "Is the color of the menu the same as the plant?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='menu')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the plant?')\nANSWER1=VQA(image=IMAGE1,question='What color is the menu?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5465, "imageId": "n23181", "question": "Do the draperies have the same color as the sheets?", "program": "BOX0=LOC(image=IMAGE,object='draperies')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sheets')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the draperies?')\nANSWER1=VQA(image=IMAGE1,question='What color are the sheets?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5466, "imageId": "n380113", "question": "Are the gloves large?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nANSWER0=VQA(image=IMAGE,question='Are the gloves large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5467, "imageId": "n68769", "question": "Are all the people the same gender?", "program": "ANSWER0=VQA(image=IMAGE,question='Are all the people the same gender?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5468, "imageId": "n314630", "question": "Are there any houses to the left of the paper towel?", "program": "BOX0=LOC(image=IMAGE,object='paper towel')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='house')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5469, "imageId": "n137182", "question": "Who is younger, the man or the child?", "program": "ANSWER0=VQA(image=IMAGE,question='Who is younger, the man or the child?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5470, "imageId": "n137182", "question": "Who is younger, the girl or the man?", "program": "ANSWER0=VQA(image=IMAGE,question='Who is younger, the girl or the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5471, "imageId": "n520071", "question": "Are there any computers or TVs that are not silver?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nBOX1=LOC(image=IMAGE,object='TV')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5472, "imageId": "n433532", "question": "What is the lady in front of?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the lady in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5473, "imageId": "n433532", "question": "Are there ladies in front of the plates?", "program": "BOX0=LOC(image=IMAGE,object='plates')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ladies')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5474, "imageId": "n170941", "question": "Does the coffee mug near the plate have round shape and blue color?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='coffee mug')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What shape is the coffee mug?')\nANSWER1=VQA(image=IMAGE1,question='What color is the coffee mug?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5475, "imageId": "n317260", "question": "Where is the catcher standing on?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the catcher standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5476, "imageId": "n97485", "question": "What's standing on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5477, "imageId": "n97485", "question": "What is standing on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5478, "imageId": "n154856", "question": "Do you see a silver bench?", "program": "BOX0=LOC(image=IMAGE,object='silver bench')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5479, "imageId": "n118102", "question": "Is the person that looks young sitting at a couch?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5480, "imageId": "n49438", "question": "How is the item of furniture below the curtain on the left side called?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtain')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5481, "imageId": "n432591", "question": "Is the hat near the nightstand orange and uncomfortable?", "program": "BOX0=LOC(image=IMAGE,object='nightstand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE0,question='Is the hat uncomfortable?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5482, "imageId": "n118102", "question": "Is the color of the counter brown?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the counter?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5483, "imageId": "n532213", "question": "Who is walking across the crosswalk?", "program": "BOX0=LOC(image=IMAGE,object='crosswalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is walking across the crosswalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5484, "imageId": "n310625", "question": "Are there toothbrushes in this picture?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5485, "imageId": "n567860", "question": "What does the banana bunch hang above?", "program": "BOX0=LOC(image=IMAGE,object='banana bunch')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the banana bunch hang above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5486, "imageId": "n223750", "question": "Is there any fence in front of the bushes?", "program": "BOX0=LOC(image=IMAGE,object='bushes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5487, "imageId": "n44249", "question": "Which kind of animal is the woman on?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is the woman on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5488, "imageId": "n312206", "question": "Does the plate to the right of the container have round shape and red color?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What shape is the plate?')\nANSWER3=VQA(image=IMAGE0,question='What color is the plate?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'round' and {ANSWER3} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 5489, "imageId": "n249903", "question": "Is the poster that is not horizontal short and narrow?", "program": "BOX0=LOC(image=IMAGE,object='poster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the poster horizontal?')\nANSWER1=VQA(image=IMAGE0,question='Is the poster short and narrow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5490, "imageId": "n315887", "question": "Which kind of furniture is this, a desk or a sofa?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nBOX1=LOC(image=IMAGE,object='sofa')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'desk' if {ANSWER0} > {ANSWER1} else 'sofa'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5491, "imageId": "n472825", "question": "Are there any men or skateboarders?", "program": "BOX0=LOC(image=IMAGE,object='man')\nBOX1=LOC(image=IMAGE,object='skateboarder')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5492, "imageId": "n544255", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5493, "imageId": "n23181", "question": "Does the window look clear and open?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the window look clear and open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5494, "imageId": "n159802", "question": "Who wears the hair clip?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the hair clip?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5495, "imageId": "n335542", "question": "Are the rocks both brown and huge?", "program": "BOX0=LOC(image=IMAGE,object='rocks')\nANSWER0=VQA(image=IMAGE,question='What color are the rocks?')\nANSWER1=VQA(image=IMAGE,question='How big are the rocks?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'huge' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5496, "imageId": "n335542", "question": "Which color are the small rocks that are lying on top of the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small rocks')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which color are the small rocks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5497, "imageId": "n554880", "question": "Is the couch to the left or to the right of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5498, "imageId": "n51002", "question": "Is the vase next to the lamp white and triangular?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vase')\nANSWER0=VQA(image=IMAGE0,question='What color is the vase?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the vase?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'triangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5499, "imageId": "n159802", "question": "Is this girl Caucasian or Asian?", "program": "ANSWER0=VQA(image=IMAGE,question='Is this girl Caucasian or Asian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5500, "imageId": "n141939", "question": "How big is the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5501, "imageId": "n206785", "question": "Do the eye glasses look black?", "program": "BOX0=LOC(image=IMAGE,object='eye glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the eye glasses?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5502, "imageId": "n398257", "question": "Do you see either any metallic desks or boxes?", "program": "BOX0=LOC(image=IMAGE,object='metallic desk')\nBOX1=LOC(image=IMAGE,object='box')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5503, "imageId": "n141939", "question": "Does the towel have a different color than the floor?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='floor')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the towel?')\nANSWER1=VQA(image=IMAGE1,question='What color is the floor?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5504, "imageId": "n542609", "question": "Is the platform made of the same material as the post?", "program": "BOX0=LOC(image=IMAGE,object='platform')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='post')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the platform made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the post made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5505, "imageId": "n411121", "question": "How large is the dog?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5506, "imageId": "n83784", "question": "What animal is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What animal is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5507, "imageId": "n19152", "question": "Is that tire green and round?", "program": "BOX0=LOC(image=IMAGE,object='tire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tire?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the tire?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5508, "imageId": "n542609", "question": "Are the people on the right side or on the left?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5509, "imageId": "n578564", "question": "Is that toaster rectangular and black?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the toaster?')\nANSWER1=VQA(image=IMAGE0,question='What color is the toaster?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rectangular' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5510, "imageId": "n162586", "question": "Are the sheets soft?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the sheets soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5511, "imageId": "n578564", "question": "What shape is the toaster that is below the chalkboard?", "program": "BOX0=LOC(image=IMAGE,object='chalkboard')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toaster')\nANSWER0=VQA(image=IMAGE0,question='What shape is the toaster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5512, "imageId": "n162586", "question": "Are the sheets near the woman white or purple?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sheets')\nANSWER0=VQA(image=IMAGE0,question='What color are the sheets?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'purple'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5513, "imageId": "n357784", "question": "What is plugged into the outlets?", "program": "BOX0=LOC(image=IMAGE,object='outlets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is plugged into the outlets?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5514, "imageId": "n468864", "question": "Is the open purse in the bottom part or in the top of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='open purse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5515, "imageId": "n88933", "question": "Which kind of furniture is the boy sitting in?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the boy sitting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5516, "imageId": "n88933", "question": "What kind of furniture is the person to the right of the food sitting in?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of furniture is the person sitting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5517, "imageId": "n181355", "question": "Which kind of furniture is rectangular?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is rectangular?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5518, "imageId": "n280089", "question": "What's sitting on the counter?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on the counter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5519, "imageId": "n181355", "question": "Which kind of furniture is not wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} == 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5520, "imageId": "n280089", "question": "What is sitting on the counter?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on the counter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5521, "imageId": "n214497", "question": "Which side of the picture is the man on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5522, "imageId": "n181355", "question": "Which kind of furniture isn't rectangular?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture isn\\'t rectangular?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5523, "imageId": "n369595", "question": "What's the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5524, "imageId": "n501951", "question": "Do the building and the helmet have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='helmet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the building?')\nANSWER1=VQA(image=IMAGE1,question='What color is the helmet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5525, "imageId": "n173807", "question": "Is the vehicle that is driving light and cream colored?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'light' or {ANSWER0} == 'cream' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5526, "imageId": "n433692", "question": "Is the dirt white and light?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the dirt?')\nANSWER1=VQA(image=IMAGE0,question='Is the dirt light?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5527, "imageId": "n214497", "question": "Are the windows above the light fixture closed and high?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='windows')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Are the windows closed?')\nANSWER1=VQA(image=IMAGE1,question='Are the windows high?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5528, "imageId": "n219840", "question": "Is the zebra to the left of cows?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5529, "imageId": "n16378", "question": "Who is the man walking behind of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man walking behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5530, "imageId": "n278453", "question": "What are the blue clothing items in this photo?", "program": "BOX0=LOC(image=IMAGE,object='blue clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5531, "imageId": "n255161", "question": "Is the artwork on the sign post black and ugly?", "program": "BOX0=LOC(image=IMAGE,object='sign post')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='artwork')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the artwork?')\nANSWER1=VQA(image=IMAGE1,question='Is the artwork ugly?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5532, "imageId": "n219840", "question": "Is there a gray horse or elephant?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nBOX1=LOC(image=IMAGE,object='elephant')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5533, "imageId": "n23762", "question": "What is the chair made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the chair made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5534, "imageId": "n281241", "question": "Are the black pants made of leather or cloth?", "program": "ANSWER0=VQA(image=IMAGE,question='What material are the black pants made of?')\nANSWER1=EVAL(expr=\"'leather' if {ANSWER0} == 'leather' else 'cloth'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5535, "imageId": "n281241", "question": "Which kind of clothing is long?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5536, "imageId": "n246334", "question": "What kind of furniture is made?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is made?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5537, "imageId": "n54424", "question": "Which kind of furniture is the wall behind of?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is behind the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5538, "imageId": "n485969", "question": "Which color is the hat that the player is wearing?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nANSWER0=VQA(image=IMAGE0,question='Which color is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5539, "imageId": "n485969", "question": "Is the hat that is red and white made of paper or cloth?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the material of the hat?')\nANSWER1=EVAL(expr=\"'paper' if 'paper' in {ANSWER0} else 'cloth'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5540, "imageId": "n244826", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5541, "imageId": "n69237", "question": "Do you see bags to the right of the bed the pillow is on?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='bags')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5542, "imageId": "n469156", "question": "Where is this?", "program": "ANSWER0=VQA(image=IMAGE,question='Where is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5543, "imageId": "n69237", "question": "Is there a bag in this image that is not black?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nANSWER0=VQA(image=IMAGE,question='What color is the bag?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5544, "imageId": "n469156", "question": "Is it outdoors or indoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it outdoors or indoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5545, "imageId": "n240973", "question": "To what is the tray mounted?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mounted')\nANSWER0=VQA(image=IMAGE0,question='To what is the tray mounted?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5546, "imageId": "n477702", "question": "Does the smiling man wear shorts?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the man wear shorts?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'smiling' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5547, "imageId": "n240973", "question": "To which kind of furniture is the tray mounted?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='To which kind of furniture is the tray mounted?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5548, "imageId": "n578564", "question": "Is the pan made of the same material as the hook?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hook')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the pan made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the hook made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5549, "imageId": "n240973", "question": "What is mounted to the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is mounted to the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5550, "imageId": "n500209", "question": "What sits on the shelf?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What sits on the shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5551, "imageId": "n429883", "question": "Are there men to the left of the woman on the right?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5552, "imageId": "n65230", "question": "What is connected to the walls?", "program": "BOX0=LOC(image=IMAGE,object='walls')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is connected to the walls?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5553, "imageId": "n578564", "question": "What type of cooking utensil is made of the same material as the picture on the left side of the image?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of cooking utensil is made of the same material as the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5554, "imageId": "n65230", "question": "What are the pipes connected to?", "program": "BOX0=LOC(image=IMAGE,object='pipes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the pipes connected to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5555, "imageId": "n578564", "question": "What is common to the cutting board and the picture?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the cutting board and the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5556, "imageId": "n536256", "question": "What does the standing person to the right of the lamp used, a Wii controller or a laptop?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What does the person use, a Wii controller or a laptop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5557, "imageId": "n235859", "question": "Does the wine have little size and black color?", "program": "BOX0=LOC(image=IMAGE,object='wine')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the wine?')\nANSWER1=VQA(image=IMAGE0,question='What color is the wine?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'little' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5558, "imageId": "n536256", "question": "What does the man used?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the man use?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5559, "imageId": "n119944", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5560, "imageId": "n536256", "question": "Which kind of device does the man used?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device does the man use?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5561, "imageId": "n223750", "question": "Does the woman's hair have brunette color and long length?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the woman\\'s hair?')\nANSWER1=VQA(image=IMAGE0,question='What is the length of the woman\\'s hair?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brunette' and {ANSWER1} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5562, "imageId": "n279173", "question": "Is there a cow on the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cow')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5563, "imageId": "n279173", "question": "Where is the cow?", "program": "BOX0=LOC(image=IMAGE,object='cow')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5564, "imageId": "n317189", "question": "Do the skis that are not short look thin and dirty?", "program": "BOX0=LOC(image=IMAGE,object='skis')\nBOX1=LOC(image=IMAGE,object='short')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=IMAGE0)\nANSWER1=COUNT(box=IMAGE1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5565, "imageId": "n272313", "question": "Is the boy above a bicycle?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5566, "imageId": "n48494", "question": "Is the vast sky above the buildings both clear and blue?", "program": "BOX0=LOC(image=IMAGE,object='buildings')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vast sky')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the sky clear?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sky?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5567, "imageId": "n415215", "question": "Is the artwork above the toilet rectangular and black?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='artwork')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the artwork rectangular and black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5568, "imageId": "n200907", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5569, "imageId": "n415215", "question": "Are there either any traffic lights or cigarettes in the photo?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nBOX1=LOC(image=IMAGE,object='cigarette')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5570, "imageId": "n526228", "question": "Does the lamp have small size?", "program": "ANSWER0=VQA(image=IMAGE,question='What size is the lamp?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5571, "imageId": "n199097", "question": "Is the vehicle both modern and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the vehicle modern?')\nANSWER1=VQA(image=IMAGE,question='What color is the vehicle?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5572, "imageId": "n187961", "question": "What is the animal that is in front of the child?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5573, "imageId": "n578564", "question": "What is the shape of the chalkboard?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the shape of the chalkboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5574, "imageId": "n289376", "question": "What are the leafy trees covered by?", "program": "BOX0=LOC(image=IMAGE,object='leafy trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the leafy trees covered by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5575, "imageId": "n578564", "question": "What is the color of the chalkboard?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the color of the chalkboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5576, "imageId": "n557666", "question": "Is there any bus near the white sign?", "program": "BOX0=LOC(image=IMAGE,object='white sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5577, "imageId": "n479092", "question": "Is the napkin to the right of a bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='napkin')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5578, "imageId": "n58220", "question": "What color is the road, black or white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the road?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5579, "imageId": "n526228", "question": "What device is to the left of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the left of the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5580, "imageId": "n573460", "question": "Who is watching the person that is holding the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5581, "imageId": "n24526", "question": "Is the car to the left of her?", "program": "BOX0=LOC(image=IMAGE,object='her')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5582, "imageId": "n49310", "question": "What is the ethnicity of the person that the woman is sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='What is the ethnicity of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5583, "imageId": "n512257", "question": "Who wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who wears a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5584, "imageId": "n411121", "question": "What vehicle is to the right of the dog?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is to the right of the dog?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5585, "imageId": "n12214", "question": "On which side of the image is the black van?", "program": "BOX0=LOC(image=IMAGE,object='black van')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5586, "imageId": "n272098", "question": "What color is the hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5587, "imageId": "n531731", "question": "Is the bag next to the player square and red?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='red')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 5588, "imageId": "n531731", "question": "Which shape is the bag on the left of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='Which shape is the bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5589, "imageId": "n250715", "question": "What is the pilot sitting in?", "program": "BOX0=LOC(image=IMAGE,object='pilot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pilot sitting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5590, "imageId": "n250715", "question": "What type of furniture is the young person sitting in?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is the young person sitting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5591, "imageId": "n250715", "question": "What is he sitting in?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is he sitting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5592, "imageId": "n250715", "question": "Who is sitting in the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting in the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5593, "imageId": "n199097", "question": "What color is the umbrella the gentleman is wearing?", "program": "BOX0=LOC(image=IMAGE,object='gentleman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5594, "imageId": "n451187", "question": "Is the man to the right or to the left of the purse?", "program": "BOX0=LOC(image=IMAGE,object='purse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5595, "imageId": "n199097", "question": "How big is the umbrella in the top of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5596, "imageId": "n513429", "question": "Which kind of device is the poster behind of?", "program": "BOX0=LOC(image=IMAGE,object='poster')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is behind the poster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5597, "imageId": "n513429", "question": "Are there either bird cages or wheelchairs in the picture?", "program": "BOX0=LOC(image=IMAGE,object='bird cage')\nBOX1=LOC(image=IMAGE,object='wheelchair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5598, "imageId": "n429961", "question": "What is the vegetable that is on the table in front of the vehicle called?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vegetable')\nANSWER0=VQA(image=IMAGE1,question='What is the vegetable called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5599, "imageId": "n260521", "question": "What color does the book that is not closed have?", "program": "BOX0=LOC(image=IMAGE,object='book')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='closed')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='book')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What color is the book?')\nANSWER1=EVAL(expr=\"'not closed' if {ANSWER0} != 'closed' else 'closed'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5600, "imageId": "n429961", "question": "Are there cabbages next to the cauliflower?", "program": "BOX0=LOC(image=IMAGE,object='cauliflower')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabbages')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5601, "imageId": "n77818", "question": "What device is to the left of the gray thing above the entertainment center?", "program": "BOX0=LOC(image=IMAGE,object='entertainment center')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gray thing')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nANSWER0=VQA(image=IMAGE1,question='What device is to the left of the gray thing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5602, "imageId": "n235859", "question": "Is the shirt that looks white long sleeved or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='Is the shirt long sleeved or short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5603, "imageId": "n90294", "question": "What device is to the left of the magazine?", "program": "BOX0=LOC(image=IMAGE,object='magazine')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the left of the magazine?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5604, "imageId": "n90294", "question": "Is the remote control to the left of a chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote control')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5605, "imageId": "n16656", "question": "Does the gray ground look smooth and hard?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the gray ground look smooth and hard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5606, "imageId": "n279173", "question": "Which color does the sign in front of the building have?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color does the sign have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5607, "imageId": "n470131", "question": "Is the foil gold and round?", "program": "BOX0=LOC(image=IMAGE,object='foil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the foil?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the foil?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gold' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5608, "imageId": "n55058", "question": "Are there burgers on top of the cutting board in this picture?", "program": "BOX0=LOC(image=IMAGE,object='cutting board')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='burger')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5609, "imageId": "n16656", "question": "Are the leaves both still and orange?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the leaves still?')\nANSWER1=VQA(image=IMAGE,question='What color are the leaves?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5610, "imageId": "n23181", "question": "Are there any beds in the picture that are not dirty?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='dirty')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5611, "imageId": "n414992", "question": "The hairy man is wearing what?", "program": "BOX0=LOC(image=IMAGE,object='hairy man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the hairy man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5612, "imageId": "n541688", "question": "Is the boy in front of a couch?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5613, "imageId": "n288870", "question": "Does the young person wear sandals?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing on their feet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'sandals' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5614, "imageId": "n318370", "question": "Is the person next to the sign wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5615, "imageId": "n51002", "question": "Which color is the television, black or white?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the television, black or white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5616, "imageId": "n473688", "question": "What's the faucet mounted on?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the faucet mounted on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5617, "imageId": "n140421", "question": "Are the curtains to the right of a shelf?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtains')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5618, "imageId": "n140421", "question": "What's covering the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is covering the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5619, "imageId": "n9181", "question": "Is the motorbike made of the same material as the sign?", "program": "BOX0=LOC(image=IMAGE,object='motorbike')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the motorbike made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the sign made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5620, "imageId": "n437064", "question": "What dessert is to the left of the whipped cream?", "program": "BOX0=LOC(image=IMAGE,object='whipped cream')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nANSWER0=VQA(image=IMAGE0,question='What dessert is to the left of the whipped cream?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5621, "imageId": "n499081", "question": "Does the picture frame have small size?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What size is the picture frame?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5622, "imageId": "n433692", "question": "Do the pot and the mouse have the same shape?", "program": "ANSWER0=VQA(image=IMAGE,question='What shape is the pot?')\nANSWER1=VQA(image=IMAGE,question='What shape is the mouse?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5623, "imageId": "n319845", "question": "Do the chairs that are to the left of the vase appear to be empty and dark brown?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Do the chairs appear to be empty?')\nANSWER3=VQA(image=IMAGE1,question='What color are the chairs?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER3} == 'dark brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 5624, "imageId": "n499081", "question": "Is the picture frame that looks square small and black?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the picture frame square?')\nANSWER1=VQA(image=IMAGE0,question='Is the picture frame small?')\nANSWER2=VQA(image=IMAGE0,question='What color is the picture frame?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' and {ANSWER2} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 5625, "imageId": "n572716", "question": "Is the jet large or small?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the jet large or small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5626, "imageId": "n222915", "question": "What is sitting under the cooked vegetable?", "program": "BOX0=LOC(image=IMAGE,object='cooked vegetable')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting under the cooked vegetable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5627, "imageId": "n546616", "question": "How big is the round cake?", "program": "BOX0=LOC(image=IMAGE,object='round cake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the round cake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5628, "imageId": "n4777", "question": "Do you see a chair to the right of the bag?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5629, "imageId": "n532191", "question": "Which kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5630, "imageId": "n64959", "question": "Is the plastic pipe higher than the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic pipe')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the plastic pipe higher than the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5631, "imageId": "n222915", "question": "What does the fork sit on?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the fork sit on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5632, "imageId": "n162108", "question": "Is the white cabinet to the right of the shower curtain that is shown in the image?", "program": "BOX0=LOC(image=IMAGE,object='shower curtain')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white cabinet')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5633, "imageId": "n527290", "question": "Who is wearing trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5634, "imageId": "n527290", "question": "Who is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5635, "imageId": "n159284", "question": "What is the image showing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the image showing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5636, "imageId": "n579256", "question": "On which side of the picture is the large appliance?", "program": "BOX0=LOC(image=IMAGE,object='large appliance')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5637, "imageId": "n527290", "question": "What is she holding?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is she holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5638, "imageId": "n77818", "question": "What piece of furniture is underneath the television?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is underneath the television?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5639, "imageId": "n77818", "question": "What is the piece of furniture that is underneath the TV?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5640, "imageId": "n310828", "question": "On which side are the small glasses?", "program": "BOX0=LOC(image=IMAGE,object='small glasses')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5641, "imageId": "n334278", "question": "Is the field both brown and rocky?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the field?')\nANSWER1=VQA(image=IMAGE,question='What texture is the field?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'rocky' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5642, "imageId": "n398429", "question": "What appliance is on top of the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is on top of the oven?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5643, "imageId": "n334278", "question": "Of what color is that field?", "program": "ANSWER0=VQA(image=IMAGE,question='Of what color is that field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5644, "imageId": "n140421", "question": "What are the chairs made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the chairs made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5645, "imageId": "n4777", "question": "How hard is the chair in the bottom of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How hard is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5646, "imageId": "n355339", "question": "Is the table in front of the people beige or red?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=EVAL(expr=\"'beige' if {ANSWER0} == 'beige' else 'red'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5647, "imageId": "n274905", "question": "Which kind of clothing is not sleeveless?", "program": "BOX0=LOC(image=IMAGE,object='sleeveless clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'sleeveless' if {ANSWER0} > 0 else 'not sleeveless'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5648, "imageId": "n146522", "question": "Is the field green?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the field?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5649, "imageId": "n350766", "question": "What appliance is above the appliance that is above the drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What appliance is above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5650, "imageId": "n250715", "question": "What kind of aircraft is the controller mounted to?", "program": "BOX0=LOC(image=IMAGE,object='controller')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of aircraft is the controller mounted to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5651, "imageId": "n357784", "question": "Who is holding onto the device that looks black?", "program": "BOX0=LOC(image=IMAGE,object='black device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding onto the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5652, "imageId": "n256120", "question": "Is the van pink and metallic?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the van?')\nANSWER1=VQA(image=IMAGE0,question='What material is the van made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'pink' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5653, "imageId": "n240973", "question": "In which part of the picture is the black towel?", "program": "BOX0=LOC(image=IMAGE,object='black towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=EVAL(expr=\"'top' if {BOX1} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5654, "imageId": "n363445", "question": "What is the food that is above the fruits to the left of the dessert called?", "program": "BOX0=LOC(image=IMAGE,object='fruits')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the food called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5655, "imageId": "n357784", "question": "What is the woman looking at?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the woman looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5656, "imageId": "n546616", "question": "Is the small cup in the top of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small cup')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5657, "imageId": "n571179", "question": "Is the man beside the sign wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the man wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5658, "imageId": "n357784", "question": "What is the person that is not sad holding onto?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5659, "imageId": "n382416", "question": "Are the black heels small or large?", "program": "BOX0=LOC(image=IMAGE,object='black heels')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} < 10 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5660, "imageId": "n511913", "question": "The woman is holding what?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The woman is holding what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5661, "imageId": "n382416", "question": "Are the heels black?", "program": "BOX0=LOC(image=IMAGE,object='heels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the heels?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5662, "imageId": "n511913", "question": "What is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5663, "imageId": "n522733", "question": "Does the traffic signal to the right of the signal light appear to be metallic and high?", "program": "BOX0=LOC(image=IMAGE,object='signal light')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic signal')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5664, "imageId": "n511913", "question": "What device is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5665, "imageId": "n511913", "question": "What device is the blonde woman in front of the table holding, a Wii controller or a phone?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blonde woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What device is the woman holding?')\nANSWER1=EVAL(expr=\"'Wii controller' if {ANSWER0} == 'Wii controller' else 'phone'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5666, "imageId": "n256120", "question": "What vehicle is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=VQA(image=IMAGE,question='What vehicle is made of metal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5667, "imageId": "n312206", "question": "Which shape is the packet?", "program": "BOX0=LOC(image=IMAGE,object='packet')\nANSWER0=VQA(image=IMAGE,question='Which shape is the packet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5668, "imageId": "n312206", "question": "What is inside the container next to the glass?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='container')\nANSWER0=VQA(image=IMAGE0,question='What is inside the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5669, "imageId": "n548534", "question": "Do the sharp knives that are to the left of the oven look black and metallic?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sharp knives')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color are the sharp knives?')\nANSWER1=VQA(image=IMAGE1,question='What material are the sharp knives made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5670, "imageId": "n312206", "question": "What's inside the container?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5671, "imageId": "n483840", "question": "Who is wearing a ring?", "program": "BOX0=LOC(image=IMAGE,object='ring')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a ring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5672, "imageId": "n573460", "question": "Does the racket look white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the racket look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5673, "imageId": "n35676", "question": "What appliance is behind the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What appliance is behind the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5674, "imageId": "n275148", "question": "Is that picture frame white and high?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the picture frame?')\nANSWER1=VQA(image=IMAGE0,question='How high is the picture frame?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'high' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5675, "imageId": "n275148", "question": "Are both the mirror and the TV stand made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='TV stand')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the mirror made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the TV stand made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5676, "imageId": "n275857", "question": "Are there small desk lamps or fences?", "program": "BOX0=LOC(image=IMAGE,object='small desk lamp')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5677, "imageId": "n451187", "question": "What color is the sidewalk?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5678, "imageId": "n148872", "question": "Does the skinny girl look blond?", "program": "ANSWER0=VQA(image=IMAGE,question='What color hair does the skinny girl have?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blond' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5679, "imageId": "n431447", "question": "Is that napkin both white and clean?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the napkin?')\nANSWER1=VQA(image=IMAGE0,question='Is the napkin clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5680, "imageId": "n207708", "question": "What's the chair in front of?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the chair in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5681, "imageId": "n207708", "question": "What is the chair in front of?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the chair in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5682, "imageId": "n207708", "question": "Are there chairs or cabinets in the photo?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='cabinet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5683, "imageId": "n141939", "question": "Is the white towel short or long?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nANSWER0=VQA(image=IMAGE,question='Is the towel short or long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5684, "imageId": "n310828", "question": "What is the box on?", "program": "BOX0=LOC(image=IMAGE,object='box')\nANSWER0=VQA(image=IMAGE,question='What is the box on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5685, "imageId": "n310828", "question": "What is the piece of furniture that the box is on?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5686, "imageId": "n310828", "question": "Which kind of furniture is the box on?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the box on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5687, "imageId": "n150962", "question": "What is the piece of furniture that is below the window that is below the coats called?", "program": "BOX0=LOC(image=IMAGE,object='coats')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='piece of furniture')\nANSWER0=VQA(image=IMAGE1,question='What is the piece of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5688, "imageId": "n477215", "question": "Are the animals of different types?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the animals of different types?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5689, "imageId": "n311910", "question": "What color is the vehicle above the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5690, "imageId": "n6309", "question": "What material is the fence made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5691, "imageId": "n520071", "question": "Which kind of furniture isn't stacked?", "program": "BOX0=LOC(image=IMAGE,object='stacked furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} == 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5692, "imageId": "n335542", "question": "Does the bear that is walking look little?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the bear look little?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5693, "imageId": "n520071", "question": "Which item of furniture is full, the desk or the bookcase?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bookcase')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Is the desk full?')\nANSWER1=VQA(image=IMAGE1,question='Is the bookcase full?')\nANSWER2=EVAL(expr=\"'desk' if {ANSWER0} == 'yes' else 'bookcase'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5694, "imageId": "n64959", "question": "Is the freezer to the right of the cardboard container?", "program": "BOX0=LOC(image=IMAGE,object='cardboard container')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='freezer')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5695, "imageId": "n520071", "question": "What piece of furniture is not full?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} < 4 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5696, "imageId": "n137182", "question": "Does the shirt look long sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the shirt look long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5697, "imageId": "n470920", "question": "Who in this picture is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5698, "imageId": "n200692", "question": "Which side is the gas stove on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gas stove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5699, "imageId": "n262929", "question": "What is in front of the bag?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5700, "imageId": "n480253", "question": "Do the fire truck and the barn have the same color?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='barn')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the fire truck?')\nANSWER1=VQA(image=IMAGE1,question='What color is the barn?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5701, "imageId": "n480253", "question": "Do the fire truck and the wire have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='wire')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the fire truck?')\nANSWER1=VQA(image=IMAGE1,question='What color is the wire?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5702, "imageId": "n145498", "question": "What is the piece of furniture on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5703, "imageId": "n310828", "question": "What's the mouse pad on?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the mouse pad on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5704, "imageId": "n531359", "question": "What is the color of the tables that are on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tables')\nANSWER0=VQA(image=IMAGE0,question='What color are the tables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5705, "imageId": "n145498", "question": "Which kind of furniture is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5706, "imageId": "n473688", "question": "What hangs on the beige wall?", "program": "BOX0=LOC(image=IMAGE,object='beige wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What hangs on the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5707, "imageId": "n207893", "question": "What animal is standing in the tall grass?", "program": "BOX0=LOC(image=IMAGE,object='tall grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is standing in the tall grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5708, "imageId": "n204894", "question": "Which side of the photo is the toy on?", "program": "BOX0=LOC(image=IMAGE,object='toy')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5709, "imageId": "n271392", "question": "Which kind of vehicle is to the right of the men?", "program": "BOX0=LOC(image=IMAGE,object='men')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5710, "imageId": "n486200", "question": "Is there a fence or a traffic light in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='traffic light')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5711, "imageId": "n310828", "question": "What piece of furniture is the mouse pad on?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is the mouse pad on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5712, "imageId": "n259002", "question": "Is the small vehicle behind the goal?", "program": "BOX0=LOC(image=IMAGE,object='goal')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5713, "imageId": "n324908", "question": "How thick is the hair?", "program": "BOX0=LOC(image=IMAGE,object='hair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How thick is the hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5714, "imageId": "n324908", "question": "Is the short hair thick and black?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the short hair thick and black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5715, "imageId": "n151768", "question": "Does the street seem to be narrow?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the street seem to be narrow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5716, "imageId": "n311910", "question": "Are the glass buildings cream colored and low?", "program": "BOX0=LOC(image=IMAGE,object='glass buildings')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the glass buildings?')\nANSWER1=VQA(image=IMAGE0,question='Are the glass buildings low?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'cream' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5717, "imageId": "n455563", "question": "Is the mirror in front of the woman made of glass?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the mirror made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'glass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5718, "imageId": "n119944", "question": "Is the old tree behind the baskets near the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='baskets')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='old tree')\nIMAGE2=CROP_BEHIND(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5719, "imageId": "n350766", "question": "Which type of material is used to make the trash bin below the pepper shaker?", "program": "BOX0=LOC(image=IMAGE,object='pepper shaker')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trash bin')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which type of material is used to make the trash bin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5720, "imageId": "n208302", "question": "Which side are the metal cars on?", "program": "BOX0=LOC(image=IMAGE,object='metal cars')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5721, "imageId": "n154856", "question": "Is the silver car in front of the parked vehicle near the doorway?", "program": "BOX0=LOC(image=IMAGE,object='parked vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='doorway')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='silver car')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5722, "imageId": "n154856", "question": "Is the silver car in front or behind the van made of metal?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='silver car')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'front' if {ANSWER0} > 0 else 'behind'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5723, "imageId": "n54424", "question": "Are there any Wii controllers to the right of the shuttle?", "program": "BOX0=LOC(image=IMAGE,object='shuttle')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='Wii controllers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5724, "imageId": "n473688", "question": "What is the soap dish sitting on?", "program": "BOX0=LOC(image=IMAGE,object='soap dish')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the soap dish sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5725, "imageId": "n310828", "question": "What kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5726, "imageId": "n534106", "question": "Do the shirt and the shoe have the same color?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shoe')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the shoe?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5727, "imageId": "n473688", "question": "What color is the soap dish?", "program": "BOX0=LOC(image=IMAGE,object='soap dish')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the soap dish?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5728, "imageId": "n65885", "question": "Is the animal to the left of the cabinet gold or gray?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What color is the animal?')\nANSWER1=EVAL(expr=\"'gold' if {ANSWER0} == 'gold' else 'gray'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5729, "imageId": "n554880", "question": "Is the floor made of the same material as the chair?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='chair')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the floor made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the chair made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5730, "imageId": "n381072", "question": "Of what color is the knife the plate is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knife')\nANSWER0=VQA(image=IMAGE0,question='What color is the knife?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5731, "imageId": "n298104", "question": "Who is standing against the surfboard?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing against the surfboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5732, "imageId": "n435808", "question": "What is sitting next to the mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting next to the mouse pad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5733, "imageId": "n350766", "question": "Does the microwave have a different color than the toaster?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='toaster')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the microwave?')\nANSWER1=VQA(image=IMAGE1,question='What color is the toaster?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5734, "imageId": "n259002", "question": "Who is that spectator watching?", "program": "BOX0=LOC(image=IMAGE,object='spectator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is that spectator watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5735, "imageId": "n133585", "question": "Who wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who wears a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5736, "imageId": "n350766", "question": "Is the coffee pot different in color than the burner?", "program": "BOX0=LOC(image=IMAGE,object='coffee pot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='burner')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the coffee pot?')\nANSWER1=VQA(image=IMAGE1,question='What color is the burner?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5737, "imageId": "n350766", "question": "What kind of cooking utensil is the same color as the stove top that is made of chrome?", "program": "BOX0=LOC(image=IMAGE,object='stove top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chrome')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of cooking utensil is the same color as the stove top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5738, "imageId": "n280089", "question": "Is the bowl to the right of the containers the mugs are to the left of?", "program": "BOX0=LOC(image=IMAGE,object='containers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mugs')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='bowl')\nIMAGE2=CROP_RIGHTOF(image=IMAGE,box=BOX2)\nANSWER0=EVAL(expr=\"'yes' if {IMAGE2} == {IMAGE1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5739, "imageId": "n380113", "question": "Is it an indoors scene?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an indoors scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5740, "imageId": "n166008", "question": "Who is sitting in front of the water?", "program": "BOX0=LOC(image=IMAGE,object='water')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting in front of the water?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5741, "imageId": "n380113", "question": "Is the headband different in color than the field?", "program": "BOX0=LOC(image=IMAGE,object='headband')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='field')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the headband?')\nANSWER1=VQA(image=IMAGE1,question='What color is the field?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5742, "imageId": "n398257", "question": "Which kind of device is above the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is above the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5743, "imageId": "n398257", "question": "What kind of device is above the device the desk is under of?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of device is above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5744, "imageId": "n199286", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5745, "imageId": "n526228", "question": "Is the remote control made of the same material as the frame?", "program": "BOX0=LOC(image=IMAGE,object='remote control')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='frame')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the remote control made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the frame made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5746, "imageId": "n240973", "question": "Is the white device in the top part or in the bottom of the picture?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5747, "imageId": "n417401", "question": "What sits on the shelf inside the bathroom?", "program": "BOX0=LOC(image=IMAGE,object='bathroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What sits on the shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5748, "imageId": "n64959", "question": "What is the pipe higher than?", "program": "BOX0=LOC(image=IMAGE,object='pipe')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pipe higher than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5749, "imageId": "n556604", "question": "Is the color of the tree different than the table?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the tree?')\nANSWER1=VQA(image=IMAGE1,question='What color is the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5750, "imageId": "n541482", "question": "Are the pants white and soft?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the pants?')\nANSWER1=VQA(image=IMAGE,question='What texture are the pants?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'soft' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5751, "imageId": "n526228", "question": "Are the pillows on top of a bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5752, "imageId": "n204894", "question": "Who is talking on the phone?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is talking on the phone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5753, "imageId": "n204894", "question": "Is the person talking on a phone?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='phone')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5754, "imageId": "n357784", "question": "Does the bottle cap look closed or open?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the bottle cap look closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5755, "imageId": "n578564", "question": "Is the window behind a girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5756, "imageId": "n204894", "question": "Who is in front of the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5757, "imageId": "n281241", "question": "Who is sitting beside the gentleman?", "program": "BOX0=LOC(image=IMAGE,object='gentleman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting beside the gentleman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5758, "imageId": "n567860", "question": "What is the animal that is white?", "program": "BOX0=LOC(image=IMAGE,object='animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the animal?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5759, "imageId": "n173807", "question": "Are there any fire hydrants or street signs that are not red?", "program": "BOX0=LOC(image=IMAGE,object='fire hydrant')\nBOX1=LOC(image=IMAGE,object='street sign')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5760, "imageId": "n271392", "question": "What is the sidewalk made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sidewalk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5761, "imageId": "n281241", "question": "Who is the young person to the left of the chair sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young person')\nANSWER0=VQA(image=IMAGE0,question='Who is the young person sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5762, "imageId": "n281241", "question": "Who is the man sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5763, "imageId": "n207893", "question": "Are the mountains high or low?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the mountains high or low?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5764, "imageId": "n567860", "question": "What animal is young?", "program": "BOX0=LOC(image=IMAGE,object='young')\nANSWER0=VQA(image=IMAGE,question='What animal is young?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5765, "imageId": "n280089", "question": "What does the stove sit next to?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the stove sit next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5766, "imageId": "n282436", "question": "Is the monitor to the right of a computer?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='monitor')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5767, "imageId": "n98540", "question": "What type of clothing is not short, the pants or the socks?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='socks')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What type of clothing is not short?')\nANSWER1=VQA(image=IMAGE1,question='What type of clothing is not short?')\nANSWER2=EVAL(expr=\"'pants' if {ANSWER0} != 'short' else 'socks'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5768, "imageId": "n55058", "question": "What food is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown food')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5769, "imageId": "n98540", "question": "Which kind of clothing is not short?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is not short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5770, "imageId": "n98540", "question": "Which kind of clothing in the image is short?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of clothing is short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5771, "imageId": "n98540", "question": "Which kind of clothing is short?", "program": "BOX0=LOC(image=IMAGE,object='short')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5772, "imageId": "n55058", "question": "What kind of fast food is crispy?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of fast food is crispy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5773, "imageId": "n98540", "question": "Are the trousers white and long?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the trousers?')\nANSWER1=VQA(image=IMAGE,question='Are the trousers long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5774, "imageId": "n55058", "question": "Which kind of food isn't crispy?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food isn't crispy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5775, "imageId": "n234683", "question": "What kind of clothing is black?", "program": "BOX0=LOC(image=IMAGE,object='black clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5776, "imageId": "n118102", "question": "Is the round cake to the left or to the right of the girl who wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='girl who wears a shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='round cake')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5777, "imageId": "n59147", "question": "What is the item of furniture that is to the right of the white toilet?", "program": "BOX0=LOC(image=IMAGE,object='white toilet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5778, "imageId": "n118102", "question": "What kind of dessert is on top of the tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of dessert is on top of the tray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5779, "imageId": "n118102", "question": "Is there a cake on top of the tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cake')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5780, "imageId": "n556604", "question": "What is the young woman near the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the young woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5781, "imageId": "n315859", "question": "The trees that look tall are growing behind what?", "program": "BOX0=LOC(image=IMAGE,object='tall trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The trees that look tall are growing behind what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5782, "imageId": "n556604", "question": "What device is the woman near the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What device is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5783, "imageId": "n434283", "question": "Is the tire that looks dark round and old?", "program": "BOX0=LOC(image=IMAGE,object='dark tire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the tire round and old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5784, "imageId": "n305495", "question": "Do the blinds look thin?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the blinds look thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5785, "imageId": "n379991", "question": "Does the baking pan to the left of the scissors appear to be round?", "program": "BOX0=LOC(image=IMAGE,object='scissors')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='baking pan')\nANSWER0=VQA(image=IMAGE0,question='Does the baking pan appear to be round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5786, "imageId": "n305495", "question": "Are the blinds in front of the window dense or sparse?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blinds')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'dense' if {ANSWER0} > 0 else 'sparse'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5787, "imageId": "n262929", "question": "Is the dark tie below the small hat?", "program": "BOX0=LOC(image=IMAGE,object='small hat')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dark tie')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5788, "imageId": "n283587", "question": "Which kind of furniture is below the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is below the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5789, "imageId": "n283587", "question": "What are the pieces of furniture below the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5790, "imageId": "n283587", "question": "Is there a chair next to the cupboard?", "program": "BOX0=LOC(image=IMAGE,object='cupboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5791, "imageId": "n496803", "question": "What are the items of furniture to the left of the person that is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What are the items of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5792, "imageId": "n66756", "question": "Is the heavy person wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='heavy person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='helmet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5793, "imageId": "n551964", "question": "What is the long fence made of?", "program": "BOX0=LOC(image=IMAGE,object='long fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the long fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5794, "imageId": "n283587", "question": "Are the tall chairs below a countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tall chairs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5795, "imageId": "n69237", "question": "Are both the window and the heater made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='heater')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the window made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the heater made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5796, "imageId": "n264887", "question": "Does the speaker have white color?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the speaker?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5797, "imageId": "n352479", "question": "Do the jacket and the hat have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='hat')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE1,question='What color is the hat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5798, "imageId": "n536256", "question": "Is the person that is to the right of the man looking at a laptop?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person looking at?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'laptop' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5799, "imageId": "n567860", "question": "Does the yellow fruit look unpeeled and ripe?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the yellow fruit look unpeeled and ripe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5800, "imageId": "n567860", "question": "Does the ripe banana look peeled?", "program": "BOX0=LOC(image=IMAGE,object='ripe banana')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the ripe banana look peeled?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5801, "imageId": "n433532", "question": "Is the red drink in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='red drink')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5802, "imageId": "n522733", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5803, "imageId": "n522733", "question": "Where is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Where is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5804, "imageId": "n264887", "question": "Do the keyboard and the monitor have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='monitor')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the keyboard?')\nANSWER1=VQA(image=IMAGE1,question='What color is the monitor?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5805, "imageId": "n289376", "question": "What kind of sign is standing in the lawn?", "program": "BOX0=LOC(image=IMAGE,object='lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of sign is standing in the lawn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5806, "imageId": "n498712", "question": "Does that luggage cart look still?", "program": "BOX0=LOC(image=IMAGE,object='luggage cart')\nANSWER0=VQA(image=IMAGE,question='Does the luggage cart look still?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5807, "imageId": "n498712", "question": "Does the luggage cart look blue and still?", "program": "BOX0=LOC(image=IMAGE,object='luggage cart')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the luggage cart?')\nANSWER1=VQA(image=IMAGE0,question='Is the luggage cart still?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5808, "imageId": "n195925", "question": "Is the boat near the bridge white and small?", "program": "BOX0=LOC(image=IMAGE,object='bridge')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boat')\nANSWER0=VQA(image=IMAGE0,question='What color is the boat?')\nANSWER1=VQA(image=IMAGE0,question='How big is the boat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5809, "imageId": "n578564", "question": "What kind of cooking utensil is above the flower pot?", "program": "BOX0=LOC(image=IMAGE,object='flower pot')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=VQA(image=IMAGE0,question='What kind of cooking utensil is above the flower pot?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5810, "imageId": "n473688", "question": "Which color is the soap dispenser on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soap dispenser')\nANSWER0=VQA(image=IMAGE0,question='Which color is the soap dispenser?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5811, "imageId": "n508733", "question": "Which kind of food is on the table?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5812, "imageId": "n162586", "question": "What piece of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What piece of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5813, "imageId": "n508733", "question": "What is the piece of furniture that the soup is on?", "program": "BOX0=LOC(image=IMAGE,object='soup')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5814, "imageId": "n162586", "question": "What is the purple item of furniture called?", "program": "BOX0=LOC(image=IMAGE,object='purple item of furniture')\nANSWER0=VQA(image=IMAGE,question='What is the purple item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5815, "imageId": "n162586", "question": "Which kind of furniture is purple?", "program": "BOX0=LOC(image=IMAGE,object='purple')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is purple?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5816, "imageId": "n173807", "question": "What vehicle is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5817, "imageId": "n111390", "question": "Is the material of the window the same as the table?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the window made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5818, "imageId": "n28996", "question": "Are there any round plates or grapes?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='grapes')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5819, "imageId": "n28996", "question": "Are there any kiwis in the scene?", "program": "BOX0=LOC(image=IMAGE,object='kiwi')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5820, "imageId": "n513100", "question": "What's the table sitting on?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the table sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5821, "imageId": "n238266", "question": "Are the cookies to the right of a knife?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cookies')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5822, "imageId": "n460385", "question": "In which part are the glasses, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glasses')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5823, "imageId": "n513429", "question": "What's the speaker sitting on?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the speaker sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5824, "imageId": "n12404", "question": "Does the clear water look white?", "program": "BOX0=LOC(image=IMAGE,object='clear water')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the clear water?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5825, "imageId": "n59627", "question": "What is worn on the man that is not young?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is worn on the man?')\nANSWER1=VQA(image=IMAGE0,question='Is the man young?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if {ANSWER1} == 'no' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5826, "imageId": "n133585", "question": "Is the person to the left of the boy wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5827, "imageId": "n473688", "question": "What's the girl using?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the girl using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5828, "imageId": "n125122", "question": "Does the television appear to be on?", "program": "BOX0=LOC(image=IMAGE,object='television')\nANSWER0=VQA(image=IMAGE,question='Does the television appear to be on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5829, "imageId": "n432591", "question": "Which kind of furniture is not long?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is not long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5830, "imageId": "n260762", "question": "Who is watching the player that is to the right of the frisbee?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='player')\nANSWER0=VQA(image=IMAGE0,question='Who is watching the player?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5831, "imageId": "n283587", "question": "Is the countertop above the chairs that are next to the cupboard?", "program": "BOX0=LOC(image=IMAGE,object='cupboard')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='countertop')\nIMAGE2=CROP_ABOVE(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5832, "imageId": "n432591", "question": "What kind of furniture is long?", "program": "BOX0=LOC(image=IMAGE,object='long furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5833, "imageId": "n432591", "question": "What do you think is the long piece of furniture?", "program": "BOX0=LOC(image=IMAGE,object='long piece of furniture')\nANSWER0=VQA(image=IMAGE,question='What do you think is the long piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5834, "imageId": "n473688", "question": "Who is using the toothbrush?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is using the toothbrush?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5835, "imageId": "n260762", "question": "Who is the man that is standing watching?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man that is standing watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5836, "imageId": "n125122", "question": "What color are the pillows that look clean?", "program": "BOX0=LOC(image=IMAGE,object='clean pillows')\nANSWER0=VQA(image=IMAGE,question='What color are the pillows?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5837, "imageId": "n111390", "question": "Who is waiting for the cake?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is waiting for the cake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5838, "imageId": "n111390", "question": "Who is waiting for the blue thing to the right of the knife?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blue thing')\nANSWER0=VQA(image=IMAGE0,question='Who is waiting for the blue thing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5839, "imageId": "n279173", "question": "Are the triangular flags to the right of him?", "program": "BOX0=LOC(image=IMAGE,object='him')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='triangular flags')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5840, "imageId": "n314630", "question": "Is the house both wooden and red?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the house made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the house?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5841, "imageId": "n12214", "question": "Is the shoe worn on a skater?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shoe')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5842, "imageId": "n196058", "question": "What are the large animals called?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the large animals called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5843, "imageId": "n562105", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5844, "imageId": "n133585", "question": "Is the fat person to the right or to the left of the boy that is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='boy wearing pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fat person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5845, "imageId": "n196058", "question": "Are these zebras or goats?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nBOX1=LOC(image=IMAGE,object='goat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'zebras' if {ANSWER0} > 0 else 'goats'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5846, "imageId": "n196058", "question": "What kind of animal is large?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of animal is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5847, "imageId": "n435808", "question": "Is the computer different in color than the router?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='router')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the computer?')\nANSWER1=VQA(image=IMAGE1,question='What color is the router?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5848, "imageId": "n222297", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5849, "imageId": "n16378", "question": "Do the bag and the blouse have the same color?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='blouse')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bag?')\nANSWER1=VQA(image=IMAGE1,question='What color is the blouse?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5850, "imageId": "n488874", "question": "Is the shirt sleeveless or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt sleeveless or short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5851, "imageId": "n532191", "question": "What kind of bag is to the right of the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='What kind of bag is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5852, "imageId": "n216553", "question": "Which color is the small sky?", "program": "BOX0=LOC(image=IMAGE,object='small sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the small sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5853, "imageId": "n532191", "question": "Is the black bag to the right of a chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5854, "imageId": "n513100", "question": "Are there chairs below the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5855, "imageId": "n4777", "question": "What is the lid made of plastic sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='lid')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5856, "imageId": "n525901", "question": "What is common to the shelf and the desk?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the shelf and the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5857, "imageId": "n493357", "question": "Does that house look small and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Does that house look small and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5858, "imageId": "n493357", "question": "Which side of the picture is the house on?", "program": "BOX0=LOC(image=IMAGE,object='house')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5859, "imageId": "n90294", "question": "How thick is the book to the left of the remote?", "program": "BOX0=LOC(image=IMAGE,object='remote')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='book')\nANSWER0=VQA(image=IMAGE0,question='How thick is the book?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5860, "imageId": "n410289", "question": "Is the ceiling different in color than the sink?", "program": "BOX0=LOC(image=IMAGE,object='ceiling')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sink')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the ceiling?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sink?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5861, "imageId": "n14087", "question": "What is the furry animal wearing?", "program": "BOX0=LOC(image=IMAGE,object='furry animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the furry animal wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5862, "imageId": "n130638", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5863, "imageId": "n460385", "question": "What is on the shelf?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5864, "imageId": "n460385", "question": "What is on the shelf made of wood?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nANSWER0=VQA(image=IMAGE0,question='What is on the shelf?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5865, "imageId": "n9856", "question": "Do the socks that are not short have black color?", "program": "BOX0=LOC(image=IMAGE,object='socks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='black')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5866, "imageId": "n460385", "question": "What's the plant on?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nANSWER0=VQA(image=IMAGE,question='What is the plant on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5867, "imageId": "n579256", "question": "How long is the brown hair?", "program": "BOX0=LOC(image=IMAGE,object='brown hair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the brown hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5868, "imageId": "n541854", "question": "Are there chairs or knives in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='knife')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5869, "imageId": "n4777", "question": "Is the bottle tall?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the bottle tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5870, "imageId": "n200907", "question": "Does the shirt look short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5871, "imageId": "n480253", "question": "Which color is the car, brown or white?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the car?')\nANSWER1=EVAL(expr=\"'brown' if {ANSWER0} == 'brown' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5872, "imageId": "n441859", "question": "Is the surf board to the left of the person both black and wooden?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surf board')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color is the surf board?')\nANSWER3=VQA(image=IMAGE1,question='What material is the surf board made of?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'black' and {ANSWER3} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 5873, "imageId": "n181210", "question": "What is the name of the fruit that has the same shape as the lid on top of the cup?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lid')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the name of the fruit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5874, "imageId": "n14087", "question": "What is the dog wearing?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the dog wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5875, "imageId": "n313060", "question": "Does the square table look brown and metallic?", "program": "BOX0=LOC(image=IMAGE,object='square table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the square table?')\nANSWER1=VQA(image=IMAGE0,question='What material is the square table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5876, "imageId": "n507149", "question": "Does the water have a different color than the sea foam?", "program": "BOX0=LOC(image=IMAGE,object='water')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sea foam')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the water?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sea foam?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5877, "imageId": "n499081", "question": "Are there both a window and a door in the image?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5878, "imageId": "n390187", "question": "Is this person looking up or playing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person doing?')\nANSWER1=EVAL(expr=\"'looking up' if {ANSWER0} == 'looking up' else 'playing'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5879, "imageId": "n543966", "question": "What type of animal is in front of the trees that the clouds are above?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clouds')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nANSWER0=VQA(image=IMAGE1,question='What type of animal is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5880, "imageId": "n167164", "question": "Are there any grinders or traffic lights in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='grinder')\nBOX1=LOC(image=IMAGE,object='traffic light')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5881, "imageId": "n433692", "question": "Does the mouse have the same shape as the laptop computer?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the mouse have the same shape as the laptop computer?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5882, "imageId": "n497789", "question": "Does the vehicle on the field seem to be small?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Does the vehicle seem to be small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5883, "imageId": "n347706", "question": "Is there a child in the image that is eating?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the child eating?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5884, "imageId": "n347706", "question": "Who is playing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5885, "imageId": "n95369", "question": "Do you see any counters in the empty bathroom?", "program": "BOX0=LOC(image=IMAGE,object='empty bathroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='counters')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5886, "imageId": "n355339", "question": "Is the reading man in front of the people watching the laptop near the glass?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='people')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='man')\nIMAGE3=CROP(image=IMAGE2,box=BOX3)\nBOX4=LOC(image=IMAGE3,object='reading man')\nANSWER0=COUNT(box=BOX4)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5887, "imageId": "n413761", "question": "Is the white vehicle on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5888, "imageId": "n275148", "question": "Is there a silver television or speaker?", "program": "BOX0=LOC(image=IMAGE,object='television')\nBOX1=LOC(image=IMAGE,object='speaker')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5889, "imageId": "n441859", "question": "Is the wet sand both soft and brown?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sand soft?')\nANSWER1=VQA(image=IMAGE,question='What color is the sand?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5890, "imageId": "n275148", "question": "What device is behind the couch near the wall?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What device is behind the couch near the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5891, "imageId": "n355339", "question": "What kind of furniture is to the left of the drink?", "program": "BOX0=LOC(image=IMAGE,object='drink')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is to the left of the drink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5892, "imageId": "n355339", "question": "What do the people that are talking sit around?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do the people sit around?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5893, "imageId": "n167552", "question": "Are there cats near the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cats')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5894, "imageId": "n433692", "question": "Does the lamp look fat?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the lamp look fat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5895, "imageId": "n410476", "question": "Is this giraffe in front of a fence?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5896, "imageId": "n315887", "question": "Are there both computers and phones in the image?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nBOX1=LOC(image=IMAGE,object='phone')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5897, "imageId": "n471866", "question": "Does the man look tall or short?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the man look tall or short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5898, "imageId": "n167164", "question": "Does the street look straight?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the street look straight?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5899, "imageId": "n271392", "question": "What devices are on the sidewalk in the image?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What devices are on the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5900, "imageId": "n234722", "question": "What is the cooking utensil above the flat table?", "program": "BOX0=LOC(image=IMAGE,object='flat table')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5901, "imageId": "n125122", "question": "On which side are the white pillows, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='white pillows')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5902, "imageId": "n526228", "question": "Which kind of device is on top of the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is on top of the coffee table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5903, "imageId": "n127705", "question": "What color is the shirt the person is playing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5904, "imageId": "n150962", "question": "Is the window above the table rectangular and black?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the window rectangular and black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5905, "imageId": "n540852", "question": "Is the man that is to the right of the woman wearing a suit?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the man wearing a suit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5906, "imageId": "n540852", "question": "The man to the right of the woman is wearing what?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5907, "imageId": "n127705", "question": "What is the height of the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='What is the height of the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5908, "imageId": "n326988", "question": "Which side of the photo is the adult man on?", "program": "BOX0=LOC(image=IMAGE,object='adult man')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='adult man')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5909, "imageId": "n279173", "question": "What is the sign in front of the building?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sign in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5910, "imageId": "n326988", "question": "What is the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5911, "imageId": "n68769", "question": "Is the plate the same color as the curtain?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='curtain')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the plate?')\nANSWER1=VQA(image=IMAGE1,question='What color is the curtain?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5912, "imageId": "n181355", "question": "What kind of furniture isn't soft?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture isn't soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5913, "imageId": "n68769", "question": "What do both the ceiling and the table have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the ceiling and the table have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5914, "imageId": "n181355", "question": "Which kind of furniture is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5915, "imageId": "n181355", "question": "What is the soft piece of furniture?", "program": "BOX0=LOC(image=IMAGE,object='soft piece of furniture')\nANSWER0=VQA(image=IMAGE,question='What is the soft piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5916, "imageId": "n146555", "question": "Which side is the plastic bottle on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5917, "imageId": "n181355", "question": "What type of furniture is not soft, the couch or the coffee table?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of furniture is not soft?')\nANSWER1=EVAL(expr=\"'couch' if {ANSWER0} == 'coffee table' else 'coffee table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5918, "imageId": "n71728", "question": "Is the woman to the left or to the right of the man in the middle of the picture?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5919, "imageId": "n302358", "question": "What is under the man in this picture?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5920, "imageId": "n125122", "question": "What's in front of the curtains?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the curtains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5921, "imageId": "n208458", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5922, "imageId": "n433532", "question": "Who is looking down?", "program": "BOX0=LOC(image=IMAGE,object='down')\nANSWER0=VQA(image=IMAGE,question='Who is looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5923, "imageId": "n28572", "question": "The flowers are in front of what?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The flowers are in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5924, "imageId": "n166008", "question": "Is it an outdoors or indoors scene?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an outdoors or indoors scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5925, "imageId": "n334278", "question": "Who is playing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is playing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5926, "imageId": "n355339", "question": "What is the device to the right of the person that watches the laptop?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nANSWER0=VQA(image=IMAGE1,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5927, "imageId": "n398429", "question": "Does the microwave look rectangular and white?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the microwave?')\nANSWER1=VQA(image=IMAGE0,question='What color is the microwave?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rectangular' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5928, "imageId": "n344136", "question": "Do the small books look short?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the small books look short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5929, "imageId": "n513429", "question": "What device is not open, the monitor or the laptop?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nBOX1=LOC(image=IMAGE,object='laptop')\nANSWER0=VQA(image=IMAGE,question='Is the monitor open?')\nANSWER1=VQA(image=IMAGE,question='Is the laptop open?')\nANSWER2=EVAL(expr=\"'monitor' if {ANSWER0} == 'no' else 'laptop'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5930, "imageId": "n119944", "question": "Do the clean shorts look gray and short?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the clean shorts?')\nANSWER1=VQA(image=IMAGE,question='Are the clean shorts short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5931, "imageId": "n44249", "question": "Does the woman to the left of the man appear to be sitting?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5932, "imageId": "n310625", "question": "Is the blue toothbrush leaning against the tap to the right of the bottle?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tap')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='blue toothbrush')\nIMAGE2=CROP_LEANING(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5933, "imageId": "n501609", "question": "What shape is the microwave in the middle of the picture?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the microwave?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5934, "imageId": "n153118", "question": "Are there any American flags on the pole that is not short?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nBOX1=LOC(image=IMAGE,object='American flag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='short pole')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5935, "imageId": "n566028", "question": "Is the skateboard to the left or to the right of the tall person?", "program": "BOX0=LOC(image=IMAGE,object='tall person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5936, "imageId": "n315887", "question": "What kind of furniture is below the white thing that is in front of the monitor?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white thing')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of furniture is below the white thing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5937, "imageId": "n119886", "question": "Is the shelf above the toilet brown and small?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the shelf?')\nANSWER1=VQA(image=IMAGE1,question='How big is the shelf?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5938, "imageId": "n233607", "question": "Is the controller in the top part or in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='controller')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5939, "imageId": "n451187", "question": "What vehicles are white?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=VQA(image=IMAGE,question='What color is the vehicle?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5940, "imageId": "n274905", "question": "Is the fence behind the man metallic and red?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=VQA(image=IMAGE0,question='What color is the fence?')\nANSWER1=VQA(image=IMAGE0,question='What material is the fence made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5941, "imageId": "n398257", "question": "What is in front of the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5942, "imageId": "n501609", "question": "What is the appliance that is not gray called?", "program": "BOX0=LOC(image=IMAGE,object='gray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What is the appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5943, "imageId": "n125122", "question": "What is the shape of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nANSWER0=VQA(image=IMAGE,question='What is the shape of the lamp?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5944, "imageId": "n346736", "question": "Is the long door on the edge of a bus?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='long door')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5945, "imageId": "n159802", "question": "Who is holding the cell phone?", "program": "BOX0=LOC(image=IMAGE,object='cell phone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the cell phone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5946, "imageId": "n159802", "question": "Who is holding the device in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5947, "imageId": "n65202", "question": "Do the bags that are not up look still?", "program": "BOX0=LOC(image=IMAGE,object='up')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bags')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Do the bags look still?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5948, "imageId": "n369970", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5949, "imageId": "n497789", "question": "Are the grazing animals behind the wild plant that grows in the field?", "program": "BOX0=LOC(image=IMAGE,object='wild plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grazing animals')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5950, "imageId": "n548534", "question": "Are there either any towels or shelves in this photo?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nBOX1=LOC(image=IMAGE,object='shelf')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5951, "imageId": "n200692", "question": "Is the plate blue?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the plate?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5952, "imageId": "n16378", "question": "What is the woman looking down at?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman looking down at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5953, "imageId": "n369970", "question": "Who is wearing the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5954, "imageId": "n546616", "question": "Who is the baby sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='baby')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the baby sitting atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5955, "imageId": "n486200", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5956, "imageId": "n83784", "question": "What animal do you think is to the right of the side table?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is to the right of the side table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5957, "imageId": "n83784", "question": "Does the black and white cat sit atop the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black and white cat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5958, "imageId": "n126087", "question": "What are the rackets lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='rackets')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the rackets lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5959, "imageId": "n126087", "question": "What is in front of the sitting-down people that are lying on top of the courtyard?", "program": "BOX0=LOC(image=IMAGE,object='courtyard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sitting-down people')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='lying people')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What is in front of the sitting-down people?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5960, "imageId": "n126087", "question": "Who are the rackets in front of?", "program": "BOX0=LOC(image=IMAGE,object='rackets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who are the rackets in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5961, "imageId": "n382416", "question": "What is this item of furniture called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is this item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5962, "imageId": "n238266", "question": "Do you see both plates and pizzas?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='pizza')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5963, "imageId": "n435808", "question": "Are there any monitors to the right of the black object which sits on top of the mousepad?", "program": "BOX0=LOC(image=IMAGE,object='black object')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mousepad')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='monitors')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5964, "imageId": "n382416", "question": "Which kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5965, "imageId": "n367944", "question": "Which kind of furniture is to the left of the calculator?", "program": "BOX0=LOC(image=IMAGE,object='calculator')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5966, "imageId": "n159802", "question": "Is the man to the right of a chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5967, "imageId": "n263180", "question": "What kind of vehicle is to the left of the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5968, "imageId": "n554880", "question": "On which side of the image is the TV?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5969, "imageId": "n554880", "question": "Which type of device is made of glass, the television or the mobile phone?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='mobile phone')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Which type of device is made of glass?')\nANSWER1=VQA(image=IMAGE1,question='Which type of device is made of glass?')\nANSWER2=EVAL(expr=\"'television' if {ANSWER0} == 'glass' else 'mobile phone'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5970, "imageId": "n369595", "question": "Is the lawn brown and grassy?", "program": "BOX0=LOC(image=IMAGE,object='lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the lawn?')\nANSWER1=VQA(image=IMAGE0,question='Is the lawn grassy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5971, "imageId": "n279581", "question": "Is the bat that is made of wood thin and brown?", "program": "BOX0=LOC(image=IMAGE,object='wooden bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the bat thin?')\nANSWER1=VQA(image=IMAGE0,question='What color is the bat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5972, "imageId": "n532213", "question": "Is the shirt short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5973, "imageId": "n508733", "question": "What kind of clothing is long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5974, "imageId": "n240666", "question": "Is there any mirror above the faucet made of metal?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the mirror made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'metal' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5975, "imageId": "n119944", "question": "Who is the large animal looking down at?", "program": "BOX0=LOC(image=IMAGE,object='large animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the large animal looking down at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5976, "imageId": "n497789", "question": "Where do the brown animals stand on?", "program": "BOX0=LOC(image=IMAGE,object='brown animals')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where do the brown animals stand on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5977, "imageId": "n489190", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5978, "imageId": "n432591", "question": "What is the piece of furniture that the clock near the books sits atop called?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5979, "imageId": "n549922", "question": "What is the stuffed bear in front of?", "program": "BOX0=LOC(image=IMAGE,object='stuffed bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the stuffed bear in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5980, "imageId": "n549922", "question": "What toy is in front of the counter?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toy')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What toy is in front of the counter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5981, "imageId": "n508641", "question": "The glove has what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the glove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5982, "imageId": "n273901", "question": "What is the vehicle that is parked on the pavement called?", "program": "BOX0=LOC(image=IMAGE,object='pavement')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5983, "imageId": "n393305", "question": "Is the fire hydrant made of the same material as the traffic sign?", "program": "BOX0=LOC(image=IMAGE,object='fire hydrant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='traffic sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the fire hydrant made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the traffic sign made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5984, "imageId": "n296467", "question": "Which are less healthy, the cupcakes or the carrots?", "program": "BOX0=LOC(image=IMAGE,object='cupcakes')\nBOX1=LOC(image=IMAGE,object='carrots')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'cupcakes' if {ANSWER0} > {ANSWER1} else 'carrots'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5985, "imageId": "n302387", "question": "Is that rug both clean and green?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the rug clean?')\nANSWER1=VQA(image=IMAGE,question='What color is the rug?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'clean' and {ANSWER1} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5986, "imageId": "n275148", "question": "Does the TV stand look brown and short?", "program": "BOX0=LOC(image=IMAGE,object='TV stand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the TV stand?')\nANSWER1=VQA(image=IMAGE0,question='How tall is the TV stand?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5987, "imageId": "n35676", "question": "Is the electric oven below a microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='electric oven')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5988, "imageId": "n97485", "question": "Are the utensils to the left of the oven wooden and clean?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensils')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What material are the utensils made of?')\nANSWER3=VQA(image=IMAGE1,question='Are the utensils clean?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'wooden' and {ANSWER3} == 'clean' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 5989, "imageId": "n411121", "question": "Is there a helmet that is not silver?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nANSWER0=VQA(image=IMAGE,question='What color is the helmet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'silver' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5990, "imageId": "n556604", "question": "What's the tree in front of?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tree in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5991, "imageId": "n556604", "question": "What is the tree in front of?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tree in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5992, "imageId": "n411121", "question": "Is the helmet blue?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the helmet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 5993, "imageId": "n234722", "question": "What is the pizza on?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pizza on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5994, "imageId": "n526228", "question": "Is the skateboard both wooden and long?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the skateboard wooden?')\nANSWER1=VQA(image=IMAGE,question='Is the skateboard long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5995, "imageId": "n290409", "question": "What's the sidewalk in front of?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sidewalk in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5996, "imageId": "n181355", "question": "Are there either any TVs or Wii controllers?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nBOX1=LOC(image=IMAGE,object='Wii controller')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 5997, "imageId": "n317189", "question": "How clean are the skis?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean are the skis?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5998, "imageId": "n119944", "question": "What is the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 5999, "imageId": "n295771", "question": "Is the couch near the window both red and smooth?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the couch?')\nANSWER3=VQA(image=IMAGE0,question='What texture is the couch?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'red' and {ANSWER3} == 'smooth' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6000, "imageId": "n199758", "question": "The tall person is holding what?", "program": "BOX0=LOC(image=IMAGE,object='tall person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tall person holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6001, "imageId": "n272313", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6002, "imageId": "n272313", "question": "Is he wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='hand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6003, "imageId": "n210269", "question": "Is that window new or old?", "program": "ANSWER0=VQA(image=IMAGE,question='Is that window new or old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6004, "imageId": "n398257", "question": "On which side is the wood shelf?", "program": "BOX0=LOC(image=IMAGE,object='wood shelf')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6005, "imageId": "n199286", "question": "What animal is to the left of the girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is to the left of the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6006, "imageId": "n199097", "question": "Who is the vehicle in front of?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the vehicle in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6007, "imageId": "n437192", "question": "What kind of animal sits on the gray sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='gray sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal sits on the gray sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6008, "imageId": "n437192", "question": "What kind of animal sits on the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal sits on the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6009, "imageId": "n437192", "question": "What does the bear that is not small sit on?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not small')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What does the bear sit on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6010, "imageId": "n278312", "question": "What appliance is to the left of the toaster?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is to the left of the toaster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6011, "imageId": "n282607", "question": "Who is standing on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6012, "imageId": "n450919", "question": "What animal is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6013, "imageId": "n578564", "question": "Are there any pans?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6014, "imageId": "n541688", "question": "On which side of the image is the young girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6015, "imageId": "n578564", "question": "Are there buckets or sugar packets?", "program": "BOX0=LOC(image=IMAGE,object='bucket')\nBOX1=LOC(image=IMAGE,object='sugar packet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6016, "imageId": "n526228", "question": "On which side is the telephone?", "program": "BOX0=LOC(image=IMAGE,object='telephone')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6017, "imageId": "n290409", "question": "What height is the basket behind the truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='basket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What height is the basket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6018, "imageId": "n433692", "question": "Is the small cat lying next to a computer mouse?", "program": "BOX0=LOC(image=IMAGE,object='computer mouse')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small cat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6019, "imageId": "n187961", "question": "Does the animal in front of the kid look short?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the animal look short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6020, "imageId": "n199097", "question": "Does the coat look uncomfortable and long?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the coat look uncomfortable?')\nANSWER1=VQA(image=IMAGE,question='Does the coat look long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6021, "imageId": "n199097", "question": "Which kind of clothing isn't comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing isn't comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6022, "imageId": "n68769", "question": "Does the curtain look red and long?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the curtain?')\nANSWER1=VQA(image=IMAGE0,question='Does the curtain look long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6023, "imageId": "n250821", "question": "What color are the jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6024, "imageId": "n49310", "question": "Does the Caucasian person to the left of the woman look young?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='Caucasian person')\nANSWER0=VQA(image=IMAGE0,question='Does the person look young?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6025, "imageId": "n210269", "question": "How wide is the open window?", "program": "BOX0=LOC(image=IMAGE,object='open window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How wide is the open window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6026, "imageId": "n79078", "question": "What's located on top of the pole?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the pole?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6027, "imageId": "n250715", "question": "Who is looking out the helicopter?", "program": "BOX0=LOC(image=IMAGE,object='helicopter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking out the helicopter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6028, "imageId": "n386682", "question": "What are the items of furniture above the appliance that is above the dishwasher?", "program": "BOX0=LOC(image=IMAGE,object='dishwasher')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6029, "imageId": "n250715", "question": "What is the person to the right of the device sitting in front of?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person sitting in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6030, "imageId": "n250715", "question": "Who is sitting in front of the control panel?", "program": "BOX0=LOC(image=IMAGE,object='control panel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting in front of the control panel?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6031, "imageId": "n429961", "question": "Which side of the picture is the green cabbage on?", "program": "BOX0=LOC(image=IMAGE,object='green cabbage')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6032, "imageId": "n299528", "question": "Is the skater standing?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nANSWER0=POSE(image=IMAGE,box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'standing' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6033, "imageId": "n470131", "question": "How large is the bottle in the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the bottle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6034, "imageId": "n429961", "question": "Is the cabbage to the right of the other cabbage purple or maybe green?", "program": "BOX0=LOC(image=IMAGE,object='cabbage')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other cabbage')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the cabbage?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'purple' or {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6035, "imageId": "n264887", "question": "Are there both desks and monitors in the image?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nBOX1=LOC(image=IMAGE,object='monitor')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6036, "imageId": "n118102", "question": "Is the shirt sleeveless or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt sleeveless or short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6037, "imageId": "n39114", "question": "Are the trousers wet?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the trousers wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6038, "imageId": "n118102", "question": "Is the shirt both short sleeved and black?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE0,question='What type of sleeves does the shirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6039, "imageId": "n77818", "question": "Is the rectangular device to the right or to the left of the TV?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rectangular device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6040, "imageId": "n9181", "question": "Are the shoes that are made of rubber white and comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='What material are the shoes made of?')\nANSWER1=VQA(image=IMAGE,question='What color are the shoes?')\nANSWER2=VQA(image=IMAGE,question='Are the shoes comfortable?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'rubber' and {ANSWER1} == 'white' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6041, "imageId": "n214497", "question": "Does the wide window look open or closed?", "program": "BOX0=LOC(image=IMAGE,object='wide window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the wide window look open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6042, "imageId": "n518912", "question": "What color is the chair in the bottom of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6043, "imageId": "n518912", "question": "What kind of furniture is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of furniture is on top of the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6044, "imageId": "n414992", "question": "What is the man that is happy doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man that is happy doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6045, "imageId": "n414992", "question": "Is the man to the right of the other man fat and angry?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the man fat and angry?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6046, "imageId": "n295771", "question": "How large is the window near the plant?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6047, "imageId": "n571179", "question": "Is the hat the same color as the sign?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sign?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6048, "imageId": "n288870", "question": "What is the person that is not old sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person sitting next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6049, "imageId": "n295771", "question": "Do you see any windows that are small?", "program": "BOX0=LOC(image=IMAGE,object='window')\nANSWER0=VQA(image=IMAGE,question='Are there any small windows?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6050, "imageId": "n288870", "question": "Is the person that is not old wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person old?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'no' else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='Is the person wearing jeans?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6051, "imageId": "n571179", "question": "Do both the people have the same gender?", "program": "ANSWER0=VQA(image=IMAGE,question='Do both the people have the same gender?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6052, "imageId": "n23181", "question": "Are the open drapes to the left or to the right of the fluffy pillow which is on top of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fluffy pillow')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='open drapes')\nIMAGE2=CROP_LEFTOF(image=IMAGE1,box=BOX2)\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6053, "imageId": "n523165", "question": "Is the tall person on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6054, "imageId": "n498712", "question": "What is the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6055, "imageId": "n449058", "question": "Is the street near the building paved and wide?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='street')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the street paved?')\nANSWER1=VQA(image=IMAGE1,question='Is the street wide?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6056, "imageId": "n449058", "question": "What was used to make the street?", "program": "ANSWER0=VQA(image=IMAGE,question='What was used to make the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6057, "imageId": "n4777", "question": "Is there a printer or a speaker in this picture?", "program": "BOX0=LOC(image=IMAGE,object='printer')\nBOX1=LOC(image=IMAGE,object='speaker')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6058, "imageId": "n449058", "question": "What is the street made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the street made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6059, "imageId": "n437064", "question": "Is the cake to the left or to the right of the bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cake')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6060, "imageId": "n77818", "question": "What is the device that is to the right of the cat behind the wall?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wall')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nANSWER0=VQA(image=IMAGE1,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6061, "imageId": "n309148", "question": "What do you think is the color of the bucket?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is the color of the bucket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6062, "imageId": "n412144", "question": "Is the color of the shirt the same as the color of the video camera?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='video camera')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the video camera?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6063, "imageId": "n499081", "question": "What shape is the small picture frame?", "program": "BOX0=LOC(image=IMAGE,object='small picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the small picture frame?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6064, "imageId": "n278312", "question": "Are there both a plate and a knife in this photo?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='knife')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6065, "imageId": "n369313", "question": "Are the curtains both red and soft?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the curtains?')\nANSWER1=VQA(image=IMAGE,question='What texture are the curtains?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'soft' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6066, "imageId": "n319845", "question": "How big is the rug that is under the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=VQA(image=IMAGE0,question='How big is the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6067, "imageId": "n54424", "question": "Does the pillow seem to be blue or yellow?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the pillow?')\nANSWER1=EVAL(expr=\"'blue' if {ANSWER0} == 'blue' else 'yellow'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6068, "imageId": "n117888", "question": "Is this a tall fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='Is this a tall fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6069, "imageId": "n257997", "question": "Do the green trees look bare and tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the green trees look bare and tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6070, "imageId": "n460385", "question": "Are there either cabinets or tables that are not light brown?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6071, "imageId": "n194179", "question": "Are the socks on the shoes red and soft?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='socks')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color are the socks?')\nANSWER1=VQA(image=IMAGE1,question='Are the socks soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6072, "imageId": "n222915", "question": "Is there a hamburger next to the cooked vegetable?", "program": "BOX0=LOC(image=IMAGE,object='cooked vegetable')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hamburger')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6073, "imageId": "n460385", "question": "What is the color of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6074, "imageId": "n546616", "question": "What kind of food is on top of the cake?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of food is on top of the cake?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6075, "imageId": "n77818", "question": "What type of furniture is below the device that is not turned-off?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is below the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6076, "imageId": "n77818", "question": "Which kind of furniture is below the television?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is below the television?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6077, "imageId": "n35676", "question": "What color is the floor?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6078, "imageId": "n246334", "question": "What do the nightstand and the mirror have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the nightstand and the mirror have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6079, "imageId": "n293477", "question": "What item of furniture is the purse lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='purse')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is the purse lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6080, "imageId": "n130638", "question": "Which side of the photo is the girl on?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6081, "imageId": "n115614", "question": "On which side of the picture are the people?", "program": "BOX0=LOC(image=IMAGE,object='people')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6082, "imageId": "n432591", "question": "Does the clock sit atop a nightstand?", "program": "BOX0=LOC(image=IMAGE,object='nightstand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clock')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6083, "imageId": "n4777", "question": "What is the long sleeved article of clothing?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved article of clothing')\nANSWER0=VQA(image=IMAGE,question='What is the long sleeved article of clothing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6084, "imageId": "n140421", "question": "What type of furniture is to the right of the towel?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is to the right?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6085, "imageId": "n350766", "question": "On which side is the microwave, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='microwave')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6086, "imageId": "n4777", "question": "Is the sweater that is made of cloth short sleeved and blue?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the sweater made of?')\nANSWER1=VQA(image=IMAGE0,question='Are the sleeves of the sweater short?')\nANSWER2=VQA(image=IMAGE0,question='What color is the sweater?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'cloth' and {ANSWER1} == 'yes' and {ANSWER2} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6087, "imageId": "n250715", "question": "Which kind of aircraft is off?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of aircraft is off?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6088, "imageId": "n250715", "question": "What is the name of the parked aircraft?", "program": "BOX0=LOC(image=IMAGE,object='parked aircraft')\nANSWER0=VQA(image=IMAGE,question='What is the name of the parked aircraft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6089, "imageId": "n274905", "question": "Does the shirt look short sleeved or long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look short sleeved or long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6090, "imageId": "n250715", "question": "What kind of aircraft is parked?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of aircraft is parked?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6091, "imageId": "n431447", "question": "Are there boys near the pizza inside the pizza box?", "program": "BOX0=LOC(image=IMAGE,object='pizza box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pizza')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='boys')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6092, "imageId": "n315887", "question": "Which kind of device is to the right of the coffee cup?", "program": "BOX0=LOC(image=IMAGE,object='coffee cup')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is to the right?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6093, "imageId": "n520071", "question": "Is the water bottle black?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the water bottle?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6094, "imageId": "n207708", "question": "On which side of the photo are the yellow fruits?", "program": "BOX0=LOC(image=IMAGE,object='yellow fruits')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6095, "imageId": "n240973", "question": "Which device is on, the laptop computer or the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='laptop computer')\nBOX1=LOC(image=IMAGE,object='keyboard')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'laptop computer' if {ANSWER0} > 0 else 'keyboard'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6096, "imageId": "n500209", "question": "What is the size of the squash that is sitting inside the bowls?", "program": "BOX0=LOC(image=IMAGE,object='bowls')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='squash')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the size of the squash?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6097, "imageId": "n543966", "question": "How hard is the dirt that the elephants are on?", "program": "BOX0=LOC(image=IMAGE,object='elephants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dirt')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How hard is the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6098, "imageId": "n511913", "question": "Does the chair to the left of the books have small size?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6099, "imageId": "n95369", "question": "Does the faucet below the ring look black and curved?", "program": "BOX0=LOC(image=IMAGE,object='ring')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='faucet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the faucet?')\nANSWER3=VQA(image=IMAGE0,question='Is the faucet curved?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'black' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6100, "imageId": "n312206", "question": "On which side is the container?", "program": "BOX0=LOC(image=IMAGE,object='container')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6101, "imageId": "n115614", "question": "Who is standing near the crosswalk that is near the lamp post?", "program": "BOX0=LOC(image=IMAGE,object='crosswalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp post')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='person')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6102, "imageId": "n137182", "question": "What is the girl in front of?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the girl in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6103, "imageId": "n235859", "question": "Are all these people the same gender?", "program": "ANSWER0=VQA(image=IMAGE,question='Are all these people the same gender?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6104, "imageId": "n573460", "question": "What does the tennis racket hit?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the tennis racket hit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6105, "imageId": "n573460", "question": "What hits the tennis ball?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What hits the tennis ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6106, "imageId": "n296467", "question": "Does the white food look small and thick?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the white food look small and thick?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6107, "imageId": "n573460", "question": "What does the racket hit?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the racket hit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6108, "imageId": "n406334", "question": "Which kind of vehicle is black?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6109, "imageId": "n145498", "question": "Do you see any trash cans near the long bench?", "program": "BOX0=LOC(image=IMAGE,object='long bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trash cans')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6110, "imageId": "n98540", "question": "Who is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6111, "imageId": "n216553", "question": "Which kind of animal is looking down?", "program": "BOX0=LOC(image=IMAGE,object='down')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6112, "imageId": "n150962", "question": "What is the color of the door that is behind the mat?", "program": "BOX0=LOC(image=IMAGE,object='mat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='door')\nANSWER0=VQA(image=IMAGE0,question='What color is the door?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6113, "imageId": "n95313", "question": "What kind of furniture is yellow?", "program": "BOX0=LOC(image=IMAGE,object='yellow')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is yellow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6114, "imageId": "n150962", "question": "Does that table look blue and wooden?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6115, "imageId": "n317260", "question": "Does the glove made of leather look black and large?", "program": "BOX0=LOC(image=IMAGE,object='glove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the glove made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the glove?')\nANSWER2=VQA(image=IMAGE0,question='What size is the glove?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'leather' and {ANSWER1} == 'black' and {ANSWER2} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6116, "imageId": "n520071", "question": "Is the open computer to the left or to the right of the books near the water bottle?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='water bottle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='open computer')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6117, "imageId": "n342511", "question": "What animal is sitting beside the person that the coat is worn around?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='coat')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nANSWER0=VQA(image=IMAGE1,question='What animal is sitting beside the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6118, "imageId": "n278312", "question": "Is the refrigerator to the left of the silver thing that is to the left of the bread?", "program": "BOX0=LOC(image=IMAGE,object='bread')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='silver thing')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='refrigerator')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6119, "imageId": "n571179", "question": "The woman is where?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6120, "imageId": "n571179", "question": "Where is the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6121, "imageId": "n571179", "question": "Are there any skiers on the snow?", "program": "BOX0=LOC(image=IMAGE,object='snow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skier')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6122, "imageId": "n211324", "question": "Are the white cars on the left or on the right side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white cars')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6123, "imageId": "n525901", "question": "What do you think is in front of the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is in front of the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6124, "imageId": "n127705", "question": "Is the woman that is standing holding a racket?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the woman holding a racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6125, "imageId": "n159802", "question": "What piece of clothing is long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved')\nANSWER0=VQA(image=IMAGE,question='What piece of clothing is long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6126, "imageId": "n117888", "question": "Who is wearing the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6127, "imageId": "n119944", "question": "What animal does the kid that looks little look at?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal does the kid look at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6128, "imageId": "n566028", "question": "What is the person that is waiting doing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6129, "imageId": "n566028", "question": "Does the person that is sitting-down look old?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the person that is sitting-down look old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6130, "imageId": "n554880", "question": "What is sitting behind the person on the left?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='object')\nANSWER0=VQA(image=IMAGE0,question='What is sitting behind the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6131, "imageId": "n357784", "question": "Does the bracelet have orange color?", "program": "BOX0=LOC(image=IMAGE,object='bracelet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bracelet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6132, "imageId": "n357784", "question": "Is the happy woman behind the brown cat?", "program": "BOX0=LOC(image=IMAGE,object='brown cat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='happy woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6133, "imageId": "n250715", "question": "Does the shirt that is not dirty look long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='dirty shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the shirt look long sleeved?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'dirty' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6134, "imageId": "n381072", "question": "Are there either plates or napkins in this image?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='napkin')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6135, "imageId": "n250715", "question": "Does the shirt look brown and clean?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE,question='Does the shirt look clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6136, "imageId": "n334278", "question": "Are there any performers or employees?", "program": "BOX0=LOC(image=IMAGE,object='performer')\nBOX1=LOC(image=IMAGE,object='employee')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6137, "imageId": "n311910", "question": "What kind of sign is made of the same material as the vehicle next to the sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of sign is made of the same material as the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6138, "imageId": "n14087", "question": "What type of furniture is behind the animal that is wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='animal wearing hat')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is behind?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6139, "imageId": "n311910", "question": "What do the street sign and the bus have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the street sign and the bus have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6140, "imageId": "n545516", "question": "Does the clean shirt above the pavement have black color?", "program": "BOX0=LOC(image=IMAGE,object='pavement')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clean shirt')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the clean shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6141, "imageId": "n274905", "question": "Is the racket that looks green and yellow made of wood or metal?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the racket?')\nANSWER1=VQA(image=IMAGE0,question='What material is the racket made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green and yellow' and ({ANSWER1} == 'wood' or {ANSWER1} == 'metal') else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6142, "imageId": "n324908", "question": "How long do you think is the black hair?", "program": "BOX0=LOC(image=IMAGE,object='black hair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the black hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6143, "imageId": "n503626", "question": "What is mounted on the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is mounted on the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6144, "imageId": "n433532", "question": "Does the shelf look brown?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shelf?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6145, "imageId": "n363445", "question": "What kind of food is below the carrots?", "program": "BOX0=LOC(image=IMAGE,object='carrots')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What kind of food is below the carrots?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6146, "imageId": "n278312", "question": "What color is the towel?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the towel?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6147, "imageId": "n355339", "question": "On which side of the photo is the black screen?", "program": "BOX0=LOC(image=IMAGE,object='black screen')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6148, "imageId": "n89148", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6149, "imageId": "n119944", "question": "What are the baskets that are not empty made of?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='empty')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='basket')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='What are the empty baskets made of?')\nANSWER1=VQA(image=IMAGE2,question='What are the non-empty baskets made of?')\nANSWER2=EVAL(expr=\"'{ANSWER0}, {ANSWER1}'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6150, "imageId": "n473688", "question": "What color is the toothbrush?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toothbrush?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6151, "imageId": "n159802", "question": "What kind of clothing is small?", "program": "BOX0=LOC(image=IMAGE,object='small')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6152, "imageId": "n346736", "question": "What vehicle are the trees behind of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 0 else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6153, "imageId": "n90294", "question": "Is the remote made of the same material as the calculator?", "program": "BOX0=LOC(image=IMAGE,object='remote')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='calculator')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the remote made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the calculator made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6154, "imageId": "n65885", "question": "Is the animal to the left of the cabinet holding a teddy bear?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the animal holding a teddy bear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6155, "imageId": "n317189", "question": "Do the pants look black?", "program": "ANSWER0=VQA(image=IMAGE,question='What color do the pants look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6156, "imageId": "n37274", "question": "Who is in front of the sign?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6157, "imageId": "n554880", "question": "Are the television and the chair made of the same material?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the television made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the chair made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6158, "imageId": "n65885", "question": "What is the animal that is lying on the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6159, "imageId": "n249639", "question": "Is the size of the trash bin small?", "program": "BOX0=LOC(image=IMAGE,object='trash bin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the size of the trash bin?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6160, "imageId": "n37274", "question": "Who is in front of the plastic sign?", "program": "BOX0=LOC(image=IMAGE,object='plastic sign')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the plastic sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6161, "imageId": "n140421", "question": "What kind of furniture is cushioned?", "program": "BOX0=LOC(image=IMAGE,object='cushioned')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is cushioned?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6162, "imageId": "n37274", "question": "Do you see any men behind the appliance that is on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='men')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6163, "imageId": "n406334", "question": "Do you think the people are old?", "program": "ANSWER0=VQA(image=IMAGE,question='Do you think the people are old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6164, "imageId": "n351318", "question": "Are the blue stickers below the paper?", "program": "BOX0=LOC(image=IMAGE,object='paper')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blue stickers')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6165, "imageId": "n228268", "question": "Is the water both wavy and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the water wavy?')\nANSWER1=VQA(image=IMAGE,question='What color is the water?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6166, "imageId": "n398257", "question": "Is the device below the picture frame made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6167, "imageId": "n140421", "question": "Are the chairs below the chandelier wooden and small?", "program": "BOX0=LOC(image=IMAGE,object='chandelier')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material are the chairs made of?')\nANSWER1=VQA(image=IMAGE1,question='What size are the chairs?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6168, "imageId": "n501951", "question": "Is the plastic helmet on the left side or on the right of the image?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic helmet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6169, "imageId": "n351318", "question": "Are there any hammers or keyboards?", "program": "BOX0=LOC(image=IMAGE,object='hammer')\nBOX1=LOC(image=IMAGE,object='keyboard')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6170, "imageId": "n4777", "question": "Is the soft toy on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soft toy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6171, "imageId": "n429883", "question": "What color is the stage?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the stage?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6172, "imageId": "n278312", "question": "The microwave oven made of stainless steel is hanging from what?", "program": "BOX0=LOC(image=IMAGE,object='microwave oven')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the microwave oven hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6173, "imageId": "n278312", "question": "What is hanging from the cabinets that look white?", "program": "BOX0=LOC(image=IMAGE,object='white cabinets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the cabinets?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6174, "imageId": "n278312", "question": "What is the appliance that is hanging from the cabinets that are hanging from the wall called?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabinets')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What is the appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6175, "imageId": "n222915", "question": "What is the round bowl sitting on?", "program": "BOX0=LOC(image=IMAGE,object='round bowl')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the round bowl sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6176, "imageId": "n222915", "question": "What is sitting on the papers?", "program": "BOX0=LOC(image=IMAGE,object='papers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on the papers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6177, "imageId": "n513100", "question": "Is there a chair underneath the white table?", "program": "BOX0=LOC(image=IMAGE,object='white table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6178, "imageId": "n329514", "question": "Does the skateboard above the steps look wooden and white?", "program": "BOX0=LOC(image=IMAGE,object='steps')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the skateboard?')\nANSWER1=VQA(image=IMAGE1,question='What material is the skateboard made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6179, "imageId": "n184385", "question": "Is the small utensil in the top of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6180, "imageId": "n437064", "question": "Which is less healthy, the whipped cream or the strawberry?", "program": "ANSWER0=VQA(image=IMAGE,question='Which is less healthy, the whipped cream or the strawberry?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6181, "imageId": "n324908", "question": "Are there any sheep or goats that are not brown?", "program": "BOX0=LOC(image=IMAGE,object='sheep')\nBOX1=LOC(image=IMAGE,object='goat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6182, "imageId": "n379991", "question": "Where in the image are the silver scissors, on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='silver scissors')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6183, "imageId": "n171169", "question": "Are both the boot and the polo shirt the same color?", "program": "BOX0=LOC(image=IMAGE,object='boot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='polo shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the boot?')\nANSWER1=VQA(image=IMAGE1,question='What color is the polo shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6184, "imageId": "n282436", "question": "What device is not large?", "program": "ANSWER0=VQA(image=IMAGE,question='What device is not large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6185, "imageId": "n282436", "question": "What device is large?", "program": "BOX0=LOC(image=IMAGE,object='large')\nANSWER0=VQA(image=IMAGE,question='What device is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6186, "imageId": "n171169", "question": "Do the lawn and the polo shirt have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='polo shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the lawn?')\nANSWER1=VQA(image=IMAGE1,question='What color is the polo shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6187, "imageId": "n206785", "question": "Is the cabinet brown and wooden?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cabinet?')\nANSWER1=VQA(image=IMAGE0,question='What material is the cabinet made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6188, "imageId": "n281241", "question": "Is the black and white picture black and white or colorful?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the black and white picture black and white or colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6189, "imageId": "n55058", "question": "What food is shown in this photograph?", "program": "ANSWER0=VQA(image=IMAGE,question='What food is shown in this photograph?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6190, "imageId": "n199758", "question": "Does the remote control to the right of the person appear to be white and small?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote control')\nANSWER0=VQA(image=IMAGE0,question='What color is the remote control?')\nANSWER1=VQA(image=IMAGE0,question='How does the remote control appear?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6191, "imageId": "n55058", "question": "What food is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What food is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6192, "imageId": "n55058", "question": "What food is tasty?", "program": "ANSWER0=VQA(image=IMAGE,question='What food is tasty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6193, "imageId": "n527589", "question": "Who is wearing an earring?", "program": "BOX0=LOC(image=IMAGE,object='earring')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing an earring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6194, "imageId": "n437064", "question": "Do you see either any cloth napkins or tables?", "program": "BOX0=LOC(image=IMAGE,object='cloth napkins')\nBOX1=LOC(image=IMAGE,object='tables')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6195, "imageId": "n319845", "question": "Does the wood floor below the rug look covered and light?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood floor')\nANSWER0=VQA(image=IMAGE0,question='Does the wood floor look covered?')\nANSWER1=VQA(image=IMAGE0,question='Does the wood floor look light?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6196, "imageId": "n59147", "question": "Is the toilet seat that looks round blue or is it white?", "program": "BOX0=LOC(image=IMAGE,object='toilet seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet seat?')\nANSWER1=EVAL(expr=\"'blue' if {ANSWER0} == 'round' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6197, "imageId": "n417401", "question": "The sink is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The sink is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6198, "imageId": "n59147", "question": "Is the toilet seat round and black?", "program": "BOX0=LOC(image=IMAGE,object='toilet seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the toilet seat?')\nANSWER1=VQA(image=IMAGE0,question='What color is the toilet seat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6199, "imageId": "n97485", "question": "Do you see microwaves or faucets that are off?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nBOX1=LOC(image=IMAGE,object='faucet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6200, "imageId": "n305495", "question": "Are the blinds behind or in front of the closed window?", "program": "BOX0=LOC(image=IMAGE,object='closed window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blinds')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'behind' if {ANSWER0} > 0 else 'in front'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6201, "imageId": "n262929", "question": "What do you think is he in front of?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is he in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6202, "imageId": "n262929", "question": "What is the boy in front of?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the boy in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6203, "imageId": "n119886", "question": "Where is the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6204, "imageId": "n66756", "question": "How big is the leather glove?", "program": "BOX0=LOC(image=IMAGE,object='leather glove')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6205, "imageId": "n532191", "question": "Is the laptop black?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the laptop?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6206, "imageId": "n336443", "question": "Which kind of furniture is large?", "program": "BOX0=LOC(image=IMAGE,object='large furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6207, "imageId": "n468864", "question": "What is the color of the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6208, "imageId": "n352479", "question": "Is this a snowboarder or a skateboarder?", "program": "BOX0=LOC(image=IMAGE,object='snowboarder')\nBOX1=LOC(image=IMAGE,object='skateboarder')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'snowboarder' if {ANSWER0} > {ANSWER1} else 'skateboarder'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6209, "imageId": "n100991", "question": "On which side is the cooked meat?", "program": "BOX0=LOC(image=IMAGE,object='cooked meat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6210, "imageId": "n530733", "question": "What do both the garbage can and the trash bag have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the garbage can and the trash bag have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6211, "imageId": "n133585", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6212, "imageId": "n59147", "question": "What is the piece of furniture that the empty bag is resting on called?", "program": "BOX0=LOC(image=IMAGE,object='empty bag')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='piece of furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6213, "imageId": "n351318", "question": "What is the tape on?", "program": "BOX0=LOC(image=IMAGE,object='tape')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tape on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6214, "imageId": "n259002", "question": "Which gender is the spectator that is watching the soccer player?", "program": "BOX0=LOC(image=IMAGE,object='soccer player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which gender is the spectator?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6215, "imageId": "n54180", "question": "Are there any mirrors in this picture?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6216, "imageId": "n48494", "question": "Is the river low and wavy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the river low and wavy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6217, "imageId": "n259002", "question": "Are both the spectator to the left of the car and the soccer player to the right of the ball male?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='spectator')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the spectator male?')\n\nBOX2=LOC(image=IMAGE,object='ball')\nIMAGE2=CROP_RIGHTOF(image=IMAGE,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='soccer player')\nIMAGE3=CROP(image=IMAGE2,box=BOX3)\nANSWER1=VQA(image=IMAGE3,question='Is the soccer player male?')\n\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6218, "imageId": "n272313", "question": "Is it cloudy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it cloudy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6219, "imageId": "n272313", "question": "Do the building and the helmet have the same color?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='helmet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the building?')\nANSWER1=VQA(image=IMAGE1,question='What color is the helmet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6220, "imageId": "n293477", "question": "What piece of furniture is white?", "program": "BOX0=LOC(image=IMAGE,object='white')\nANSWER0=VQA(image=IMAGE,question='What piece of furniture is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6221, "imageId": "n140421", "question": "Does the cupboard have the same material as the chandelier?", "program": "BOX0=LOC(image=IMAGE,object='cupboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='chandelier')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the cupboard made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the chandelier made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6222, "imageId": "n264887", "question": "What is common to the plant and the mousepad?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the plant and the mousepad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6223, "imageId": "n336443", "question": "Is the white bowl on the left of the photo?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white bowl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6224, "imageId": "n140421", "question": "Are the clock and the chandelier the same color?", "program": "BOX0=LOC(image=IMAGE,object='clock')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='chandelier')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the clock?')\nANSWER1=VQA(image=IMAGE1,question='What color is the chandelier?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6225, "imageId": "n184385", "question": "What material is the pot to the left of the spoon, stainless steel or glass?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pot')\nANSWER0=VQA(image=IMAGE0,question='What material is the pot?')\nANSWER1=EVAL(expr=\"'stainless steel' if {ANSWER0} == 'stainless steel' else 'glass'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6226, "imageId": "n140421", "question": "Is the color of the countertop different than that of the soap bottle?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='soap bottle')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the countertop?')\nANSWER1=VQA(image=IMAGE1,question='What color is the soap bottle?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6227, "imageId": "n162586", "question": "What's hanging from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6228, "imageId": "n162586", "question": "What is hanging from the white wall?", "program": "BOX0=LOC(image=IMAGE,object='white wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the white wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6229, "imageId": "n162586", "question": "What's the picture frame made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the picture frame made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6230, "imageId": "n88933", "question": "Who in the picture is eating?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is eating?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6231, "imageId": "n49310", "question": "Who in the photo is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6232, "imageId": "n66756", "question": "Does the door look closed and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the door look closed?')\nANSWER1=VQA(image=IMAGE,question='Does the door look large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6233, "imageId": "n500308", "question": "Which kind of furniture is metallic?", "program": "BOX0=LOC(image=IMAGE,object='metallic')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6234, "imageId": "n162586", "question": "What's the picture frame hanging from?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the picture frame hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6235, "imageId": "n513100", "question": "Which color is the chair to the left of the other chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='Which color is the chair?')\nANSWER1=VQA(image=IMAGE0,question='Which color is the other chair?')\nANSWER2=EVAL(expr=\"'left' if {ANSWER0} != {ANSWER1} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6236, "imageId": "n363445", "question": "What kind of food isn't cut?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food isn\\'t cut?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6237, "imageId": "n524855", "question": "Does the cow that looks white and brown appear to be resting?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the cow appear to be resting?')\nANSWER1=VQA(image=IMAGE,question='What color is the cow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white and brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6238, "imageId": "n513100", "question": "What is in front of the fence made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood fence')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6239, "imageId": "n28996", "question": "What fruits are above the sandwiches?", "program": "BOX0=LOC(image=IMAGE,object='sandwiches')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruits')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6240, "imageId": "n530733", "question": "Are there either round windows or doors?", "program": "BOX0=LOC(image=IMAGE,object='round windows')\nBOX1=LOC(image=IMAGE,object='doors')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6241, "imageId": "n433692", "question": "Are the pens next to the cat small and colorful?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pens')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Are the pens colorful?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6242, "imageId": "n556604", "question": "What is the fat man standing on?", "program": "BOX0=LOC(image=IMAGE,object='fat man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fat man standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6243, "imageId": "n433692", "question": "Are there any laptops near the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6244, "imageId": "n184385", "question": "What is the pan on?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surface')\nANSWER0=VQA(image=IMAGE0,question='What is the pan on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6245, "imageId": "n59627", "question": "Is the man to the right of the other man old and short?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the man old and short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6246, "imageId": "n528403", "question": "Does the field look grassy?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the field look grassy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6247, "imageId": "n346736", "question": "What's in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6248, "imageId": "n551964", "question": "Who seems to be older, the woman or the girl?", "program": "ANSWER0=VQA(image=IMAGE,question='Who seems to be older, the woman or the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6249, "imageId": "n111390", "question": "Where is the lady to the left of the phone sitting?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lady')\nANSWER0=VQA(image=IMAGE0,question='Where is the lady sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6250, "imageId": "n59676", "question": "Is the color of the saucer different than the plate?", "program": "BOX0=LOC(image=IMAGE,object='saucer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='plate')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the saucer?')\nANSWER1=VQA(image=IMAGE1,question='What color is the plate?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6251, "imageId": "n181210", "question": "What type of meat is above the utensil that looks white?", "program": "BOX0=LOC(image=IMAGE,object='utensil')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='meat')\nANSWER0=VQA(image=IMAGE0,question='What type of meat is above the utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6252, "imageId": "n111390", "question": "Who is wearing the coat?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the coat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6253, "imageId": "n111390", "question": "Who is wearing a coat?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a coat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6254, "imageId": "n507959", "question": "What color does the purse have?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the purse have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6255, "imageId": "n279173", "question": "What is in front of the person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='front')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6256, "imageId": "n279173", "question": "What is in front of the person on the motorbike?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorbike')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6257, "imageId": "n551964", "question": "Who is younger, the man or the girl?", "program": "ANSWER0=VQA(image=IMAGE,question='Who is younger, the man or the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6258, "imageId": "n435808", "question": "Is the black device on top of the desk sitting next to a mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black device')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='mouse pad')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6259, "imageId": "n77818", "question": "On which side is the TV?", "program": "BOX0=LOC(image=IMAGE,object='TV')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6260, "imageId": "n77818", "question": "Which kind of animal is still?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is still?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6261, "imageId": "n77818", "question": "Which kind of animal is black?", "program": "BOX0=LOC(image=IMAGE,object='black')\nANSWER0=VQA(image=IMAGE,question='Which kind of animal is black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6262, "imageId": "n235859", "question": "Who is wearing a dress?", "program": "BOX0=LOC(image=IMAGE,object='dress')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a dress?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6263, "imageId": "n572716", "question": "What are the trees in front of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the trees in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6264, "imageId": "n100552", "question": "Is the brown animal behind a fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown animal')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6265, "imageId": "n100552", "question": "Is the elephant behind or in front of the fence?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'behind' if {ANSWER0} > 0 else 'in front'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6266, "imageId": "n52544", "question": "Is the door behind the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='door')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6267, "imageId": "n14087", "question": "Is there either a table or a couch in this photo?", "program": "BOX0=LOC(image=IMAGE,object='table')\nBOX1=LOC(image=IMAGE,object='couch')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6268, "imageId": "n71728", "question": "Who does the boy sit beside?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who does the boy sit beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6269, "imageId": "n126087", "question": "Who is wearing the wristband?", "program": "BOX0=LOC(image=IMAGE,object='wristband')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the wristband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6270, "imageId": "n431447", "question": "Is the pizza box above the rectangular table?", "program": "BOX0=LOC(image=IMAGE,object='rectangular table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pizza box')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6271, "imageId": "n431447", "question": "Is the pizza box in front of the container that is on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='container')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='pizza box')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6272, "imageId": "n525901", "question": "What is underneath the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6273, "imageId": "n488874", "question": "Does the white shirt look sleeveless and comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the white shirt look sleeveless?')\nANSWER1=VQA(image=IMAGE,question='Does the white shirt look comfortable?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6274, "imageId": "n431447", "question": "What's the pizza box in front of?", "program": "BOX0=LOC(image=IMAGE,object='pizza box')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pizza box in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6275, "imageId": "n262920", "question": "Do you see any large couch or desk?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nBOX1=LOC(image=IMAGE,object='desk')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6276, "imageId": "n59676", "question": "Who is sitting at the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting at the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6277, "imageId": "n507959", "question": "What color is the luggage that the people are standing behind of?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='luggage')\nANSWER0=VQA(image=IMAGE0,question='What color is the luggage?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6278, "imageId": "n507959", "question": "How is the piece of furniture that is the same color as the umbrella that is to the left of the person called?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nANSWER0=VQA(image=IMAGE1,question='What color is the umbrella?')\nANSWER1=VQA(image=IMAGE0,question='How is the piece of furniture called?')\nANSWER2=EVAL(expr=\"'{ANSWER1}' if {ANSWER0} == 'blue' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6279, "imageId": "n507959", "question": "What do you think is the luggage that looks brown and blue sitting in front of?", "program": "BOX0=LOC(image=IMAGE,object='luggage')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the luggage?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6280, "imageId": "n9856", "question": "Which color are the trousers that the shirt is above?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trousers')\nANSWER0=VQA(image=IMAGE0,question='Which color are the trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6281, "imageId": "n513100", "question": "What is underneath the wood table?", "program": "BOX0=LOC(image=IMAGE,object='wood table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the wood table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6282, "imageId": "n153293", "question": "Do you see any toilets near the clean sink?", "program": "BOX0=LOC(image=IMAGE,object='clean sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6283, "imageId": "n541854", "question": "The utensil that is not dirty has what color?", "program": "BOX0=LOC(image=IMAGE,object='dirty utensil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='utensil')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the utensil?')\nANSWER1=EVAL(expr=\"'not dirty' if {ANSWER0} != 'dirty' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6284, "imageId": "n157375", "question": "Is the runway made of the same material as the staircase?", "program": "BOX0=LOC(image=IMAGE,object='runway')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='staircase')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the runway made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the staircase made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6285, "imageId": "n133585", "question": "Which color are the trousers that the person is wearing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color are the trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6286, "imageId": "n386688", "question": "What is the watercraft that is above the sailboats on the left called?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sailboats')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the watercraft called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6287, "imageId": "n499081", "question": "What color is the counter, cream colored or silver?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the counter?')\nANSWER1=EVAL(expr=\"'cream colored' if {ANSWER0} == 'cream' else 'silver'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6288, "imageId": "n499081", "question": "What item of furniture is behind the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is behind the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6289, "imageId": "n413002", "question": "Are the leaves both brown and short?", "program": "BOX0=LOC(image=IMAGE,object='leaves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the leaves?')\nANSWER1=VQA(image=IMAGE0,question='What is the height of the leaves?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6290, "imageId": "n499081", "question": "What is the item of furniture behind the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6291, "imageId": "n551964", "question": "Is there a helmet that is not small?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nANSWER0=VQA(image=IMAGE,question='What size is the helmet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6292, "imageId": "n88366", "question": "Are there both trash cans and skis in this picture?", "program": "BOX0=LOC(image=IMAGE,object='trash cans')\nBOX1=LOC(image=IMAGE,object='skis')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6293, "imageId": "n507149", "question": "Are the high clouds thin or thick?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the high clouds thin or thick?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6294, "imageId": "n28572", "question": "Does the napkin look red?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the napkin?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6295, "imageId": "n160664", "question": "What's the woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6296, "imageId": "n160664", "question": "What is the woman in front of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6297, "imageId": "n160664", "question": "Who is in front of the post?", "program": "BOX0=LOC(image=IMAGE,object='post')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the post?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6298, "imageId": "n160664", "question": "Who is in front of the post made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood post')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the wood post?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6299, "imageId": "n357784", "question": "What is this woman behind of, a cat or a dog?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cat')\nBOX2=LOC(image=IMAGE0,object='dog')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'cat' if {ANSWER0} > 0 else 'dog'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6300, "imageId": "n347706", "question": "What color do the shorts the child is wearing have?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6301, "imageId": "n315887", "question": "What is the shape of that CD?", "program": "BOX0=LOC(image=IMAGE,object='CD')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the shape of the CD?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6302, "imageId": "n95904", "question": "Is the material of the ground the same as the fence post?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fence post')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is the material of the ground?')\nANSWER1=VQA(image=IMAGE1,question='What is the material of the fence post?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6303, "imageId": "n95369", "question": "Is the toilet low and brown?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet?')\nANSWER1=VQA(image=IMAGE0,question='Is the toilet low?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6304, "imageId": "n159284", "question": "Is the person at the skateboard real and young?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the person at the skateboard real?')\nANSWER1=VQA(image=IMAGE,question='Is the person at the skateboard young?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6305, "imageId": "n548534", "question": "Do you see any refrigerator or bag there?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nBOX1=LOC(image=IMAGE,object='bag')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6306, "imageId": "n12404", "question": "How long is the container made of metal?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6307, "imageId": "n16425", "question": "Which kind of vehicle is gold?", "program": "BOX0=LOC(image=IMAGE,object='gold')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is gold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6308, "imageId": "n16425", "question": "On which side is the person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6309, "imageId": "n88366", "question": "Do you think the jacket is empty?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do you think the jacket is empty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6310, "imageId": "n326988", "question": "Does the remote on top of the television look black and large?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the remote?')\nANSWER1=VQA(image=IMAGE1,question='How large is the remote?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6311, "imageId": "n186491", "question": "Which kind of device is sitting on the table?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of device is sitting on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6312, "imageId": "n16656", "question": "What race is the person that the tree is behind of?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What race is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6313, "imageId": "n554880", "question": "What is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6314, "imageId": "n410476", "question": "What animal is to the left of the giraffe?", "program": "BOX0=LOC(image=IMAGE,object='giraffe')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is to the left of the giraffe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6315, "imageId": "n410476", "question": "Is the bison behind a monkey?", "program": "BOX0=LOC(image=IMAGE,object='monkey')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bison')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6316, "imageId": "n554880", "question": "The person to the left of the gift is holding what?", "program": "BOX0=LOC(image=IMAGE,object='gift')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The person is holding what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6317, "imageId": "n532191", "question": "How fat is the charger that is plugged into the laptop computer?", "program": "BOX0=LOC(image=IMAGE,object='laptop computer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='charger')\nANSWER0=VQA(image=IMAGE0,question='How fat is the charger?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6318, "imageId": "n150962", "question": "Is the window above a radiator?", "program": "BOX0=LOC(image=IMAGE,object='radiator')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6319, "imageId": "n527290", "question": "Is she to the left or to the right of the couch that is not uncomfortable?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='uncomfortable')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='she')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6320, "imageId": "n414992", "question": "How wide is the beach the man is standing on top of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='beach')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How wide is the beach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6321, "imageId": "n150962", "question": "Are there round windows in this photo?", "program": "BOX0=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6322, "imageId": "n579256", "question": "Is the shirt sleeveless and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the shirt sleeveless?')\nANSWER1=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6323, "imageId": "n579256", "question": "Which kind of clothing is white?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of clothing is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6324, "imageId": "n150962", "question": "Is the glass window below the coats that are not thin?", "program": "BOX0=LOC(image=IMAGE,object='coats')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='thin')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='glass window')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6325, "imageId": "n477215", "question": "How thick are the clouds the birds are flying in?", "program": "BOX0=LOC(image=IMAGE,object='birds')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clouds')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How thick are the clouds?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6326, "imageId": "n531731", "question": "Who wears an athletic shoe?", "program": "BOX0=LOC(image=IMAGE,object='athletic shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears an athletic shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6327, "imageId": "n543966", "question": "What animals are shown in the photo?", "program": "BOX0=LOC(image=IMAGE,object='animal')\nANSWER0=VQA(image=IMAGE,question='What animals are shown in the photo?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6328, "imageId": "n334278", "question": "Are there umpires behind the person in the middle?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umpires')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX0)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6329, "imageId": "n246334", "question": "Is it outdoors or indoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it outdoors or indoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6330, "imageId": "n167164", "question": "How big is that house?", "program": "ANSWER0=VQA(image=IMAGE,question='How big is that house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6331, "imageId": "n4777", "question": "Does the toy to the right of the bag seem to be soft and brown?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toy')\nANSWER0=VQA(image=IMAGE0,question='What color is the toy?')\nANSWER1=VQA(image=IMAGE0,question='Does the toy seem to be soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6332, "imageId": "n146555", "question": "What is the bottle made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the bottle made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6333, "imageId": "n315887", "question": "What's the coffee cup in front of?", "program": "BOX0=LOC(image=IMAGE,object='coffee cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the coffee cup in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6334, "imageId": "n363445", "question": "Which side of the picture is the fork on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fork')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6335, "imageId": "n181355", "question": "Is there a soft blanket or couch?", "program": "BOX0=LOC(image=IMAGE,object='blanket')\nBOX1=LOC(image=IMAGE,object='couch')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6336, "imageId": "n222915", "question": "What vegetable is sitting on the plate next to the mat?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mat')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What vegetable is sitting on the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6337, "imageId": "n222915", "question": "Is there broccoli near the round food?", "program": "BOX0=LOC(image=IMAGE,object='round food')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='broccoli')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6338, "imageId": "n543966", "question": "Do you see either any brown grass or mud?", "program": "BOX0=LOC(image=IMAGE,object='brown grass')\nBOX1=LOC(image=IMAGE,object='mud')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6339, "imageId": "n324908", "question": "What do you think are the mountains that are not narrow higher than?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think are the mountains that are not narrow higher than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6340, "imageId": "n433532", "question": "How old is that lady?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How old is the lady?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6341, "imageId": "n55058", "question": "Are the green vegetables in the bottom part or in the top?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green vegetables')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6342, "imageId": "n170941", "question": "Do both the plate that is to the left of the other plate and the coffee mug on top of the table have round shape?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='coffee mug')\nIMAGE2=CROP_ABOVE(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='What shape is the plate?')\nANSWER1=VQA(image=IMAGE2,question='What shape is the coffee mug?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6343, "imageId": "n240666", "question": "What's the mirror made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the mirror made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6344, "imageId": "n334278", "question": "Is the batter in front of the umpire that is wearing a belt?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='belt')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='batter')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6345, "imageId": "n441859", "question": "Is the brown sand wet or dry?", "program": "BOX0=LOC(image=IMAGE,object='brown sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the brown sand wet or dry?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6346, "imageId": "n390187", "question": "How clean is the glove made of leather?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the glove made of leather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6347, "imageId": "n119886", "question": "Which kind of furniture is underneath the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is underneath the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6348, "imageId": "n363445", "question": "Does the dessert look white?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the dessert look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6349, "imageId": "n119886", "question": "What is underneath the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6350, "imageId": "n357784", "question": "What is the cat doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the cat doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6351, "imageId": "n240666", "question": "Is the soap on the left side of the photo?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soap')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6352, "imageId": "n240666", "question": "Does the soap on the sink appear to be pink and small?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soap')\nANSWER0=VQA(image=IMAGE0,question='What color is the soap?')\nANSWER1=VQA(image=IMAGE0,question='What size is the soap?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'pink' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6353, "imageId": "n386688", "question": "What watercraft is the airplane flying above?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watercraft')\nANSWER0=VQA(image=IMAGE0,question='What watercraft is the airplane flying above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6354, "imageId": "n219840", "question": "What is higher than the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is higher than the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6355, "imageId": "n475030", "question": "Which kind of animal is on the beach?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is on the beach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6356, "imageId": "n282607", "question": "Who is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6357, "imageId": "n317260", "question": "Is the coach leaning on the dugout?", "program": "BOX0=LOC(image=IMAGE,object='coach')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dugout')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6358, "imageId": "n317260", "question": "What's the coach leaning on?", "program": "BOX0=LOC(image=IMAGE,object='coach')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the coach leaning on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6359, "imageId": "n369970", "question": "Who is wearing the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6360, "imageId": "n317260", "question": "Who is leaning on the dugout?", "program": "BOX0=LOC(image=IMAGE,object='dugout')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is leaning on the dugout?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6361, "imageId": "n548534", "question": "What's hanging from the cabinets?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question=\"What's hanging from the cabinets?\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6362, "imageId": "n548534", "question": "What is the cloth towel hanging from?", "program": "BOX0=LOC(image=IMAGE,object='cloth towel')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cloth towel hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6363, "imageId": "n204894", "question": "What color is the crown?", "program": "BOX0=LOC(image=IMAGE,object='crown')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the crown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6364, "imageId": "n548534", "question": "What is the towel hanging from?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the towel hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6365, "imageId": "n541688", "question": "What does the boy hold?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the boy hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6366, "imageId": "n262929", "question": "Do you see small umbrellas or bags?", "program": "BOX0=LOC(image=IMAGE,object='small umbrellas')\nBOX1=LOC(image=IMAGE,object='bags')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6367, "imageId": "n497789", "question": "On which side of the image are the striped animals?", "program": "BOX0=LOC(image=IMAGE,object='striped animals')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6368, "imageId": "n573460", "question": "Do the trousers have black color?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the trousers?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6369, "imageId": "n126087", "question": "Are the tennis rackets in the bottom?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis rackets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6370, "imageId": "n23181", "question": "How big is the black sculpture?", "program": "BOX0=LOC(image=IMAGE,object='black sculpture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the black sculpture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6371, "imageId": "n238266", "question": "Which part is the plate in, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6372, "imageId": "n187961", "question": "Which kind of animal isn't short?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal isn't short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6373, "imageId": "n23181", "question": "Does the sculpture have black color and small size?", "program": "BOX0=LOC(image=IMAGE,object='sculpture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sculpture?')\nANSWER1=VQA(image=IMAGE0,question='How large is the sculpture?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6374, "imageId": "n554880", "question": "Is the device to the right of the cellphone made of glass?", "program": "BOX0=LOC(image=IMAGE,object='cellphone')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the device made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'glass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6375, "imageId": "n312206", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6376, "imageId": "n159802", "question": "What clothing item is gray?", "program": "BOX0=LOC(image=IMAGE,object='gray')\nANSWER0=VQA(image=IMAGE,question='What clothing item is gray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6377, "imageId": "n222297", "question": "What is the palm tree in front of?", "program": "BOX0=LOC(image=IMAGE,object='palm tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the palm tree in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6378, "imageId": "n435808", "question": "What is sitting next to the computer mouse?", "program": "BOX0=LOC(image=IMAGE,object='computer mouse')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting next to the computer mouse?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6379, "imageId": "n554880", "question": "What do you think is the device to the right of the device the man is holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What do you think is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6380, "imageId": "n524855", "question": "Is there a bike or sand in the photo?", "program": "BOX0=LOC(image=IMAGE,object='bike')\nBOX1=LOC(image=IMAGE,object='sand')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6381, "imageId": "n541688", "question": "Is the toothbrush that is to the right of the other toothbrush large and yellow?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toothbrush?')\nANSWER1=VQA(image=IMAGE0,question='Is the toothbrush large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6382, "imageId": "n125122", "question": "Does the mounted mirror that is to the left of the curtains look dirty?", "program": "BOX0=LOC(image=IMAGE,object='curtains')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mounted mirror')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the mirror look dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6383, "imageId": "n469525", "question": "In which part of the image is the tall animal, the top or the bottom?", "program": "BOX0=LOC(image=IMAGE,object='tall animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6384, "imageId": "n97485", "question": "What shape is the table that is next to the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_NEXTTO(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=VQA(image=IMAGE0,question='What shape is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6385, "imageId": "n131634", "question": "Is this a small motorcycle?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nANSWER0=VQA(image=IMAGE,question='Is this a small motorcycle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6386, "imageId": "n100991", "question": "What type of baked good is on top of the plate that is on top of the tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='baked good')\nANSWER0=VQA(image=IMAGE1,question='What type of baked good is on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6387, "imageId": "n100991", "question": "What kind of baked good is on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of baked good is on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6388, "imageId": "n219840", "question": "Are the gray horses to the right of the zebra?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gray horses')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6389, "imageId": "n59147", "question": "Are the vase and the toilet that looks rectangular both white?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='toilet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the vase?')\nANSWER1=VQA(image=IMAGE1,question='What color is the toilet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6390, "imageId": "n39114", "question": "What is the mound in front of?", "program": "BOX0=LOC(image=IMAGE,object='mound')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the mound in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6391, "imageId": "n527589", "question": "What is that woman doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is that woman doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6392, "imageId": "n527589", "question": "What is the woman doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the woman doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6393, "imageId": "n390187", "question": "Is the helmet small and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the helmet small and blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6394, "imageId": "n273901", "question": "Is the sky cloudy and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE,question='Is the sky cloudy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6395, "imageId": "n14", "question": "Is the skateboard hard and white?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the material of the skateboard?')\nANSWER1=VQA(image=IMAGE,question='What color is the skateboard?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'hard' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6396, "imageId": "n14", "question": "Is the skateboard hard?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the skateboard hard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6397, "imageId": "n489190", "question": "Is the skateboard both black and wooden?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the skateboard?')\nANSWER1=VQA(image=IMAGE0,question='What material is the skateboard made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6398, "imageId": "n240973", "question": "Which kind of furniture is above the bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is above the bowl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6399, "imageId": "n240973", "question": "Are the shelves above a bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelves')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6400, "imageId": "n234722", "question": "Which kind of food isn't delicious?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food isn't delicious?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6401, "imageId": "n234722", "question": "Is this a clean table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is this a clean table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6402, "imageId": "n475030", "question": "Does the beach below the sky appear to be white and sandy?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='beach')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the beach?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white and sandy' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6403, "imageId": "n234722", "question": "What is under the pan?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the pan?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6404, "imageId": "n243701", "question": "How long is the hair?", "program": "BOX0=LOC(image=IMAGE,object='hair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6405, "imageId": "n49438", "question": "Who is sitting on top of the small bed?", "program": "BOX0=LOC(image=IMAGE,object='small bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting on top of the small bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6406, "imageId": "n556604", "question": "Is the table black and smooth?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=VQA(image=IMAGE0,question='Is the table smooth?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6407, "imageId": "n97485", "question": "What are the utensils made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the utensils made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6408, "imageId": "n208302", "question": "Does the road near the sidewalk look brown?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='road')\nANSWER0=VQA(image=IMAGE0,question='What color is the road?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6409, "imageId": "n546616", "question": "Is the baby to the right of the food that looks soft?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='baby')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='soft')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6410, "imageId": "n413002", "question": "Where in the picture are the ripe fruits, on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='ripe fruits')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6411, "imageId": "n541482", "question": "What is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6412, "imageId": "n393305", "question": "The sign behind the girl is of which shape?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sign')\nANSWER0=VQA(image=IMAGE0,question='The sign behind the girl is of which shape?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6413, "imageId": "n200907", "question": "Is the girl to the left or to the right of the silver car?", "program": "BOX0=LOC(image=IMAGE,object='silver car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6414, "imageId": "n272313", "question": "Are the pants both long and brown?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nANSWER0=VQA(image=IMAGE,question='Are the pants long?')\nANSWER1=VQA(image=IMAGE,question='What color are the pants?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6415, "imageId": "n367944", "question": "Does the bag have a different color than the calculator?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='calculator')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bag?')\nANSWER1=VQA(image=IMAGE1,question='What color is the calculator?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6416, "imageId": "n206358", "question": "Does the SUV look metallic and small?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the SUV look metallic?')\nANSWER1=VQA(image=IMAGE,question='Does the SUV look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6417, "imageId": "n200907", "question": "Are there any black rackets or baseball bats in this image?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nBOX1=LOC(image=IMAGE,object='baseball bat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6418, "imageId": "n200907", "question": "What color is the tennis racket?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tennis racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6419, "imageId": "n565418", "question": "Does the sky above the trees look sunny and light?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sky')\nANSWER0=VQA(image=IMAGE0,question='What does the sky look like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'sunny and light' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6420, "imageId": "n199286", "question": "Do the shorts have dark color and large size?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE0,question='What size are the shorts?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6421, "imageId": "n479092", "question": "Which material is the table made of?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material is the table made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6422, "imageId": "n479092", "question": "What is the table made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the table made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6423, "imageId": "n479092", "question": "Is the table black and metallic?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6424, "imageId": "n289376", "question": "What is the sign that the bench that is made of wood is sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6425, "imageId": "n289376", "question": "What is sitting beside the street sign that is standing in the lawn?", "program": "BOX0=LOC(image=IMAGE,object='street sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lawn')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='beside')\nANSWER0=VQA(image=IMAGE1,question='What is sitting beside the street sign?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6426, "imageId": "n513429", "question": "What color is the keyboard that is to the right of the bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='keyboard')\nANSWER0=VQA(image=IMAGE0,question='What color is the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6427, "imageId": "n58220", "question": "Who wears the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6428, "imageId": "n526228", "question": "Do the books that are made of paper look open and small?", "program": "BOX0=LOC(image=IMAGE,object='books made of paper')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do the books look open?')\nANSWER1=VQA(image=IMAGE0,question='Do the books look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6429, "imageId": "n162108", "question": "Which type of material was used to make the bottle that looks white?", "program": "BOX0=LOC(image=IMAGE,object='white bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which type of material was used to make the bottle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6430, "imageId": "n23762", "question": "What color do you think is the high ceiling?", "program": "ANSWER0=VQA(image=IMAGE,question='What color do you think is the high ceiling?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6431, "imageId": "n49310", "question": "Is the man wearing a watch?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6432, "imageId": "n68769", "question": "Is the thin woman to the right or to the left of the adult person?", "program": "BOX0=LOC(image=IMAGE,object='adult person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='thin woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6433, "imageId": "n250821", "question": "The cable is on what?", "program": "BOX0=LOC(image=IMAGE,object='cable')\nANSWER0=VQA(image=IMAGE,question='The cable is on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6434, "imageId": "n250821", "question": "What is on the paper?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the paper?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6435, "imageId": "n513100", "question": "What is the image showing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the image showing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6436, "imageId": "n257997", "question": "Is the hat black?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6437, "imageId": "n65202", "question": "How long are the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long are the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6438, "imageId": "n79078", "question": "On which side of the photo is the trash bin?", "program": "BOX0=LOC(image=IMAGE,object='trash bin')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6439, "imageId": "n513100", "question": "Is the table made of the same material as the fence?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fence')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the fence made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6440, "imageId": "n410289", "question": "Is the sink hard and brown?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the texture of the sink?')\nANSWER1=VQA(image=IMAGE0,question='What color is the sink?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'hard' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6441, "imageId": "n125122", "question": "Which side is the red pillow on?", "program": "BOX0=LOC(image=IMAGE,object='red pillow')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6442, "imageId": "n398257", "question": "Is the rug the same color as the plant?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='plant')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the rug?')\nANSWER1=VQA(image=IMAGE1,question='What color is the plant?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6443, "imageId": "n100991", "question": "Is there a carrot to the right of the vegetables that are to the right of the banana?", "program": "BOX0=LOC(image=IMAGE,object='banana')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetables')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='carrot')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6444, "imageId": "n200907", "question": "What material is the fence to the left of the other fence made of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6445, "imageId": "n485969", "question": "What are the spectators watching?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the spectators watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6446, "imageId": "n485969", "question": "Are the spectators that are sitting-down watching the pitcher?", "program": "BOX0=LOC(image=IMAGE,object='pitcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='spectators')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='sitting-down')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='Are the spectators watching the pitcher?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6447, "imageId": "n119886", "question": "Is the toilet antique?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the toilet antique?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6448, "imageId": "n356822", "question": "Is the old person sitting next to the girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='old person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6449, "imageId": "n356822", "question": "Who is the man sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6450, "imageId": "n209843", "question": "Does the door look white and wooden?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the door?')\nANSWER1=VQA(image=IMAGE0,question='What material is the door made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6451, "imageId": "n485969", "question": "The people that are staring are watching what?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the people watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6452, "imageId": "n485969", "question": "Who is watching the pitcher?", "program": "BOX0=LOC(image=IMAGE,object='pitcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the pitcher?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6453, "imageId": "n336443", "question": "What is the food to the left of the utensil that is to the left of the bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nANSWER0=VQA(image=IMAGE1,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6454, "imageId": "n285391", "question": "Which kind of furniture is old?", "program": "BOX0=LOC(image=IMAGE,object='old')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6455, "imageId": "n162108", "question": "On which side of the image is the toilet?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6456, "imageId": "n279173", "question": "What sign is in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What sign is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6457, "imageId": "n162108", "question": "Is that toilet metallic and white?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet?')\nANSWER1=VQA(image=IMAGE0,question='What material is the toilet made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6458, "imageId": "n69237", "question": "What kind of furniture is not black, the bookcase or the bed?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bed')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bookcase?')\nANSWER1=VQA(image=IMAGE1,question='What color is the bed?')\nANSWER2=EVAL(expr=\"'bookcase' if {ANSWER0} != 'black' else 'bed'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6459, "imageId": "n279173", "question": "What sign is on the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What sign is on the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6460, "imageId": "n508733", "question": "Are there either any paintings or toothbrushes?", "program": "BOX0=LOC(image=IMAGE,object='painting')\nBOX1=LOC(image=IMAGE,object='toothbrush')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6461, "imageId": "n526228", "question": "What is located on top of the jeans that are made of jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='jeans')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is located on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6462, "imageId": "n260521", "question": "Are both the bench and the long broom dark?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='long broom')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bench?')\nANSWER1=VQA(image=IMAGE1,question='What color is the long broom?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' and {ANSWER1} == 'dark' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6463, "imageId": "n527290", "question": "What device is to the right of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the right of the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6464, "imageId": "n260521", "question": "What color is the bench that the person sits on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=VQA(image=IMAGE0,question='What color is the bench?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6465, "imageId": "n446242", "question": "What's the woman on?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6466, "imageId": "n263180", "question": "Is the car to the right of the bus that the arrow is next to?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='arrow')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='car')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6467, "imageId": "n117888", "question": "Is the bench behind a fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6468, "imageId": "n380113", "question": "Who is running?", "program": "BOX0=LOC(image=IMAGE,object='running')\nANSWER0=VQA(image=IMAGE,question='Who is running?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6469, "imageId": "n4777", "question": "Is the person that is to the right of the cup sitting on the chair in the bottom of the photo?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='chair')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6470, "imageId": "n4777", "question": "What is the person that is to the right of the cup using?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6471, "imageId": "n274905", "question": "Who is the man standing behind of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man standing behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6472, "imageId": "n498712", "question": "Who is standing behind the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing behind the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6473, "imageId": "n437192", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6474, "imageId": "n319845", "question": "What is around the table that the ceiling is above?", "program": "BOX0=LOC(image=IMAGE,object='ceiling')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is around the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6475, "imageId": "n412144", "question": "Is there a plastic helmet or skateboard?", "program": "BOX0=LOC(image=IMAGE,object='plastic helmet')\nBOX1=LOC(image=IMAGE,object='skateboard')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6476, "imageId": "n578564", "question": "What is the pan in front of?", "program": "BOX0=LOC(image=IMAGE,object='pan')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pan in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6477, "imageId": "n411121", "question": "Is the large vehicle in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6478, "imageId": "n525029", "question": "Is the window small and black?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the window?')\nANSWER1=VQA(image=IMAGE0,question='Is the window small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6479, "imageId": "n511913", "question": "How big is the table made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=VQA(image=IMAGE0,question='How big is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6480, "imageId": "n470131", "question": "What is the color of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6481, "imageId": "n16378", "question": "What is pulled by the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is pulled by the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6482, "imageId": "n546616", "question": "What's located on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6483, "imageId": "n117888", "question": "Are there both a fence and a bench?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='bench')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6484, "imageId": "n202379", "question": "Is the fence round or rectangular?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='Is the fence round or rectangular?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6485, "imageId": "n293477", "question": "Are there monitors to the left of the pens that are lying on top of the bed?", "program": "BOX0=LOC(image=IMAGE,object='pens')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='monitors')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6486, "imageId": "n52544", "question": "Is the blouse colorful?", "program": "BOX0=LOC(image=IMAGE,object='blouse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the blouse colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6487, "imageId": "n536256", "question": "Are the movies inside the TV stand?", "program": "BOX0=LOC(image=IMAGE,object='TV stand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='movies')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6488, "imageId": "n140421", "question": "What kind of furniture is below the chandelier?", "program": "BOX0=LOC(image=IMAGE,object='chandelier')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is below the chandelier?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6489, "imageId": "n140421", "question": "How are the items of furniture below the chandelier called?", "program": "ANSWER0=VQA(image=IMAGE,question='How are the items of furniture below the chandelier called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6490, "imageId": "n118102", "question": "What is located on top of the dessert that is on top of the tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is located on top of the dessert?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6491, "imageId": "n195249", "question": "Which company is the wristband from?", "program": "ANSWER0=VQA(image=IMAGE,question='Which company is the wristband from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6492, "imageId": "n355567", "question": "Does the person that is to the right of the lady look modern?", "program": "BOX0=LOC(image=IMAGE,object='lady')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Does the person look modern?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6493, "imageId": "n146522", "question": "Which material was used to make the black bag that is to the left of the boy, cloth or plastic?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which material was used to make the bag?')\nANSWER1=EVAL(expr=\"'cloth' if {ANSWER0} == 'cloth' else 'plastic'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6494, "imageId": "n51002", "question": "Which side of the image is the plastic keyboard on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic keyboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6495, "imageId": "n16656", "question": "What is the name of the animal that the shoe is in front of?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What is the name of the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6496, "imageId": "n431447", "question": "What is the person to the left of the pizza box doing?", "program": "BOX0=LOC(image=IMAGE,object='pizza box')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6497, "imageId": "n431447", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6498, "imageId": "n90294", "question": "Where is the bag?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6499, "imageId": "n460385", "question": "Who is sitting at the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting at the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6500, "imageId": "n95369", "question": "Do you see any faucets below the ring?", "program": "BOX0=LOC(image=IMAGE,object='ring')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='faucets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6501, "imageId": "n95313", "question": "What's underneath the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6502, "imageId": "n116329", "question": "Is the window made of the same material as the door?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='door')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the window made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the door made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6503, "imageId": "n95369", "question": "Is the bath tub near the sink red and small?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bath tub')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the bath tub?')\nANSWER1=VQA(image=IMAGE1,question='How big is the bath tub?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6504, "imageId": "n382416", "question": "Is the purse soft?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the purse soft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6505, "imageId": "n511913", "question": "What is the item of furniture that is to the left of the books on the right?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6506, "imageId": "n382416", "question": "Is the leather bag light brown and soft?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the leather bag?')\nANSWER1=VQA(image=IMAGE,question='Is the leather bag soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'light brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6507, "imageId": "n116329", "question": "Are the tree branch and the fence made of the same material?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the tree branch made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the fence made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6508, "imageId": "n575770", "question": "What kind of clothing is long?", "program": "BOX0=LOC(image=IMAGE,object='long')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6509, "imageId": "n298104", "question": "Where is the surfboard?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6510, "imageId": "n485969", "question": "What is wearing a baseball mitt?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is wearing a baseball mitt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6511, "imageId": "n256120", "question": "What is in front of the green flag?", "program": "BOX0=LOC(image=IMAGE,object='green flag')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the green flag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6512, "imageId": "n256120", "question": "What is in front of the flag?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the flag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6513, "imageId": "n275148", "question": "What is the item of furniture on top of the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6514, "imageId": "n275148", "question": "What is located on top of the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6515, "imageId": "n256120", "question": "What is in front of the tents?", "program": "BOX0=LOC(image=IMAGE,object='tents')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='front')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the tents?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6516, "imageId": "n256120", "question": "What kind of vehicle is in front of the tents?", "program": "BOX0=LOC(image=IMAGE,object='tents')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is in front of the tents?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6517, "imageId": "n571179", "question": "Is the man standing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=POSE(image=IMAGE,box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'standing' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6518, "imageId": "n275148", "question": "What item of furniture is on top of the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6519, "imageId": "n309148", "question": "Is the street gray?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the street?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6520, "imageId": "n483840", "question": "Is the man Asian or Caucasian?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the man Asian or Caucasian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6521, "imageId": "n575770", "question": "How are the gray clothing items called?", "program": "ANSWER0=VQA(image=IMAGE,question='How are the gray clothing items called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6522, "imageId": "n406334", "question": "What is the bus in front of?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bus in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6523, "imageId": "n9181", "question": "Does the vest look black and long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='vest')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the vest?')\nANSWER1=VQA(image=IMAGE0,question='Are the sleeves of the vest long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6524, "imageId": "n406334", "question": "What kind of vehicle is in front of the buildings that the sky is behind of?", "program": "BOX0=LOC(image=IMAGE,object='buildings')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sky')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=VQA(image=IMAGE1,question='What kind of vehicle is in front of the buildings?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6525, "imageId": "n560243", "question": "Does the athlete look young or old?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the athlete look young or old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6526, "imageId": "n90294", "question": "Is the laptop near the book silver or black?", "program": "BOX0=LOC(image=IMAGE,object='book')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nANSWER0=VQA(image=IMAGE0,question='What color is the laptop?')\nANSWER1=EVAL(expr=\"'silver' if {ANSWER0} == 'silver' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6527, "imageId": "n310828", "question": "Is the computer desk both full and white?", "program": "BOX0=LOC(image=IMAGE,object='computer desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the computer desk full?')\nANSWER1=VQA(image=IMAGE0,question='What color is the computer desk?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6528, "imageId": "n531731", "question": "Is the wood bench in the top or in the bottom of the picture?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6529, "imageId": "n95313", "question": "What's in front of the closet?", "program": "BOX0=LOC(image=IMAGE,object='closet')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the closet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6530, "imageId": "n170941", "question": "Do you see plates near the fork that is on the left?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plates')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6531, "imageId": "n164272", "question": "What are the trees behind of, pigs or cows?", "program": "BOX0=LOC(image=IMAGE,object='pigs')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'pigs' if {ANSWER0} > 0 else 'cows'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6532, "imageId": "n164272", "question": "Which kind of animal are the trees behind of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal are the trees behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6533, "imageId": "n262920", "question": "What are the devices that the person that is not old is touching called?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the devices that the person that is not old is touching called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6534, "imageId": "n545516", "question": "What does the man that looks heavy hold?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the man hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6535, "imageId": "n95313", "question": "What kind of furniture is the bed in front of?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the bed in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6536, "imageId": "n262920", "question": "Which kind of device is the man touching?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is the man touching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6537, "imageId": "n6309", "question": "What animal is to the left of the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is to the left of the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6538, "imageId": "n296467", "question": "Which kind of vegetable is to the right of the dip?", "program": "BOX0=LOC(image=IMAGE,object='dip')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetable')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vegetable is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6539, "imageId": "n317260", "question": "Do the spectators who are to the right of the batter appear to be sitting?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='spectators')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6540, "imageId": "n296467", "question": "What is the food inside the bowl on the right side of the photo?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the food inside the bowl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6541, "imageId": "n296467", "question": "The cookies are inside what?", "program": "BOX0=LOC(image=IMAGE,object='cookies')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The cookies are inside what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6542, "imageId": "n551964", "question": "The girl that is to the right of the helmet is walking next to who?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='The girl is walking next to who?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6543, "imageId": "n278312", "question": "Does the kitchen look closed?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the kitchen look closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6544, "imageId": "n279581", "question": "Does the shirt look black?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6545, "imageId": "n278312", "question": "Are there both toasters and stoves?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nBOX1=LOC(image=IMAGE,object='stove')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6546, "imageId": "n207893", "question": "Are there any fences or cars in this picture?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='car')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6547, "imageId": "n88933", "question": "Of which color is that gown?", "program": "ANSWER0=VQA(image=IMAGE,question='Of which color is that gown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6548, "imageId": "n531359", "question": "Is there a pink tie in this image?", "program": "BOX0=LOC(image=IMAGE,object='pink tie')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6549, "imageId": "n578564", "question": "What's the picture hanging above?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging above the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6550, "imageId": "n88933", "question": "Which kind of clothing is not bright?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is not bright?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6551, "imageId": "n531359", "question": "Are there both glasses and ties in this image?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nBOX1=LOC(image=IMAGE,object='ties')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6552, "imageId": "n500209", "question": "What is the shelf in front of the wall made of?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nANSWER0=VQA(image=IMAGE0,question='What is the shelf made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6553, "imageId": "n264887", "question": "The headphones are in front of what?", "program": "BOX0=LOC(image=IMAGE,object='headphones')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The headphones are in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6554, "imageId": "n357784", "question": "Do you see any cell phones or laptops in the image?", "program": "BOX0=LOC(image=IMAGE,object='cell phone')\nBOX1=LOC(image=IMAGE,object='laptop')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6555, "imageId": "n381072", "question": "Does the cake to the left of the knife look baked and triangular?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cake')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='Does the cake look baked?')\nANSWER3=VQA(image=IMAGE0,question='Does the cake look triangular?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6556, "imageId": "n554880", "question": "Where in the image is the lamp, on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='LEFT')\nBOX2=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'left' if {ANSWER1} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6557, "imageId": "n207708", "question": "Is there a red peach or banana in the image?", "program": "BOX0=LOC(image=IMAGE,object='peach')\nBOX1=LOC(image=IMAGE,object='banana')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6558, "imageId": "n264887", "question": "What is in front of the device in the middle?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='middle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6559, "imageId": "n37274", "question": "What appliance is full of ice?", "program": "BOX0=LOC(image=IMAGE,object='ice')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What appliance is full of ice?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6560, "imageId": "n357784", "question": "Is the black camera in the bottom part or in the top of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black camera')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6561, "imageId": "n274905", "question": "Who is the person that is standing standing behind of?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the person standing behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6562, "imageId": "n6908", "question": "The flowers are inside what?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The flowers are inside what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6563, "imageId": "n6908", "question": "What are the flowers inside of?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the flowers inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6564, "imageId": "n6908", "question": "What are the flowers in front of?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the flowers in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6565, "imageId": "n318684", "question": "The man to the left of the glasses is looking at what?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The man is looking at what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6566, "imageId": "n6908", "question": "What is inside the clear glass on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clear glass')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is inside the clear glass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6567, "imageId": "n6908", "question": "What is inside the glass?", "program": "ANSWER0=VQA(image=IMAGE,question='What is inside the glass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6568, "imageId": "n315887", "question": "What kind of device is to the left of the device near the tape?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tape')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nANSWER0=VQA(image=IMAGE1,question='What kind of device is to the left of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6569, "imageId": "n315887", "question": "Which kind of device is left of the computer?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is left of the computer?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6570, "imageId": "n6908", "question": "Are the flowers inside a vase?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flowers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6571, "imageId": "n311910", "question": "How wide is the street the car is above?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='street')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How wide is the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6572, "imageId": "n433532", "question": "What kind of furniture is high?", "program": "BOX0=LOC(image=IMAGE,object='high')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is high?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6573, "imageId": "n433532", "question": "What color is the towel, red or white?", "program": "BOX0=LOC(image=IMAGE,object='towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the towel?')\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} == 'red' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6574, "imageId": "n433532", "question": "What is the item of furniture that is brown called?", "program": "BOX0=LOC(image=IMAGE,object='brown')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6575, "imageId": "n503626", "question": "What color is the countertop?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6576, "imageId": "n19152", "question": "Is the sidewalk made of cobblestone or stone?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the sidewalk made of?')\nANSWER1=EVAL(expr=\"'cobblestone' if {ANSWER0} == 'cobblestone' or {ANSWER0} == 'stone' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6577, "imageId": "n403734", "question": "Is the ipod on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ipod')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6578, "imageId": "n298104", "question": "The woman is posing with what?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The woman is posing with what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6579, "imageId": "n298104", "question": "Who is posing with the surfboard?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is posing with the surfboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6580, "imageId": "n298104", "question": "Is the happy person posing with the surfboard?", "program": "BOX0=LOC(image=IMAGE,object='happy person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surfboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6581, "imageId": "n23181", "question": "What is the item of furniture to the right of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6582, "imageId": "n485969", "question": "Is the pitcher that is not old wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='pitcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the pitcher old?')\nBOX1=LOC(image=IMAGE0,object='glove')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6583, "imageId": "n167164", "question": "Which side of the image is the house on?", "program": "BOX0=LOC(image=IMAGE,object='house')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6584, "imageId": "n55058", "question": "Is there any food on top of the food tray on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food tray')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6585, "imageId": "n477215", "question": "Does the river that is not wide look curved?", "program": "BOX0=LOC(image=IMAGE,object='river')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the river curved?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER0} != 'wide' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6586, "imageId": "n141939", "question": "Does the white toilet seem to be clean and wooden?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the white toilet seem to be clean and wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6587, "imageId": "n460556", "question": "Is this a skateboarder or a snowboarder?", "program": "ANSWER0=VQA(image=IMAGE,question='Is this a skateboarder or a snowboarder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6588, "imageId": "n55058", "question": "Does the food on top of the serving tray look red?", "program": "BOX0=LOC(image=IMAGE,object='serving tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the food?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6589, "imageId": "n355567", "question": "Does the plastic bat look antique?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the plastic bat look antique?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6590, "imageId": "n380113", "question": "Does the soccer ball on the field seem to be still and red?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer ball')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the soccer ball?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6591, "imageId": "n351318", "question": "Are the scissors on the white thing above the stickers?", "program": "BOX0=LOC(image=IMAGE,object='stickers')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white thing')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='scissors')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6592, "imageId": "n380113", "question": "Are the soccer ball on the grass and the folding chair that looks blue both still?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer ball')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='folding chair')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='Is the soccer ball still?')\nANSWER1=VQA(image=IMAGE2,question='Is the folding chair still?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6593, "imageId": "n315859", "question": "Do the skis look dry?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the skis look dry?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6594, "imageId": "n532213", "question": "What is this, a fire hydrant or a traffic light?", "program": "BOX0=LOC(image=IMAGE,object='fire hydrant')\nBOX1=LOC(image=IMAGE,object='traffic light')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'fire hydrant' if {ANSWER0} > 0 else 'traffic light'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6595, "imageId": "n380113", "question": "Do you think the soccer ball is still?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do you think the soccer ball is still?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6596, "imageId": "n293477", "question": "What device is lying on top of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is lying on top of the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6597, "imageId": "n293477", "question": "What is the cell phone lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='cell phone')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cell phone lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6598, "imageId": "n293477", "question": "What's the cell phone made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the cell phone made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6599, "imageId": "n28572", "question": "Is that glass full or empty?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the glass full or empty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6600, "imageId": "n314630", "question": "What is the appliance that is to the right of the house that is in front of the light switch?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light switch')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6601, "imageId": "n293477", "question": "What type of furniture is the cellphone lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='cellphone')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is the cellphone lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6602, "imageId": "n66756", "question": "Do you see doors there?", "program": "BOX0=LOC(image=IMAGE,object='doors')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6603, "imageId": "n350732", "question": "Is the soccer ball blue?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the soccer ball?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6604, "imageId": "n315887", "question": "Which side is the water bottle on?", "program": "BOX0=LOC(image=IMAGE,object='water bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6605, "imageId": "n494677", "question": "Are the trees small and brown?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the trees small?')\nANSWER1=VQA(image=IMAGE,question='Are the trees brown?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6606, "imageId": "n204894", "question": "Who is talking?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is talking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6607, "imageId": "n282436", "question": "On which side of the image is the large device?", "program": "BOX0=LOC(image=IMAGE,object='large device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6608, "imageId": "n100552", "question": "Does this fence look tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Does this fence look tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6609, "imageId": "n100552", "question": "Is the fence behind the elephant tall and wooden?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='wooden')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6610, "imageId": "n324908", "question": "What's smaller than the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is smaller than the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6611, "imageId": "n324908", "question": "Is the hair above a zebra?", "program": "BOX0=LOC(image=IMAGE,object='zebra')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6612, "imageId": "n324908", "question": "What is the hair smaller than?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the hair smaller than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6613, "imageId": "n259002", "question": "What is the car in front of?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the car in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6614, "imageId": "n206785", "question": "Is the door made of wood closed or open?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the door made of?')\nANSWER1=VQA(image=IMAGE0,question='Is the door closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6615, "imageId": "n234683", "question": "Are the metal glasses clean and black?", "program": "BOX0=LOC(image=IMAGE,object='metal glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the metal glasses clean?')\nANSWER1=VQA(image=IMAGE0,question='What color are the metal glasses?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'clean' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6616, "imageId": "n234683", "question": "Are the glasses clean?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the glasses clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6617, "imageId": "n234683", "question": "Which kind of clothing is teal?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is teal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6618, "imageId": "n256120", "question": "What is the pole in front of?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pole in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6619, "imageId": "n28572", "question": "Is the glass in front of the menu clear and full?", "program": "BOX0=LOC(image=IMAGE,object='menu')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the glass clear?')\nANSWER1=VQA(image=IMAGE1,question='Is the glass full?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6620, "imageId": "n153118", "question": "Are the trees behind a truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6621, "imageId": "n350732", "question": "What kind of furniture is on the lawn?", "program": "BOX0=LOC(image=IMAGE,object='lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is on the lawn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6622, "imageId": "n59147", "question": "Does the toilet brush have white color?", "program": "BOX0=LOC(image=IMAGE,object='toilet brush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet brush?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6623, "imageId": "n350732", "question": "Where is the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6624, "imageId": "n511881", "question": "Is the gate small?", "program": "BOX0=LOC(image=IMAGE,object='gate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the gate small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6625, "imageId": "n44249", "question": "What animal is in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6626, "imageId": "n83784", "question": "What color is the striped rug on top of the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='striped rug')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the striped rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6627, "imageId": "n262929", "question": "Who is on the bike?", "program": "BOX0=LOC(image=IMAGE,object='bike')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is on the bike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6628, "imageId": "n262929", "question": "What is he on?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is he on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6629, "imageId": "n51002", "question": "Do you see any mats or toys there?", "program": "BOX0=LOC(image=IMAGE,object='mat')\nBOX1=LOC(image=IMAGE,object='toys')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6630, "imageId": "n532191", "question": "Is the laptop computer white and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='laptop computer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the laptop computer?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the laptop computer?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6631, "imageId": "n536256", "question": "Are there any chairs or bags in this picture?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='bag')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6632, "imageId": "n352479", "question": "Is the female person standing or jumping?", "program": "BOX0=LOC(image=IMAGE,object='female person')\nANSWER0=POSE(image=IMAGE,box=BOX0)\nANSWER1=EVAL(expr=\"'standing' if {ANSWER0} == 'standing' else 'jumping'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6633, "imageId": "n69237", "question": "The metal appliance has what color?", "program": "BOX0=LOC(image=IMAGE,object='metal appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the metal appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6634, "imageId": "n498712", "question": "Is the receipt on top of the luggage that is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='luggage')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='receipt')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6635, "imageId": "n393305", "question": "In front of who is the fire hydrant?", "program": "BOX0=LOC(image=IMAGE,object='fire hydrant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In front of who is the fire hydrant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6636, "imageId": "n393305", "question": "In front of who is the hydrant?", "program": "BOX0=LOC(image=IMAGE,object='hydrant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In front of who is the hydrant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6637, "imageId": "n393305", "question": "What is in front of the girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6638, "imageId": "n88933", "question": "Are there sofas that are not brown?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nANSWER0=VQA(image=IMAGE,question='What color is the sofa?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6639, "imageId": "n54180", "question": "Does the toilet paper to the right of the cup look soft and blue?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet paper')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the toilet paper?')\nANSWER3=VQA(image=IMAGE0,question='Does the toilet paper look soft?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'blue' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6640, "imageId": "n95904", "question": "What color is the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6641, "imageId": "n181355", "question": "Is there either a bed or a nightstand in the picture?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='nightstand')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6642, "imageId": "n259949", "question": "Who is wearing the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6643, "imageId": "n289376", "question": "What is the lawn sitting beside?", "program": "BOX0=LOC(image=IMAGE,object='lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the lawn sitting beside?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6644, "imageId": "n184385", "question": "What color is the cooking utensil that is to the right of the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=VQA(image=IMAGE0,question='What color is the cooking utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6645, "imageId": "n276011", "question": "Is the floor both wooden and light brown?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the floor made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the floor?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'light brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6646, "imageId": "n276011", "question": "What material is the floor that looks dark brown made of?", "program": "BOX0=LOC(image=IMAGE,object='dark brown floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the floor made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6647, "imageId": "n305495", "question": "How long is the dark shirt?", "program": "BOX0=LOC(image=IMAGE,object='dark shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the dark shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6648, "imageId": "n162586", "question": "On which side is the picture?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6649, "imageId": "n497789", "question": "Where is the vehicle?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=EVAL(expr=\"'top' if {BOX0[1]} < 0.5 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6650, "imageId": "n475030", "question": "Are there any horses or cows?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nBOX1=LOC(image=IMAGE,object='cow')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6651, "imageId": "n246334", "question": "On which side of the image is the house?", "program": "BOX0=LOC(image=IMAGE,object='house')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6652, "imageId": "n500308", "question": "Is there a dishwasher on the floor that is shown in the image?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dishwasher')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6653, "imageId": "n570181", "question": "How clean is the uniform that looks gray and red?", "program": "BOX0=LOC(image=IMAGE,object='uniform')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6654, "imageId": "n393305", "question": "Who wears a tshirt?", "program": "BOX0=LOC(image=IMAGE,object='tshirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears a tshirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6655, "imageId": "n393305", "question": "Is the person behind the hydrant wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='hydrant')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the person wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6656, "imageId": "n500209", "question": "What kind of furniture is the wall behind of?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is behind the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6657, "imageId": "n350766", "question": "What is the cooking utensil above the drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6658, "imageId": "n271392", "question": "What is in front of the old people?", "program": "BOX0=LOC(image=IMAGE,object='old people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='object')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the old people?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6659, "imageId": "n508641", "question": "Which material makes up the bat, aluminum or wood?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material makes up the bat, aluminum or wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6660, "imageId": "n133585", "question": "What color do you think the trousers the boy is wearing have?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6661, "imageId": "n315887", "question": "Does the device to the left of the CD look black?", "program": "BOX0=LOC(image=IMAGE,object='CD')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6662, "imageId": "n357784", "question": "Is the woman happy and brunette?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the woman happy?')\nANSWER1=VQA(image=IMAGE,question='Is the woman brunette?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6663, "imageId": "n346247", "question": "The sculpture is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='sculpture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The sculpture is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6664, "imageId": "n346247", "question": "What is in front of the tree that is in front of the school?", "program": "BOX0=LOC(image=IMAGE,object='school')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tree')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the tree?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6665, "imageId": "n235859", "question": "Does the watch have round shape and large size?", "program": "ANSWER0=VQA(image=IMAGE,question='What shape is the watch?')\nANSWER1=VQA(image=IMAGE,question='What size is the watch?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6666, "imageId": "n131634", "question": "Is the street wide?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the street wide?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6667, "imageId": "n259002", "question": "Is the grass underneath the ball tall and green?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6668, "imageId": "n250715", "question": "What is the device that is not turned-off mounted to?", "program": "BOX0=LOC(image=IMAGE,object='turned-off')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the device mounted to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6669, "imageId": "n240666", "question": "What is the sink made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sink made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6670, "imageId": "n240666", "question": "Is the sink made of porcelain or wood?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the sink made of?')\nANSWER1=EVAL(expr=\"'porcelain' if {ANSWER0} == 'porcelain' else 'wood'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6671, "imageId": "n250715", "question": "What kind of aircraft is the device that is not turned-off mounted to?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='aircraft')\nANSWER0=VQA(image=IMAGE0,question='What kind of aircraft is the device mounted to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6672, "imageId": "n111390", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6673, "imageId": "n543966", "question": "Are there both elephant and a dolphin in this picture?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nBOX1=LOC(image=IMAGE,object='dolphin')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6674, "imageId": "n59676", "question": "What is the ceramic cup sitting on?", "program": "BOX0=LOC(image=IMAGE,object='ceramic cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the ceramic cup sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6675, "imageId": "n59676", "question": "What is the cup sitting on?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cup sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6676, "imageId": "n496803", "question": "What's the racket larger than?", "program": "ANSWER0=VQA(image=IMAGE,question='What\\'s the racket larger than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6677, "imageId": "n69237", "question": "What is hang from the window made of glass?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass')\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the window?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'glass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6678, "imageId": "n69237", "question": "Do the drapes to the right of the heater look dull?", "program": "BOX0=LOC(image=IMAGE,object='heater')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drapes')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6679, "imageId": "n318370", "question": "Does the white shirt look sleeveless?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the white shirt look sleeveless?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6680, "imageId": "n83784", "question": "Which animal is black and white?", "program": "BOX0=LOC(image=IMAGE,object='black')\nBOX1=LOC(image=IMAGE,object='white')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'zebra' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'panda'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6681, "imageId": "n69237", "question": "Do the drapes look gold and dull?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the drapes?')\nANSWER1=VQA(image=IMAGE,question='Do the drapes look dull?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gold' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6682, "imageId": "n228268", "question": "What is worn on the person the oar is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='oar')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is worn on the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6683, "imageId": "n470920", "question": "Does the umbrella to the left of the man look black?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the umbrella?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6684, "imageId": "n69237", "question": "What are the draperies to the right of the heater hang from?", "program": "BOX0=LOC(image=IMAGE,object='heater')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='draperies')\nANSWER0=VQA(image=IMAGE0,question='What are the draperies hang from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6685, "imageId": "n309148", "question": "What is the size of the bucket?", "program": "BOX0=LOC(image=IMAGE,object='bucket')\nANSWER0=VQA(image=IMAGE,question='What is the size of the bucket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6686, "imageId": "n77818", "question": "What device isn't square?", "program": "BOX0=LOC(image=IMAGE,object='device')\nANSWER0=VQA(image=IMAGE,question='What device isn\\'t square?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6687, "imageId": "n77818", "question": "What is the name of the illuminated device?", "program": "BOX0=LOC(image=IMAGE,object='illuminated device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the illuminated device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6688, "imageId": "n228268", "question": "Who are the shorts that are not dry worn on?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who are the shorts worn on?')\nANSWER1=EVAL(expr=\"'not dry' if {ANSWER0} != 'dry' else 'dry'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6689, "imageId": "n100552", "question": "What is the animal in front of the fence that is not short?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What is the animal?')\nANSWER1=VQA(image=IMAGE0,question='Is the animal short?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if {ANSWER1} == 'no' else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6690, "imageId": "n488874", "question": "In front of what is the beach?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In front of what is the beach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6691, "imageId": "n240973", "question": "What is sitting on the tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on the tray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6692, "imageId": "n14087", "question": "What is the dog in front of?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the dog in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6693, "imageId": "n499081", "question": "Are the books on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6694, "imageId": "n14087", "question": "Which kind of animal is in front of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is in front of the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6695, "imageId": "n489699", "question": "Is the sky cloudy and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE,question='Is the sky cloudy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6696, "imageId": "n525901", "question": "Is there a desk that is tan?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the desk?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'tan' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6697, "imageId": "n579928", "question": "How big is the gray window?", "program": "BOX0=LOC(image=IMAGE,object='gray window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How big is the gray window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6698, "imageId": "n119944", "question": "Is the person to the right of the benches both young and female?", "program": "BOX0=LOC(image=IMAGE,object='benches')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='Is the person young?')\nANSWER3=VQA(image=IMAGE0,question='Is the person female?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6699, "imageId": "n240973", "question": "What kind of device is to the left of the tray?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is to the left of the tray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6700, "imageId": "n9856", "question": "Does the shirt that looks yellow and white look long sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the shirt that looks yellow and white look long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6701, "imageId": "n549922", "question": "On which side of the image is the stuffed bear?", "program": "BOX0=LOC(image=IMAGE,object='stuffed bear')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6702, "imageId": "n541854", "question": "Which kind of fruit is shiny?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fruit is shiny?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6703, "imageId": "n318684", "question": "Is the deep sky blue and clear?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE,question='Is the sky clear?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'deep sky blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6704, "imageId": "n541854", "question": "What fruit is hard?", "program": "ANSWER0=VQA(image=IMAGE,question='What fruit is hard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6705, "imageId": "n153293", "question": "Are the towels made of cloth hanging from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towels')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6706, "imageId": "n541854", "question": "What fruit is green?", "program": "ANSWER0=VQA(image=IMAGE,question='What fruit is green?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6707, "imageId": "n153293", "question": "What is hanging from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6708, "imageId": "n570181", "question": "Who is crouching?", "program": "BOX0=LOC(image=IMAGE,object='crouching')\nANSWER0=VQA(image=IMAGE,question='Who is crouching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6709, "imageId": "n196058", "question": "Is the stone behind the zebras above the grass?", "program": "BOX0=LOC(image=IMAGE,object='zebras')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stone')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='grass')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6710, "imageId": "n12404", "question": "Does the shoe that is made of leather have orange color?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the shoe made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the shoe?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'leather' and {ANSWER1} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6711, "imageId": "n499081", "question": "How clean is the counter that is made of marble?", "program": "BOX0=LOC(image=IMAGE,object='marble counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the counter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6712, "imageId": "n551964", "question": "On which side of the image is the small helmet?", "program": "BOX0=LOC(image=IMAGE,object='small helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6713, "imageId": "n88366", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6714, "imageId": "n468864", "question": "What is the young woman holding?", "program": "BOX0=LOC(image=IMAGE,object='young woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the young woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6715, "imageId": "n199286", "question": "Is the girl on the right side or on the left of the photo?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nANSWER0=EVAL(expr=\"'right' if {BOX0.x} > IMAGE.width/2 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6716, "imageId": "n551964", "question": "Is the helmet to the left of the man small and gray?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='helmet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color is the helmet?')\nANSWER3=VQA(image=IMAGE1,question='What size is the helmet?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'gray' and {ANSWER3} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6717, "imageId": "n468864", "question": "What's the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6718, "imageId": "n98544", "question": "Is the size of the bathroom large?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the size of the bathroom large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6719, "imageId": "n344136", "question": "Which type of furniture is made of wood, the bookcase or the couch?", "program": "ANSWER0=VQA(image=IMAGE,question='Which type of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6720, "imageId": "n28572", "question": "What is in front of the napkin?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='front')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the napkin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6721, "imageId": "n95904", "question": "Does the person that is not male hold a surfboard?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='male')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='surfboard')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6722, "imageId": "n433692", "question": "What kind of device is the same color as the tall lamp?", "program": "BOX0=LOC(image=IMAGE,object='tall lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tall lamp?')\nBOX1=LOC(image=IMAGE,object=ANSWER0)\nANSWER1=VQA(image=IMAGE,question='What kind of device is the same color as the tall lamp?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6723, "imageId": "n199758", "question": "Do the shoes that are not uncomfortable have black color?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Are the shoes uncomfortable?')\nANSWER1=VQA(image=IMAGE0,question='What color are the shoes?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6724, "imageId": "n95904", "question": "What does the person near the wall hold?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What does the person hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6725, "imageId": "n95904", "question": "What does the person hold?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the person hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6726, "imageId": "n187961", "question": "Are the clouds high or low?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the clouds high or low?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6727, "imageId": "n498140", "question": "Does the sign have the same color as the grill?", "program": "BOX0=LOC(image=IMAGE,object='grill')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the grill?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sign?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6728, "imageId": "n347706", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6729, "imageId": "n347706", "question": "Who is wearing the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6730, "imageId": "n498140", "question": "Do the building and the sign have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the building?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sign?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6731, "imageId": "n546884", "question": "Is the doughnut round and brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What shape is the doughnut?')\nANSWER1=VQA(image=IMAGE,question='What color is the doughnut?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6732, "imageId": "n498140", "question": "What is common to the streetlight and the grill?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the streetlight and the grill?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6733, "imageId": "n344136", "question": "What kind of furniture is made of wood?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6734, "imageId": "n437064", "question": "Is the white bowl on the left or on the right side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white bowl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6735, "imageId": "n412144", "question": "Do you see pictures or fences?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6736, "imageId": "n513429", "question": "What is the device that is to the right of the bowl that is behind the bottle?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nANSWER0=VQA(image=IMAGE1,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6737, "imageId": "n280089", "question": "What is the ceramic pot sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='ceramic pot')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='object')\nANSWER0=VQA(image=IMAGE0,question='What is the ceramic pot sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6738, "imageId": "n155555", "question": "Do the mountains that are dark look snowy?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the mountains that are dark look snowy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6739, "imageId": "n125122", "question": "Is the red pillow to the left of the made bed that is in front of the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='made bed')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='red pillow')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6740, "imageId": "n500209", "question": "Which kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6741, "imageId": "n500209", "question": "What is the name of this piece of furniture?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the name of this piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6742, "imageId": "n500209", "question": "Is there either any mirror or desk in the image?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nBOX1=LOC(image=IMAGE,object='desk')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6743, "imageId": "n554880", "question": "Is the young woman to the left of the chair made of wood?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the young woman made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6744, "imageId": "n16378", "question": "What's the woman using?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6745, "imageId": "n28572", "question": "Does the table have brown color and square shape?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6746, "imageId": "n546616", "question": "Does the marshmallow that is to the left of the baby look white and soft?", "program": "BOX0=LOC(image=IMAGE,object='baby')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='marshmallow')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the marshmallow?')\nANSWER1=VQA(image=IMAGE1,question='Is the marshmallow soft?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6747, "imageId": "n162108", "question": "What color is the cabinet made of wood?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cabinet?')\nANSWER1=EVAL(expr=\"'wood' if {ANSWER0} == 'brown' else 'not wood'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6748, "imageId": "n554880", "question": "What is the person to the left of the chair sitting atop?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person sitting atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6749, "imageId": "n410476", "question": "What kind of animal is grazing on the plain?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of animal is grazing on the plain?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6750, "imageId": "n77818", "question": "Do the speaker and the DVD player have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='speaker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='DVD player')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the speaker?')\nANSWER1=VQA(image=IMAGE1,question='What color is the DVD player?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6751, "imageId": "n525029", "question": "On which side of the picture is the white car?", "program": "BOX0=LOC(image=IMAGE,object='white car')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6752, "imageId": "n527290", "question": "Who is standing on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6753, "imageId": "n141939", "question": "Does the appliance under the sink have long length?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6754, "imageId": "n522733", "question": "Does the traffic signal to the left of the signal light look metallic and high?", "program": "BOX0=LOC(image=IMAGE,object='signal light')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic signal')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What does the traffic signal look like?')\nANSWER3=VQA(image=IMAGE0,question='How high is the traffic signal?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'metallic' and {ANSWER3} == 'high' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6755, "imageId": "n200907", "question": "Is the tennis racket to the right or to the left of the person that is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='person wearing shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tennis racket')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6756, "imageId": "n88366", "question": "Who is wearing the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6757, "imageId": "n441859", "question": "Is the surf board to the right of the person who is wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='person wearing hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surf board')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6758, "imageId": "n97485", "question": "On which side of the image is the clean oven, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='clean oven')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6759, "imageId": "n314171", "question": "How big is the room?", "program": "ANSWER0=VQA(image=IMAGE,question='How big is the room?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6760, "imageId": "n573460", "question": "Who is in front of the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6761, "imageId": "n315887", "question": "Which kind of device is behind the phone?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is behind the phone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6762, "imageId": "n326988", "question": "What is the name of the pieces of furniture behind the person in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the name of the pieces of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6763, "imageId": "n159802", "question": "What do you think is the person to the left of the hair clip wearing?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6764, "imageId": "n315887", "question": "Is the computer to the left or to the right of the device in the middle?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='computer')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6765, "imageId": "n145498", "question": "What is the person sleeping on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person sleeping on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6766, "imageId": "n4777", "question": "Is the stuffed toy hanging from the stroller?", "program": "BOX0=LOC(image=IMAGE,object='stroller')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stuffed toy')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6767, "imageId": "n326988", "question": "Do you see flowers behind the person on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='flowers')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6768, "imageId": "n137182", "question": "Are the trees in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6769, "imageId": "n363445", "question": "Are there either clean plates or forks?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='fork')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6770, "imageId": "n146555", "question": "Is the bottle made of the same material as the post?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='post')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the bottle made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the post made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6771, "imageId": "n546616", "question": "Does the chocolate dessert look round and green?", "program": "ANSWER0=VQA(image=IMAGE,question='What does the chocolate dessert look like?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'round and green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6772, "imageId": "n159802", "question": "Is the woman to the left or to the right of the small device?", "program": "BOX0=LOC(image=IMAGE,object='small device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6773, "imageId": "n200225", "question": "Is the spinach on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='spinach')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6774, "imageId": "n170941", "question": "Is the white coffee mug on the left side?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white coffee mug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6775, "imageId": "n95904", "question": "Does the person near the wall look male?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6776, "imageId": "n570181", "question": "Who in the picture is waiting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6777, "imageId": "n450919", "question": "Is the fur colorful and smooth?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the fur colorful?')\nANSWER1=VQA(image=IMAGE,question='Is the fur smooth?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6778, "imageId": "n570181", "question": "What is the catcher doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the catcher doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6779, "imageId": "n513429", "question": "Is there a laptop near the plastic device?", "program": "BOX0=LOC(image=IMAGE,object='plastic device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6780, "imageId": "n566028", "question": "Is the building behind a bench?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='building')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6781, "imageId": "n315887", "question": "What is the device above the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6782, "imageId": "n86120", "question": "Do the jeans look blue and short?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the jeans?')\nANSWER1=VQA(image=IMAGE,question='What length are the jeans?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6783, "imageId": "n381072", "question": "Which color is the wide table?", "program": "BOX0=LOC(image=IMAGE,object='wide table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the wide table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6784, "imageId": "n249639", "question": "What is on the white wall?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the white wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6785, "imageId": "n119886", "question": "On which side of the photo is the mirror, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6786, "imageId": "n381072", "question": "Are there either lamps or tables that are not white?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6787, "imageId": "n167164", "question": "What color is the SUV below the traffic light?", "program": "BOX0=LOC(image=IMAGE,object='traffic light')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='SUV')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the SUV?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6788, "imageId": "n37274", "question": "Is the man that is to the left of the crate wearing a watch?", "program": "BOX0=LOC(image=IMAGE,object='crate')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the man wearing a watch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6789, "imageId": "n23181", "question": "Are the sheets on the right side or on the left of the image?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sheets')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6790, "imageId": "n471866", "question": "Does the policeman to the right of the man appear to be standing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='policeman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6791, "imageId": "n511913", "question": "What device is the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6792, "imageId": "n141939", "question": "Is the sink made of chrome?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the sink made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'chrome' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6793, "imageId": "n207708", "question": "Are there any stoves or microwaves?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nBOX1=LOC(image=IMAGE,object='microwave')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6794, "imageId": "n240666", "question": "Is the faucet on the left?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nANSWER0=EVAL(expr=\"'yes' if {BOX0[0]} < 0.5 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6795, "imageId": "n511913", "question": "What is the man in front of the table holding?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6796, "imageId": "n511913", "question": "What device do you think is the old man holding?", "program": "ANSWER0=VQA(image=IMAGE,question='What device is the old man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6797, "imageId": "n511913", "question": "What's the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6798, "imageId": "n386688", "question": "What is in front of the beautiful trees?", "program": "BOX0=LOC(image=IMAGE,object='beautiful trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the beautiful trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6799, "imageId": "n219840", "question": "What is the beautiful animal?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the beautiful animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6800, "imageId": "n16378", "question": "Is the happy person waiting or looking down?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person waiting or looking down?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6801, "imageId": "n317260", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6802, "imageId": "n470920", "question": "Are there any women to the right of the glasses that the man is wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glasses')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='woman')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6803, "imageId": "n532213", "question": "Is there a street sign that is not made of wood?", "program": "BOX0=LOC(image=IMAGE,object='street sign')\nANSWER0=VQA(image=IMAGE,question='What material is the street sign made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6804, "imageId": "n532213", "question": "What is the color of the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6805, "imageId": "n200692", "question": "Is the stove that is to the right of the orange small and white?", "program": "BOX0=LOC(image=IMAGE,object='orange')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='stove')\nANSWER0=VQA(image=IMAGE0,question='Is the stove small and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6806, "imageId": "n275148", "question": "Which kind of furniture is not wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} == 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6807, "imageId": "n275148", "question": "Which kind of furniture is wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6808, "imageId": "n275148", "question": "Which kind of furniture is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6809, "imageId": "n528403", "question": "What is the color of the small shirt?", "program": "BOX0=LOC(image=IMAGE,object='small shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the small shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6810, "imageId": "n274905", "question": "Does the hat that is not closed look Adidas?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not closed')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the hat look Adidas?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6811, "imageId": "n281241", "question": "On which side of the picture is the happy gentleman?", "program": "BOX0=LOC(image=IMAGE,object='happy gentleman')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6812, "imageId": "n232810", "question": "Is the color of this rug tan?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the rug?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'tan' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6813, "imageId": "n208458", "question": "The canopy is standing where?", "program": "BOX0=LOC(image=IMAGE,object='canopy')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6814, "imageId": "n208458", "question": "Where is the canopy standing on?", "program": "BOX0=LOC(image=IMAGE,object='canopy')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ground')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'ground' if {ANSWER0} > 0 else 'other'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6815, "imageId": "n274905", "question": "Does the hat that looks black and white look closed and Adidas?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER1=VQA(image=IMAGE0,question='Is the hat closed?')\nANSWER2=VQA(image=IMAGE0,question='What brand is the hat?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'black and white' and {ANSWER1} == 'yes' and {ANSWER2} == 'Adidas' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6816, "imageId": "n278453", "question": "Does the ring look black and round?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the ring?')\nANSWER1=VQA(image=IMAGE,question='What shape is the ring?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6817, "imageId": "n280089", "question": "What is leaning against the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is leaning against the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6818, "imageId": "n355339", "question": "Which kind of device is the man watching?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of device is the man watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6819, "imageId": "n280089", "question": "What is leaning against the wall the stove is sitting in front of?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wall')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is leaning against the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6820, "imageId": "n520071", "question": "Does the metal lamp have black color?", "program": "BOX0=LOC(image=IMAGE,object='metal lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the metal lamp?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6821, "imageId": "n49438", "question": "How long is the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nANSWER0=VQA(image=IMAGE,question='How long is the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6822, "imageId": "n381072", "question": "On which side is the knife?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6823, "imageId": "n312206", "question": "Which kind of baked good is the woman behind of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of baked good is the woman behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6824, "imageId": "n312206", "question": "What is the food that the woman is behind of called?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the food called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6825, "imageId": "n23762", "question": "Is the plate different in color than the mug?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='mug')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the plate?')\nANSWER1=VQA(image=IMAGE1,question='What color is the mug?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6826, "imageId": "n260521", "question": "Is stone used to make the statue?", "program": "ANSWER0=VQA(image=IMAGE,question='Is stone used to make the statue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6827, "imageId": "n23762", "question": "Is the chair made of the same material as the table?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the chair made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6828, "imageId": "n67005", "question": "What is the size of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nANSWER0=VQA(image=IMAGE,question='What is the size of the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6829, "imageId": "n24526", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6830, "imageId": "n572716", "question": "Does the grass look brown?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the grass?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6831, "imageId": "n145498", "question": "What color is the pillow?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nANSWER0=VQA(image=IMAGE,question='What color is the pillow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6832, "imageId": "n525901", "question": "What kind of device is on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6833, "imageId": "n579928", "question": "Is there any tall grass or snow?", "program": "BOX0=LOC(image=IMAGE,object='tall grass')\nBOX1=LOC(image=IMAGE,object='snow')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6834, "imageId": "n527589", "question": "What's the woman doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the woman doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6835, "imageId": "n527589", "question": "What is the Caucasian woman doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the Caucasian woman doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6836, "imageId": "n480253", "question": "Do the green trees look full and tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the green trees look full and tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6837, "imageId": "n485969", "question": "Do the pants look clean or dirty?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the pants look clean or dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6838, "imageId": "n469156", "question": "How long is the skateboard to the right of the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How long is the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6839, "imageId": "n62458", "question": "What is the seat on?", "program": "BOX0=LOC(image=IMAGE,object='seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the seat on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6840, "imageId": "n489190", "question": "What color is the skatepark?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the skatepark?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6841, "imageId": "n511881", "question": "What is the weather like, rainy or overcast?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the weather like?')\nANSWER1=EVAL(expr=\"'rainy' if {ANSWER0} == 'rainy' else 'overcast'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6842, "imageId": "n234722", "question": "What food is warm?", "program": "ANSWER0=VQA(image=IMAGE,question='What food is warm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6843, "imageId": "n97485", "question": "What is inside the utensil holder?", "program": "BOX0=LOC(image=IMAGE,object='utensil holder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the utensil holder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6844, "imageId": "n477702", "question": "What kind of furniture is the happy man sitting on, a sofa or a coffee table?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sofa')\nBOX2=LOC(image=IMAGE0,object='coffee table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'sofa' if {ANSWER0} > 0 else 'coffee table'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6845, "imageId": "n477702", "question": "What is the happy man sitting on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6846, "imageId": "n259949", "question": "Do you see any green skateboards or bicycles?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nBOX1=LOC(image=IMAGE,object='bicycle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6847, "imageId": "n234722", "question": "Which kind of food is not warm?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is not warm?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6848, "imageId": "n475030", "question": "Is the beach sandy or snowy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the beach sandy or snowy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6849, "imageId": "n526228", "question": "Is the clean shirt both green and short sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE,question='What type of sleeves does the shirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'short sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6850, "imageId": "n97485", "question": "Are the utensils inside the utensil holder clean or dirty?", "program": "BOX0=LOC(image=IMAGE,object='utensil holder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensils')\nANSWER0=VQA(image=IMAGE0,question='Are the utensils clean or dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6851, "imageId": "n540852", "question": "What is the umbrella to the right of the other umbrella made of?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC_RIGHTOF(image=IMAGE0,object='umbrella')\nANSWER0=VQA(image=IMAGE0,question='What is the umbrella made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6852, "imageId": "n94074", "question": "Does the woman to the left of the man seem to be walking?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=VQA(image=IMAGE0,question='Does the woman seem to be walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6853, "imageId": "n214497", "question": "What is higher than the cars?", "program": "BOX0=LOC(image=IMAGE,object='cars')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is higher than the cars?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6854, "imageId": "n546616", "question": "Does the marker look gray or red?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the marker look like?')\nANSWER1=EVAL(expr=\"'gray' if {ANSWER0} == 'gray' else 'red'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6855, "imageId": "n238266", "question": "What is the dessert that the candle is on?", "program": "BOX0=LOC(image=IMAGE,object='candle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the dessert?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6856, "imageId": "n574498", "question": "What is the pattern of the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pattern of the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6857, "imageId": "n184551", "question": "What do you think is the color of the jacket?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is the color of the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6858, "imageId": "n272313", "question": "Does the shirt look sleeveless or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look sleeveless or short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6859, "imageId": "n184551", "question": "Does the jacket have gray color and long length?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE0,question='What is the length of the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6860, "imageId": "n210269", "question": "Is the fence in the top or in the bottom of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6861, "imageId": "n317189", "question": "What color is the jacket near the gloves?", "program": "BOX0=LOC(image=IMAGE,object='gloves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='jacket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6862, "imageId": "n229548", "question": "Are the clouds large and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the clouds large?')\nANSWER1=VQA(image=IMAGE,question='What color are the clouds?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6863, "imageId": "n64959", "question": "Are there stoves near the freezer to the right of the tap?", "program": "BOX0=LOC(image=IMAGE,object='tap')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='freezer')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='stoves')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6864, "imageId": "n206358", "question": "Is the large vehicle in the bottom part or in the top of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6865, "imageId": "n572716", "question": "Are there airplanes behind the long runway?", "program": "BOX0=LOC(image=IMAGE,object='long runway')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='airplanes')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6866, "imageId": "n240973", "question": "The newspaper is of what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the newspaper?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6867, "imageId": "n6309", "question": "Is the vehicle to the right of the horse both new and white?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the vehicle?')\nANSWER3=VQA(image=IMAGE0,question='Is the vehicle new?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'white' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 6868, "imageId": "n556604", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6869, "imageId": "n289376", "question": "Is the sky both cloudy and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sky cloudy?')\nANSWER1=VQA(image=IMAGE,question='What color is the sky?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6870, "imageId": "n450919", "question": "Are there any rugs or fences in the picture?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6871, "imageId": "n209843", "question": "What is on the wall?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6872, "imageId": "n140421", "question": "What is the color of the soap bottle?", "program": "BOX0=LOC(image=IMAGE,object='soap bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the soap bottle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6873, "imageId": "n526228", "question": "What device is on top of the side table?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is on top of the side table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6874, "imageId": "n526228", "question": "What is located on top of the side table?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is located on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6875, "imageId": "n240666", "question": "What is in front of the trash can?", "program": "BOX0=LOC(image=IMAGE,object='trash can')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the trash can?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6876, "imageId": "n508641", "question": "What's the umpire doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the umpire doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6877, "imageId": "n240666", "question": "What is in front of the sink that is below the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sink')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='in front')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6878, "imageId": "n240666", "question": "What's in front of the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6879, "imageId": "n240666", "question": "Are there mats in front of the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6880, "imageId": "n192021", "question": "Does the pillow that looks rectangular look red?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the pillow?')\nANSWER1=VQA(image=IMAGE0,question='What color is the pillow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rectangular' and {ANSWER1} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6881, "imageId": "n192021", "question": "What shape is the pillow on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillow')\nANSWER0=VQA(image=IMAGE0,question='What shape is the pillow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6882, "imageId": "n100991", "question": "What is common to the tray and the cup?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the tray and the cup?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6883, "imageId": "n65202", "question": "Do you see any skateboarders or boys that are skating?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nBOX1=LOC(image=IMAGE,object='boy')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6884, "imageId": "n264887", "question": "What device is behind the mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is behind the mouse pad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6885, "imageId": "n260521", "question": "Is the car thin and dark?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the car thin and dark?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6886, "imageId": "n429961", "question": "Which kind of vegetable is round?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of vegetable is round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6887, "imageId": "n429961", "question": "Which type of vegetable is not round, the broccoli or the cauliflower?", "program": "ANSWER0=VQA(image=IMAGE,question='Which type of vegetable is not round, the broccoli or the cauliflower?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6888, "imageId": "n65230", "question": "Is it an indoors or outdoors scene?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an indoors or outdoors scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6889, "imageId": "n433532", "question": "Do you think the robe is long?", "program": "BOX0=LOC(image=IMAGE,object='robe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do you think the robe is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6890, "imageId": "n65230", "question": "Is the bathroom clean?", "program": "BOX0=LOC(image=IMAGE,object='bathroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the bathroom clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6891, "imageId": "n153118", "question": "Do the pole and the traffic signal have the same color?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='traffic signal')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the pole?')\nANSWER1=VQA(image=IMAGE1,question='What color is the traffic signal?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6892, "imageId": "n514467", "question": "Is the Caucasian person male and happy?", "program": "BOX0=LOC(image=IMAGE,object='Caucasian person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person male?')\nANSWER1=VQA(image=IMAGE0,question='Is the person happy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6893, "imageId": "n95369", "question": "Is the bathroom full or empty?", "program": "BOX0=LOC(image=IMAGE,object='bathroom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'full' if {ANSWER0} > 0 else 'empty'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6894, "imageId": "n336443", "question": "What is the food that is to the right of the utensil on the left of the photo?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nANSWER0=VQA(image=IMAGE1,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6895, "imageId": "n222915", "question": "What kind of food is not leafy?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food is not leafy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6896, "imageId": "n485969", "question": "Is the baseball both heavy and dense?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the baseball heavy?')\nANSWER1=VQA(image=IMAGE,question='Is the baseball dense?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6897, "imageId": "n264887", "question": "What device is on the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is on the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6898, "imageId": "n485969", "question": "Is paper used to make the hat that looks white and red?", "program": "ANSWER0=VQA(image=IMAGE,question='Is paper used to make the hat that looks white and red?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6899, "imageId": "n485969", "question": "What color is the hat the pitcher is wearing?", "program": "BOX0=LOC(image=IMAGE,object='pitcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6900, "imageId": "n290409", "question": "What are the trees behind of, a truck or a train?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'truck' if {ANSWER0} > 0 else 'train'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6901, "imageId": "n222915", "question": "What kind of food is leafy?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food is leafy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6902, "imageId": "n263180", "question": "On which side is the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6903, "imageId": "n69237", "question": "What item of furniture is modern?", "program": "BOX0=LOC(image=IMAGE,object='modern')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is modern?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6904, "imageId": "n263180", "question": "What color is the vehicle in front of the apartment building?", "program": "BOX0=LOC(image=IMAGE,object='apartment building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6905, "imageId": "n184385", "question": "Which kind of appliance is not metallic, the oven or the stove?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='stove')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the oven made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the stove made of?')\nANSWER2=EVAL(expr=\"'oven' if {ANSWER0} != 'metallic' else 'stove'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6906, "imageId": "n184385", "question": "What kind of appliance is not metallic?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nANSWER0=VQA(image=IMAGE,question='What kind of appliance is not metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6907, "imageId": "n4777", "question": "Are there any paper cups or napkins?", "program": "BOX0=LOC(image=IMAGE,object='paper cup')\nBOX1=LOC(image=IMAGE,object='napkin')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6908, "imageId": "n70461", "question": "What vehicle does the building stand beside of?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle does the building stand beside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6909, "imageId": "n184385", "question": "Which kind of appliance isn't white?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nANSWER0=VQA(image=IMAGE,question='Which kind of appliance isn\\'t white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6910, "imageId": "n305495", "question": "Does the window behind the fan look large and closed?", "program": "BOX0=LOC(image=IMAGE,object='fan')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nANSWER0=VQA(image=IMAGE0,question='Does the window look large and closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6911, "imageId": "n187961", "question": "The trees are in front of what?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The trees are in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6912, "imageId": "n403734", "question": "On which side is the cloth bag?", "program": "BOX0=LOC(image=IMAGE,object='cloth bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6913, "imageId": "n25275", "question": "The trash bin on the beach is of which color?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trash bin')\nANSWER0=VQA(image=IMAGE0,question='What color is the trash bin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6914, "imageId": "n514467", "question": "Is there any tan coat in this scene?", "program": "BOX0=LOC(image=IMAGE,object='tan coat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6915, "imageId": "n313060", "question": "Who is this purse in front of?", "program": "BOX0=LOC(image=IMAGE,object='purse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is this purse in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6916, "imageId": "n187961", "question": "What are the trees before?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the trees before?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6917, "imageId": "n410289", "question": "Are there light bulbs on the white ceiling?", "program": "BOX0=LOC(image=IMAGE,object='ceiling')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light bulbs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6918, "imageId": "n410289", "question": "What is on the ceiling?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the ceiling?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6919, "imageId": "n59676", "question": "What kind of cooking utensil is the pizza on?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of cooking utensil is the pizza on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6920, "imageId": "n199097", "question": "Does the street sign have the same color as the vehicle?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='street sign')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nANSWER1=VQA(image=IMAGE1,question='What color is the street sign?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6921, "imageId": "n117888", "question": "Do you see balls or fences there?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6922, "imageId": "n511913", "question": "Do you see both a chair and a table?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6923, "imageId": "n116329", "question": "What is the man in front of the door doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man in front of the door doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6924, "imageId": "n116329", "question": "On which side of the photo is the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6925, "imageId": "n554880", "question": "What is the blue clothing item called?", "program": "BOX0=LOC(image=IMAGE,object='blue clothing item')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the blue clothing item called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6926, "imageId": "n52544", "question": "What kind of clothing is black?", "program": "BOX0=LOC(image=IMAGE,object='black clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6927, "imageId": "n52544", "question": "What kind of clothing is black?", "program": "BOX0=LOC(image=IMAGE,object='black clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6928, "imageId": "n52544", "question": "What kind of clothing is colorful?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6929, "imageId": "n52544", "question": "Is that blouse green and long sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the blouse?')\nANSWER1=VQA(image=IMAGE,question='What type of sleeves does the blouse have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6930, "imageId": "n318370", "question": "Are the glasses on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glasses')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6931, "imageId": "n162586", "question": "On which side of the photo is the television?", "program": "BOX0=LOC(image=IMAGE,object='television')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6932, "imageId": "n431447", "question": "Who is resting?", "program": "BOX0=LOC(image=IMAGE,object='resting')\nANSWER0=VQA(image=IMAGE,question='Who is resting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6933, "imageId": "n194179", "question": "What is the person to the right of the chair doing?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6934, "imageId": "n126087", "question": "Does the shirt seem to be long sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the shirt seem to be long sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6935, "imageId": "n250715", "question": "Do you see words that are small?", "program": "BOX0=LOC(image=IMAGE,object='words')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6936, "imageId": "n232810", "question": "Is it indoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it indoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6937, "imageId": "n431447", "question": "What is the boy doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the boy doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6938, "imageId": "n431447", "question": "What is that boy doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is that boy doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6939, "imageId": "n90294", "question": "Do you see calculators that are not made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='calculator')\nANSWER0=VQA(image=IMAGE,question='What material is the calculator made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6940, "imageId": "n90294", "question": "What is the device to the right of the device that is next to the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6941, "imageId": "n179136", "question": "Does the green water look still and murky?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the green water look still and murky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6942, "imageId": "n309148", "question": "What kind of vehicle is below the flag?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is below the flag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6943, "imageId": "n90294", "question": "Is the keyboard on the left side?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nANSWER0=EVAL(expr=\"'yes' if {BOX0}.x < IMAGE.width/2 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6944, "imageId": "n148872", "question": "Does the shirt that looks white and blue look short sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the shirt that looks white and blue look short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6945, "imageId": "n90294", "question": "Are there any calculators to the right of the device next to the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='calculators')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6946, "imageId": "n179136", "question": "Does the water that looks green look clear?", "program": "BOX0=LOC(image=IMAGE,object='green water')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the water look clear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6947, "imageId": "n518912", "question": "Is the chair which is to the left of the cups gold or black?", "program": "BOX0=LOC(image=IMAGE,object='cups')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'gold' if {ANSWER0} == 'gold' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6948, "imageId": "n435808", "question": "What is the color of the router that looks rectangular?", "program": "BOX0=LOC(image=IMAGE,object='router')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the router?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6949, "imageId": "n480253", "question": "What is in front of the green trees?", "program": "BOX0=LOC(image=IMAGE,object='green trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the green trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6950, "imageId": "n480253", "question": "Does the barn seem to be snowy?", "program": "BOX0=LOC(image=IMAGE,object='barn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the barn seem to be snowy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6951, "imageId": "n548534", "question": "Is the fridge to the left of a drawer?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fridge')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6952, "imageId": "n137182", "question": "Who is wearing the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6953, "imageId": "n137182", "question": "Is the girl in front of the trees holding a racket?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='racket')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6954, "imageId": "n480253", "question": "The barn is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='barn')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The barn is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6955, "imageId": "n296467", "question": "Do you think this rice is black and white?", "program": "BOX0=LOC(image=IMAGE,object='rice')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the rice?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6956, "imageId": "n479092", "question": "Are the forks silver and hard?", "program": "BOX0=LOC(image=IMAGE,object='forks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the forks?')\nANSWER1=VQA(image=IMAGE0,question='What texture are the forks?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'hard' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6957, "imageId": "n571179", "question": "Does the man appear to be surfing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the man appear to be surfing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6958, "imageId": "n145498", "question": "Is the bench next to the bed long and beige?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='long')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='beige')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 6959, "imageId": "n97485", "question": "Does the basket below the other basket look large and tan?", "program": "BOX0=LOC(image=IMAGE,object='basket')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='basket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the basket?')\nANSWER1=VQA(image=IMAGE1,question='Is the basket large?')\nANSWER2=VQA(image=IMAGE1,question='Is the basket tan?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'tan' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 6960, "imageId": "n413319", "question": "Is the male person wearing a uniform?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person wearing a uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6961, "imageId": "n433532", "question": "What material is the utensil that looks big made of?", "program": "BOX0=LOC(image=IMAGE,object='big utensil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the utensil made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6962, "imageId": "n413319", "question": "Who is wearing the shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6963, "imageId": "n235859", "question": "Is the dress that is not small sleeveless or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='dress')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the dress sleeveless?')\nANSWER1=VQA(image=IMAGE0,question='Is the dress short sleeved?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' or {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6964, "imageId": "n546616", "question": "Is that cup sitting on top of a nightstand?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='nightstand')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6965, "imageId": "n16936", "question": "Who wears trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6966, "imageId": "n16936", "question": "Who wears the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6967, "imageId": "n531731", "question": "Is the bench wooden and gray?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the bench made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the bench?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wooden' and {ANSWER1} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6968, "imageId": "n262920", "question": "Is the black bag in the top part of the picture?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6969, "imageId": "n6309", "question": "Do you see a horse behind the fence made of metal?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6970, "imageId": "n6309", "question": "Which kind of animal is behind the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is behind the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6971, "imageId": "n480253", "question": "Is the barn blue and snowy?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the barn?')\nANSWER1=VQA(image=IMAGE,question='Is it snowy?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6972, "imageId": "n162148", "question": "Is there a woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6973, "imageId": "n480253", "question": "What color is the barn in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='barn')\nANSWER0=VQA(image=IMAGE0,question='What color is the barn?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6974, "imageId": "n570181", "question": "Who is wearing the uniform?", "program": "BOX0=LOC(image=IMAGE,object='uniform')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6975, "imageId": "n570181", "question": "Who is wearing a uniform?", "program": "BOX0=LOC(image=IMAGE,object='uniform')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6976, "imageId": "n279581", "question": "Is the color of the net the same as the home plate?", "program": "BOX0=LOC(image=IMAGE,object='home plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='net')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the home plate?')\nANSWER1=VQA(image=IMAGE1,question='What color is the net?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6977, "imageId": "n279581", "question": "Is the color of the shirt different than the net?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='net')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the net?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6978, "imageId": "n35676", "question": "What are the pieces of furniture that are to the left of the cabinets on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabinets')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What are the pieces of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6979, "imageId": "n525901", "question": "What is beneath the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is beneath the laptop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6980, "imageId": "n278312", "question": "On which side is the toaster?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6981, "imageId": "n88933", "question": "Do you see a plate to the left of the boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6982, "imageId": "n296467", "question": "What dessert is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What dessert is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6983, "imageId": "n16378", "question": "Who is walking behind the person that is to the right of the safety vest?", "program": "BOX0=LOC(image=IMAGE,object='safety vest')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who is walking behind?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6984, "imageId": "n449058", "question": "What color is the motorbike the person is riding?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorbike')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the motorbike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6985, "imageId": "n486200", "question": "Does the traffic sign in the street have small size?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic sign')\nANSWER0=VQA(image=IMAGE0,question='What is the size of the traffic sign?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6986, "imageId": "n531359", "question": "What is the color of the flower?", "program": "BOX0=LOC(image=IMAGE,object='flower')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the flower?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6987, "imageId": "n65885", "question": "What's mounted on the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is mounted on the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6988, "imageId": "n65885", "question": "What is mounted on the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is mounted on the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6989, "imageId": "n65885", "question": "Which kind of furniture is mounted on the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is mounted on the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6990, "imageId": "n65885", "question": "What are the pieces of furniture that are mounted on the beige wall?", "program": "BOX0=LOC(image=IMAGE,object='beige wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the pieces of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6991, "imageId": "n95904", "question": "Is the ground orange or gray?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the ground?')\nANSWER1=EVAL(expr=\"'orange' if {ANSWER0} == 'orange' else 'gray'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6992, "imageId": "n250715", "question": "Which kind of clothing is gray?", "program": "BOX0=LOC(image=IMAGE,object='gray clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6993, "imageId": "n37274", "question": "Is the blender in front of the man sitting atop a crate?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='crate')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='blender')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6994, "imageId": "n207708", "question": "Are there bookcases in the image?", "program": "BOX0=LOC(image=IMAGE,object='bookcases')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6995, "imageId": "n250715", "question": "What is the name of the clothing item that is long sleeved?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved')\nANSWER0=VQA(image=IMAGE,question='What is the name of the clothing item?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6996, "imageId": "n95904", "question": "Do the pants look dark and long?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the pants look dark?')\nANSWER1=VQA(image=IMAGE,question='Do the pants look long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 6997, "imageId": "n315887", "question": "Is the large monitor to the right or to the left of the white thing that is on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white thing')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='large monitor')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 6998, "imageId": "n12404", "question": "What's the sidewalk made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sidewalk made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 6999, "imageId": "n51658", "question": "Are there any rackets that are red?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the racket?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7000, "imageId": "n51658", "question": "Is the racket on the left?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='racket')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7001, "imageId": "n90944", "question": "Is the wet suit comfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the wet suit comfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7002, "imageId": "n355339", "question": "Which kind of device is the screen in front of?", "program": "BOX0=LOC(image=IMAGE,object='screen')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is the screen in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7003, "imageId": "n355339", "question": "What is the screen in front of?", "program": "BOX0=LOC(image=IMAGE,object='screen')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the screen in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7004, "imageId": "n94074", "question": "Does the necktie have a different color than the suit?", "program": "BOX0=LOC(image=IMAGE,object='necktie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='suit')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the necktie?')\nANSWER1=VQA(image=IMAGE1,question='What color is the suit?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7005, "imageId": "n117888", "question": "What color does the fence that is in front of the bench have?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=VQA(image=IMAGE0,question='What color is the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7006, "imageId": "n326988", "question": "On which side of the photo is the adult woman?", "program": "BOX0=LOC(image=IMAGE,object='adult woman')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7007, "imageId": "n485969", "question": "Is the field both brown and grassy?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the field?')\nANSWER1=VQA(image=IMAGE,question='What is the texture of the field?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'grassy' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7008, "imageId": "n37274", "question": "Which side of the image is the cup on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cup')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7009, "imageId": "n229548", "question": "Is it outdoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it outdoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7010, "imageId": "n141939", "question": "Which type of material is the counter top that looks brown made of?", "program": "BOX0=LOC(image=IMAGE,object='brown counter top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which type of material is the counter top made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7011, "imageId": "n229548", "question": "Which kind of aircraft is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of aircraft is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7012, "imageId": "n417401", "question": "Is the sink in front of a mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_FRONTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sink')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7013, "imageId": "n229548", "question": "Which kind of aircraft is large?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of aircraft is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7014, "imageId": "n229548", "question": "What kind of aircraft is large?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of aircraft is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7015, "imageId": "n309148", "question": "Is the young person behind the fire truck?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7016, "imageId": "n12404", "question": "Are both the machine and the container made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='machine')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='container')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the machine made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the container made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7017, "imageId": "n166008", "question": "Is there any fork next to the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fork')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7018, "imageId": "n380113", "question": "Who is wearing the headband?", "program": "BOX0=LOC(image=IMAGE,object='headband')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the headband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7019, "imageId": "n146555", "question": "Does that crowd look abundant?", "program": "ANSWER0=VQA(image=IMAGE,question='Does that crowd look abundant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7020, "imageId": "n314630", "question": "How large is the container beside the knives?", "program": "BOX0=LOC(image=IMAGE,object='knives')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='container')\nANSWER0=VQA(image=IMAGE0,question='How large is the container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7021, "imageId": "n382416", "question": "What height is the person that is to the left of the suitcase?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='What height is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7022, "imageId": "n204894", "question": "Is the white chair to the right or to the left of the device the person is talking on?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='white chair')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7023, "imageId": "n95369", "question": "Does the ring that looks round look gold?", "program": "BOX0=LOC(image=IMAGE,object='ring')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the ring look like?')\nANSWER1=VQA(image=IMAGE0,question='What color is the ring?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'round' and {ANSWER1} == 'gold' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7024, "imageId": "n310625", "question": "What is the color of the toothbrush to the left of the other toothbrush?", "program": "BOX0=LOC(image=IMAGE,object='toothbrush')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toothbrush')\nANSWER0=VQA(image=IMAGE0,question='What is the color of the toothbrush?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7025, "imageId": "n373692", "question": "Who is walking?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7026, "imageId": "n283587", "question": "What item of furniture is the coffee table in front of?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is the coffee table in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7027, "imageId": "n494677", "question": "What size are the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nANSWER0=VQA(image=IMAGE,question='What size are the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7028, "imageId": "n100991", "question": "What kind of food is on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of food is on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7029, "imageId": "n100991", "question": "What kind of food is on top of the round plate?", "program": "BOX0=LOC(image=IMAGE,object='round plate')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What kind of food is on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7030, "imageId": "n283587", "question": "Which kind of furniture is in front of the sofa?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which kind of furniture is in front of the sofa?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7031, "imageId": "n100552", "question": "What is the fence made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7032, "imageId": "n259002", "question": "What is the vehicle to the left of the soccer player on the right?", "program": "BOX0=LOC(image=IMAGE,object='soccer player')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7033, "imageId": "n259002", "question": "What do you think is the vehicle that is to the right of the person that is watching the soccer player?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soccer player')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=VQA(image=IMAGE1,question='What do you think is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7034, "imageId": "n324908", "question": "What color does the shirt above the pants have?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shirt')\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7035, "imageId": "n324908", "question": "Is the shirt black and white or colorful?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'black and white' if {ANSWER0} == 'black' or {ANSWER0} == 'white' else 'colorful'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7036, "imageId": "n310828", "question": "Does the shirt look sleeveless?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the shirt look sleeveless?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7037, "imageId": "n557666", "question": "What type of vehicle is to the left of the person that is to the left of the mirror?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=VQA(image=IMAGE1,question='What type of vehicle is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7038, "imageId": "n200225", "question": "Is the cheese on a bread?", "program": "BOX0=LOC(image=IMAGE,object='cheese')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bread')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7039, "imageId": "n206785", "question": "What is the person pulling?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person pulling?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7040, "imageId": "n411121", "question": "Is there a motorcycle or a helmet in the image?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nBOX1=LOC(image=IMAGE,object='helmet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7041, "imageId": "n557666", "question": "On which side of the photo is the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7042, "imageId": "n153118", "question": "Are the buildings made of brick old fashioned or modern?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the buildings made of brick?')\nANSWER1=VQA(image=IMAGE,question='Are the buildings old fashioned?')\nANSWER2=VQA(image=IMAGE,question='Are the buildings modern?')\nANSWER3=EVAL(expr=\"'old fashioned' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'modern'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 7043, "imageId": "n238266", "question": "What is the item of furniture that the cookies are on?", "program": "BOX0=LOC(image=IMAGE,object='cookies')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7044, "imageId": "n48494", "question": "Do you see any wide boat?", "program": "BOX0=LOC(image=IMAGE,object='boat')\nANSWER0=VQA(image=IMAGE,question='Do you see any wide boat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7045, "imageId": "n283587", "question": "What are the pieces of furniture in front of the staircase?", "program": "BOX0=LOC(image=IMAGE,object='staircase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What are the pieces of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7046, "imageId": "n283587", "question": "How do the chairs look, black or silver?", "program": "ANSWER0=VQA(image=IMAGE,question='How do the chairs look, black or silver?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7047, "imageId": "n83784", "question": "Is the rug on top of the carpet striped and beige?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the rug striped?')\nANSWER1=VQA(image=IMAGE1,question='What color is the rug?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'beige' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7048, "imageId": "n578564", "question": "On which side of the picture is the chalkboard?", "program": "BOX0=LOC(image=IMAGE,object='chalkboard')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7049, "imageId": "n66756", "question": "How big is the field?", "program": "ANSWER0=VQA(image=IMAGE,question='How big is the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7050, "imageId": "n523165", "question": "Is the bike in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bike')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7051, "imageId": "n496803", "question": "On which side of the photo is the person, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7052, "imageId": "n468864", "question": "Is the hair long and straight?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the hair long?')\nANSWER1=VQA(image=IMAGE,question='Is the hair straight?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7053, "imageId": "n393305", "question": "What color is the t-shirt?", "program": "BOX0=LOC(image=IMAGE,object='t-shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the t-shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7054, "imageId": "n235859", "question": "Does the glass that is standing look large and dirty?", "program": "BOX0=LOC(image=IMAGE,object='standing glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the glass look large?')\nANSWER1=VQA(image=IMAGE0,question='Does the glass look dirty?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7055, "imageId": "n293477", "question": "What is the wallet that is made of leather lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='leather wallet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the wallet lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7056, "imageId": "n293477", "question": "What is the wallet lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='wallet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the wallet lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7057, "imageId": "n500308", "question": "What is in front of the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7058, "imageId": "n500308", "question": "What is in front of the glass window near the freezer?", "program": "BOX0=LOC(image=IMAGE,object='freezer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass window')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the glass window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7059, "imageId": "n95313", "question": "Which kind of furniture is before the closet?", "program": "BOX0=LOC(image=IMAGE,object='closet')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is before the closet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7060, "imageId": "n166008", "question": "What is the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7061, "imageId": "n166008", "question": "What is the person in front of the kitchen doing?", "program": "BOX0=LOC(image=IMAGE,object='kitchen')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7062, "imageId": "n386688", "question": "Is the sailboat underneath the plane both large and blue?", "program": "BOX0=LOC(image=IMAGE,object='plane')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sailboat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='large')\nBOX3=LOC(image=IMAGE0,object='blue')\nANSWER2=COUNT(box=BOX2)\nANSWER3=COUNT(box=BOX3)\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} > 0 and {ANSWER3} > 0 else 'no'\")\nANSWER5=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER4} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 7063, "imageId": "n256120", "question": "Who wears shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nANSWER0=VQA(image=IMAGE,question='Who wears shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7064, "imageId": "n184385", "question": "What is the cooking utensil that is to the right of the appliance that is not open?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the cooking utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7065, "imageId": "n276011", "question": "What pieces of furniture are made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nANSWER0=VQA(image=IMAGE,question='What pieces of furniture are made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7066, "imageId": "n350732", "question": "Where is the person near the plants running?", "program": "BOX0=LOC(image=IMAGE,object='plants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Where is the person running?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7067, "imageId": "n350732", "question": "Where is the man running?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the man running?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7068, "imageId": "n350732", "question": "What is the man looking at?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7069, "imageId": "n276011", "question": "What kind of furniture is light brown?", "program": "BOX0=LOC(image=IMAGE,object='light brown furniture')\nANSWER0=VQA(image=IMAGE,question='What kind of furniture is light brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7070, "imageId": "n276011", "question": "What are the hard pieces of furniture called?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the hard pieces of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7071, "imageId": "n415215", "question": "Does the person near the toilet look Caucasian and male?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='Caucasian')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='male')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 7072, "imageId": "n508733", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7073, "imageId": "n475030", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7074, "imageId": "n508733", "question": "Do the old women appear to be walking?", "program": "BOX0=LOC(image=IMAGE,object='old women')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7075, "imageId": "n173807", "question": "How large are the buildings behind the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='buildings')\nANSWER0=VQA(image=IMAGE0,question='How large are the buildings?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7076, "imageId": "n192021", "question": "What is on the ceiling?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the ceiling?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7077, "imageId": "n192021", "question": "What's on the ceiling?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the ceiling?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7078, "imageId": "n310828", "question": "Does the mousepad seem to be large or small?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the mousepad seem to be large or small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7079, "imageId": "n262920", "question": "How large is the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nANSWER0=VQA(image=IMAGE,question='How large is the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7080, "imageId": "n192021", "question": "What is the fan on the ceiling made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fan on the ceiling made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7081, "imageId": "n508641", "question": "Does the white jersey look dirty?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the white jersey look dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7082, "imageId": "n234683", "question": "What is the long sleeved clothing item?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved clothing')\nANSWER0=VQA(image=IMAGE,question='What is the long sleeved clothing item?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7083, "imageId": "n55058", "question": "Which color are the French fries the burger is next to?", "program": "BOX0=LOC(image=IMAGE,object='burger')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='French fries')\nANSWER0=VQA(image=IMAGE0,question='Which color are the French fries?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7084, "imageId": "n271392", "question": "What is the vehicle that is on the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7085, "imageId": "n234683", "question": "Which type of clothing is not ugly, the suit or the dress shirt?", "program": "ANSWER0=VQA(image=IMAGE,question='Which type of clothing is not ugly, the suit or the dress shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7086, "imageId": "n386688", "question": "What watercraft is floating on the ocean?", "program": "BOX0=LOC(image=IMAGE,object='ocean')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What watercraft is floating on the ocean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7087, "imageId": "n498140", "question": "Are there windows or doors that are made of wood?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7088, "imageId": "n98544", "question": "Is the small heater clean or dirty?", "program": "BOX0=LOC(image=IMAGE,object='small heater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the small heater clean or dirty?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7089, "imageId": "n131634", "question": "What is in front of the stone building?", "program": "BOX0=LOC(image=IMAGE,object='stone building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the stone building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7090, "imageId": "n309148", "question": "Which kind of vehicle isn't clean?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=VQA(image=IMAGE,question='Which kind of vehicle isn\\'t clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7091, "imageId": "n433692", "question": "What device is on top of the mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is on top of the mouse pad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7092, "imageId": "n233607", "question": "Do the rug and the window have a different colors?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='window')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the rug?')\nANSWER1=VQA(image=IMAGE1,question='What color is the window?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7093, "imageId": "n579928", "question": "What type of vehicle is gray?", "program": "BOX0=LOC(image=IMAGE,object='gray vehicle')\nANSWER0=VQA(image=IMAGE,question='What type of vehicle is gray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7094, "imageId": "n579928", "question": "What kind of vehicle is gray?", "program": "BOX0=LOC(image=IMAGE,object='gray vehicle')\nANSWER0=VQA(image=IMAGE,question='What kind of vehicle is gray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7095, "imageId": "n263180", "question": "Are the clouds above the brick building?", "program": "BOX0=LOC(image=IMAGE,object='brick building')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='clouds')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7096, "imageId": "n579928", "question": "What vehicle is large?", "program": "BOX0=LOC(image=IMAGE,object='large')\nANSWER0=VQA(image=IMAGE,question='What vehicle is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7097, "imageId": "n565418", "question": "How clean is the white snow?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the white snow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7098, "imageId": "n302387", "question": "Do you see instruments near the cardboard container?", "program": "BOX0=LOC(image=IMAGE,object='cardboard container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='instruments')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7099, "imageId": "n381072", "question": "Are there cakes to the left of the plate that is to the left of the knife?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knife')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='cakes')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7100, "imageId": "n329479", "question": "What are the wheels made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the wheels made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7101, "imageId": "n278312", "question": "What pieces of furniture are this?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What pieces of furniture are this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7102, "imageId": "n278312", "question": "What kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7103, "imageId": "n278312", "question": "Which kind of furniture is made of glass?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is made of glass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7104, "imageId": "n100552", "question": "What color is the huge animal?", "program": "BOX0=LOC(image=IMAGE,object='huge animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the huge animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7105, "imageId": "n532191", "question": "Is the black bag on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7106, "imageId": "n14087", "question": "Is the comfortable couch on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='comfortable couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7107, "imageId": "n28572", "question": "What is in front of the menu?", "program": "BOX0=LOC(image=IMAGE,object='menu')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the menu?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7108, "imageId": "n28572", "question": "That glass is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='That glass is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7109, "imageId": "n489699", "question": "Does the snowy ground have black color?", "program": "BOX0=LOC(image=IMAGE,object='snowy ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the snowy ground?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7110, "imageId": "n35676", "question": "On which side is the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7111, "imageId": "n246334", "question": "What is standing by the doors?", "program": "BOX0=LOC(image=IMAGE,object='doors')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing by the doors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7112, "imageId": "n346247", "question": "Is the manhole cover metallic and round?", "program": "BOX0=LOC(image=IMAGE,object='manhole cover')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the manhole cover made of?')\nANSWER1=VQA(image=IMAGE0,question='What shape is the manhole cover?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'metallic' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7113, "imageId": "n98540", "question": "Does the man look young and tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the man look young?')\nANSWER1=VQA(image=IMAGE,question='Does the man look tall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7114, "imageId": "n16936", "question": "Is it an outdoors scene?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an outdoors scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7115, "imageId": "n16936", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7116, "imageId": "n363445", "question": "Is that food container on a bookcase?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food container')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7117, "imageId": "n9856", "question": "Which kind of clothing is not wrinkled?", "program": "BOX0=LOC(image=IMAGE,object='wrinkled clothing')\nANSWER0=VQA(image=IMAGE,question='Which kind of clothing is not wrinkled?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7118, "imageId": "n570181", "question": "Who is wearing trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7119, "imageId": "n344136", "question": "Does the mirror on the wall have silver color and round shape?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the mirror?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the mirror?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7120, "imageId": "n260762", "question": "What's the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7121, "imageId": "n153293", "question": "How clean is that toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean is the toilet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7122, "imageId": "n260762", "question": "Does the person that is standing seem to be talking?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the person that is standing seem to be talking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7123, "imageId": "n534106", "question": "Are the pillows to the left of her square and white?", "program": "BOX0=LOC(image=IMAGE,object='her')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='What color are the pillows?')\nANSWER3=VQA(image=IMAGE1,question='What shape are the pillows?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'square' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 7124, "imageId": "n28572", "question": "What makes up the fork, stainless steel or plastic?", "program": "ANSWER0=VQA(image=IMAGE,question='What makes up the fork, stainless steel or plastic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7125, "imageId": "n534106", "question": "Which shape do you think the pillows that look white and brown are?", "program": "ANSWER0=VQA(image=IMAGE,question='Which shape do you think the pillows that look white and brown are?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7126, "imageId": "n222297", "question": "The young man above the swimming pool is wearing what?", "program": "BOX0=LOC(image=IMAGE,object='swimming pool')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the young man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7127, "imageId": "n433692", "question": "What is the device that is the same shape as the pot called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the device that is the same shape as the pot called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7128, "imageId": "n16656", "question": "What color is the ground that looks rough?", "program": "BOX0=LOC(image=IMAGE,object='rough ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the ground?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7129, "imageId": "n28572", "question": "Do you see either any forks or spoons that are made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nBOX1=LOC(image=IMAGE,object='spoon')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What material are the forks made of?')\nANSWER4=VQA(image=IMAGE,question='What material are the spoons made of?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} == 'plastic' or {ANSWER4} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER5)"}, {"index": 7130, "imageId": "n16378", "question": "Is the large bag to the right or to the left of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7131, "imageId": "n207708", "question": "Is that table round?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='Is that table round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7132, "imageId": "n498140", "question": "Is the chimney high and clean?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the chimney high?')\nANSWER1=VQA(image=IMAGE,question='Is the chimney clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7133, "imageId": "n498140", "question": "Are there any mirrors or trays?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nBOX1=LOC(image=IMAGE,object='tray')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7134, "imageId": "n95904", "question": "Is the person that is walking both female and Asian?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the person that is walking female?')\nANSWER1=VQA(image=IMAGE,question='Is the person that is walking Asian?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7135, "imageId": "n295771", "question": "Is the window near the plant both large and clear?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the window large?')\nANSWER1=VQA(image=IMAGE1,question='Is the window clear?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7136, "imageId": "n336443", "question": "Which side is the fork on?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7137, "imageId": "n272098", "question": "Is the coat blue or yellow?", "program": "BOX0=LOC(image=IMAGE,object='coat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the coat?')\nANSWER1=EVAL(expr=\"'blue' if {ANSWER0} == 'blue' else 'yellow'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7138, "imageId": "n314171", "question": "Which material makes up the green balloon, rubber or paper?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material makes up the green balloon, rubber or paper?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7139, "imageId": "n23181", "question": "Is any desk observable in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7140, "imageId": "n446242", "question": "What is under the picture?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7141, "imageId": "n23181", "question": "Are there brown desks or dressers?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nBOX1=LOC(image=IMAGE,object='dresser')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7142, "imageId": "n199097", "question": "What is the color of the hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7143, "imageId": "n324644", "question": "What shape is the sticker that looks purple and white?", "program": "BOX0=LOC(image=IMAGE,object='purple and white sticker')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the sticker?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7144, "imageId": "n435808", "question": "Which color is the keyboard in the middle of the photo?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7145, "imageId": "n202379", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7146, "imageId": "n437064", "question": "What dessert is the spoon in front of?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nANSWER0=VQA(image=IMAGE0,question='What dessert is the spoon in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7147, "imageId": "n167552", "question": "On which side is the red rug?", "program": "BOX0=LOC(image=IMAGE,object='red rug')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7148, "imageId": "n172618", "question": "What is the kite in front of?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the kite in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7149, "imageId": "n172618", "question": "Are there any kites in front of the blue dress?", "program": "BOX0=LOC(image=IMAGE,object='blue dress')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='kites')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7150, "imageId": "n532191", "question": "Are there both a window and a chair in the scene?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7151, "imageId": "n546616", "question": "What is the name of the food that has the same color as the dessert near the plates?", "program": "BOX0=LOC(image=IMAGE,object='plates')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the dessert?')\nBOX2=LOC(image=IMAGE0,object='food')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER1=VQA(image=IMAGE2,question='What is the name of the food?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7152, "imageId": "n65866", "question": "What is under the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7153, "imageId": "n546616", "question": "What do both the cake and the marshmallow have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the cake and the marshmallow have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7154, "imageId": "n541854", "question": "Is that a banana or a pear?", "program": "BOX0=LOC(image=IMAGE,object='banana')\nBOX1=LOC(image=IMAGE,object='pear')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'banana' if {ANSWER0} > 0 else 'pear'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7155, "imageId": "n260521", "question": "Is the book above the bench open and white?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='book')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the book open?')\nANSWER1=VQA(image=IMAGE1,question='What color is the book?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7156, "imageId": "n117888", "question": "Is the athlete blond?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the athlete blond?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7157, "imageId": "n295771", "question": "Are the mountains gray or dark?", "program": "BOX0=LOC(image=IMAGE,object='mountains')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the mountains?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' or {ANSWER0} == 'dark' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7158, "imageId": "n257997", "question": "In which part of the photo is the gray car?", "program": "BOX0=LOC(image=IMAGE,object='gray car')\nANSWER0=EVAL(expr=\"'top' if {BOX0}.y < IMAGE.height/2 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7159, "imageId": "n95313", "question": "Are both the closet and the bookshelf behind the bed full?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='closet')\nBOX2=LOC(image=IMAGE0,object='bookshelf')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7160, "imageId": "n151768", "question": "What's the woman doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the woman doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7161, "imageId": "n151768", "question": "Who is resting?", "program": "BOX0=LOC(image=IMAGE,object='resting')\nANSWER0=VQA(image=IMAGE,question='Who is resting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7162, "imageId": "n95313", "question": "What kind of furniture is not closed?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is not closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7163, "imageId": "n528403", "question": "What is the color of the tall house?", "program": "BOX0=LOC(image=IMAGE,object='tall house')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the tall house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7164, "imageId": "n334278", "question": "What is the fence surrounding?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence surrounding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7165, "imageId": "n170941", "question": "What kind of meat is on top of the plate near the fork?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fork')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of meat is on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7166, "imageId": "n92308", "question": "Is the weather cloudy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the weather cloudy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7167, "imageId": "n162148", "question": "Is the woman to the left or to the right of the young man?", "program": "BOX0=LOC(image=IMAGE,object='young man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7168, "imageId": "n314171", "question": "Is the size of the picture large?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the size of the picture large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7169, "imageId": "n233607", "question": "Which color is the wire shelf?", "program": "BOX0=LOC(image=IMAGE,object='wire shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the wire shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7170, "imageId": "n314171", "question": "Is the picture both gray and large?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the picture?')\nANSWER1=VQA(image=IMAGE,question='How large is the picture?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7171, "imageId": "n441859", "question": "Is the surfboard yellow or blue?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the surfboard?')\nANSWER1=EVAL(expr=\"'yellow' if {ANSWER0} == 'yellow' else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7172, "imageId": "n46510", "question": "Does the palm seem to be high and skinny?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the palm seem to be high and skinny?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7173, "imageId": "n350766", "question": "Is the garbage can below a sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='garbage can')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7174, "imageId": "n262920", "question": "Does the person to the left of the laptops look short and young?", "program": "BOX0=LOC(image=IMAGE,object='laptops')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Does the person look short and young?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7175, "imageId": "n4777", "question": "Is there a brown table or couch?", "program": "BOX0=LOC(image=IMAGE,object='table')\nBOX1=LOC(image=IMAGE,object='couch')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7176, "imageId": "n315887", "question": "On which side is the small coffee cup?", "program": "BOX0=LOC(image=IMAGE,object='small coffee cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7177, "imageId": "n146555", "question": "Who does the light post made of metal hang above?", "program": "BOX0=LOC(image=IMAGE,object='light post')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who does the light post made of metal hang above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7178, "imageId": "n146555", "question": "What hangs above the crowd?", "program": "BOX0=LOC(image=IMAGE,object='crowd')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hanging object')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'nothing' if {ANSWER0} == 0 else 'something'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7179, "imageId": "n37274", "question": "What is in front of the man that is in front of the sign?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7180, "imageId": "n357784", "question": "Is the mirror both small and clean?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the mirror small?')\nANSWER1=VQA(image=IMAGE,question='Is the mirror clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7181, "imageId": "n523165", "question": "Is there either a blue scooter or bike?", "program": "BOX0=LOC(image=IMAGE,object='scooter')\nBOX1=LOC(image=IMAGE,object='bike')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7182, "imageId": "n37274", "question": "What type of appliance is in front of the man that is in front of the bicycle?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bicycle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What type of appliance is in front of the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7183, "imageId": "n154160", "question": "Is the catcher on the left side or on the right of the picture?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7184, "imageId": "n154160", "question": "Do you think the catcher is clean?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do you think the catcher is clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7185, "imageId": "n579256", "question": "Where is she?", "program": "ANSWER0=VQA(image=IMAGE,question='Where is she?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7186, "imageId": "n159284", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7187, "imageId": "n579256", "question": "Is the tall woman wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the clothing of the woman?')\nANSWER1=EVAL(expr=\"'yes' if 'jeans' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7188, "imageId": "n579256", "question": "Who is wearing jeans?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing jeans?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7189, "imageId": "n579256", "question": "Is she holding the food on the right?", "program": "BOX0=LOC(image=IMAGE,object='food')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7190, "imageId": "n398429", "question": "What appliance isn't closed?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nANSWER0=VQA(image=IMAGE,question='What appliance isn\\'t closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7191, "imageId": "n334278", "question": "How old is the batter?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How old is the batter?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7192, "imageId": "n460385", "question": "What kind of clothing is black?", "program": "BOX0=LOC(image=IMAGE,object='black clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7193, "imageId": "n460385", "question": "Is the shelf behind a woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7194, "imageId": "n262920", "question": "Are there rugs on top of the dark floor?", "program": "BOX0=LOC(image=IMAGE,object='dark floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rugs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7195, "imageId": "n16425", "question": "What vehicle is in front of the telephone pole?", "program": "BOX0=LOC(image=IMAGE,object='telephone pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is in front of the telephone pole?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7196, "imageId": "n386688", "question": "What type of watercraft is the white airplane flying above?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watercraft')\nANSWER0=VQA(image=IMAGE0,question='What type of watercraft is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7197, "imageId": "n146522", "question": "Do you see either a ball or a helmet?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nBOX1=LOC(image=IMAGE,object='helmet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7198, "imageId": "n355339", "question": "Who is the chair in front of?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the chair in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7199, "imageId": "n262920", "question": "What piece of furniture is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7200, "imageId": "n86120", "question": "What is the name of the animals?", "program": "BOX0=LOC(image=IMAGE,object='animals')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the animals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7201, "imageId": "n86120", "question": "What animals are it?", "program": "BOX0=LOC(image=IMAGE,object='animals')\nANSWER0=VQA(image=IMAGE,question='What animals are it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7202, "imageId": "n167164", "question": "How big is the vehicle on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='How big is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7203, "imageId": "n28996", "question": "Which kind of food is to the left of the cookie?", "program": "BOX0=LOC(image=IMAGE,object='cookie')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='Which kind of food is to the left of the cookie?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7204, "imageId": "n233607", "question": "Is the window covered and brown?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the window covered?')\nANSWER1=VQA(image=IMAGE0,question='What color is the window?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7205, "imageId": "n160664", "question": "Are the black glasses in the top?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black glasses')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7206, "imageId": "n86120", "question": "What are the animals that are white?", "program": "BOX0=LOC(image=IMAGE,object='white')\nANSWER0=VQA(image=IMAGE,question='What are the animals that are white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7207, "imageId": "n207708", "question": "What is the cabinet made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the cabinet made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7208, "imageId": "n511913", "question": "Is the person that is to the right of the woman wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Is the person wearing glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7209, "imageId": "n172618", "question": "Which color do you think the boots which are walking on the grass are?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boots')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which color are the boots?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7210, "imageId": "n511913", "question": "Who wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who wears a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7211, "imageId": "n429961", "question": "Is the container to the right of the eggplant round and small?", "program": "BOX0=LOC(image=IMAGE,object='eggplant')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='container')\nANSWER0=VQA(image=IMAGE0,question='Is the container round and small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7212, "imageId": "n186491", "question": "Is the shape of the table the same as the bowl?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bowl')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is the shape of the table?')\nANSWER1=VQA(image=IMAGE1,question='What is the shape of the bowl?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7213, "imageId": "n511913", "question": "What is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7214, "imageId": "n172618", "question": "What are the green boots walking on?", "program": "BOX0=LOC(image=IMAGE,object='green boots')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the green boots walking on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7215, "imageId": "n28792", "question": "Is the man that is short wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='short man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the man wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7216, "imageId": "n119886", "question": "Does the toilet seat appear to be white and low?", "program": "BOX0=LOC(image=IMAGE,object='toilet seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet seat?')\nANSWER1=VQA(image=IMAGE0,question='Is the toilet seat low?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7217, "imageId": "n335542", "question": "Who is looking at the large picture frame?", "program": "BOX0=LOC(image=IMAGE,object='large picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking at the large picture frame?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7218, "imageId": "n90294", "question": "Does the book look thick and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the book look thick and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7219, "imageId": "n200692", "question": "What is the size of the appliance the countertop is standing against?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What is the size of the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7220, "imageId": "n160664", "question": "What type of material are the glasses made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of material are the glasses made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7221, "imageId": "n369970", "question": "Does the jacket look long sleeved and dark?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the jacket look long sleeved?')\nANSWER1=VQA(image=IMAGE,question='Does the jacket look dark?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7222, "imageId": "n68769", "question": "Is the young woman sitting at a mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='young woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7223, "imageId": "n326988", "question": "What is the device that the man is looking at?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the device that the man is looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7224, "imageId": "n127705", "question": "How hard is the racket that the person is holding?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='racket')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How hard is the racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7225, "imageId": "n127705", "question": "Does the ground look smooth and green?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the ground look smooth and green?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7226, "imageId": "n390187", "question": "Are there any black coffee tables or mirrors in the photo?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nBOX1=LOC(image=IMAGE,object='mirror')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7227, "imageId": "n331357", "question": "How's the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How\\'s the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7228, "imageId": "n222297", "question": "Does the playing man above the water look old?", "program": "BOX0=LOC(image=IMAGE,object='water')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='playing man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7229, "imageId": "n6309", "question": "Is the cart that is to the left of the car metallic and black?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cart')\nANSWER0=VQA(image=IMAGE0,question='What color is the cart?')\nANSWER1=VQA(image=IMAGE0,question='What material is the cart made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7230, "imageId": "n503626", "question": "Are both the urinal that is white and silver and the urinal that is white and silver made of porcelain?", "program": "BOX0=LOC(image=IMAGE,object='urinal',color='white',material='porcelain')\nBOX1=LOC(image=IMAGE,object='urinal',color='silver',material='porcelain')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7231, "imageId": "n67005", "question": "What is the white item of furniture called?", "program": "BOX0=LOC(image=IMAGE,object='white item of furniture')\nANSWER0=VQA(image=IMAGE,question='What is the white item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7232, "imageId": "n298104", "question": "Do you see any snowboard or surfboard there?", "program": "BOX0=LOC(image=IMAGE,object='snowboard')\nBOX1=LOC(image=IMAGE,object='surfboard')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7233, "imageId": "n532213", "question": "Is the street sign that looks black and white hanging above a man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='street sign')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the street sign?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black and white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7234, "imageId": "n234722", "question": "Does the chair have dark brown color?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'dark brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7235, "imageId": "n532213", "question": "Who is the street sign that is black and white hanging above?", "program": "BOX0=LOC(image=IMAGE,object='black and white street sign')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the street sign hanging above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7236, "imageId": "n525901", "question": "On which side of the photo is the book?", "program": "BOX0=LOC(image=IMAGE,object='book')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7237, "imageId": "n310625", "question": "Is the bottle to the left or to the right of the mug that looks red and orange?", "program": "BOX0=LOC(image=IMAGE,object='mug',color='red orange')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7238, "imageId": "n566028", "question": "Does the shirt that looks dry have striped pattern and black color?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What pattern does the shirt have?')\nANSWER1=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'striped' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7239, "imageId": "n541688", "question": "What is the clothing item that is colorful called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the clothing item that is colorful called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7240, "imageId": "n541688", "question": "What clothing item is colorful?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nANSWER0=VQA(image=IMAGE,question='What clothing item is colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7241, "imageId": "n566028", "question": "Is the striped shirt dry or wet?", "program": "BOX0=LOC(image=IMAGE,object='striped shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the striped shirt dry or wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7242, "imageId": "n186491", "question": "Does the water look clear and dry?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the water look clear?')\nANSWER1=VQA(image=IMAGE,question='Does the water look dry?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7243, "imageId": "n186491", "question": "Is the water clear?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the water clear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7244, "imageId": "n310625", "question": "Is the bottle to the right of a refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7245, "imageId": "n59147", "question": "Is the white thing that is to the right of the toilet resting on the chair?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='white thing')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7246, "imageId": "n480253", "question": "Is this a fire truck or a tractor?", "program": "BOX0=LOC(image=IMAGE,object='fire truck')\nBOX1=LOC(image=IMAGE,object='tractor')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'fire truck' if {ANSWER0} > 0 else 'tractor'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7247, "imageId": "n480253", "question": "What vehicle is not sturdy?", "program": "ANSWER0=VQA(image=IMAGE,question='What vehicle is not sturdy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7248, "imageId": "n480253", "question": "Which vehicle is sturdy, the ambulance or the fire truck?", "program": "ANSWER0=VQA(image=IMAGE,question='Which vehicle is sturdy, the ambulance or the fire truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7249, "imageId": "n480253", "question": "What vehicle is sturdy?", "program": "ANSWER0=VQA(image=IMAGE,question='What vehicle is sturdy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7250, "imageId": "n49310", "question": "Are the trousers red?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the trousers?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7251, "imageId": "n336443", "question": "Does the glass look clear and full?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the glass look clear and full?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7252, "imageId": "n51658", "question": "What is the standing person to the right of the man doing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='standing person')\nANSWER0=VQA(image=IMAGE0,question='What is the standing person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7253, "imageId": "n79078", "question": "Which color are the shorts, orange or white?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color are the shorts?')\nANSWER1=EVAL(expr=\"'orange' if {ANSWER0} == 'orange' else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7254, "imageId": "n234722", "question": "Is that table smooth and dark brown?", "program": "ANSWER0=VQA(image=IMAGE,question='Is that table smooth?')\nANSWER1=VQA(image=IMAGE,question='What color is the table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'dark brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7255, "imageId": "n282607", "question": "Does the racket have a different color than the floor?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='floor')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the racket?')\nANSWER1=VQA(image=IMAGE1,question='What color is the floor?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7256, "imageId": "n556604", "question": "Are there any elephants behind the green tree?", "program": "BOX0=LOC(image=IMAGE,object='green tree')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='elephants')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7257, "imageId": "n567860", "question": "What do both the banana bunch and the banana have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the banana bunch and the banana have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7258, "imageId": "n115614", "question": "Which kind of vehicle is to the left of the people?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7259, "imageId": "n567860", "question": "What is the name of the animal that has the same color as the door?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the door?')\nBOX1=LOC(image=IMAGE,object=ANSWER0)\nANSWER1=VQA(image=IMAGE,question='What is the name of the animal?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7260, "imageId": "n393305", "question": "Does the traffic sign have a different color than the skirt?", "program": "BOX0=LOC(image=IMAGE,object='traffic sign')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='skirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the traffic sign?')\nANSWER1=VQA(image=IMAGE1,question='What color is the skirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7261, "imageId": "n210269", "question": "Are there any bicycles or fences in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7262, "imageId": "n95904", "question": "What is located on top of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7263, "imageId": "n97485", "question": "What are the pieces of furniture underneath the cabinet that is not small?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What are the pieces of furniture?')\nANSWER1=EVAL(expr=\"' '.join({ANSWER0}.split())\")\nANSWER2=EVAL(expr=\"' '.join([word for word in {ANSWER1}.split() if word != 'small'])\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7264, "imageId": "n199097", "question": "Does that store look modern and huge?", "program": "ANSWER0=VQA(image=IMAGE,question='Does that store look modern?')\nANSWER1=VQA(image=IMAGE,question='Does that store look huge?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7265, "imageId": "n199097", "question": "Is the store that is not antique huge or small?", "program": "BOX0=LOC(image=IMAGE,object='antique store')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='store')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'huge' if {ANSWER0} > 1 else 'small'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7266, "imageId": "n240973", "question": "What kind of furniture is above the empty bowl?", "program": "BOX0=LOC(image=IMAGE,object='empty bowl')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is above the empty bowl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7267, "imageId": "n469525", "question": "Are there any deer in the photo that are standing?", "program": "BOX0=LOC(image=IMAGE,object='deer')\nBOX1=LOC(image=IMAGE,object='standing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7268, "imageId": "n153293", "question": "Which side are the white shelves on?", "program": "BOX0=LOC(image=IMAGE,object='white shelves')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7269, "imageId": "n199097", "question": "Is the store modern?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the store modern?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7270, "imageId": "n282607", "question": "Is he in front of the net above the floor?", "program": "BOX0=LOC(image=IMAGE,object='net')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='floor')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='he')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7271, "imageId": "n415215", "question": "Which kind of clothing is white?", "program": "BOX0=LOC(image=IMAGE,object='white clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7272, "imageId": "n153293", "question": "Are the folded towels sitting inside the shelves next to the wall?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='folded towels')\nIMAGE1=CROP_INSIDE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='wall')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7273, "imageId": "n153293", "question": "What are the pieces of furniture that the folded towels are sitting inside of?", "program": "BOX0=LOC(image=IMAGE,object='folded towels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the pieces of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7274, "imageId": "n411121", "question": "Is the small dog to the right or to the left of the waiting person near the van?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='waiting person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='small dog')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7275, "imageId": "n498712", "question": "On which side of the photo is the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7276, "imageId": "n240666", "question": "Is the white mat on the left or on the right side of the photo?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white mat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7277, "imageId": "n4777", "question": "How large is the table that the cup sits on top of?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7278, "imageId": "n65866", "question": "What item of furniture isn't modern?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='What item of furniture isn\\'t modern?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7279, "imageId": "n65866", "question": "Which piece of furniture is not modern, the drawer or the cabinet?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cabinet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Is the drawer modern?')\nANSWER1=VQA(image=IMAGE1,question='Is the cabinet modern?')\nANSWER2=EVAL(expr=\"'drawer' if {ANSWER0} == 'no' else 'cabinet'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7280, "imageId": "n65866", "question": "Which kind of furniture is modern?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is modern?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7281, "imageId": "n65866", "question": "How is the modern item of furniture called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the modern item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7282, "imageId": "n65202", "question": "What is the person that is skating doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the person that is skating doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7283, "imageId": "n65202", "question": "What is the skateboarder doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the skateboarder doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7284, "imageId": "n100991", "question": "What food is not ripe?", "program": "BOX0=LOC(image=IMAGE,object='ripe food')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 0 else 'some'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7285, "imageId": "n100991", "question": "What is the food that is not thin called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the food that is not thin called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7286, "imageId": "n100991", "question": "Which kind of food is not thin, the sausage or the banana?", "program": "BOX0=LOC(image=IMAGE,object='sausage')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='banana')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='Is the sausage thin?')\nANSWER1=VQA(image=IMAGE1,question='Is the banana thin?')\nANSWER2=EVAL(expr=\"'sausage' if {ANSWER0} == 'no' else 'banana'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7287, "imageId": "n100991", "question": "What kind of fruit is thin?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of fruit is thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7288, "imageId": "n12214", "question": "Who is jumping?", "program": "BOX0=LOC(image=IMAGE,object='jumping')\nANSWER0=VQA(image=IMAGE,question='Who is jumping?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7289, "imageId": "n100991", "question": "Which kind of food is not thin?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is not thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7290, "imageId": "n200907", "question": "Does the fence to the left of the girl look metallic and silver?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=VQA(image=IMAGE1,question='What color is the fence?')\nANSWER1=VQA(image=IMAGE1,question='What material is the fence made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7291, "imageId": "n228268", "question": "Are the shorts black and wet?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE0,question='Are the shorts wet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7292, "imageId": "n433532", "question": "Which kind of clothing is long?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of clothing is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7293, "imageId": "n433532", "question": "What kind of clothing is red?", "program": "BOX0=LOC(image=IMAGE,object='red clothing')\nANSWER0=VQA(image=IMAGE,question='What kind of clothing is red?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7294, "imageId": "n536256", "question": "Which kind of furniture are the DVDs inside of?", "program": "BOX0=LOC(image=IMAGE,object='DVDs')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture are the DVDs inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7295, "imageId": "n118102", "question": "What is located on top of the cake?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'nothing' if {ANSWER0} == 0 else 'something'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7296, "imageId": "n119886", "question": "What do the sink and the pipe have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the sink and the pipe have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7297, "imageId": "n119886", "question": "Are the floor and the mirror the same shape?", "program": "ANSWER0=VQA(image=IMAGE,question='What shape is the floor?')\nANSWER1=VQA(image=IMAGE,question='What shape is the mirror?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7298, "imageId": "n153118", "question": "Are the train tracks near the platform long and metallic?", "program": "BOX0=LOC(image=IMAGE,object='platform')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='train tracks')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Are the train tracks long and metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7299, "imageId": "n264887", "question": "What device is in front of the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is in front of the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7300, "imageId": "n536256", "question": "What is standing against the white wall behind the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white wall')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is standing against the white wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7301, "imageId": "n536256", "question": "What kind of furniture is standing against the wall behind the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is standing against the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7302, "imageId": "n536256", "question": "What is standing against the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing against the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7303, "imageId": "n536256", "question": "Is the TV stand that is made of wood standing against the wall that looks white?", "program": "BOX0=LOC(image=IMAGE,object='TV stand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='wall')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='white')\nANSWER0=COUNT(box=BOX3)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7304, "imageId": "n500308", "question": "What shape is that refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nANSWER0=VQA(image=IMAGE,question='What shape is the refrigerator?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7305, "imageId": "n181355", "question": "Is the woman to the right or to the left of the man that is wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='man with hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7306, "imageId": "n223750", "question": "What is the short sleeved clothing item?", "program": "BOX0=LOC(image=IMAGE,object='short sleeved clothing')\nANSWER0=VQA(image=IMAGE,question='What is the short sleeved clothing item?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7307, "imageId": "n223750", "question": "What clothing item is short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='short sleeved')\nANSWER0=VQA(image=IMAGE,question='What clothing item is short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7308, "imageId": "n263180", "question": "Which kind of vehicle is parked behind the bus?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is parked behind the bus?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7309, "imageId": "n263180", "question": "What is the parked vehicle parked behind of?", "program": "BOX0=LOC(image=IMAGE,object='parked vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the parked vehicle parked behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7310, "imageId": "n386682", "question": "Do you see any mirrors above the sink?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7311, "imageId": "n151768", "question": "Does the vegetable inside the boxes look colorful?", "program": "BOX0=LOC(image=IMAGE,object='boxes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetable')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the vegetable look colorful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7312, "imageId": "n449058", "question": "Do the helmet and the street have the same material?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='street')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the helmet made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the street made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7313, "imageId": "n498712", "question": "Does the office look open?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the office look open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7314, "imageId": "n449058", "question": "Are the street and the gun made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='gun')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the street made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the gun made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7315, "imageId": "n449058", "question": "Is the material of the window the same as the gun?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='gun')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the window made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the gun made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7316, "imageId": "n296467", "question": "What kind of dessert is baked?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of dessert is baked?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7317, "imageId": "n305495", "question": "On which side is the couch, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7318, "imageId": "n283587", "question": "What piece of furniture is to the left of the coffee table that is in front of the sofa?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='coffee table')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What piece of furniture is to the left of the coffee table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7319, "imageId": "n313060", "question": "What color are the trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7320, "imageId": "n283587", "question": "What item of furniture is to the left of the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is to the left of the coffee table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7321, "imageId": "n319845", "question": "Do the chairs that are to the right of the vase seem to be old fashioned?", "program": "BOX0=LOC(image=IMAGE,object='vase')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chairs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7322, "imageId": "n283587", "question": "Is the cupboard to the left of the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cupboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7323, "imageId": "n500308", "question": "Is there a refrigerator next to the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='refrigerator')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7324, "imageId": "n302358", "question": "Are the trees below the sky green and abundant?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color are the trees?')\nANSWER3=VQA(image=IMAGE0,question='Are the trees abundant?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'green' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 7325, "imageId": "n238266", "question": "Is the material of the table the same as the cake stand?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cake stand')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the cake stand made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7326, "imageId": "n410289", "question": "Is the bright window rectangular or round?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the bright window rectangular or round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7327, "imageId": "n501609", "question": "Do you see both a microwave and a dish washer?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nBOX1=LOC(image=IMAGE,object='dish washer')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7328, "imageId": "n130638", "question": "Who is in front of the young boy?", "program": "BOX0=LOC(image=IMAGE,object='young boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the young boy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7329, "imageId": "n116329", "question": "Does the traffic signal above the man appear to be metallic and green?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic signal')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the traffic signal?')\nANSWER1=VQA(image=IMAGE1,question='Does the traffic signal appear to be metallic?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7330, "imageId": "n541482", "question": "Is the color of the cloud the same as the sweater?", "program": "BOX0=LOC(image=IMAGE,object='cloud')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sweater')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the cloud?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sweater?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7331, "imageId": "n116329", "question": "Which color is the traffic light the man is below?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='traffic light')\nANSWER0=VQA(image=IMAGE0,question='Which color is the traffic light?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7332, "imageId": "n318684", "question": "Is the sand on the beach rough or smooth?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the sand on the beach rough or smooth?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7333, "imageId": "n541482", "question": "Does the cloud have the same color as the scarf?", "program": "BOX0=LOC(image=IMAGE,object='scarf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cloud')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the scarf?')\nANSWER1=VQA(image=IMAGE1,question='What color is the cloud?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7334, "imageId": "n293477", "question": "Which color is the bag which is lying on top of the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nANSWER0=VQA(image=IMAGE0,question='Which color is the bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7335, "imageId": "n202379", "question": "Does the baseball field look grassy and green?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the baseball field look grassy and green?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7336, "imageId": "n131634", "question": "Is the van parked behind the vehicle that looks silver?", "program": "BOX0=LOC(image=IMAGE,object='silver vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='van')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7337, "imageId": "n181210", "question": "Are there any apples or oranges that are not unpeeled?", "program": "BOX0=LOC(image=IMAGE,object='apple')\nBOX1=LOC(image=IMAGE,object='orange')\nBOX2=LOC(image=IMAGE,object='unpeeled')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if ({ANSWER0} + {ANSWER1}) > {ANSWER2} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 7338, "imageId": "n131634", "question": "What vehicle is the van parked behind of?", "program": "BOX0=LOC(image=IMAGE,object='van')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is the van parked behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7339, "imageId": "n69237", "question": "Is there a chair in the photo that is giant?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nANSWER0=VQA(image=IMAGE,question='Is there a chair that is giant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7340, "imageId": "n162586", "question": "Are there both televisions and pictures in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='television')\nBOX1=LOC(image=IMAGE,object='picture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7341, "imageId": "n131634", "question": "What is the vehicle to the left of the vehicle that is made of metal called?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='metal')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7342, "imageId": "n451187", "question": "Which side is the man on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7343, "imageId": "n194179", "question": "What is the item of furniture to the left of the person that is sleeping?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sleeping')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7344, "imageId": "n329479", "question": "How clean do you think are the shoes?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean do you think are the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7345, "imageId": "n148872", "question": "What is the skinny girl holding?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the girl holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7346, "imageId": "n195249", "question": "Is the white logo antique or modern?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the white logo antique or modern?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7347, "imageId": "n518912", "question": "Which color is the chair the man is standing beside of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='Which color is the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7348, "imageId": "n518912", "question": "What is the item of furniture on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7349, "imageId": "n518912", "question": "Does the chair to the left of the cups look short and gold?", "program": "BOX0=LOC(image=IMAGE,object='cups')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=VQA(image=IMAGE0,question='What is the height of the chair?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gold' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7350, "imageId": "n545516", "question": "Is there a speaker above the pavement?", "program": "BOX0=LOC(image=IMAGE,object='pavement')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='speaker')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7351, "imageId": "n179136", "question": "Are the grouped people watching the surfer?", "program": "BOX0=LOC(image=IMAGE,object='surfer')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grouped people')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7352, "imageId": "n179136", "question": "Who are the people next to the tree watching?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='people')\nANSWER0=VQA(image=IMAGE0,question='Who are the people watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7353, "imageId": "n77818", "question": "Are the white book and the tissue box both rectangular?", "program": "BOX0=LOC(image=IMAGE,object='white book')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='tissue box')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What shape is the white book?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the tissue box?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'rectangular' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7354, "imageId": "n412144", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7355, "imageId": "n412144", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7356, "imageId": "n355339", "question": "What is in front of the device near the glass?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7357, "imageId": "n435808", "question": "What is located on top of the black computer underneath the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black computer')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='TOP')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What is located on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7358, "imageId": "n460385", "question": "What is the item of furniture that is made of same material as the table the silverware is on called?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture that is made of same material as the table the silverware is on called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7359, "imageId": "n222297", "question": "Do you see women or boys there?", "program": "BOX0=LOC(image=IMAGE,object='women')\nBOX1=LOC(image=IMAGE,object='boys')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7360, "imageId": "n460385", "question": "What type of furniture has the same color as the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nBOX1=LOC(image=IMAGE,object='furniture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='What color is the furniture?')\nANSWER2=EVAL(expr=\"'{ANSWER1}' if '{ANSWER0}' == '{ANSWER1}' else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7361, "imageId": "n235859", "question": "Which side of the picture is the light bulb on?", "program": "BOX0=LOC(image=IMAGE,object='light bulb')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7362, "imageId": "n77818", "question": "Is the printed book near the pepper grinder brown and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='pepper grinder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='printed book')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the printed book?')\nANSWER1=VQA(image=IMAGE1,question='What shape is the printed book?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7363, "imageId": "n25275", "question": "Are there any short fences or ladders?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='ladder')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7364, "imageId": "n35676", "question": "Does the appliance underneath the counter top look old or new?", "program": "BOX0=LOC(image=IMAGE,object='counter top')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='Does the appliance look old or new?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7365, "imageId": "n275148", "question": "On which side of the image is the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < {IMAGE}['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7366, "imageId": "n296467", "question": "What kind of vegetable is cylindrical?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vegetable is cylindrical?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7367, "imageId": "n479092", "question": "What are the forks inside of?", "program": "BOX0=LOC(image=IMAGE,object='forks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the forks inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7368, "imageId": "n256120", "question": "Which vehicle is metallic?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nANSWER0=VQA(image=IMAGE,question='Which vehicle is metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7369, "imageId": "n256120", "question": "What vehicle is metallic?", "program": "BOX0=LOC(image=IMAGE,object='metallic')\nANSWER0=VQA(image=IMAGE,question='What vehicle is metallic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7370, "imageId": "n256120", "question": "Which kind of vehicle is pink?", "program": "BOX0=LOC(image=IMAGE,object='pink vehicle')\nANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is pink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7371, "imageId": "n483840", "question": "Is the man to the right of a car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7372, "imageId": "n262920", "question": "Is the large device on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7373, "imageId": "n256120", "question": "Which kind of vehicle is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7374, "imageId": "n256120", "question": "Which vehicle is this?", "program": "ANSWER0=VQA(image=IMAGE,question='Which vehicle is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7375, "imageId": "n489699", "question": "What is the color of the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7376, "imageId": "n262920", "question": "What is the hanging device called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the hanging device called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7377, "imageId": "n571179", "question": "Is the man to the left of the woman?", "program": "BOX0=LOC(image=IMAGE,object='man')\nBOX1=LOC(image=IMAGE,object='woman')\nANSWER0=EVAL(expr=\"'yes' if {BOX0[0]} < {BOX1[0]} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7378, "imageId": "n501951", "question": "Are the helmet and the tool made of the same material?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the helmet made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the tool made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7379, "imageId": "n347706", "question": "What is the man sitting on?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7380, "imageId": "n546616", "question": "Is the blond woman on the right side or on the left?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='blond woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7381, "imageId": "n347706", "question": "What is the man to the right of the child sitting on?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='What is the man sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7382, "imageId": "n347706", "question": "Who is the man looking at?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7383, "imageId": "n363445", "question": "What item of furniture is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7384, "imageId": "n55058", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7385, "imageId": "n574498", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7386, "imageId": "n455563", "question": "Is the mug near the spray bottle black and large?", "program": "BOX0=LOC(image=IMAGE,object='spray bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mug')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the mug?')\nANSWER1=VQA(image=IMAGE1,question='How large is the mug?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7387, "imageId": "n51002", "question": "What shape is the device the keyboard is in front of?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7388, "imageId": "n206358", "question": "Is the sidewalk brown and clean?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sidewalk?')\nANSWER1=VQA(image=IMAGE0,question='Is the sidewalk clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7389, "imageId": "n455563", "question": "Is the mug near the woman small or large?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'small' if {ANSWER0} > 0 else 'large'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7390, "imageId": "n16656", "question": "What is the tree in front of?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tree in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7391, "imageId": "n326988", "question": "Are there remote controls or keyboards that are not small?", "program": "BOX0=LOC(image=IMAGE,object='remote control')\nBOX1=LOC(image=IMAGE,object='keyboard')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7392, "imageId": "n88366", "question": "Are there any orange skis or snowboards in the photo?", "program": "BOX0=LOC(image=IMAGE,object='ski')\nBOX1=LOC(image=IMAGE,object='snowboard')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7393, "imageId": "n525901", "question": "What device is below the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is below the laptop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7394, "imageId": "n204894", "question": "What is the name of the device to the right of the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7395, "imageId": "n119944", "question": "What is the skinny woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7396, "imageId": "n119944", "question": "Who is holding the brown basket?", "program": "BOX0=LOC(image=IMAGE,object='brown basket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the brown basket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7397, "imageId": "n12404", "question": "Does the concrete sidewalk look old?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the concrete sidewalk look old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7398, "imageId": "n449058", "question": "Who is riding a motorcycle?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is riding a motorcycle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7399, "imageId": "n65885", "question": "On which side of the image are the shelves?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7400, "imageId": "n334278", "question": "Where is the player that is to the left of the umpire standing on?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='player')\nANSWER0=VQA(image=IMAGE0,question='Where is the player standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7401, "imageId": "n501951", "question": "Is the helmet made of the same material as the table?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the helmet made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7402, "imageId": "n319845", "question": "Is the door closed or open?", "program": "BOX0=LOC(image=IMAGE,object='door')\nANSWER0=VQA(image=IMAGE,question='Is the door closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7403, "imageId": "n543966", "question": "What animals are on the dirt?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animals are on the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7404, "imageId": "n543966", "question": "What are the animals that are on the dirt?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the animals?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7405, "imageId": "n543966", "question": "What animal is on the dirt?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is on the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7406, "imageId": "n543966", "question": "Where are the elephants?", "program": "BOX0=LOC(image=IMAGE,object='elephants')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7407, "imageId": "n400036", "question": "Do the shoes seem to be small and black and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the shoes seem to be small and black and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7408, "imageId": "n95369", "question": "How large is the sink near the bathtub?", "program": "BOX0=LOC(image=IMAGE,object='bathtub')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sink')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the sink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7409, "imageId": "n194179", "question": "Are the trousers short and green?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the trousers short?')\nANSWER1=VQA(image=IMAGE,question='What color are the trousers?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'short' and {ANSWER1} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7410, "imageId": "n28572", "question": "On which side is the saucer?", "program": "BOX0=LOC(image=IMAGE,object='saucer')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7411, "imageId": "n528403", "question": "Does the shirt seem to be pink and small?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE,question='What size is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'pink' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7412, "imageId": "n451187", "question": "Do the vehicles to the left of the bench look white and metallic?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicles')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7413, "imageId": "n154856", "question": "What color is the window that is made of metal?", "program": "BOX0=LOC(image=IMAGE,object='metal window')\nANSWER0=VQA(image=IMAGE,question='What color is the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7414, "imageId": "n167552", "question": "Is the wood chair to the left or to the right of the shelf in the top of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='wood chair')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7415, "imageId": "n68769", "question": "What does the man wear?", "program": "ANSWER0=VQA(image=IMAGE,question='What does the man wear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7416, "imageId": "n172618", "question": "Is the girl to the right of the other girl young and short?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other girl')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the girl young and short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7417, "imageId": "n451187", "question": "Which kind of vehicle is parked?", "program": "BOX0=LOC(image=IMAGE,object='parked')\nANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is parked?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7418, "imageId": "n119886", "question": "Are there both a window and a door in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7419, "imageId": "n86120", "question": "How does the shirt look like, long sleeved or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How does the shirt look like, long sleeved or short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7420, "imageId": "n233607", "question": "Beside what is the table that looks brown and black sitting?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown and black sitting')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Beside what is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7421, "imageId": "n233607", "question": "Which kind of furniture is sitting beside the shelf?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is sitting beside the shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7422, "imageId": "n257997", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7423, "imageId": "n55058", "question": "How big is the serving dish in the center?", "program": "BOX0=LOC(image=IMAGE,object='center')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='serving dish')\nANSWER0=VQA(image=IMAGE0,question='How big is the serving dish?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7424, "imageId": "n229548", "question": "Does the helicopter look small?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the helicopter look small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7425, "imageId": "n296467", "question": "Are there both cookies and glasses in this picture?", "program": "BOX0=LOC(image=IMAGE,object='cookies')\nBOX1=LOC(image=IMAGE,object='glasses')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7426, "imageId": "n417401", "question": "What sits on the shelf?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What sits on the shelf?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7427, "imageId": "n95313", "question": "Are there pillows or paper towels in the image?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nBOX1=LOC(image=IMAGE,object='paper towels')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7428, "imageId": "n164272", "question": "Are the flowers underneath a horse?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='flowers')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7429, "imageId": "n202379", "question": "Are there both a fence and a hat in the image?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='hat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7430, "imageId": "n334278", "question": "The player that is to the left of the umpire is watching who?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='player')\nANSWER0=VQA(image=IMAGE0,question='Who is the player watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7431, "imageId": "n92308", "question": "Which side of the picture is the palm on?", "program": "BOX0=LOC(image=IMAGE,object='palm')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7432, "imageId": "n437064", "question": "What do the spoon and the fork have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the spoon and the fork have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7433, "imageId": "n305495", "question": "Are there any lamps behind him?", "program": "BOX0=LOC(image=IMAGE,object='him')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7434, "imageId": "n398429", "question": "What is located on top of the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the oven?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7435, "imageId": "n305495", "question": "Is the lamp on or off?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nANSWER0=VQA(image=IMAGE,question='Is the lamp on or off?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7436, "imageId": "n186491", "question": "What kind of vegetable does the bowl contain?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vegetable does the bowl contain?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7437, "imageId": "n314630", "question": "Which color is the small container?", "program": "BOX0=LOC(image=IMAGE,object='small container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the small container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7438, "imageId": "n579928", "question": "Which color does the sky above the grass have?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sky')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which color does the sky have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7439, "imageId": "n578564", "question": "Which color are the canisters that are made of metal?", "program": "BOX0=LOC(image=IMAGE,object='canisters')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color are the canisters?')\nANSWER1=EVAL(expr=\"'metal' if {ANSWER0} == 'silver' or {ANSWER0} == 'gray' else 'not metal'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7440, "imageId": "n432591", "question": "Is there any lamp in the image that is not off?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='off')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} - {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7441, "imageId": "n100552", "question": "What color is the fence?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the fence?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7442, "imageId": "n171169", "question": "Is the helmet different in color than the boot?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='boot')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the helmet?')\nANSWER1=VQA(image=IMAGE1,question='What color is the boot?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7443, "imageId": "n240666", "question": "Is the garbage bin below the light fixture next to the mirror?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='garbage bin')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7444, "imageId": "n302387", "question": "Which kind of furniture is to the left of the instrument?", "program": "BOX0=LOC(image=IMAGE,object='instrument')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is to the left of the instrument?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7445, "imageId": "n471866", "question": "Who in the image is walking?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7446, "imageId": "n171169", "question": "Is the color of the pipe the same as the polo shirt?", "program": "BOX0=LOC(image=IMAGE,object='pipe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='polo shirt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the pipe?')\nANSWER1=VQA(image=IMAGE1,question='What color is the polo shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7447, "imageId": "n319845", "question": "Are the trees both leafy and bright?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the trees leafy?')\nANSWER1=VQA(image=IMAGE,question='Are the trees bright?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7448, "imageId": "n240666", "question": "What is the color of the trash bin?", "program": "BOX0=LOC(image=IMAGE,object='trash bin')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the trash bin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7449, "imageId": "n331357", "question": "Is the small calf in the bottom part of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small calf')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7450, "imageId": "n240666", "question": "Are there any cans near the toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cans')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7451, "imageId": "n554880", "question": "What device is to the right of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the right of the lamp?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7452, "imageId": "n151768", "question": "Is there a woman in the image that is young?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nANSWER0=VQA(image=IMAGE,question='Is the woman young?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'young' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7453, "imageId": "n334278", "question": "Who is standing next to the umpire that is on the left side?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Who is standing next to the umpire?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7454, "imageId": "n51002", "question": "What's under the artwork?", "program": "BOX0=LOC(image=IMAGE,object='artwork')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is under the artwork?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7455, "imageId": "n12404", "question": "Is the sidewalk new and small?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the condition of the sidewalk?')\nANSWER1=VQA(image=IMAGE0,question='What is the size of the sidewalk?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'new' and {ANSWER1} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7456, "imageId": "n9856", "question": "What is the tree in front of?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tree in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7457, "imageId": "n51002", "question": "Which kind of device is under the artwork?", "program": "BOX0=LOC(image=IMAGE,object='artwork')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is under the artwork?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7458, "imageId": "n206785", "question": "Is the person to the right or to the left of the bag that sits on top of the cabinet?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='person')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7459, "imageId": "n411121", "question": "What animal is the male person carrying?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the male person carrying?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7460, "imageId": "n411121", "question": "The male person is carrying what animal?", "program": "BOX0=LOC(image=IMAGE,object='male person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The male person is carrying what animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7461, "imageId": "n54180", "question": "Is the small faucet in the bottom part of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small faucet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7462, "imageId": "n305495", "question": "Do you see any boys near the couch in the image?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='boys')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7463, "imageId": "n83784", "question": "Which kind of furniture is above the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is above the carpet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7464, "imageId": "n499081", "question": "What's in front of the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7465, "imageId": "n162586", "question": "Does the woman seem to be cooking or sleeping?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the woman seem to be cooking or sleeping?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7466, "imageId": "n83784", "question": "Which kind of furniture is on top of the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is on top of the carpet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7467, "imageId": "n162586", "question": "What is this woman on?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is this woman on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7468, "imageId": "n511913", "question": "How big are the blinds?", "program": "BOX0=LOC(image=IMAGE,object='blinds')\nANSWER0=VQA(image=IMAGE,question='How big are the blinds?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7469, "imageId": "n162586", "question": "What item of furniture is the woman on?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is the woman on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7470, "imageId": "n468864", "question": "Is the black hair curly or straight?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the black hair curly or straight?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7471, "imageId": "n181355", "question": "What is the color of the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7472, "imageId": "n39114", "question": "Are there any umbrellas or benches in the picture?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nBOX1=LOC(image=IMAGE,object='bench')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7473, "imageId": "n293477", "question": "Does the wallet have small size?", "program": "ANSWER0=VQA(image=IMAGE,question='What size is the wallet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7474, "imageId": "n39114", "question": "Is the grass behind a bear?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7475, "imageId": "n434283", "question": "Is the tie above the garbage black or tan?", "program": "BOX0=LOC(image=IMAGE,object='garbage')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tie')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} > 0 else 'tan'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7476, "imageId": "n386688", "question": "Are the boats still?", "program": "BOX0=LOC(image=IMAGE,object='boats')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7477, "imageId": "n501609", "question": "Is the sink that is not turned on silver and curved?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sink?')\nANSWER1=VQA(image=IMAGE0,question='Is the sink curved?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7478, "imageId": "n293477", "question": "What's the wallet made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the wallet made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7479, "imageId": "n293477", "question": "Is the wallet small and beige?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the wallet small?')\nANSWER1=VQA(image=IMAGE,question='What color is the wallet?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'small' and {ANSWER1} == 'beige' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7480, "imageId": "n65885", "question": "Which kind of furniture is behind the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is behind the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7481, "imageId": "n143672", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7482, "imageId": "n54424", "question": "What is the designed piece of clothing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the designed piece of clothing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7483, "imageId": "n398257", "question": "What is on the shelf made of wood?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wood')\nANSWER0=VQA(image=IMAGE0,question='What is on the shelf?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7484, "imageId": "n153118", "question": "Do the bare trees look wooden and tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the bare trees look wooden?')\nANSWER1=VQA(image=IMAGE,question='Do the bare trees look tall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7485, "imageId": "n173807", "question": "The street is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The street is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7486, "imageId": "n173807", "question": "What is the street in front of?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the street in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7487, "imageId": "n140421", "question": "Is the freezer in front of the counter top tall and white?", "program": "BOX0=LOC(image=IMAGE,object='counter top')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='freezer')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='tall')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nBOX3=LOC(image=IMAGE0,object='white')\nANSWER4=COUNT(box=BOX3)\nANSWER5=EVAL(expr=\"'yes' if {ANSWER4} > 0 else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 7488, "imageId": "n162148", "question": "Does the remote have the same color as the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='remote')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the remote?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7489, "imageId": "n500209", "question": "Do you think the squash is raw?", "program": "ANSWER0=VQA(image=IMAGE,question='Do you think the squash is raw?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7490, "imageId": "n240666", "question": "Is the glass mirror on the left of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glass mirror')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7491, "imageId": "n538684", "question": "Who is waiting?", "program": "BOX0=LOC(image=IMAGE,object='waiting')\nANSWER0=VQA(image=IMAGE,question='Who is waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7492, "imageId": "n23181", "question": "Is the lamp on the right side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7493, "imageId": "n66756", "question": "What is the batter holding onto?", "program": "BOX0=LOC(image=IMAGE,object='batter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the batter holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7494, "imageId": "n336443", "question": "Is the table made of wood large or small?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE0,question='Is the table large or small?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7495, "imageId": "n357784", "question": "What is the device that she is holding onto called?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is she holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7496, "imageId": "n204894", "question": "Which color is the curtain?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the curtain?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7497, "imageId": "n406334", "question": "What are the buildings in front of?", "program": "BOX0=LOC(image=IMAGE,object='buildings')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the buildings in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7498, "imageId": "n578564", "question": "Do the containers to the left of the toaster look metallic and white?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='containers')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color are the containers?')\nANSWER1=VQA(image=IMAGE1,question='What material are the containers made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7499, "imageId": "n489190", "question": "Is there a skateboarder in the photograph that is male?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the skateboarder male?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7500, "imageId": "n263180", "question": "Are there any buses or fences in this picture?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7501, "imageId": "n489190", "question": "Who is crouching?", "program": "BOX0=LOC(image=IMAGE,object='crouching')\nANSWER0=VQA(image=IMAGE,question='Who is crouching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7502, "imageId": "n234683", "question": "Does the telephone look black and old?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the telephone?')\nANSWER1=VQA(image=IMAGE,question='Does the telephone look old?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7503, "imageId": "n477702", "question": "Who is wearing the vest?", "program": "BOX0=LOC(image=IMAGE,object='vest')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the vest?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7504, "imageId": "n302387", "question": "Is the luggage black and huge?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the luggage?')\nANSWER1=VQA(image=IMAGE,question='How big is the luggage?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'huge' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7505, "imageId": "n98544", "question": "Are there any towels next to the white sink?", "program": "BOX0=LOC(image=IMAGE,object='white sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towels')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7506, "imageId": "n69237", "question": "What type of furniture is the same color as the small bag on the floor?", "program": "BOX0=LOC(image=IMAGE,object='small bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the small bag?')\nBOX1=LOC(image=IMAGE,object='furniture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER1=VQA(image=IMAGE1,question='What type of furniture is the same color as the small bag?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7507, "imageId": "n309148", "question": "What kind of vehicle is parked on the street?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vehicle is parked on the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7508, "imageId": "n240666", "question": "Does the sink underneath the mirror have large size and white color?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sink')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='sink')\nIMAGE1=CROP(image=IMAGE0,box=BOX2)\nANSWER2=VQA(image=IMAGE1,question='What color is the sink?')\nANSWER3=VQA(image=IMAGE1,question='How large is the sink?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'white' and {ANSWER3} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 7509, "imageId": "n69237", "question": "Is it outdoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it outdoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7510, "imageId": "n434283", "question": "Is the tie above the trash both long and blue?", "program": "BOX0=LOC(image=IMAGE,object='trash')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='tie')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color is the tie?')\nANSWER3=VQA(image=IMAGE0,question='Is the tie long?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'blue' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 7511, "imageId": "n14087", "question": "What's in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7512, "imageId": "n14087", "question": "What is in front of the wood wall?", "program": "BOX0=LOC(image=IMAGE,object='wood wall')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the wood wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7513, "imageId": "n97485", "question": "What are the utensils inside of?", "program": "BOX0=LOC(image=IMAGE,object='utensils')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the utensils inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7514, "imageId": "n204894", "question": "Is there either any black phone or remote control?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nBOX1=LOC(image=IMAGE,object='remote control')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7515, "imageId": "n472825", "question": "Which color is the vehicle to the left of the skateboarder?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which color is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7516, "imageId": "n579928", "question": "Of which color is the tail?", "program": "BOX0=LOC(image=IMAGE,object='tail')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Of which color is the tail?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7517, "imageId": "n282607", "question": "Are there any scarves?", "program": "BOX0=LOC(image=IMAGE,object='scarf')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7518, "imageId": "n54180", "question": "What kind of device is the man using?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of device is the man using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7519, "imageId": "n475030", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7520, "imageId": "n565418", "question": "Are the trees behind the wood fence?", "program": "BOX0=LOC(image=IMAGE,object='wood fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7521, "imageId": "n263180", "question": "Are the clouds white and bright?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the clouds?')\nANSWER1=VQA(image=IMAGE,question='Are the clouds bright?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7522, "imageId": "n250715", "question": "Does the chair look black and small?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the chair?')\nANSWER1=VQA(image=IMAGE,question='Does the chair look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7523, "imageId": "n541482", "question": "Is the woman wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the woman wearing glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7524, "imageId": "n329479", "question": "What color is the skateboard the man is using?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the skateboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7525, "imageId": "n90944", "question": "What is the sand surrounded by?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sand surrounded by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7526, "imageId": "n278312", "question": "What pieces of furniture is the microwave oven hanging from?", "program": "BOX0=LOC(image=IMAGE,object='microwave oven')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7527, "imageId": "n315887", "question": "Is the speaker to the left or to the right of the device the phone is in front of?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='speaker')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7528, "imageId": "n293477", "question": "Are the pens lying on top of a coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pens')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7529, "imageId": "n494918", "question": "Are there any frisbees or ropes that are thin?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nBOX1=LOC(image=IMAGE,object='rope')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7530, "imageId": "n578564", "question": "Where in the picture is the wood picture, on the right or on the left?", "program": "BOX0=LOC(image=IMAGE,object='wood picture')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='wood picture')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7531, "imageId": "n217003", "question": "Who is riding?", "program": "BOX0=LOC(image=IMAGE,object='riding')\nANSWER0=VQA(image=IMAGE,question='Who is riding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7532, "imageId": "n222915", "question": "Which kind of furniture is the mat sitting on?", "program": "BOX0=LOC(image=IMAGE,object='mat')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the mat sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7533, "imageId": "n186491", "question": "Which color is the table?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7534, "imageId": "n293477", "question": "What type of furniture are the pens that are black and yellow lying on top of, a bed or a desk?", "program": "BOX0=LOC(image=IMAGE,object='black and yellow pens')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nBOX2=LOC(image=IMAGE0,object='desk')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'bed' if {ANSWER0} > 0 else 'desk'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7535, "imageId": "n578564", "question": "Are the paper towels behind the jar made of glass?", "program": "BOX0=LOC(image=IMAGE,object='jar')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='paper towels')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material are the paper towels made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'glass' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7536, "imageId": "n488874", "question": "What do you think is the watercraft that is lying next to the beach?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watercraft')\nANSWER0=VQA(image=IMAGE0,question='What do you think is the watercraft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7537, "imageId": "n411121", "question": "Behind what vehicle is the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7538, "imageId": "n497658", "question": "What color is the logo?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the logo?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7539, "imageId": "n326988", "question": "Is that remote on top of a DVD player?", "program": "BOX0=LOC(image=IMAGE,object='DVD player')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='remote')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7540, "imageId": "n488874", "question": "Which kind of watercraft is assorted?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of watercraft is assorted?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7541, "imageId": "n489699", "question": "How is the weather in this scene?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather in this scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7542, "imageId": "n411121", "question": "What is the vehicle that the building is behind?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7543, "imageId": "n488874", "question": "Which kind of watercraft is behind the beach?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='watercraft')\nANSWER0=VQA(image=IMAGE0,question='Which kind of watercraft is behind the beach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7544, "imageId": "n488874", "question": "What is the watercraft behind the beach that the surfer is walking across?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surfer')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='watercraft')\nANSWER0=VQA(image=IMAGE1,question='What is the watercraft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7545, "imageId": "n54180", "question": "What is the white sink below the shelf made of?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white sink')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the white sink made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7546, "imageId": "n246334", "question": "Does the bed sheet have the same color as the pillow?", "program": "BOX0=LOC(image=IMAGE,object='bed sheet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='pillow')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bed sheet?')\nANSWER1=VQA(image=IMAGE1,question='What color is the pillow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7547, "imageId": "n246334", "question": "Does the mirror look small and round?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the mirror look small and round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7548, "imageId": "n223750", "question": "Is the person in front of the bushes wearing a necklace?", "program": "BOX0=LOC(image=IMAGE,object='bushes')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the person wearing a necklace?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7549, "imageId": "n14", "question": "How tall is the skateboarder?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How tall is the skateboarder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7550, "imageId": "n346247", "question": "What is the size of the school?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the size of the school?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7551, "imageId": "n549922", "question": "Does the counter have a different color than the cable?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cable')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the counter?')\nANSWER1=VQA(image=IMAGE1,question='What color is the cable?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7552, "imageId": "n363445", "question": "Do the carrots look healthy and green?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the carrots look healthy?')\nANSWER1=VQA(image=IMAGE,question='What color are the carrots?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7553, "imageId": "n223750", "question": "Who is wearing the skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7554, "imageId": "n386682", "question": "What color is the dishwasher?", "program": "BOX0=LOC(image=IMAGE,object='dishwasher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the dishwasher?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7555, "imageId": "n541854", "question": "Does the fruit on the tray look brown or green?", "program": "BOX0=LOC(image=IMAGE,object='tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruit')\nANSWER0=VQA(image=IMAGE0,question='What color is the fruit?')\nANSWER1=EVAL(expr=\"'brown' if {ANSWER0} == 'brown' else 'green'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7556, "imageId": "n570181", "question": "Of what color are the pants that the umpire wears?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Of what color are the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7557, "imageId": "n541854", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7558, "imageId": "n90944", "question": "What is the sand in front of?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sand in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7559, "imageId": "n260762", "question": "Is the person on the field wearing a uniform?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the person wearing a uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7560, "imageId": "n260762", "question": "Who is throwing the frisbee that looks white?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is throwing the frisbee?')\nANSWER1=VQA(image=IMAGE0,question='What color is the frisbee?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if {ANSWER1} == 'white' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7561, "imageId": "n567860", "question": "What fruit has the same color as the banana bunch?", "program": "BOX0=LOC(image=IMAGE,object='banana bunch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the banana bunch?')\nBOX1=LOC(image=IMAGE,object='fruit')\nANSWER1=VQA(image=IMAGE,question='What color is the {BOX1}?')\nANSWER2=EVAL(expr=\"'{BOX1}' if {ANSWER0} == {ANSWER1} else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7562, "imageId": "n507149", "question": "Which tone is the kite, light or dark?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which tone is the kite?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7563, "imageId": "n507149", "question": "Is the kite above the person long and light?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='kite')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the kite long and light?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7564, "imageId": "n98544", "question": "Does the shelf look wooden and white?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shelf?')\nANSWER1=VQA(image=IMAGE0,question='What material is the shelf made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7565, "imageId": "n318370", "question": "Is the bottle near the person open or closed?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle')\nANSWER0=VQA(image=IMAGE0,question='Is the bottle open or closed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7566, "imageId": "n498140", "question": "Are there suitcases or carts?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nBOX1=LOC(image=IMAGE,object='cart')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7567, "imageId": "n363445", "question": "Is the food container made of the same material as the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food container')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the food container made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7568, "imageId": "n363445", "question": "Is the food container made of the same material as the fork?", "program": "BOX0=LOC(image=IMAGE,object='food container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fork')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the food container made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the fork made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7569, "imageId": "n23181", "question": "What item of furniture is sturdy?", "program": "ANSWER0=VQA(image=IMAGE,question='What item of furniture is sturdy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7570, "imageId": "n363445", "question": "Which seem to be less healthy, the hot dogs or the carrots?", "program": "ANSWER0=VQA(image=IMAGE,question='Which seem to be less healthy, the hot dogs or the carrots?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7571, "imageId": "n363445", "question": "Which are less healthy, the hot dogs or the apples?", "program": "ANSWER0=VQA(image=IMAGE,question='Which are less healthy, the hot dogs or the apples?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7572, "imageId": "n207708", "question": "Is concrete used to make that floor?", "program": "ANSWER0=VQA(image=IMAGE,question='Is concrete used to make that floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7573, "imageId": "n210269", "question": "What animals are it?", "program": "BOX0=LOC(image=IMAGE,object='animals')\nANSWER0=VQA(image=IMAGE,question='What animals are it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7574, "imageId": "n513429", "question": "On which side of the picture is the glass bottle?", "program": "BOX0=LOC(image=IMAGE,object='glass bottle')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7575, "imageId": "n260521", "question": "On which side is the bronze statue?", "program": "BOX0=LOC(image=IMAGE,object='bronze statue')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7576, "imageId": "n480253", "question": "What is the wire connected to?", "program": "BOX0=LOC(image=IMAGE,object='wire')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the wire connected to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7577, "imageId": "n390187", "question": "What is on the motorbike that the person is riding?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorbike')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is on the motorbike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7578, "imageId": "n437064", "question": "Is there a cake or a sandwich in this picture?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nBOX1=LOC(image=IMAGE,object='sandwich')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7579, "imageId": "n369970", "question": "Is the forest dry or wet?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the forest dry or wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7580, "imageId": "n64959", "question": "What is the appliance to the right of the container that is smaller than the vacuum?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vacuum')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What is the appliance?')\nANSWER1=EVAL(expr=\"'yes' if {BOX2.width} < {BOX1.width} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7581, "imageId": "n572716", "question": "Is the little building in between the tall trees near the crane?", "program": "BOX0=LOC(image=IMAGE,object='crane')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='little building')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='tall trees')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7582, "imageId": "n67005", "question": "What do both the door and the mirror have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the door and the mirror have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7583, "imageId": "n499081", "question": "Which color does the mirror that is made of metal have?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7584, "imageId": "n14087", "question": "Which kind of furniture is this?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7585, "imageId": "n573460", "question": "Does the player hold a bat?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bat')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7586, "imageId": "n14087", "question": "What kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7587, "imageId": "n272098", "question": "What is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7588, "imageId": "n480253", "question": "Are the brown trees behind the vehicle that is parked along the street?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7589, "imageId": "n257997", "question": "What are the people on the grass doing, talking or playing?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the people on the grass doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7590, "imageId": "n532191", "question": "Is the chair to the right or to the left of the black bag?", "program": "BOX0=LOC(image=IMAGE,object='black bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7591, "imageId": "n206358", "question": "Are there men near the wall the newspaper is on top of?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='newspaper')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='men')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7592, "imageId": "n4777", "question": "Which color is the chair to the left of the laptop, brown or green?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=VQA(image=IMAGE0,question='What color is the chair?')\nANSWER1=EVAL(expr=\"'brown' if {ANSWER0} == 'brown' else 'green'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7593, "imageId": "n259002", "question": "Does the car that is not large look closed?", "program": "BOX0=LOC(image=IMAGE,object='car')\nBOX1=LOC(image=IMAGE,object='large')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the car look closed?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7594, "imageId": "n548534", "question": "Which kind of furniture is on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7595, "imageId": "n65866", "question": "In which part of the photo is the drawer, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nBOX1=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='drawer')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7596, "imageId": "n541854", "question": "Does the hard table look small and round?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the hard table look small and round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7597, "imageId": "n295771", "question": "Does the sky have dark tone?", "program": "ANSWER0=VQA(image=IMAGE,question='What tone does the sky have?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7598, "imageId": "n259002", "question": "What kind of vehicle is behind the small trash can?", "program": "BOX0=LOC(image=IMAGE,object='small trash can')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is behind the small trash can?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7599, "imageId": "n65866", "question": "Does the drawer in the cabinet look square and brown?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drawer')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What shape is the drawer?')\nANSWER1=VQA(image=IMAGE1,question='What color is the drawer?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'square' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7600, "imageId": "n170941", "question": "How is the meat that is long called?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the meat that is long called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7601, "imageId": "n522733", "question": "Of what color is the car that is to the right of the other car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='car')\nANSWER0=VQA(image=IMAGE1,question='Of what color is the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7602, "imageId": "n432591", "question": "Is the nightstand on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='nightstand')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7603, "imageId": "n543966", "question": "What animals are dry?", "program": "BOX0=LOC(image=IMAGE,object='animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animals are dry?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7604, "imageId": "n83784", "question": "What does the cat sit atop?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the cat sit atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7605, "imageId": "n314171", "question": "How big is she?", "program": "ANSWER0=VQA(image=IMAGE,question='How big is she?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7606, "imageId": "n146522", "question": "What is hitting the ball that he is playing with?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hitting the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7607, "imageId": "n499081", "question": "Is the color of the sink the same as the color of the picture frame?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='picture frame')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the sink?')\nANSWER1=VQA(image=IMAGE1,question='What color is the picture frame?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7608, "imageId": "n35676", "question": "The countertop that is made of granite has which color?", "program": "BOX0=LOC(image=IMAGE,object='granite countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7609, "imageId": "n363445", "question": "What is the fork made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the fork made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7610, "imageId": "n37274", "question": "Which kind of appliance is half full?", "program": "BOX0=LOC(image=IMAGE,object='half full')\nANSWER0=VQA(image=IMAGE,question='Which kind of appliance is half full?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7611, "imageId": "n37274", "question": "What kind of appliance is electric?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of appliance is electric?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7612, "imageId": "n357784", "question": "Is the bottle cap on the right side?", "program": "BOX0=LOC(image=IMAGE,object='bottle cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7613, "imageId": "n543966", "question": "Which kind of animal is standing?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7614, "imageId": "n280089", "question": "On which side of the photo is the bowl?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7615, "imageId": "n357784", "question": "Is the bottle cap on top of the bottle both closed and white?", "program": "BOX0=LOC(image=IMAGE,object='bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bottle cap')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the bottle cap closed?')\nANSWER1=VQA(image=IMAGE1,question='What color is the bottle cap?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7616, "imageId": "n382416", "question": "Is the suitcase that looks square large and brown?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the suitcase large?')\nANSWER1=VQA(image=IMAGE0,question='What color is the suitcase?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'large' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7617, "imageId": "n154160", "question": "Who wears trousers?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7618, "imageId": "n534106", "question": "On which side is the bag?", "program": "BOX0=LOC(image=IMAGE,object='bag')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7619, "imageId": "n154160", "question": "Who wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who wears a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7620, "imageId": "n159284", "question": "Is he wearing a cap?", "program": "BOX0=LOC(image=IMAGE,object='cap')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7621, "imageId": "n159284", "question": "Who is wearing a cap?", "program": "BOX0=LOC(image=IMAGE,object='cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a cap?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7622, "imageId": "n159284", "question": "Who is wearing the cap?", "program": "BOX0=LOC(image=IMAGE,object='cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the cap?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7623, "imageId": "n159284", "question": "Where is this boy?", "program": "ANSWER0=VQA(image=IMAGE,question='Where is this boy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7624, "imageId": "n159284", "question": "Where is the boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nANSWER0=VQA(image=IMAGE,question='Where is the boy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7625, "imageId": "n450919", "question": "Which kind of animal is sitting?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7626, "imageId": "n51002", "question": "What is the device behind the keyboard made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What is the device made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7627, "imageId": "n527589", "question": "What is the name of the fruits below the person that is wearing an earring?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fruits')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the name of the fruits?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7628, "imageId": "n344136", "question": "What kind of furniture is the wall behind of?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is behind the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7629, "imageId": "n262929", "question": "What color is the shirt near the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shirt')\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7630, "imageId": "n141939", "question": "The tissue is in what?", "program": "BOX0=LOC(image=IMAGE,object='tissue')\nANSWER0=VQA(image=IMAGE,question='The tissue is in what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7631, "imageId": "n275148", "question": "Is the couch to the left or to the right of the black device?", "program": "BOX0=LOC(image=IMAGE,object='black device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7632, "imageId": "n124651", "question": "Is it an indoors scene?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an indoors scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7633, "imageId": "n501609", "question": "Is there a black microwave or dishwasher?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nBOX1=LOC(image=IMAGE,object='dishwasher')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7634, "imageId": "n520071", "question": "What type of furniture is to the left of the books near the water bottle?", "program": "BOX0=LOC(image=IMAGE,object='books')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='water bottle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nANSWER0=VQA(image=IMAGE1,question='What type of furniture is to the left of the books?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7635, "imageId": "n435808", "question": "What device is sitting on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is sitting on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7636, "imageId": "n386688", "question": "Is the airplane that looks white dirty or clean?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the airplane?')\nANSWER1=EVAL(expr=\"'dirty' if {ANSWER0} == 'white' else 'clean'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7637, "imageId": "n382416", "question": "Are there children near the skinny woman that is wearing heels?", "program": "BOX0=LOC(image=IMAGE,object='skinny woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='heels')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='children')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7638, "imageId": "n335542", "question": "What is the snow covering?", "program": "BOX0=LOC(image=IMAGE,object='snow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the snow covering?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7639, "imageId": "n335542", "question": "What is the white snow covering?", "program": "BOX0=LOC(image=IMAGE,object='white snow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the white snow covering?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7640, "imageId": "n520071", "question": "What is the cat on?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the cat on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7641, "imageId": "n435808", "question": "Does the monitor to the left of the mouse have silver color?", "program": "BOX0=LOC(image=IMAGE,object='mouse')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='monitor')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the monitor?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7642, "imageId": "n435808", "question": "What is sitting on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7643, "imageId": "n548534", "question": "What is the container made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the container made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7644, "imageId": "n369970", "question": "Does the snowy ground look wet?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the snowy ground look wet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7645, "imageId": "n28572", "question": "The menu is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='menu')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The menu is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7646, "imageId": "n544255", "question": "What kind of animal is under the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is under the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7647, "imageId": "n548534", "question": "What is the container sitting on?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surface')\nANSWER0=VQA(image=IMAGE0,question='What is the container sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7648, "imageId": "n317260", "question": "Is the fence made out of brick or aluminum?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='What material is the fence made of?')\nANSWER1=EVAL(expr=\"'brick' if 'brick' in {ANSWER0} else 'aluminum'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7649, "imageId": "n317260", "question": "Are the coach and the person in front of the catcher both standing?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='coach')\nANSWER0=COUNT(box=BOX1)\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7650, "imageId": "n211324", "question": "Is the bicycle to the left of the baby colorful and small?", "program": "BOX0=LOC(image=IMAGE,object='baby')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bicycle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER2=VQA(image=IMAGE1,question='Is the bicycle colorful and small?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 7651, "imageId": "n211324", "question": "Does the bicycle on the walkway look colorful?", "program": "BOX0=LOC(image=IMAGE,object='walkway')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bicycle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the bicycle look colorful?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'colorful' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7652, "imageId": "n187544", "question": "Is the frisbee pink?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the frisbee?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'pink' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7653, "imageId": "n542609", "question": "How large is the train station the train is parked at?", "program": "BOX0=LOC(image=IMAGE,object='train')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='train station')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the train station?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7654, "imageId": "n336443", "question": "What kind of meat is on the plate?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of meat is on the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7655, "imageId": "n208458", "question": "How tall is the dock that goes into the ocean?", "program": "BOX0=LOC(image=IMAGE,object='ocean')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dock')\nANSWER0=VQA(image=IMAGE0,question='How tall is the dock?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7656, "imageId": "n164272", "question": "Does the cow above the grass look small?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cow')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the cow look small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7657, "imageId": "n310828", "question": "What is the item of furniture that the laptop is on called?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7658, "imageId": "n77818", "question": "What animal is to the left of the entertainment center?", "program": "BOX0=LOC(image=IMAGE,object='entertainment center')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is to the left of the entertainment center?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7659, "imageId": "n312206", "question": "Is the woman Asian?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the woman Asian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7660, "imageId": "n148872", "question": "Who is wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7661, "imageId": "n148872", "question": "Who is wearing the glasses?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the glasses?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7662, "imageId": "n148872", "question": "Who do you think is wearing sneakers?", "program": "BOX0=LOC(image=IMAGE,object='sneakers')\nANSWER0=VQA(image=IMAGE,question='Who is wearing sneakers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7663, "imageId": "n12404", "question": "Is the small cone behind the person that is playing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='playing')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='small cone')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7664, "imageId": "n355567", "question": "Is the clock to the right or to the left of the person that the lady is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lady')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='clock')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7665, "imageId": "n9181", "question": "Are there either any black skateboards or motorcycles?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nBOX1=LOC(image=IMAGE,object='motorcycle')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7666, "imageId": "n118102", "question": "Is she looking at a cell phone?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cell phone')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7667, "imageId": "n541688", "question": "Is the toothbrush to the left of the boy yellow or blue?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toothbrush')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yellow' if {ANSWER0} > 0 else 'blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7668, "imageId": "n508641", "question": "Are there both paper dispensers and helmets in this scene?", "program": "BOX0=LOC(image=IMAGE,object='paper dispenser')\nBOX1=LOC(image=IMAGE,object='helmet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7669, "imageId": "n525901", "question": "Is the office chair on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='office chair')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7670, "imageId": "n44249", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7671, "imageId": "n520071", "question": "Which kind of furniture is stacked?", "program": "BOX0=LOC(image=IMAGE,object='stacked furniture')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'chair' if {ANSWER0} > 0 else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7672, "imageId": "n67005", "question": "What kind of device is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7673, "imageId": "n187961", "question": "What is the brown animal?", "program": "BOX0=LOC(image=IMAGE,object='brown animal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the brown animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7674, "imageId": "n186491", "question": "How is the food to the left of the drink in the middle of the photo called?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drink')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nANSWER0=VQA(image=IMAGE1,question='How is the food called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7675, "imageId": "n67005", "question": "What is the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7676, "imageId": "n357784", "question": "Do you see any cat in front of the person that is in front of the mirror?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP_FRONTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='cat')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7677, "imageId": "n67005", "question": "What is the adult person holding?", "program": "BOX0=LOC(image=IMAGE,object='adult person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the adult person holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7678, "imageId": "n480253", "question": "What vehicle is shiny?", "program": "BOX0=LOC(image=IMAGE,object='shiny')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What vehicle is shiny?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7679, "imageId": "n264887", "question": "Is this desk both wooden and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Is this desk wooden?')\nANSWER1=VQA(image=IMAGE,question='Is this desk large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7680, "imageId": "n6309", "question": "What is in front of the horse that is attached to the cart?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cart')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the horse?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7681, "imageId": "n14", "question": "What size is the motorbike the skateboarder is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorbike')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What size is the motorbike?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7682, "imageId": "n469156", "question": "Is there any helmet to the left of the skateboard on the right side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='helmet')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7683, "imageId": "n159802", "question": "On which side is the adult man?", "program": "BOX0=LOC(image=IMAGE,object='adult man')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7684, "imageId": "n259949", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7685, "imageId": "n240973", "question": "Which kind of furniture is sitting on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is sitting on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7686, "imageId": "n49310", "question": "Are the glasses to the left or to the right of the person the woman is sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='glasses')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7687, "imageId": "n526228", "question": "Do you see any men to the right of the side table?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='men')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7688, "imageId": "n16656", "question": "What is the cat doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the cat doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7689, "imageId": "n240973", "question": "What are the shelves that are made of wood sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelves')\nANSWER0=VQA(image=IMAGE0,question='What are the shelves sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7690, "imageId": "n429883", "question": "Which color is the man's beard?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the man\\'s beard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7691, "imageId": "n6908", "question": "What type of furniture is in front of the Christmas light?", "program": "BOX0=LOC(image=IMAGE,object='Christmas light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is in front of the Christmas light?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7692, "imageId": "n540852", "question": "Is the umbrella in the bottom part of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='umbrella')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7693, "imageId": "n258500", "question": "Do the speakers look high and white?", "program": "BOX0=LOC(image=IMAGE,object='speakers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the speakers?')\nANSWER1=VQA(image=IMAGE0,question='Do the speakers look high?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7694, "imageId": "n541482", "question": "Who is holding the kite?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the kite?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7695, "imageId": "n541482", "question": "What's the woman holding?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7696, "imageId": "n256120", "question": "What is the color of the jacket that is not short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the jacket?')\nANSWER1=VQA(image=IMAGE0,question='Is the jacket short sleeved?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if {ANSWER1} == 'no' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7697, "imageId": "n578564", "question": "In which part of the picture is the toaster, the top or the bottom?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7698, "imageId": "n6908", "question": "What is the chair sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the chair sitting next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7699, "imageId": "n200225", "question": "Do you see a red pepper or tomato?", "program": "BOX0=LOC(image=IMAGE,object='red pepper')\nBOX1=LOC(image=IMAGE,object='tomato')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7700, "imageId": "n240666", "question": "What is the color of the mat?", "program": "BOX0=LOC(image=IMAGE,object='mat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the mat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7701, "imageId": "n314630", "question": "What kind of appliance do you think is to the left of the container that is beside the knives?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knives')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='appliance')\nANSWER0=VQA(image=IMAGE1,question='What kind of appliance is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7702, "imageId": "n6908", "question": "What is this chair sitting next to?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is this chair sitting next to?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7703, "imageId": "n282436", "question": "What animal is sitting on the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is sitting on the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7704, "imageId": "n331357", "question": "What type of animal is the same color as the building next to the mountain?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mountain')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the mountain?')\nANSWER1=VQA(image=IMAGE,question='What type of animal is the same color as the mountain?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7705, "imageId": "n52544", "question": "On which side is the bucket?", "program": "BOX0=LOC(image=IMAGE,object='bucket')\nBOX1=LOC(image=IMAGE,object='LEFT')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7706, "imageId": "n232810", "question": "Are the shoes brown?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shoes?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7707, "imageId": "n281241", "question": "What kind of furniture is to the right of the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What kind of furniture is there?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7708, "imageId": "n534106", "question": "The young person sits atop what?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The young person sits atop what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7709, "imageId": "n234683", "question": "What's the man holding?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7710, "imageId": "n331357", "question": "What do both the building and the calf have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the building and the calf have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7711, "imageId": "n524855", "question": "What is standing at the mountains?", "program": "ANSWER0=VQA(image=IMAGE,question='What is standing at the mountains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7712, "imageId": "n206358", "question": "What's the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7713, "imageId": "n524855", "question": "Where are the green trees standing?", "program": "BOX0=LOC(image=IMAGE,object='green trees')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7714, "imageId": "n500308", "question": "Are the round glasses inside the appliance next to the window?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='round glasses')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7715, "imageId": "n415215", "question": "The long sleeved shirt has which color?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the long sleeved shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7716, "imageId": "n296467", "question": "How thick is the food inside the container?", "program": "BOX0=LOC(image=IMAGE,object='container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How thick is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7717, "imageId": "n415215", "question": "Is the shirt long sleeved and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the shirt long sleeved?')\nANSWER1=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7718, "imageId": "n206358", "question": "Is the person that is looking down young or old?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person looking down young or old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7719, "imageId": "n279173", "question": "The person is on what?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The person is on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7720, "imageId": "n570181", "question": "Who is standing before the catcher?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing before the catcher?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7721, "imageId": "n200692", "question": "What appliance is black?", "program": "BOX0=LOC(image=IMAGE,object='black')\nANSWER0=VQA(image=IMAGE,question='What appliance is black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7722, "imageId": "n59147", "question": "Which item of furniture is not wide, the table or the chair?", "program": "BOX0=LOC(image=IMAGE,object='table')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=VQA(image=IMAGE,question='How wide is the table?')\nANSWER1=VQA(image=IMAGE,question='How wide is the chair?')\nANSWER2=EVAL(expr=\"'table' if {ANSWER0} < {ANSWER1} else 'chair'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7723, "imageId": "n283587", "question": "What kind of furniture is below the overhead light fixture?", "program": "BOX0=LOC(image=IMAGE,object='overhead light fixture')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is below the overhead light fixture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7724, "imageId": "n481655", "question": "Is there a bat in the image that is black?", "program": "BOX0=LOC(image=IMAGE,object='bat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7725, "imageId": "n283587", "question": "In front of what's the sofa?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='In front of what is the sofa?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7726, "imageId": "n414992", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7727, "imageId": "n290409", "question": "What vehicle is behind the logo?", "program": "BOX0=LOC(image=IMAGE,object='logo')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is behind the logo?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7728, "imageId": "n352479", "question": "Who is wearing the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7729, "imageId": "n312206", "question": "Which shape do you think is the food the woman is behind of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which shape is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7730, "imageId": "n312206", "question": "What's located on top of the chocolate?", "program": "BOX0=LOC(image=IMAGE,object='chocolate')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the chocolate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7731, "imageId": "n460556", "question": "Is the bicycle gray?", "program": "BOX0=LOC(image=IMAGE,object='bicycle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the bicycle?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7732, "imageId": "n352479", "question": "Who is wearing a boot?", "program": "BOX0=LOC(image=IMAGE,object='boot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a boot?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7733, "imageId": "n312206", "question": "Which kind of baked good is on top of the chocolate?", "program": "BOX0=LOC(image=IMAGE,object='chocolate')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='baked good')\nANSWER0=VQA(image=IMAGE0,question='Which kind of baked good is on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7734, "imageId": "n312206", "question": "Is the pie on top of the chocolate that is on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chocolate')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='pie')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7735, "imageId": "n527589", "question": "What does the woman hold?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the woman hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7736, "imageId": "n527589", "question": "What does she hold?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does she hold?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7737, "imageId": "n352479", "question": "Do the snow pants that are not short look beige?", "program": "BOX0=LOC(image=IMAGE,object='snow pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='not short')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color are the snow pants?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'beige' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7738, "imageId": "n59147", "question": "What type of furniture is the white thing to the right of the chair resting on, a bookcase or a table?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white thing')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of furniture is the white thing resting on?')\nANSWER1=EVAL(expr=\"'bookcase' if 'bookcase' in {ANSWER0} else 'table'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7739, "imageId": "n352479", "question": "What are the items of clothing that are long?", "program": "BOX0=LOC(image=IMAGE,object='clothing')\nANSWER0=VQA(image=IMAGE,question='What are the items of clothing that are long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7740, "imageId": "n59147", "question": "Is the toilet paper that is to the right of the chair resting on a lamp?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toilet paper')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='lamp')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7741, "imageId": "n513429", "question": "Is the device made of plastic white and rectangular?", "program": "BOX0=LOC(image=IMAGE,object='device')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the device made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the device?')\nANSWER2=VQA(image=IMAGE0,question='What shape is the device?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' and {ANSWER1} == 'white' and {ANSWER2} == 'rectangular' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 7742, "imageId": "n240973", "question": "What is the turned on laptop to the left of the shelves sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the laptop sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7743, "imageId": "n414992", "question": "Is it overcast?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it overcast?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7744, "imageId": "n69237", "question": "What do both the bookcase and the bag have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the bookcase and the bag have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7745, "imageId": "n470920", "question": "Are there both a blanket and a pillow in the image?", "program": "BOX0=LOC(image=IMAGE,object='blanket')\nBOX1=LOC(image=IMAGE,object='pillow')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7746, "imageId": "n65230", "question": "What is in front of the toilet?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the toilet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7747, "imageId": "n65230", "question": "What do you think is in front of the toilet made out of porcelain?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='porcelain')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What do you think is in front of the toilet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7748, "imageId": "n65230", "question": "Which color is the rug that the toilet is to the left of?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=VQA(image=IMAGE0,question='Which color is the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7749, "imageId": "n65230", "question": "What is that rug in front of?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is that rug in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7750, "imageId": "n560243", "question": "Who is holding onto the racket?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding onto the racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7751, "imageId": "n560243", "question": "Who is holding onto the tennis racket made of metal?", "program": "BOX0=LOC(image=IMAGE,object='tennis racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding onto the tennis racket?')\nANSWER1=EVAL(expr=\"'metal' if {ANSWER0} == 'tennis player' else 'not metal'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7752, "imageId": "n119886", "question": "What item of furniture is the flower pot on?", "program": "BOX0=LOC(image=IMAGE,object='flower pot')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is the flower pot on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7753, "imageId": "n119886", "question": "What's the flower pot on?", "program": "BOX0=LOC(image=IMAGE,object='flower pot')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the flower pot on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7754, "imageId": "n560243", "question": "What's the athlete holding onto?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the athlete holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7755, "imageId": "n119886", "question": "What is the flower pot on?", "program": "BOX0=LOC(image=IMAGE,object='flower pot')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the flower pot on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7756, "imageId": "n485969", "question": "What wears a shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What wears a shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7757, "imageId": "n485969", "question": "What wears the shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What wears the shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7758, "imageId": "n485969", "question": "What is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7759, "imageId": "n485969", "question": "What is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7760, "imageId": "n536256", "question": "What is the man doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7761, "imageId": "n181355", "question": "Does the hat that is made of cloth seem to be crooked and green?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the hat made of?')\nANSWER1=VQA(image=IMAGE0,question='Does the hat seem to be crooked?')\nANSWER2=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'green' and {ANSWER0} == 'cloth' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 7762, "imageId": "n181355", "question": "Which kind of furniture is the woman sitting on?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is the woman sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7763, "imageId": "n500308", "question": "Are there any refrigerators in this picture that are not clean?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the refrigerator clean?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7764, "imageId": "n181355", "question": "Is the adult woman sitting on a couch?", "program": "BOX0=LOC(image=IMAGE,object='adult woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7765, "imageId": "n233607", "question": "Is the table sitting beside a shelf?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shelf')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7766, "imageId": "n536256", "question": "Who in this photograph is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7767, "imageId": "n263180", "question": "What kind of vehicle is in front of the apartment building?", "program": "BOX0=LOC(image=IMAGE,object='apartment building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What kind of vehicle is in front of the apartment building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7768, "imageId": "n263180", "question": "What is the car in front of?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the car in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7769, "imageId": "n528403", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7770, "imageId": "n263180", "question": "What is in front of the apartment building?", "program": "BOX0=LOC(image=IMAGE,object='apartment building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the apartment building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7771, "imageId": "n283587", "question": "What is the piece of furniture to the right of the black chairs?", "program": "BOX0=LOC(image=IMAGE,object='black chairs')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7772, "imageId": "n305495", "question": "Does the hair seem to be blond and short?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the hair seem to be blond and short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7773, "imageId": "n58220", "question": "How clean are the empty tables?", "program": "BOX0=LOC(image=IMAGE,object='empty tables')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How clean are the empty tables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7774, "imageId": "n305495", "question": "How long is the blond hair?", "program": "BOX0=LOC(image=IMAGE,object='blond hair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How long is the blond hair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7775, "imageId": "n140421", "question": "Does the countertop seem to be blue and antique?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the countertop?')\nANSWER1=VQA(image=IMAGE,question='Does the countertop seem antique?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7776, "imageId": "n283587", "question": "Which kind of furniture is below the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is below the countertop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7777, "imageId": "n283587", "question": "What is the name of the piece of furniture in front of the staircase?", "program": "BOX0=LOC(image=IMAGE,object='staircase')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7778, "imageId": "n508641", "question": "Are the pants striped and black?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nANSWER1=VQA(image=IMAGE0,question='Are the pants striped?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7779, "imageId": "n276011", "question": "What items of furniture are below the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7780, "imageId": "n283587", "question": "What kind of furniture is in front of the staircase?", "program": "BOX0=LOC(image=IMAGE,object='staircase')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is in front of the staircase?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7781, "imageId": "n58220", "question": "Are the tables that look clean empty and black?", "program": "BOX0=LOC(image=IMAGE,object='clean tables')\nBOX1=LOC(image=IMAGE,object='empty tables')\nBOX2=LOC(image=IMAGE,object='black tables')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 and {ANSWER2} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 7782, "imageId": "n278312", "question": "What is that knife in?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the knife in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7783, "imageId": "n527589", "question": "Are the pants made of cloth both dark and short?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the pants made of cloth?')\nANSWER1=VQA(image=IMAGE,question='Are the pants dark?')\nANSWER2=VQA(image=IMAGE,question='Are the pants short?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 7784, "imageId": "n278312", "question": "What's the knife in?", "program": "BOX0=LOC(image=IMAGE,object='knife')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the knife in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7785, "imageId": "n6309", "question": "What color is the sky the clouds are in?", "program": "BOX0=LOC(image=IMAGE,object='clouds')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sky')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7786, "imageId": "n302358", "question": "How large is the lake?", "program": "BOX0=LOC(image=IMAGE,object='lake')\nANSWER0=SIZE(box=BOX0)\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7787, "imageId": "n513100", "question": "Is the fence small and wooden?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the fence small?')\nANSWER1=VQA(image=IMAGE,question='Is the fence wooden?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7788, "imageId": "n202379", "question": "Who plays on the field that looks brown?", "program": "BOX0=LOC(image=IMAGE,object='brown field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who plays on the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7789, "imageId": "n202379", "question": "Who plays on the field?", "program": "BOX0=LOC(image=IMAGE,object='field')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who plays on the field?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7790, "imageId": "n131634", "question": "What is parked behind the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is parked behind the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7791, "imageId": "n202379", "question": "Who wears the pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7792, "imageId": "n202379", "question": "Who is wearing the socks?", "program": "BOX0=LOC(image=IMAGE,object='socks')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the socks?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7793, "imageId": "n202379", "question": "Who is wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7794, "imageId": "n202379", "question": "Who is wearing the hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7795, "imageId": "n260762", "question": "Are there any red buses or trucks?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nBOX1=LOC(image=IMAGE,object='truck')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7796, "imageId": "n52544", "question": "Is the name tag the same color as the collar?", "program": "BOX0=LOC(image=IMAGE,object='name tag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='collar')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the name tag?')\nANSWER1=VQA(image=IMAGE1,question='What color is the collar?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7797, "imageId": "n350766", "question": "What cooking utensil is to the right of the dish drainer?", "program": "BOX0=LOC(image=IMAGE,object='dish drainer')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'spoon' if {ANSWER0} > 0 else 'knife'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7798, "imageId": "n429883", "question": "Are there any women to the left of the man the light fixture is facing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light fixture')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='woman')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7799, "imageId": "n181210", "question": "Which kind of meat is delicious?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of meat is delicious?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7800, "imageId": "n194179", "question": "Are the adult person and the person that is sleeping both male?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the adult person male?')\nANSWER1=VQA(image=IMAGE,question='Is the person that is sleeping male?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7801, "imageId": "n162586", "question": "Is the TV to the right of a boy?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TV')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7802, "imageId": "n119944", "question": "Who is sitting next to the woman that is not thin?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='thin')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='woman')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='Who is sitting next to the woman?')\nANSWER1=VQA(image=IMAGE2,question='Who is not thin?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if {ANSWER1} == 'woman' else '{ANSWER1}'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7803, "imageId": "n54424", "question": "What is he playing with?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is he playing with?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7804, "imageId": "n48494", "question": "What is the vehicle on top of the railroad called?", "program": "BOX0=LOC(image=IMAGE,object='railroad')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7805, "imageId": "n493357", "question": "What animal is walking next to the trees that look brown and green?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='brown')\nBOX2=LOC(image=IMAGE0,object='green')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='What animal is walking next to the trees?')\nANSWER1=VQA(image=IMAGE2,question='What color are the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7806, "imageId": "n119944", "question": "Who looks at the walking animal that stands in front of the benches?", "program": "BOX0=LOC(image=IMAGE,object='benches')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='walking animal')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Who looks at the walking animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7807, "imageId": "n199758", "question": "How tall is the person that is wearing glasses?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glasses')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How tall is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7808, "imageId": "n460385", "question": "Which kind of fast food is white?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of fast food is white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7809, "imageId": "n162108", "question": "Which side of the photo are the cotton towels on?", "program": "BOX0=LOC(image=IMAGE,object='cotton towels')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7810, "imageId": "n69237", "question": "Does the bookcase made of wood look modern?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the bookcase made of?')\nANSWER1=VQA(image=IMAGE,question='Does the bookcase look modern?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7811, "imageId": "n162108", "question": "Do the towels to the right of the shower curtain look colorful?", "program": "BOX0=LOC(image=IMAGE,object='shower curtain')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='towels')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7812, "imageId": "n460385", "question": "What kind of fast food is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of fast food is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7813, "imageId": "n412144", "question": "Which color does the sky have?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color does the sky have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7814, "imageId": "n235859", "question": "Does the dress look blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the dress look?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7815, "imageId": "n435808", "question": "Which kind of device is to the left of the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is to the left of the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7816, "imageId": "n369313", "question": "Are there shelves or tables?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7817, "imageId": "n480253", "question": "Does the sky look clear?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the sky look clear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7818, "imageId": "n406334", "question": "Is there a bus on the concrete sidewalk?", "program": "BOX0=LOC(image=IMAGE,object='concrete sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7819, "imageId": "n483840", "question": "How clean is the sidewalk?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the sidewalk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7820, "imageId": "n541482", "question": "Is the cloud different in color than the sky?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cloud')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the sky?')\nANSWER1=VQA(image=IMAGE1,question='What color is the cloud?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7821, "imageId": "n479092", "question": "Which kind of food is triangular?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is triangular?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7822, "imageId": "n111390", "question": "What does the wine glass sit atop?", "program": "BOX0=LOC(image=IMAGE,object='wine glass')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the wine glass sit atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7823, "imageId": "n256120", "question": "What vehicle is the flag behind of?", "program": "BOX0=LOC(image=IMAGE,object='flag')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'none' if {ANSWER0} == 0 else 'unknown'\")\nANSWER2=VQA(image=IMAGE0,question='What vehicle is the flag behind of?')\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7824, "imageId": "n571179", "question": "Is there a bag next to the person that is wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='gloves')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='bag')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7825, "imageId": "n479092", "question": "Do the food to the left of the knives look soft?", "program": "BOX0=LOC(image=IMAGE,object='knives')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What is the texture of the food?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'soft' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7826, "imageId": "n406334", "question": "Where is the bus?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nANSWER0=EVAL(expr=\"'left' if {BOX0['x']} < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7827, "imageId": "n262920", "question": "Is the backpack hanging on the white doors?", "program": "BOX0=LOC(image=IMAGE,object='white doors')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='backpack')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7828, "imageId": "n228268", "question": "Who are the shorts worn on?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who are the shorts worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7829, "imageId": "n449058", "question": "Is the gun metallic and black?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the gun?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'metallic and black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7830, "imageId": "n240973", "question": "Is the bowl on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7831, "imageId": "n429961", "question": "What color does the cabbage next to the cauliflower have?", "program": "BOX0=LOC(image=IMAGE,object='cauliflower')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabbage')\nANSWER0=VQA(image=IMAGE0,question='What color is the cabbage?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7832, "imageId": "n470920", "question": "What is the man to the left of the berries doing?", "program": "BOX0=LOC(image=IMAGE,object='berries')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='What is the man doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7833, "imageId": "n347706", "question": "Is the man to the right or to the left of the kid?", "program": "BOX0=LOC(image=IMAGE,object='kid')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7834, "imageId": "n511913", "question": "Do the windows look large and brown?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the windows look large and brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7835, "imageId": "n363445", "question": "What piece of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What piece of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7836, "imageId": "n386682", "question": "Which kind of furniture is above the microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is above the microwave?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7837, "imageId": "n455563", "question": "Is the small mug in the top or in the bottom of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small mug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7838, "imageId": "n16378", "question": "What is the person behind the papers pulling?", "program": "BOX0=LOC(image=IMAGE,object='papers')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person pulling?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7839, "imageId": "n551964", "question": "Is the shirt soft and maroon?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the shirt soft?')\nANSWER1=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'soft' and {ANSWER1} == 'maroon' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7840, "imageId": "n44249", "question": "What is the woman on, an elephant or a monkey?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7841, "imageId": "n357784", "question": "What do both the bottle cap and the bottle have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the bottle cap and the bottle have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7842, "imageId": "n278312", "question": "What is the color of the toaster that is on the counter?", "program": "BOX0=LOC(image=IMAGE,object='counter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='toaster')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the toaster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7843, "imageId": "n485969", "question": "Is that pitcher wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='pitcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='glove')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7844, "imageId": "n315887", "question": "Which kind of furniture is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7845, "imageId": "n51002", "question": "Is the pillow uncomfortable?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the pillow uncomfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7846, "imageId": "n551964", "question": "Is the girl that is walking brunette and young?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the hair color of the girl?')\nANSWER1=VQA(image=IMAGE0,question='What is the age of the girl?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brunette' and {ANSWER1} == 'young' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7847, "imageId": "n274905", "question": "Is the tennis player male or female?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the tennis player male or female?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7848, "imageId": "n567860", "question": "What do you think hangs above the counter top?", "program": "BOX0=LOC(image=IMAGE,object='counter top')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What hangs above the counter top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7849, "imageId": "n493357", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7850, "imageId": "n262920", "question": "Who is touching the laptops?", "program": "BOX0=LOC(image=IMAGE,object='laptops')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is touching the laptops?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7851, "imageId": "n54424", "question": "Do the stars look colorful and small?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the stars look colorful?')\nANSWER1=VQA(image=IMAGE,question='Do the stars look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7852, "imageId": "n431447", "question": "Are there any laptops on the table under the pizza box?", "program": "BOX0=LOC(image=IMAGE,object='pizza box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP_BELOW(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='laptop')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7853, "imageId": "n538039", "question": "Does the person that looks blond look young?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the person that looks blond look young?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7854, "imageId": "n560243", "question": "Who looks at the tennis ball the racket goes into?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who looks at the tennis ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7855, "imageId": "n314171", "question": "Does the bracelet look green and small?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the bracelet?')\nANSWER1=VQA(image=IMAGE,question='Does the bracelet look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'green' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7856, "imageId": "n449058", "question": "What weapon is the person that is looking up wearing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What weapon is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7857, "imageId": "n357784", "question": "Is that door both open and wooden?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the door open?')\nANSWER1=VQA(image=IMAGE0,question='What material is the door made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7858, "imageId": "n449058", "question": "Who is wearing the gun?", "program": "BOX0=LOC(image=IMAGE,object='gun')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the gun?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7859, "imageId": "n531731", "question": "Do you see either mouse pads or paintings in this image?", "program": "BOX0=LOC(image=IMAGE,object='mouse pads')\nBOX1=LOC(image=IMAGE,object='paintings')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7860, "imageId": "n449058", "question": "Who is looking up?", "program": "BOX0=LOC(image=IMAGE,object='up')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking up?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7861, "imageId": "n449058", "question": "What is the person doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7862, "imageId": "n554880", "question": "What device is to the right of the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the right of the laptop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7863, "imageId": "n288870", "question": "Does the grass look tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the grass look tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7864, "imageId": "n543966", "question": "Do the trees below the sky look leafy?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Do the trees look leafy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7865, "imageId": "n446242", "question": "What is common to the sink and the picture?", "program": "ANSWER0=VQA(image=IMAGE,question='What is common to the sink and the picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7866, "imageId": "n446242", "question": "Are the trousers and the towels the same color?", "program": "BOX0=LOC(image=IMAGE,object='trousers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='towels')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the trousers?')\nANSWER1=VQA(image=IMAGE1,question='What color are the towels?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7867, "imageId": "n116329", "question": "What is the busy person walking by?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the busy person walking by?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7868, "imageId": "n400036", "question": "How large are the vehicles that are on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='How large are the vehicles?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7869, "imageId": "n264887", "question": "What kind of device are the headphones in front of?", "program": "BOX0=LOC(image=IMAGE,object='headphones')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What kind of device is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7870, "imageId": "n90944", "question": "The people to the left of the surfboards are wearing what?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='surfboards')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What are the people wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7871, "imageId": "n275148", "question": "What is the length of the TV stand on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TV stand')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the length of the TV stand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7872, "imageId": "n90944", "question": "Who walks on the sand?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who walks on the sand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7873, "imageId": "n334278", "question": "Is the metal fence both blue and long?", "program": "BOX0=LOC(image=IMAGE,object='metal fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the metal fence?')\nANSWER1=VQA(image=IMAGE0,question='How long is the metal fence?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7874, "imageId": "n167552", "question": "On which side of the image is the wood chair?", "program": "BOX0=LOC(image=IMAGE,object='wood chair')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7875, "imageId": "n119886", "question": "Does the toilet seat look brown?", "program": "BOX0=LOC(image=IMAGE,object='toilet seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the toilet seat?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7876, "imageId": "n326988", "question": "What is the doll made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the doll made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7877, "imageId": "n410476", "question": "What kind of animal is narrow?", "program": "BOX0=LOC(image=IMAGE,object='narrow')\nANSWER0=VQA(image=IMAGE,question='What kind of animal is narrow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7878, "imageId": "n172618", "question": "Who is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7879, "imageId": "n326988", "question": "Is the doll made out of porcelain?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the doll made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'porcelain' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7880, "imageId": "n172618", "question": "Does the tall girl seem to be running?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the girl seem to be running?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7881, "imageId": "n315887", "question": "What device is on top of the desk that the keyboard is above?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='keyboard')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What device is on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7882, "imageId": "n410476", "question": "Which kind of animal is not tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is not tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7883, "imageId": "n326988", "question": "Which kind of toy is inside the cabinets?", "program": "BOX0=LOC(image=IMAGE,object='cabinets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of toy is inside the cabinets?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7884, "imageId": "n410476", "question": "Which animal is dark brown?", "program": "BOX0=LOC(image=IMAGE,object='dark brown')\nANSWER0=VQA(image=IMAGE,question='Which animal is dark brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7885, "imageId": "n23181", "question": "Does the black fireplace look large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the black fireplace look large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7886, "imageId": "n229548", "question": "What is using the cables?", "program": "BOX0=LOC(image=IMAGE,object='cables')\nANSWER0=VQA(image=IMAGE,question='What is using the cables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7887, "imageId": "n229548", "question": "Is the large helicopter carrying a ship?", "program": "BOX0=LOC(image=IMAGE,object='large helicopter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='ship')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7888, "imageId": "n222915", "question": "Is there a cup near the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cup')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7889, "imageId": "n229548", "question": "What is the watercraft that the big helicopter above the ocean is carrying?", "program": "BOX0=LOC(image=IMAGE,object='ocean')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='helicopter')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the watercraft?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7890, "imageId": "n229548", "question": "What is the helicopter carrying?", "program": "BOX0=LOC(image=IMAGE,object='helicopter')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the helicopter carrying?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7891, "imageId": "n229548", "question": "Which kind of aircraft is carrying the ship?", "program": "BOX0=LOC(image=IMAGE,object='ship')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of aircraft is carrying the ship?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7892, "imageId": "n280089", "question": "The plastic utensils are sitting in what?", "program": "BOX0=LOC(image=IMAGE,object='plastic utensils')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The plastic utensils are sitting in what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7893, "imageId": "n551964", "question": "Who is wearing the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7894, "imageId": "n223750", "question": "What color is the long dress?", "program": "BOX0=LOC(image=IMAGE,object='long dress')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the long dress?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7895, "imageId": "n119886", "question": "What is the toilet seat made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the toilet seat made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7896, "imageId": "n154856", "question": "Are there lamps to the right of the dark vehicle?", "program": "BOX0=LOC(image=IMAGE,object='dark vehicle')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7897, "imageId": "n305495", "question": "Is the lamp on the left side or on the right of the photo?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7898, "imageId": "n488874", "question": "What is lying next to the beach?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is lying next to the beach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7899, "imageId": "n100552", "question": "What is in front of the green bush?", "program": "BOX0=LOC(image=IMAGE,object='green bush')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the green bush?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7900, "imageId": "n100552", "question": "What is in front of the bush?", "program": "BOX0=LOC(image=IMAGE,object='bush')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the bush?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7901, "imageId": "n100552", "question": "The fence is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The fence is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7902, "imageId": "n100552", "question": "What is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7903, "imageId": "n315887", "question": "Is the computer to the right of a box?", "program": "BOX0=LOC(image=IMAGE,object='box')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='computer')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7904, "imageId": "n100552", "question": "Is the fence behind the bush?", "program": "BOX0=LOC(image=IMAGE,object='bush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7905, "imageId": "n67005", "question": "What color are the denim jeans, blue or black?", "program": "BOX0=LOC(image=IMAGE,object='denim jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the denim jeans?')\nANSWER1=EVAL(expr=\"'blue' if {ANSWER0} == 'blue' else 'black'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7906, "imageId": "n264887", "question": "Are there any mugs in front of the small plant?", "program": "BOX0=LOC(image=IMAGE,object='small plant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mugs')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7907, "imageId": "n264887", "question": "What is in front of the plant?", "program": "BOX0=LOC(image=IMAGE,object='plant')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the plant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7908, "imageId": "n373692", "question": "Is the field grassy and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the field grassy?')\nANSWER1=VQA(image=IMAGE,question='What color is the field?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7909, "imageId": "n473688", "question": "Is the plastic toothbrush to the left or to the right of the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic toothbrush')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7910, "imageId": "n296467", "question": "Does the bowl to the right of the beans look full and white?", "program": "BOX0=LOC(image=IMAGE,object='beans')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the bowl full and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7911, "imageId": "n159802", "question": "Does the hair clip that is not big look black and white?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the hair clip?')\nANSWER1=VQA(image=IMAGE0,question='Is the hair clip big?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black and white' and {ANSWER1} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7912, "imageId": "n554880", "question": "What device is sitting on top of the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is sitting on top of the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7913, "imageId": "n159802", "question": "Is the hair clip large and black and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the hair clip large and black and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7914, "imageId": "n6908", "question": "Are the flowers yellow?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the flowers?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7915, "imageId": "n554880", "question": "Does the laptop computer look black or red?", "program": "ANSWER0=VQA(image=IMAGE,question='What color does the laptop computer look?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'red'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7916, "imageId": "n159802", "question": "Does the black blouse look dotted?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the black blouse look dotted?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7917, "imageId": "n68769", "question": "Are there women to the left of the person that wears a shirt?", "program": "BOX0=LOC(image=IMAGE,object='person that wears a shirt')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='women')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7918, "imageId": "n51002", "question": "What device is to the left of the computer monitor?", "program": "BOX0=LOC(image=IMAGE,object='computer monitor')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is to the left of the computer monitor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7919, "imageId": "n554880", "question": "What is the laptop to the right of the lamp sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='laptop')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the laptop sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7920, "imageId": "n159802", "question": "Who wears a hair clip?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears a hair clip?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7921, "imageId": "n350732", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7922, "imageId": "n263180", "question": "What is parked behind the bus the apartment building is to the right of?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='apartment building')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is parked behind the bus?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7923, "imageId": "n298104", "question": "How wide is the sandy beach?", "program": "BOX0=LOC(image=IMAGE,object='sandy beach')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How wide is the sandy beach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7924, "imageId": "n44249", "question": "Is the man on a skateboard?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7925, "imageId": "n162586", "question": "Do you see a woman next to the clothes that are white?", "program": "BOX0=LOC(image=IMAGE,object='white clothes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7926, "imageId": "n206785", "question": "What item of furniture is wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='What item of furniture is wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7927, "imageId": "n37274", "question": "Is the cup made of the same material as the bicycle?", "program": "BOX0=LOC(image=IMAGE,object='cup')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bicycle')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the cup made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the bicycle made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7928, "imageId": "n398429", "question": "Is the table in front of a couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7929, "imageId": "n525029", "question": "Do the tracks seem to be long?", "program": "BOX0=LOC(image=IMAGE,object='tracks')\nANSWER0=VQA(image=IMAGE,question='Do the tracks seem to be long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7930, "imageId": "n540852", "question": "Is the walking woman to the right of the man holding a cell phone?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='walking woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the walking woman holding a cell phone?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7931, "imageId": "n37274", "question": "Do you see bicycles there?", "program": "BOX0=LOC(image=IMAGE,object='bicycles')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7932, "imageId": "n181355", "question": "Are the shorts long or short?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'short' if {ANSWER0} > 0 else 'long'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7933, "imageId": "n274905", "question": "What is the man before?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man before?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7934, "imageId": "n133585", "question": "Who wears the shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who wears the shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7935, "imageId": "n133585", "question": "Who is wearing a shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shoe?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7936, "imageId": "n133585", "question": "Is the thin boy riding on a skateboard?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboard')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7937, "imageId": "n501609", "question": "What is on the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nANSWER0=VQA(image=IMAGE,question='What is on the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7938, "imageId": "n485969", "question": "Is the small baseball in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small baseball')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7939, "imageId": "n494918", "question": "Who is looking at the frisbee?", "program": "BOX0=LOC(image=IMAGE,object='frisbee')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is looking at the frisbee?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7940, "imageId": "n279581", "question": "Does the dirt look brown and fine?", "program": "BOX0=LOC(image=IMAGE,object='dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the dirt?')\nANSWER1=VQA(image=IMAGE0,question='What texture does the dirt have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'fine' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7941, "imageId": "n279581", "question": "Are there any balls or bird houses in the picture?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nBOX1=LOC(image=IMAGE,object='bird house')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7942, "imageId": "n380113", "question": "What color is the soccer ball?", "program": "BOX0=LOC(image=IMAGE,object='soccer ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the soccer ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7943, "imageId": "n280089", "question": "What is the artwork sitting on top of?", "program": "BOX0=LOC(image=IMAGE,object='artwork')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the artwork sitting on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7944, "imageId": "n497789", "question": "What animal is in front of the vehicle?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7945, "imageId": "n173807", "question": "Are there either any cars or buses in the image?", "program": "BOX0=LOC(image=IMAGE,object='car')\nBOX1=LOC(image=IMAGE,object='bus')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7946, "imageId": "n162586", "question": "What color is the bed that is not narrow?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='narrow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bed?')\nANSWER1=VQA(image=IMAGE1,question='What color is the narrow?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7947, "imageId": "n285391", "question": "Are there any drawers or tables?", "program": "BOX0=LOC(image=IMAGE,object='drawer')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7948, "imageId": "n285391", "question": "What color is that pillow?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the pillow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7949, "imageId": "n475030", "question": "Is the horse to the left of the other horse brown and healthy?", "program": "BOX0=LOC(image=IMAGE,object='horse')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='horse')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nIMAGE1=CROP(image=IMAGE,box=BOX0)\nANSWER2=VQA(image=IMAGE1,question='What color is the horse?')\nANSWER3=VQA(image=IMAGE1,question='Is the horse healthy?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER2} == 'brown' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 7950, "imageId": "n497789", "question": "What animal is in front of the parked vehicle?", "program": "BOX0=LOC(image=IMAGE,object='parked vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is in front of the parked vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7951, "imageId": "n219840", "question": "Does the deer to the right of the horses look ugly?", "program": "BOX0=LOC(image=IMAGE,object='horses')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='deer')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7952, "imageId": "n171169", "question": "What is the person that looks young wearing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7953, "imageId": "n285391", "question": "What piece of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What piece of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7954, "imageId": "n579928", "question": "Is the hay wet and yellow?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the hay wet?')\nANSWER1=VQA(image=IMAGE,question='What color is the hay?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yellow' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7955, "imageId": "n238266", "question": "Does the dessert on the cake stand look yellow?", "program": "BOX0=LOC(image=IMAGE,object='cake stand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dessert')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the dessert?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7956, "imageId": "n171169", "question": "What's the man wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7957, "imageId": "n501951", "question": "What place was the image taken at?", "program": "ANSWER0=VQA(image=IMAGE,question='What place was the image taken at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7958, "imageId": "n263180", "question": "Does the window seem to be high and triangular?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the window seem to be high?')\nANSWER1=VQA(image=IMAGE0,question='Does the window seem to be triangular?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7959, "imageId": "n262920", "question": "What shape is the window, rectangular or round?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7960, "imageId": "n283587", "question": "What item of furniture is to the left of the sofa?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is to the left of the sofa?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7961, "imageId": "n334278", "question": "Was the picture taken at a field or at a beach?", "program": "BOX0=LOC(image=IMAGE,object='field')\nBOX1=LOC(image=IMAGE,object='beach')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'field' if {ANSWER0} > 0 else 'beach'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7962, "imageId": "n282436", "question": "The table lamp is standing on what?", "program": "BOX0=LOC(image=IMAGE,object='table lamp')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The table lamp is standing on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7963, "imageId": "n256120", "question": "What's the pattern of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the pattern of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7964, "imageId": "n283587", "question": "What type of furniture is below the counter top that is not antique?", "program": "BOX0=LOC(image=IMAGE,object='counter top')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is below the counter top that is not antique?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7965, "imageId": "n55058", "question": "What is the food inside the serving dish?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the food inside the serving dish?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7966, "imageId": "n55058", "question": "What is inside the serving dish?", "program": "BOX0=LOC(image=IMAGE,object='serving dish')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is inside the serving dish?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7967, "imageId": "n259002", "question": "What's underneath the ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is underneath the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7968, "imageId": "n357126", "question": "What vehicle is the window wrapped around?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What vehicle is the window wrapped around?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7969, "imageId": "n355339", "question": "What is the device to the right of the chair made of wood?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What is the device made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7970, "imageId": "n357126", "question": "What is wrapped around the vehicle behind the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is wrapped around the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7971, "imageId": "n477702", "question": "What is the bald man holding?", "program": "BOX0=LOC(image=IMAGE,object='bald man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bald man holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7972, "imageId": "n357126", "question": "What do you think is the black window wrapped around?", "program": "BOX0=LOC(image=IMAGE,object='black window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is the black window wrapped around?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7973, "imageId": "n477702", "question": "Is the bald man sitting on a bench?", "program": "BOX0=LOC(image=IMAGE,object='bald man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7974, "imageId": "n545516", "question": "Are there any benches on the hard pavement?", "program": "BOX0=LOC(image=IMAGE,object='hard pavement')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='benches')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7975, "imageId": "n501951", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7976, "imageId": "n508733", "question": "Is the glass large?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7977, "imageId": "n315887", "question": "What is the name of the device on top of the desk that is below the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='desk')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='device')\nIMAGE2=CROP_ABOVE(image=IMAGE1,box=BOX2)\nANSWER0=VQA(image=IMAGE2,question='What is the name of the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7978, "imageId": "n302387", "question": "What is on the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7979, "imageId": "n302387", "question": "What is on the rug that is shown in the photo?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is on the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7980, "imageId": "n153118", "question": "What color is the train?", "program": "BOX0=LOC(image=IMAGE,object='train')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the train?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7981, "imageId": "n263180", "question": "What do the bus and the tree have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the bus and the tree have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7982, "imageId": "n9856", "question": "Is the white baseball round and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the white baseball round and large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7983, "imageId": "n59627", "question": "How old is the man the polo shirt is worn on?", "program": "BOX0=LOC(image=IMAGE,object='polo shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How old is the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7984, "imageId": "n206358", "question": "Which color is the license plate?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the license plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7985, "imageId": "n302387", "question": "Is the suitcase empty or is it full?", "program": "BOX0=LOC(image=IMAGE,object='suitcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the suitcase empty or is it full?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7986, "imageId": "n250715", "question": "What type of furniture is to the right of the controller that is mounted to the helicopter?", "program": "BOX0=LOC(image=IMAGE,object='controller')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='helicopter')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What type of furniture is to the right?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7987, "imageId": "n234683", "question": "Who is in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7988, "imageId": "n240973", "question": "Is the bowl below the shelves empty or full?", "program": "BOX0=LOC(image=IMAGE,object='shelves')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bowl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'empty' if {ANSWER0} == 0 else 'full'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7989, "imageId": "n319845", "question": "What color is the statue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the statue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7990, "imageId": "n278312", "question": "What type of furniture hangs from the beige wall?", "program": "BOX0=LOC(image=IMAGE,object='beige wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of furniture hangs from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7991, "imageId": "n278312", "question": "What hangs from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What hangs from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7992, "imageId": "n278312", "question": "What hangs from the wall that is beige?", "program": "BOX0=LOC(image=IMAGE,object='beige wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hangs')\nANSWER0=VQA(image=IMAGE0,question='What hangs from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7993, "imageId": "n293477", "question": "Is the spoon to the right of a plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='spoon')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 7994, "imageId": "n472825", "question": "What is facing the car?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is facing the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7995, "imageId": "n278312", "question": "Which kind of furniture hangs from the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture hangs from the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7996, "imageId": "n250821", "question": "Is the floor dark and clean?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the floor?')\nANSWER1=VQA(image=IMAGE0,question='Is the floor clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 7997, "imageId": "n489699", "question": "What do the helmet and the sky have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the helmet and the sky have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7998, "imageId": "n49310", "question": "What is the color of the colorful flowers?", "program": "BOX0=LOC(image=IMAGE,object='colorful flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the flowers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 7999, "imageId": "n549922", "question": "What toy is it?", "program": "BOX0=LOC(image=IMAGE,object='toy')\nANSWER0=VQA(image=IMAGE,question='What toy is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8000, "imageId": "n549922", "question": "What toy is this, a doll or a stuffed bear?", "program": "BOX0=LOC(image=IMAGE,object='doll')\nBOX1=LOC(image=IMAGE,object='stuffed bear')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'doll' if {ANSWER0} > 0 else 'stuffed bear'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8001, "imageId": "n186491", "question": "Are the tomatoes round and red?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the tomatoes round and red?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8002, "imageId": "n363445", "question": "What fruits are below the food to the left of the carrots?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='carrots')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='fruits')\nANSWER0=VQA(image=IMAGE2,question='What fruits are below the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8003, "imageId": "n346247", "question": "Are there both a chair and a window in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8004, "imageId": "n369595", "question": "Is the shirt pink and sleeveless?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE,question='Does the shirt have sleeves?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'pink' and {ANSWER1} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8005, "imageId": "n206358", "question": "Is the wall made of the same material as the SUV?", "program": "BOX0=LOC(image=IMAGE,object='SUV')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='wall')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the SUV made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the wall made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8006, "imageId": "n398257", "question": "Is the keyboard made of the same material as the computer monitor?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='computer monitor')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the keyboard made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the computer monitor made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8007, "imageId": "n186491", "question": "Do the red vegetables have round shape?", "program": "BOX0=LOC(image=IMAGE,object='red vegetables')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape are the red vegetables?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'round' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8008, "imageId": "n541854", "question": "Does the green fruit seem to be hard?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the green fruit seem to be hard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8009, "imageId": "n318684", "question": "Which material makes up the brown cap, cloth or plastic?", "program": "BOX0=LOC(image=IMAGE,object='brown cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which material makes up the brown cap?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8010, "imageId": "n541854", "question": "Is the round fruit hard and brown?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the round fruit?')\nANSWER1=VQA(image=IMAGE,question='Is the round fruit hard?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8011, "imageId": "n335542", "question": "Do you see either bison or bears in this picture?", "program": "BOX0=LOC(image=IMAGE,object='bison')\nBOX1=LOC(image=IMAGE,object='bears')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8012, "imageId": "n118102", "question": "Is the fork in the top part?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fork')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8013, "imageId": "n86120", "question": "What is the woman doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the woman doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8014, "imageId": "n260762", "question": "Who is wearing shorts?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shorts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8015, "imageId": "n344136", "question": "What item of furniture is not brown?", "program": "BOX0=LOC(image=IMAGE,object='brown')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What item of furniture is not brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8016, "imageId": "n14087", "question": "What is hanging from the tree?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the tree?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8017, "imageId": "n437064", "question": "Is the utensil in front of the spoon made of wood?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8018, "imageId": "n14087", "question": "What is hanging from the tree in front of the wall?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wall')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is hanging from the tree?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8019, "imageId": "n276011", "question": "Which kind of furniture is long?", "program": "BOX0=LOC(image=IMAGE,object='long')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is long?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8020, "imageId": "n14087", "question": "Are the white curtains behind the comfortable couch?", "program": "BOX0=LOC(image=IMAGE,object='comfortable couch')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white curtains')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8021, "imageId": "n90294", "question": "What device is to the left of the calculator made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='calculator')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What material is the device made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8022, "imageId": "n314630", "question": "Which kind of appliance is the wine bottle reflecting in?", "program": "BOX0=LOC(image=IMAGE,object='wine bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is the wine bottle reflecting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8023, "imageId": "n518912", "question": "What are the cups made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the cups made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8024, "imageId": "n160664", "question": "In which part of the image is the old woman, the bottom or the top?", "program": "BOX0=LOC(image=IMAGE,object='old woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8025, "imageId": "n314630", "question": "What's reflecting in the toaster?", "program": "BOX0=LOC(image=IMAGE,object='toaster')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is reflecting in the toaster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8026, "imageId": "n314630", "question": "What is the wine bottle made of glass reflecting in?", "program": "BOX0=LOC(image=IMAGE,object='wine bottle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the wine bottle reflecting in?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8027, "imageId": "n68769", "question": "What's in front of the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8028, "imageId": "n68769", "question": "Is the long table below the light fixture?", "program": "BOX0=LOC(image=IMAGE,object='light fixture')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='long table')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8029, "imageId": "n344136", "question": "Do you see a white bookcase or bed?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nBOX1=LOC(image=IMAGE,object='bed')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8030, "imageId": "n65866", "question": "Does that sink look ceramic and light?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the sink made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the sink?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'ceramic' and {ANSWER1} == 'light' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8031, "imageId": "n546884", "question": "Does the cream look open and brown?", "program": "BOX0=LOC(image=IMAGE,object='cream')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the cream?')\nANSWER1=VQA(image=IMAGE0,question='Is the cream open?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8032, "imageId": "n347706", "question": "Are both the shorts and the jeans the same color?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='jeans')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE1,question='What color are the jeans?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8033, "imageId": "n199097", "question": "Does that jacket look black and long sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the jacket?')\nANSWER1=VQA(image=IMAGE,question='What type of sleeves does the jacket have?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'long sleeved' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8034, "imageId": "n260521", "question": "Where is the statue in front of the fence standing on?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='statue')\nANSWER0=VQA(image=IMAGE0,question='Where is the statue standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8035, "imageId": "n260521", "question": "What's standing on the stage?", "program": "BOX0=LOC(image=IMAGE,object='stage')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is standing on the stage?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8036, "imageId": "n260521", "question": "What is holding the broom?", "program": "BOX0=LOC(image=IMAGE,object='broom')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is holding the broom?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8037, "imageId": "n260521", "question": "Where is the statue standing on?", "program": "BOX0=LOC(image=IMAGE,object='statue')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Where is the statue standing on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8038, "imageId": "n400036", "question": "Is the soccer ball both round and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the soccer ball round?')\nANSWER1=VQA(image=IMAGE,question='Is the soccer ball large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8039, "imageId": "n210269", "question": "Are the horses large and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the horses large?')\nANSWER1=VQA(image=IMAGE,question='Are the horses white?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8040, "imageId": "n260521", "question": "What is the statue holding?", "program": "BOX0=LOC(image=IMAGE,object='statue')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the statue holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8041, "imageId": "n435808", "question": "What device sits on top of the mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device sits on top of the mouse pad?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8042, "imageId": "n92308", "question": "Do you see dogs there that are resting?", "program": "BOX0=LOC(image=IMAGE,object='dogs')\nANSWER0=COUNT(box=BOX0)\nBOX1=LOC(image=IMAGE,object='resting')\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8043, "imageId": "n167552", "question": "Which side of the photo is the person on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='person')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8044, "imageId": "n435808", "question": "What does the computer mouse made of plastic sit on top of?", "program": "BOX0=LOC(image=IMAGE,object='computer mouse')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the computer mouse sit on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8045, "imageId": "n483840", "question": "That American flag has what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the American flag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8046, "imageId": "n437064", "question": "Which kind of fruit is the bowl behind of?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of fruit is the bowl behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8047, "imageId": "n313060", "question": "What are the black glasses made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the black glasses made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8048, "imageId": "n313060", "question": "What are the glasses made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the glasses made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8049, "imageId": "n532191", "question": "Is the woman to the right or to the left of the bag on the right?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='woman')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8050, "imageId": "n532191", "question": "What's the woman sitting on?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman sitting on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8051, "imageId": "n100552", "question": "What the animal that is brown is called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the animal that is brown called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8052, "imageId": "n100552", "question": "Which kind of animal is brown?", "program": "BOX0=LOC(image=IMAGE,object='brown animal')\nANSWER0=VQA(image=IMAGE,question='Which kind of animal is brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8053, "imageId": "n488874", "question": "Is the person that is not female wearing a wetsuit?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person female?')\nANSWER1=VQA(image=IMAGE0,question='Is the person wearing a wetsuit?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8054, "imageId": "n499081", "question": "What is the mirror made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the mirror made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8055, "imageId": "n499081", "question": "The mirror is made of what material?", "program": "ANSWER0=VQA(image=IMAGE,question='The mirror is made of what material?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8056, "imageId": "n488874", "question": "Who do you think is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nANSWER0=VQA(image=IMAGE,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8057, "imageId": "n532191", "question": "What kind of furniture is behind the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is behind the rug?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8058, "imageId": "n532191", "question": "What is the item of furniture behind the rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8059, "imageId": "n257997", "question": "What is the vehicle behind the people on the grass?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='grass')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=VQA(image=IMAGE1,question='What is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8060, "imageId": "n16936", "question": "Is the skateboarder that is not female wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='female')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='hat')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8061, "imageId": "n65866", "question": "What is the piece of furniture to the right of the toilet near the bathtub?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bathtub')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='piece of furniture')\nANSWER0=VQA(image=IMAGE1,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8062, "imageId": "n507959", "question": "What do both the umbrella and the cabinet have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the umbrella and the cabinet have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8063, "imageId": "n532191", "question": "Is the chair behind a rug?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8064, "imageId": "n16936", "question": "Who is wearing the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8065, "imageId": "n16936", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8066, "imageId": "n293477", "question": "What kind of furniture is the bracelet lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='bracelet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is the bracelet lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8067, "imageId": "n117888", "question": "Does the grass appear to be short and light brown?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the grass appear to be short and light brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8068, "imageId": "n12404", "question": "Is the metal container in the bottom part or in the top of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='metal container')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8069, "imageId": "n293477", "question": "What is the bracelet lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='bracelet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the bracelet lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8070, "imageId": "n314171", "question": "Are there catchers or bikers?", "program": "BOX0=LOC(image=IMAGE,object='catcher')\nBOX1=LOC(image=IMAGE,object='biker')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8071, "imageId": "n46510", "question": "What is the palm tree in front of?", "program": "BOX0=LOC(image=IMAGE,object='palm tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the palm tree in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8072, "imageId": "n432591", "question": "Are the pillows on top of a couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8073, "imageId": "n313060", "question": "Is the color of the pants different than the color of the glasses?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='glasses')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nANSWER1=VQA(image=IMAGE1,question='What color are the glasses?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8074, "imageId": "n54424", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8075, "imageId": "n319845", "question": "Do the windows look closed and clean?", "program": "BOX0=LOC(image=IMAGE,object='windows')\nANSWER0=VQA(image=IMAGE,question='Do the windows look closed?')\nANSWER1=VQA(image=IMAGE,question='Do the windows look clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8076, "imageId": "n250715", "question": "Are there both a window and a chair in the picture?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8077, "imageId": "n16656", "question": "Does that shirt have red color?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'red' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8078, "imageId": "n37274", "question": "Is the crate to the left or to the right of the man that is on the left of the picture?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='crate')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8079, "imageId": "n71728", "question": "Is the woman to the left of the boy old and short?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='woman')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8080, "imageId": "n207708", "question": "What is located on top of the table the door is behind of?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='table')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8081, "imageId": "n207708", "question": "What is located on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8082, "imageId": "n544255", "question": "What is this animal called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is this animal called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8083, "imageId": "n207708", "question": "Is the plant on top of a lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plant')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8084, "imageId": "n222915", "question": "Are these apples brown or green?", "program": "BOX0=LOC(image=IMAGE,object='apples')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the apples?')\nANSWER1=EVAL(expr=\"'brown' if 'brown' in {ANSWER0} else 'green'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8085, "imageId": "n25275", "question": "Is it a beach?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it a beach?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8086, "imageId": "n544255", "question": "What animal is walking?", "program": "BOX0=LOC(image=IMAGE,object='walking')\nANSWER0=VQA(image=IMAGE,question='What animal is walking?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8087, "imageId": "n159284", "question": "Is the blue cap new or old?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the blue cap new or old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8088, "imageId": "n460385", "question": "Which side of the image is the full drink on?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='full drink')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8089, "imageId": "n216553", "question": "Is there a goat behind the man that is not old?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='goat')\nANSWER0=COUNT(box=BOX1)\nBOX2=LOC(image=IMAGE0,object='old goat')\nANSWER1=COUNT(box=BOX2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} == 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8090, "imageId": "n296467", "question": "Is the closed container to the right of the bowl on the right?", "program": "BOX0=LOC(image=IMAGE,object='bowl')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='closed container')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8091, "imageId": "n496803", "question": "Who is holding the racket that looks white?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the racket?')\nANSWER1=VQA(image=IMAGE0,question='What color is the racket?')\nANSWER2=EVAL(expr=\"'{ANSWER0}' if {ANSWER1} == 'white' else 'unknown'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8092, "imageId": "n216553", "question": "What animal is behind the young man that is reaching for the bag?", "program": "BOX0=LOC(image=IMAGE,object='young man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What animal is behind the young man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8093, "imageId": "n334278", "question": "Is the person to the left of the player playing or waiting?", "program": "BOX0=LOC(image=IMAGE,object='player')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='Is the person playing or waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8094, "imageId": "n141939", "question": "Is the black mirror on the right side of the picture?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='black')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8095, "imageId": "n546884", "question": "On which side is the round food?", "program": "BOX0=LOC(image=IMAGE,object='round food')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8096, "imageId": "n95313", "question": "Which kind of furniture is behind the bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is behind the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8097, "imageId": "n90944", "question": "What are the trees in front of?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the trees in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8098, "imageId": "n207708", "question": "What's the table in front of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the table in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8099, "imageId": "n90944", "question": "Are the trees in front of the buildings surrounding the sand?", "program": "BOX0=LOC(image=IMAGE,object='buildings')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='trees')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='sand')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8100, "imageId": "n90944", "question": "What are the trees surrounding?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the trees surrounding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8101, "imageId": "n207708", "question": "On which side is the large microwave?", "program": "BOX0=LOC(image=IMAGE,object='large microwave')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8102, "imageId": "n90944", "question": "The trees are surrounding what?", "program": "ANSWER0=VQA(image=IMAGE,question='The trees are surrounding what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8103, "imageId": "n311910", "question": "Does the street sign that looks white and black look tall and wooden?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the street sign?')\nANSWER1=VQA(image=IMAGE,question='What material is the street sign made of?')\nANSWER2=VQA(image=IMAGE,question='Does the street sign look tall?')\nANSWER3=VQA(image=IMAGE,question='Does the street sign look wooden?')\nANSWER4=EVAL(expr=\"'yes' if {ANSWER0} == 'white and black' and {ANSWER1} == 'wood' and {ANSWER2} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 8104, "imageId": "n159802", "question": "How old is the girl that is wearing a sweatshirt?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How old is the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8105, "imageId": "n167552", "question": "Is the rug the same color as the flower?", "program": "BOX0=LOC(image=IMAGE,object='rug')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='flower')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the rug?')\nANSWER1=VQA(image=IMAGE1,question='What color is the flower?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8106, "imageId": "n520071", "question": "What is the piece of furniture to the left of the metal lamp that is to the left of the water bottle?", "program": "BOX0=LOC(image=IMAGE,object='metal lamp')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='water bottle')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='piece of furniture')\nANSWER0=VQA(image=IMAGE1,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8107, "imageId": "n335542", "question": "What are the animals that are walking on the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the animals walking on the ground?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8108, "imageId": "n335542", "question": "What are the birds that are walking walking on?", "program": "BOX0=LOC(image=IMAGE,object='birds')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the birds walking on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8109, "imageId": "n296467", "question": "Are the cupcakes rainbow colored?", "program": "BOX0=LOC(image=IMAGE,object='cupcakes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the cupcakes?')\nANSWER1=EVAL(expr=\"'yes' if 'rainbow' in {ANSWER0} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8110, "imageId": "n97485", "question": "What is the shape of the appliance below the microwave?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What is the shape of the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8111, "imageId": "n162586", "question": "What leans against the wall?", "program": "BOX0=LOC(image=IMAGE,object='wall')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What leans against the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8112, "imageId": "n216553", "question": "Which material is this fence made of?", "program": "ANSWER0=VQA(image=IMAGE,question='Which material is this fence made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8113, "imageId": "n532213", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8114, "imageId": "n532213", "question": "Is it an indoors scene?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it an indoors scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8115, "imageId": "n288870", "question": "Does the shirt look short sleeved and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the shirt look short sleeved?')\nANSWER1=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8116, "imageId": "n145498", "question": "Does the floor have beige color?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the floor?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'beige' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8117, "imageId": "n357784", "question": "On which side of the image is the open bottle?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='open bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8118, "imageId": "n210269", "question": "What animals are this?", "program": "BOX0=LOC(image=IMAGE,object='animals')\nANSWER0=VQA(image=IMAGE,question='What animals are this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8119, "imageId": "n145498", "question": "Is he wearing underwear?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is he wearing underwear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8120, "imageId": "n262920", "question": "Does the man appear to be sitting?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Does the man appear to be sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8121, "imageId": "n150962", "question": "What the items of clothing that are hanging are called?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the items of clothing that are hanging called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8122, "imageId": "n141939", "question": "What is in the shower near the mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shower')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in the shower?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8123, "imageId": "n164272", "question": "What type of animal is above the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of animal is above the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8124, "imageId": "n164272", "question": "Which kind of animal is above the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is above the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8125, "imageId": "n508733", "question": "Are these people all the same gender?", "program": "ANSWER0=VQA(image=IMAGE,question='Are these people all the same gender?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8126, "imageId": "n259002", "question": "Who is kicking the ball?", "program": "BOX0=LOC(image=IMAGE,object='ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is kicking the ball?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8127, "imageId": "n259002", "question": "The soccer player that is looking up is kicking what?", "program": "BOX0=LOC(image=IMAGE,object='soccer player')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The soccer player that is looking up is kicking what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8128, "imageId": "n310828", "question": "Is the shirt dull or bright?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'bright' if {ANSWER0} in ['red', 'yellow', 'orange'] else 'dull'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8129, "imageId": "n545516", "question": "What device is below the light plane on the pavement?", "program": "BOX0=LOC(image=IMAGE,object='light plane')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What device is below the light plane?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8130, "imageId": "n324908", "question": "What is the light blue sky higher than?", "program": "BOX0=LOC(image=IMAGE,object='light blue sky')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the light blue sky higher than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8131, "imageId": "n324908", "question": "What's the sky higher than?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sky higher than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8132, "imageId": "n324908", "question": "What's higher than the mountains?", "program": "ANSWER0=VQA(image=IMAGE,question='What\\'s higher than the mountains?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8133, "imageId": "n141939", "question": "What's in the shower?", "program": "BOX0=LOC(image=IMAGE,object='shower')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in the shower?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8134, "imageId": "n315887", "question": "What kind of device is large?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of device is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8135, "imageId": "n315887", "question": "Which kind of device is large?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of device is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8136, "imageId": "n118102", "question": "What is the girl holding?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the girl holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8137, "imageId": "n571179", "question": "What is the house made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the house made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8138, "imageId": "n324644", "question": "Are the traffic lights metallic and yellow?", "program": "BOX0=LOC(image=IMAGE,object='traffic lights')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the traffic lights?')\nANSWER1=VQA(image=IMAGE0,question='What material are the traffic lights made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8139, "imageId": "n157375", "question": "Does the vehicle below the airplane look white and metallic?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the vehicle?')\nANSWER1=VQA(image=IMAGE1,question='What material is the vehicle made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8140, "imageId": "n531359", "question": "What are the Caucasian people doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the Caucasian people doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8141, "imageId": "n157375", "question": "What color is the vehicle the airplane is above?", "program": "BOX0=LOC(image=IMAGE,object='airplane')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What color is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8142, "imageId": "n352479", "question": "Do the snowpants look black and long?", "program": "ANSWER0=VQA(image=IMAGE,question='What color are the snowpants?')\nANSWER1=VQA(image=IMAGE,question='What is the length of the snowpants?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'long' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8143, "imageId": "n554880", "question": "Who is sitting beside the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting beside the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8144, "imageId": "n410476", "question": "What color is the animal that is standing on the ground?", "program": "BOX0=LOC(image=IMAGE,object='ground')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What color is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8145, "imageId": "n167164", "question": "What's in front of the truck?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8146, "imageId": "n357784", "question": "Is the bottle cap made of the same material as the door?", "program": "BOX0=LOC(image=IMAGE,object='bottle cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='door')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the bottle cap made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the door made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8147, "imageId": "n249639", "question": "Does the mirror which is to the right of the lamp have small size?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the size of the mirror?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8148, "imageId": "n249639", "question": "Does the mirror near the other mirror look square and large?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_NEAR(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mirror')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the mirror look square and large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8149, "imageId": "n274905", "question": "Who is wearing the hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8150, "imageId": "n167164", "question": "Is the red vehicle behind the vehicle on the left?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='red vehicle')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8151, "imageId": "n167164", "question": "What is in front of the truck which is driving on the street?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='street')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the truck?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8152, "imageId": "n167164", "question": "What kind of vehicle is driving on the street?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vehicle is driving on the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8153, "imageId": "n282436", "question": "What color is the device that is in the bottom of the image?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the device?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8154, "imageId": "n97485", "question": "Which side of the photo is the microwave on?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8155, "imageId": "n49310", "question": "Is there a bench on top of the green lawn?", "program": "BOX0=LOC(image=IMAGE,object='green lawn')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bench')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8156, "imageId": "n489190", "question": "Is the person to the right of the other person staring or sleeping?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the person staring or sleeping?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8157, "imageId": "n199097", "question": "What color do the trousers have?", "program": "ANSWER0=VQA(image=IMAGE,question='What color do the trousers have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8158, "imageId": "n501951", "question": "Is the tool red and metallic?", "program": "BOX0=LOC(image=IMAGE,object='tool')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tool?')\nANSWER1=VQA(image=IMAGE0,question='What material is the tool made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'metallic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8159, "imageId": "n541482", "question": "Is the kite that is purple and black large or small?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the kite?')\nANSWER1=VQA(image=IMAGE0,question='How large is the kite?')\nANSWER2=EVAL(expr=\"'large' if {ANSWER0} == 'purple' and {ANSWER1} == 'large' else 'small'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8160, "imageId": "n526228", "question": "Are there men to the right of the little books that are on top of the coffee table?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='little books')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='RIGHT')\nIMAGE2=CROP(image=IMAGE1,box=BOX2)\nBOX3=LOC(image=IMAGE2,object='men')\nANSWER0=COUNT(box=BOX3)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8161, "imageId": "n429883", "question": "Are there both ties and glasses in the photograph?", "program": "BOX0=LOC(image=IMAGE,object='tie')\nBOX1=LOC(image=IMAGE,object='glasses')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8162, "imageId": "n501951", "question": "What is the tool made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the tool made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8163, "imageId": "n469525", "question": "What is the animal that stands on the grass that looks light brown?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='light brown')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the animal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8164, "imageId": "n469525", "question": "What kind of animal stands on the grass?", "program": "BOX0=LOC(image=IMAGE,object='grass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal stands on the grass?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8165, "imageId": "n315859", "question": "What place was the picture taken at?", "program": "ANSWER0=VQA(image=IMAGE,question='What place was the picture taken at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8166, "imageId": "n315859", "question": "Which place is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which place is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8167, "imageId": "n541482", "question": "Are there any small flags or kites?", "program": "BOX0=LOC(image=IMAGE,object='small flags')\nBOX1=LOC(image=IMAGE,object='kites')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8168, "imageId": "n262929", "question": "Is the small bag to the right or to the left of the young person?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small bag')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8169, "imageId": "n315887", "question": "Is the keyboard long and regular?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nANSWER0=VQA(image=IMAGE,question='Is the keyboard long?')\nANSWER1=VQA(image=IMAGE,question='Is the keyboard regular?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8170, "imageId": "n119944", "question": "How big is the elephant the child is looking at?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='elephant')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How big is the elephant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8171, "imageId": "n200225", "question": "Does the pepper look red and cooked?", "program": "BOX0=LOC(image=IMAGE,object='pepper')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the pepper?')\nANSWER1=VQA(image=IMAGE0,question='Is the pepper cooked?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8172, "imageId": "n204894", "question": "What kind of furniture is to the left of the phone?", "program": "BOX0=LOC(image=IMAGE,object='phone')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is to the left of the phone?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8173, "imageId": "n55058", "question": "What's the table inside of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='What is the table inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8174, "imageId": "n55058", "question": "What is this table inside of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nANSWER0=VQA(image=IMAGE,question='What is this table inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8175, "imageId": "n246334", "question": "Do these beds look covered?", "program": "BOX0=LOC(image=IMAGE,object='beds')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Do these beds look covered?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8176, "imageId": "n219840", "question": "Do the tree leaves look dried?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the tree leaves look dried?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8177, "imageId": "n282436", "question": "What animal is to the left of the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal is to the left of the keyboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8178, "imageId": "n258500", "question": "Which color is that beach, blue or white?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is that beach, blue or white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8179, "imageId": "n55058", "question": "What piece of furniture is inside the restaurant?", "program": "BOX0=LOC(image=IMAGE,object='restaurant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of furniture is inside the restaurant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8180, "imageId": "n127705", "question": "How clean do you think are the trousers?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean do you think are the trousers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8181, "imageId": "n55058", "question": "What is inside the restaurant that is not little?", "program": "BOX0=LOC(image=IMAGE,object='restaurant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='little')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is inside the restaurant?')\nANSWER1=EVAL(expr=\"'nothing' if {ANSWER0} == 'little' else {ANSWER0}\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8182, "imageId": "n470131", "question": "Are there clean beds or tables?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8183, "imageId": "n55058", "question": "Does the onion to the left of the serving dish look healthy and small?", "program": "BOX0=LOC(image=IMAGE,object='serving dish')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='onion')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the onion look healthy?')\nANSWER1=VQA(image=IMAGE1,question='Does the onion look small?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8184, "imageId": "n437192", "question": "How large is the bear next to the other bear?", "program": "BOX0=LOC(image=IMAGE,object='bear')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other bear')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How large is the bear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8185, "imageId": "n415215", "question": "Is the metal tool short and black?", "program": "BOX0=LOC(image=IMAGE,object='metal tool')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the metal tool?')\nANSWER1=VQA(image=IMAGE0,question='Is the metal tool short?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8186, "imageId": "n469156", "question": "Are there either glasses or ties in the image?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nBOX1=LOC(image=IMAGE,object='ties')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8187, "imageId": "n9181", "question": "Is the mirror large or small?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nANSWER0=SIZE(box=BOX0)\nANSWER1=EVAL(expr=\"'large' if {ANSWER0} > 100 else 'small'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8188, "imageId": "n59147", "question": "Do you see any chairs or plates in this image?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='plate')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8189, "imageId": "n59147", "question": "Is the white toilet to the left or to the right of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white toilet')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8190, "imageId": "n532191", "question": "Who is using the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is using the laptop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8191, "imageId": "n532191", "question": "What is the happy person using?", "program": "BOX0=LOC(image=IMAGE,object='happy person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the happy person using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8192, "imageId": "n204894", "question": "On which side is the white chair, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='white chair')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8193, "imageId": "n498712", "question": "Is there a closed window or door?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8194, "imageId": "n283587", "question": "Which kind of furniture is to the left of the side table?", "program": "BOX0=LOC(image=IMAGE,object='side table')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is to the left?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8195, "imageId": "n352479", "question": "Who is wearing the hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8196, "imageId": "n312206", "question": "Which kind of baked good is on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of baked good is on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8197, "imageId": "n312206", "question": "What is the food that is on top of the round plate?", "program": "BOX0=LOC(image=IMAGE,object='round plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8198, "imageId": "n352479", "question": "Is the snowboarder that is not male wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='snowboarder')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the snowboarder wearing a helmet?')\nANSWER1=VQA(image=IMAGE0,question='Is the snowboarder male?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'no' and {ANSWER0} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8199, "imageId": "n352479", "question": "Who is wearing a glove?", "program": "BOX0=LOC(image=IMAGE,object='glove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a glove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8200, "imageId": "n433532", "question": "What is under the oil that is larger than the wine?", "program": "BOX0=LOC(image=IMAGE,object='wine')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='oil')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is under the oil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8201, "imageId": "n433532", "question": "What do you think is the appliance that is under the oil?", "program": "BOX0=LOC(image=IMAGE,object='oil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What do you think is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8202, "imageId": "n234683", "question": "Are there both glasses and ties in the image?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nBOX1=LOC(image=IMAGE,object='ties')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8203, "imageId": "n234683", "question": "What is the necktie tied around?", "program": "BOX0=LOC(image=IMAGE,object='necktie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the necktie tied around?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8204, "imageId": "n234683", "question": "What's the tie tied around?", "program": "BOX0=LOC(image=IMAGE,object='tie')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the tie tied around?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8205, "imageId": "n234683", "question": "Is the necktie tied around the dress shirt the man is wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dress shirt')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='necktie')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8206, "imageId": "n433532", "question": "What is the appliance in this scene?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the appliance in this scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8207, "imageId": "n314630", "question": "Do you see any faucets or coffee mugs?", "program": "BOX0=LOC(image=IMAGE,object='faucet')\nBOX1=LOC(image=IMAGE,object='coffee mug')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8208, "imageId": "n65230", "question": "Is the rug on the right side or on the left of the photo?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='rug')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8209, "imageId": "n433532", "question": "What kind of appliance is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of appliance is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8210, "imageId": "n65230", "question": "Is the patterned rug in front of the toilet soft and teal?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='patterned rug')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Is the rug soft?')\nANSWER1=VQA(image=IMAGE1,question='What color is the rug?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'teal' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8211, "imageId": "n342511", "question": "Does the dog to the left of the person look uncomfortable?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dog')\nANSWER0=VQA(image=IMAGE0,question='Does the dog look uncomfortable?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8212, "imageId": "n433692", "question": "What shape is the pot?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nANSWER0=VQA(image=IMAGE,question='What shape is the pot?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8213, "imageId": "n118102", "question": "What color is the utensil the girl is holding?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='utensil')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8214, "imageId": "n157375", "question": "What is that plane made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is that plane made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8215, "imageId": "n296467", "question": "What kind of food is black and white?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of food is black and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8216, "imageId": "n153118", "question": "Is there a round door or window?", "program": "BOX0=LOC(image=IMAGE,object='door')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8217, "imageId": "n206785", "question": "Are both the door and the cabinet made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cabinet')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the door made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the cabinet made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8218, "imageId": "n264887", "question": "On which side of the image is the mouse pad?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mouse pad')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8219, "imageId": "n264887", "question": "Does the mouse pad in front of the monitor have green color?", "program": "BOX0=LOC(image=IMAGE,object='monitor')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='mouse pad')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the mouse pad?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'green' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8220, "imageId": "n290409", "question": "What animal sits inside the vehicle that is not big?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='What animal sits inside the vehicle?')\nANSWER1=VQA(image=IMAGE0,question='Is the vehicle big?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER1} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8221, "imageId": "n290409", "question": "Where in the image is the mirror, on the left or on the right?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8222, "imageId": "n485969", "question": "The pitcher that is not old is standing where?", "program": "BOX0=LOC(image=IMAGE,object='old pitcher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pitcher')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8223, "imageId": "n143672", "question": "Who is wearing the goggles?", "program": "BOX0=LOC(image=IMAGE,object='goggles')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the goggles?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8224, "imageId": "n181355", "question": "Is the hat that is made of cloth white or green?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the hat made of?')\nANSWER1=VQA(image=IMAGE0,question='What color is the hat?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'cloth' and ({ANSWER1} == 'white' or {ANSWER1} == 'green') else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8225, "imageId": "n357126", "question": "Is the vehicle to the left of the house large and white?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='vehicle',color='white',size='large')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 8226, "imageId": "n49310", "question": "Are the jeans black and long?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the jeans?')\nANSWER1=VQA(image=IMAGE0,question='Are the jeans long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8227, "imageId": "n69237", "question": "Are both the window and the bookcase made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bookcase')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the window made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the bookcase made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8228, "imageId": "n143672", "question": "Is the skier that is not female wearing gloves?", "program": "BOX0=LOC(image=IMAGE,object='skier')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='female')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='gloves')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8229, "imageId": "n143672", "question": "Who is using the skis?", "program": "BOX0=LOC(image=IMAGE,object='skis')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is using the skis?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8230, "imageId": "n143672", "question": "What is the skier that is not female using?", "program": "BOX0=LOC(image=IMAGE,object='skier')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skier using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8231, "imageId": "n508641", "question": "Is the jersey white and clean?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the jersey?')\nANSWER1=VQA(image=IMAGE,question='Is the jersey clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8232, "imageId": "n470920", "question": "What is the smiling woman to the right of the glasses doing, waiting or staring?", "program": "BOX0=LOC(image=IMAGE,object='glasses')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='smiling woman')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the woman doing?')\nANSWER1=EVAL(expr=\"'waiting' if 'waiting' in {ANSWER0} else 'staring'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8233, "imageId": "n470920", "question": "Who is staring?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is staring?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8234, "imageId": "n86120", "question": "Does the person that is not young wear shorts?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the person young?')\nANSWER1=VQA(image=IMAGE0,question='Does the person wear shorts?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'no' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8235, "imageId": "n140421", "question": "Are the curtains to the left of the plates small and colorful?", "program": "BOX0=LOC(image=IMAGE,object='plates')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtains')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nANSWER2=VQA(image=IMAGE0,question='What color are the curtains?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER2} == 'colorful' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 8236, "imageId": "n140421", "question": "Do the colorful curtains look small?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the colorful curtains look small?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8237, "imageId": "n140421", "question": "Is the countertop behind an oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='countertop')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8238, "imageId": "n432591", "question": "Is the color of the blanket different than the color of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='blanket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='lamp')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the blanket?')\nANSWER1=VQA(image=IMAGE1,question='What color is the lamp?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8239, "imageId": "n214497", "question": "What kind of vehicle is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vehicle is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8240, "imageId": "n214497", "question": "Which kind of vehicle is pictured?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of vehicle is pictured?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8241, "imageId": "n278453", "question": "What is the mustard on?", "program": "BOX0=LOC(image=IMAGE,object='mustard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the mustard on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8242, "imageId": "n278453", "question": "The mustard is on what?", "program": "BOX0=LOC(image=IMAGE,object='mustard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The mustard is on what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8243, "imageId": "n278453", "question": "What sauce is on the ham?", "program": "BOX0=LOC(image=IMAGE,object='ham')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What sauce is on the ham?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8244, "imageId": "n278453", "question": "Which kind of meat is the mustard on?", "program": "BOX0=LOC(image=IMAGE,object='mustard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of meat is the mustard on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8245, "imageId": "n278453", "question": "What is the meat that that mustard is on?", "program": "BOX0=LOC(image=IMAGE,object='mustard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the meat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8246, "imageId": "n119944", "question": "Are there either elephants or monkeys that are sitting?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nBOX1=LOC(image=IMAGE,object='monkey')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8247, "imageId": "n89148", "question": "What shape are the windows that are above the doll?", "program": "BOX0=LOC(image=IMAGE,object='doll')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='windows')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What shape are the windows?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8248, "imageId": "n259949", "question": "What is the color of the wood trees?", "program": "BOX0=LOC(image=IMAGE,object='wood trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the wood trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8249, "imageId": "n28996", "question": "Which are healthier, the grapes or the cookie?", "program": "ANSWER0=VQA(image=IMAGE,question='Which are healthier, the grapes or the cookie?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8250, "imageId": "n192021", "question": "Does the dark chair on the carpet look round?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the dark chair on the carpet look round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8251, "imageId": "n507959", "question": "Are the small dolls to the left of the people who are standing behind the luggage?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='luggage')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='small dolls')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8252, "imageId": "n192021", "question": "Which kind of furniture is on the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture is on the carpet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8253, "imageId": "n164272", "question": "Are the green trees behind the cows in the top part of the picture?", "program": "BOX0=LOC(image=IMAGE,object='cows')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green trees')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8254, "imageId": "n507959", "question": "What are the toys to the left of the people that stand behind the luggage called?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='luggage')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='toys')\nANSWER0=VQA(image=IMAGE1,question='What are the toys called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8255, "imageId": "n299528", "question": "Is the fence both brown and tall?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=VQA(image=IMAGE,question='What color is the fence?')\nANSWER1=VQA(image=IMAGE,question='How tall is the fence?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'tall' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8256, "imageId": "n64959", "question": "Is the wire different in color than the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wire')\nANSWER0=VQA(image=IMAGE0,question='What color is the stove?')\nANSWER1=VQA(image=IMAGE0,question='What color is the wire?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8257, "imageId": "n412144", "question": "Who is looking up?", "program": "BOX0=LOC(image=IMAGE,object='up')\nANSWER0=VQA(image=IMAGE,question='Who is looking up?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8258, "imageId": "n52544", "question": "Are both the people the same gender?", "program": "ANSWER0=VQA(image=IMAGE,question='Are both the people the same gender?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8259, "imageId": "n531731", "question": "Who is sitting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is sitting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8260, "imageId": "n244826", "question": "Are the shorts small and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Are the shorts small?')\nANSWER1=VQA(image=IMAGE,question='Are the shorts white?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8261, "imageId": "n115614", "question": "Who in the picture is waiting?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is waiting?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8262, "imageId": "n77818", "question": "Are there birds next to the towels?", "program": "BOX0=LOC(image=IMAGE,object='towels')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='birds')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8263, "imageId": "n117888", "question": "What does the sign hang on?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What does the sign hang on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8264, "imageId": "n187961", "question": "What is the happy person near the goat wearing?", "program": "BOX0=LOC(image=IMAGE,object='goat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='happy person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the happy person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8265, "imageId": "n187961", "question": "What is the child wearing?", "program": "BOX0=LOC(image=IMAGE,object='child')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the child wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8266, "imageId": "n187961", "question": "Who is wearing the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8267, "imageId": "n146522", "question": "Is the jacket black or red?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the jacket?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'red'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8268, "imageId": "n507149", "question": "Is the fine sand black or beige?", "program": "BOX0=LOC(image=IMAGE,object='fine sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the fine sand?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'beige'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8269, "imageId": "n126087", "question": "Is the adult man to the right or to the left of the woman that wears a wrist band?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='wrist band')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='man')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8270, "imageId": "n111390", "question": "Is there any pizza or plate in this image?", "program": "BOX0=LOC(image=IMAGE,object='pizza')\nBOX1=LOC(image=IMAGE,object='plate')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8271, "imageId": "n195249", "question": "Is the long necklace both thin and beautiful?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the long necklace both thin and beautiful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8272, "imageId": "n126087", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8273, "imageId": "n433532", "question": "Are there either small spoons or forks?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nBOX1=LOC(image=IMAGE,object='fork')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8274, "imageId": "n290409", "question": "What is the sidewalk in front of?", "program": "BOX0=LOC(image=IMAGE,object='sidewalk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sidewalk in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8275, "imageId": "n493357", "question": "Do the green trees appear to be tall and bare?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the green trees appear to be tall and bare?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8276, "imageId": "n14", "question": "Is the skateboarder on the right of the picture?", "program": "BOX0=LOC(image=IMAGE,object='skateboarder')\nBOX1=LOC(image=IMAGE,object='RIGHT')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8277, "imageId": "n199758", "question": "What is the ethnic group of the person that is standing near the other person?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the ethnic group of the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8278, "imageId": "n199758", "question": "What is the short person holding?", "program": "BOX0=LOC(image=IMAGE,object='short person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the short person holding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8279, "imageId": "n386682", "question": "Does the dishwasher that is made of stainless steel look square and black?", "program": "BOX0=LOC(image=IMAGE,object='stainless steel dishwasher')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape does the dishwasher look like?')\nANSWER1=VQA(image=IMAGE0,question='What color is the dishwasher?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'square' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8280, "imageId": "n313060", "question": "Is she behind the coffee made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='coffee made of plastic')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='she')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8281, "imageId": "n313060", "question": "What is the drink that she is behind of?", "program": "BOX0=LOC(image=IMAGE,object='she')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='drink')\nANSWER0=VQA(image=IMAGE0,question='What is the drink?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8282, "imageId": "n369313", "question": "Which kind of furniture is it?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of furniture is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8283, "imageId": "n35676", "question": "What is the appliance that is to the left of the cabinets on the right side called?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cabinets')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8284, "imageId": "n479092", "question": "What food is to the left of the napkin?", "program": "BOX0=LOC(image=IMAGE,object='napkin')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nANSWER0=VQA(image=IMAGE0,question='What food is to the left of the napkin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8285, "imageId": "n406334", "question": "Do you see any buses near the old people?", "program": "BOX0=LOC(image=IMAGE,object='old people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8286, "imageId": "n313060", "question": "Which kind of drink is the woman behind of?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of drink is the woman behind of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8287, "imageId": "n483840", "question": "What is the color of that jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8288, "imageId": "n538039", "question": "What is the color of the trees that are not little?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nBOX1=LOC(image=IMAGE,object='little')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nIMAGE1=CROP(image=IMAGE0,box=BOX1,exclude=True)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8289, "imageId": "n274905", "question": "Are there fences in the image that are not wooden?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the fence made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} != 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8290, "imageId": "n483840", "question": "What type of device is he using?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of device is he using?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8291, "imageId": "n411121", "question": "Is the shirt that looks clean long sleeved or short sleeved?", "program": "BOX0=LOC(image=IMAGE,object='clean shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the shirt long sleeved or short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8292, "imageId": "n363445", "question": "Is the large lid above the container that the fork is inside of?", "program": "BOX0=LOC(image=IMAGE,object='fork')\nIMAGE0=CROP_INSIDE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='container')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='large lid')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8293, "imageId": "n271392", "question": "Is the car to the right of the other car blue and old?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other car')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the car?')\nANSWER1=VQA(image=IMAGE1,question='Is the car old?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8294, "imageId": "n363445", "question": "Does the lid above the food container have small size?", "program": "BOX0=LOC(image=IMAGE,object='food container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lid')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What size is the lid?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'small' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8295, "imageId": "n184551", "question": "Does the umbrella have the same color as the bag?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bag')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the umbrella?')\nANSWER1=VQA(image=IMAGE1,question='What color is the bag?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8296, "imageId": "n334278", "question": "What is the color of the belt made of leather?", "program": "BOX0=LOC(image=IMAGE,object='belt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the belt?')\nANSWER1=EVAL(expr=\"'leather' if {ANSWER0} == 'brown' else 'not leather'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8297, "imageId": "n511913", "question": "Is there a window in the scene?", "program": "BOX0=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8298, "imageId": "n429961", "question": "What is in front of the vehicle in the top of the photo?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8299, "imageId": "n65202", "question": "Who is looking up?", "program": "BOX0=LOC(image=IMAGE,object='up')\nANSWER0=VQA(image=IMAGE,question='Who is looking up?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8300, "imageId": "n429961", "question": "What type of furniture is in front of the vehicle made of metal?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='metal furniture')\nANSWER0=VQA(image=IMAGE0,question='What type of furniture is in front of the vehicle?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'metal furniture' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8301, "imageId": "n400036", "question": "Who is wearing shoes?", "program": "BOX0=LOC(image=IMAGE,object='shoes')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8302, "imageId": "n59627", "question": "What is the large animal doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the large animal doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8303, "imageId": "n59627", "question": "What is the elephant doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the elephant doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8304, "imageId": "n278312", "question": "What type of appliance is to the right of the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What type of appliance is to the right of the oven?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8305, "imageId": "n551964", "question": "Is the shirt blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8306, "imageId": "n441859", "question": "Where does the person to the left of the life vest stand on?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Where does the person stand on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8307, "imageId": "n355339", "question": "Is this a black laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the laptop?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8308, "imageId": "n278312", "question": "What kind of appliance is to the right of the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of appliance is to the right of the stove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8309, "imageId": "n16378", "question": "What is the woman that is not sad holding onto?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the woman holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8310, "imageId": "n54424", "question": "Which color is the shuttle?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the shuttle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8311, "imageId": "n167552", "question": "Does the animal next to the tree look large and yellow?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the animal?')\nANSWER1=VQA(image=IMAGE1,question='Does the animal look large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yellow' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8312, "imageId": "n65885", "question": "What is the table in front of?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the table in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8313, "imageId": "n518912", "question": "Does the jacket look long sleeved and orange?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the jacket look long sleeved?')\nANSWER1=VQA(image=IMAGE,question='What color is the jacket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'orange' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8314, "imageId": "n534106", "question": "Which kind of furniture does the woman sit atop?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of furniture does the woman sit atop?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8315, "imageId": "n413002", "question": "Is the Caucasian person holding the bag that is made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='Caucasian person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the bag made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'plastic' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8316, "imageId": "n160664", "question": "On which side is the young person?", "program": "BOX0=LOC(image=IMAGE,object='young person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8317, "imageId": "n179136", "question": "What are the bleachers made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What are the bleachers made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8318, "imageId": "n413002", "question": "What animal is the woman looking at?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is the woman looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8319, "imageId": "n65885", "question": "Is there a couch on top of the gray carpet?", "program": "BOX0=LOC(image=IMAGE,object='gray carpet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8320, "imageId": "n518912", "question": "What is the color of the jacket?", "program": "BOX0=LOC(image=IMAGE,object='jacket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jacket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8321, "imageId": "n65885", "question": "What's in front of the cabinet?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the cabinet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8322, "imageId": "n400036", "question": "What's in front of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8323, "imageId": "n257997", "question": "Which color do you think the shorts the man wears are?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color do you think the shorts the man wears are?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8324, "imageId": "n489190", "question": "Who in the image is standing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8325, "imageId": "n543966", "question": "Are the trees brown or green?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nANSWER0=VQA(image=IMAGE,question='What color are the trees?')\nANSWER1=EVAL(expr=\"'brown' if 'brown' in {ANSWER0} else 'green'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8326, "imageId": "n489190", "question": "Which gender is the skateboarder that is to the left of the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='skateboarder')\nANSWER0=VQA(image=IMAGE0,question='Which gender is the skateboarder?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8327, "imageId": "n400036", "question": "What is in front of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='front')\nANSWER0=VQA(image=IMAGE0,question='What is in front of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8328, "imageId": "n260521", "question": "How tall is the person on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nANSWER0=VQA(image=IMAGE0,question='How tall is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8329, "imageId": "n310828", "question": "Is the silver device to the right of her?", "program": "BOX0=LOC(image=IMAGE,object='her')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='silver device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8330, "imageId": "n275148", "question": "Which color is the floor?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the floor?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8331, "imageId": "n192021", "question": "Are the couch and the fan the same color?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fan')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the couch?')\nANSWER1=VQA(image=IMAGE1,question='What color is the fan?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8332, "imageId": "n70461", "question": "Is the weather cloudy?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the weather cloudy?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8333, "imageId": "n167552", "question": "What is the color of the chair the person sits on?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the color of the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8334, "imageId": "n119886", "question": "Is the pipe thin?", "program": "BOX0=LOC(image=IMAGE,object='pipe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the pipe thin?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8335, "imageId": "n315887", "question": "Does the device to the right of the keyboard look smooth and large?", "program": "BOX0=LOC(image=IMAGE,object='keyboard')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='Does the device look smooth and large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8336, "imageId": "n172618", "question": "How old is the girl that is in front of the other girl?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nANSWER0=VQA(image=IMAGE0,question='How old is the girl?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8337, "imageId": "n68769", "question": "Is the man Asian and adult?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the man Asian?')\nANSWER1=VQA(image=IMAGE,question='Is the man an adult?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8338, "imageId": "n35676", "question": "Does the granite countertop appear to be clean and beige?", "program": "BOX0=LOC(image=IMAGE,object='granite countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the granite countertop?')\nANSWER1=VQA(image=IMAGE0,question='Does the granite countertop appear to be clean?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'beige' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8339, "imageId": "n554880", "question": "Is the sweater open?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the sweater open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8340, "imageId": "n65885", "question": "Is the small animal to the left of the cabinet made of wood?", "program": "BOX0=LOC(image=IMAGE,object='cabinet')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='small animal')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What material is the small animal made of?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8341, "imageId": "n68769", "question": "Which ethnic group is the person that is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which ethnic group is the person?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8342, "imageId": "n98540", "question": "Which color is the cap?", "program": "BOX0=LOC(image=IMAGE,object='cap')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which color is the cap?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8343, "imageId": "n172618", "question": "Who is in front of the kite?", "program": "BOX0=LOC(image=IMAGE,object='kite')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is in front of the kite?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8344, "imageId": "n262920", "question": "What is in front of the black cables?", "program": "BOX0=LOC(image=IMAGE,object='black cables')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the black cables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8345, "imageId": "n229548", "question": "Do the cords look hard?", "program": "ANSWER0=VQA(image=IMAGE,question='Do the cords look hard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8346, "imageId": "n262920", "question": "What is located on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8347, "imageId": "n262920", "question": "What are the devices on top of the little desk that is on top of the floor called?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='little desk')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What are the devices called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8348, "imageId": "n262920", "question": "Which kind of device is on top of the desk?", "program": "BOX0=LOC(image=IMAGE,object='desk')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which kind of device is on top of the desk?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8349, "imageId": "n508733", "question": "Is the soup to the right of the coffee cup?", "program": "BOX0=LOC(image=IMAGE,object='coffee cup')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='soup')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8350, "imageId": "n520071", "question": "Are the thick books to the left or to the right of the cat?", "program": "BOX0=LOC(image=IMAGE,object='cat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='thick books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8351, "imageId": "n162148", "question": "What type of device is to the left of the man that is not old?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What type of device is it?')\nANSWER1=VQA(image=IMAGE0,question='Is the device old?')\nANSWER2=EVAL(expr=\"{ANSWER0} if {ANSWER1} == 'no' else 'none'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8352, "imageId": "n170941", "question": "Is the table made of wood rectangular or round?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the table made of wood?')\nANSWER1=VQA(image=IMAGE,question='Is the table rectangular?')\nANSWER2=VQA(image=IMAGE,question='Is the table round?')\nANSWER3=EVAL(expr=\"'rectangular' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'round'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 8353, "imageId": "n216553", "question": "Which color do you think are the pants?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color do you think are the pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8354, "imageId": "n64959", "question": "Which is smaller, the stove or the refrigerator?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nBOX1=LOC(image=IMAGE,object='refrigerator')\nANSWER0=SIZE(box=BOX0)\nANSWER1=SIZE(box=BOX1)\nANSWER2=EVAL(expr=\"'stove' if {ANSWER0} < {ANSWER1} else 'refrigerator'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8355, "imageId": "n398429", "question": "Does the oven to the left of the table look closed or open?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='oven')\nANSWER0=VQA(image=IMAGE0,question='Does the oven look closed or open?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8356, "imageId": "n560243", "question": "On which side is the tennis ball, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='tennis ball')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8357, "imageId": "n369970", "question": "Is that forest short or tall?", "program": "ANSWER0=VQA(image=IMAGE,question='Is that forest short or tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8358, "imageId": "n296467", "question": "Which kind of food is not sprinkled?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of food is not sprinkled?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8359, "imageId": "n64959", "question": "What is the refrigerator bigger than?", "program": "BOX0=LOC(image=IMAGE,object='refrigerator')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the refrigerator bigger than?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8360, "imageId": "n64959", "question": "Which kind of appliance is bigger than the stove?", "program": "BOX0=LOC(image=IMAGE,object='stove')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='Which kind of appliance is bigger than the stove?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8361, "imageId": "n51658", "question": "What color are the shoes that the man is wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shoes?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8362, "imageId": "n283587", "question": "What color is the coffee table?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the coffee table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8363, "imageId": "n44249", "question": "Do you see children to the right of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='children')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8364, "imageId": "n512257", "question": "Which color is the hat the man is wearing?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hat')\nANSWER0=VQA(image=IMAGE0,question='Which color is the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8365, "imageId": "n153118", "question": "What vehicle is in front of the trees made of wood?", "program": "BOX0=LOC(image=IMAGE,object='trees made of wood')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is in front of the trees made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8366, "imageId": "n153118", "question": "What's before the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is before the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8367, "imageId": "n429961", "question": "What is the name of the item of furniture that the vehicle is behind of?", "program": "BOX0=LOC(image=IMAGE,object='vehicle')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the name of the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8368, "imageId": "n250715", "question": "Who is wearing a sweater?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a sweater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8369, "imageId": "n250715", "question": "Who is wearing the sweater?", "program": "BOX0=LOC(image=IMAGE,object='sweater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the sweater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8370, "imageId": "n567860", "question": "What is lying next to the kitten that is lying on top of the countertop?", "program": "BOX0=LOC(image=IMAGE,object='countertop')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='kitten')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='object')\nANSWER0=VQA(image=IMAGE1,question='What is lying next to the kitten?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8371, "imageId": "n184385", "question": "Does the potato look fried and round?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the potato look fried?')\nANSWER1=VQA(image=IMAGE,question='Does the potato look round?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8372, "imageId": "n250715", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8373, "imageId": "n250715", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8374, "imageId": "n315887", "question": "On which side is the computer?", "program": "BOX0=LOC(image=IMAGE,object='computer')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8375, "imageId": "n250715", "question": "Who do you think is sitting in the chair?", "program": "ANSWER0=VQA(image=IMAGE,question='Who do you think is sitting in the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8376, "imageId": "n184385", "question": "What shape is the potato?", "program": "BOX0=LOC(image=IMAGE,object='potato')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What shape is the potato?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8377, "imageId": "n298104", "question": "Does the shirt that is not long sleeved have black color?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='long sleeved')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='black')\nIMAGE2=CROP(image=IMAGE0,box=BOX2)\nANSWER0=COUNT(box=IMAGE1)\nANSWER1=COUNT(box=IMAGE2)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8378, "imageId": "n412144", "question": "Does the fence look low?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the fence look low?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8379, "imageId": "n6908", "question": "What is the picture frame around of?", "program": "BOX0=LOC(image=IMAGE,object='picture frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the picture frame around of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8380, "imageId": "n6908", "question": "Is the picture frame around the picture that is hanging above the flowers?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='picture')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='picture frame')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8381, "imageId": "n240666", "question": "Are both the outlet and the light fixture made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='outlet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='light fixture')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the outlet made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the light fixture made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8382, "imageId": "n51002", "question": "On which side of the image is the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8383, "imageId": "n28572", "question": "What is the glass in front of?", "program": "BOX0=LOC(image=IMAGE,object='glass')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the glass in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8384, "imageId": "n548534", "question": "Is there either a white microwave or dishwasher?", "program": "BOX0=LOC(image=IMAGE,object='microwave')\nBOX1=LOC(image=IMAGE,object='dishwasher')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8385, "imageId": "n283587", "question": "Are both the coffee table and the side table made of wood?", "program": "BOX0=LOC(image=IMAGE,object='coffee table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='side table')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the coffee table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the side table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'wood' and {ANSWER1} == 'wood' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8386, "imageId": "n381072", "question": "Do you see either plates or breads that are round?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nBOX1=LOC(image=IMAGE,object='bread')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8387, "imageId": "n289376", "question": "What is covered by the sky?", "program": "ANSWER0=VQA(image=IMAGE,question='What is covered by the sky?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8388, "imageId": "n501609", "question": "What kind of appliance is to the left of the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of appliance is to the left of the oven?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8389, "imageId": "n37274", "question": "Is the bicycle in the top part of the image?", "program": "BOX0=LOC(image=IMAGE,object='TOP')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bicycle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8390, "imageId": "n206785", "question": "Are there either windows or doors that are made of metal?", "program": "BOX0=LOC(image=IMAGE,object='window')\nBOX1=LOC(image=IMAGE,object='door')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8391, "imageId": "n434283", "question": "Does the sand look soft and white?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the sand look soft and white?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8392, "imageId": "n181355", "question": "What kind of device is right of the pillow?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is right of the pillow?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8393, "imageId": "n181355", "question": "What kind of device is to the right of the pillow made of cloth?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='device')\nANSWER0=VQA(image=IMAGE0,question='What kind of device is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8394, "imageId": "n58220", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8395, "imageId": "n95313", "question": "What is the tray made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the tray made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8396, "imageId": "n543966", "question": "Which kind of animal is gray?", "program": "BOX0=LOC(image=IMAGE,object='gray animal')\nANSWER0=VQA(image=IMAGE,question='Which kind of animal is gray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8397, "imageId": "n393305", "question": "What is located on top of the pole?", "program": "BOX0=LOC(image=IMAGE,object='pole')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top of the pole?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8398, "imageId": "n49438", "question": "Which kind of furniture is not short?", "program": "BOX0=LOC(image=IMAGE,object='furniture')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is not short?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8399, "imageId": "n97485", "question": "Does the appliance that is not full look dirty or clean?", "program": "BOX0=LOC(image=IMAGE,object='full')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='appliance')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Does the appliance look dirty or clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8400, "imageId": "n296467", "question": "What are the vegetables that are not cut?", "program": "BOX0=LOC(image=IMAGE,object='vegetables')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cut')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What are the vegetables?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8401, "imageId": "n497789", "question": "How are the animals in front of the people near the vehicle called?", "program": "ANSWER0=VQA(image=IMAGE,question='How are the animals in front of the people near the vehicle called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8402, "imageId": "n497789", "question": "Which kind of animal is in front of the people?", "program": "BOX0=LOC(image=IMAGE,object='people')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is in front of the people?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8403, "imageId": "n100991", "question": "What is the shape of the food to the right of the sausage?", "program": "BOX0=LOC(image=IMAGE,object='sausage')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the shape of the food?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8404, "imageId": "n173807", "question": "What is located on top of the large buildings?", "program": "BOX0=LOC(image=IMAGE,object='large buildings')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is located on top?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8405, "imageId": "n508733", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8406, "imageId": "n219840", "question": "What type of animal is beautiful, the deer or the zebra?", "program": "ANSWER0=VQA(image=IMAGE,question='What type of animal is beautiful, the deer or the zebra?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8407, "imageId": "n219840", "question": "What kind of animal is not beautiful?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of animal is not beautiful?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8408, "imageId": "n126891", "question": "Does the boy's hair have short length and white color?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the length of the boy\\'s hair?')\nANSWER1=VQA(image=IMAGE0,question='What color is the boy\\'s hair?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'short' and {ANSWER1} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8409, "imageId": "n100991", "question": "Are there any potatoes to the left of the silver fork?", "program": "BOX0=LOC(image=IMAGE,object='silver fork')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='potatoes')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8410, "imageId": "n171169", "question": "What is covered by the man?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is covered by the man?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8411, "imageId": "n480253", "question": "What is parked along the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is parked along the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8412, "imageId": "n480253", "question": "What kind of vehicle is parked along the street?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of vehicle is parked along the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8413, "imageId": "n480253", "question": "Which kind of vehicle is parked along the street?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='Which kind of vehicle is parked along the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8414, "imageId": "n480253", "question": "Are there both motorcycles and ambulances in this photo?", "program": "BOX0=LOC(image=IMAGE,object='motorcycle')\nBOX1=LOC(image=IMAGE,object='ambulance')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8415, "imageId": "n480253", "question": "Are there either any steel fences or ambulances?", "program": "BOX0=LOC(image=IMAGE,object='steel fences')\nBOX1=LOC(image=IMAGE,object='ambulance')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8416, "imageId": "n246334", "question": "Are there any open doors or windows?", "program": "BOX0=LOC(image=IMAGE,object='door')\nBOX1=LOC(image=IMAGE,object='window')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8417, "imageId": "n367944", "question": "Is the white device to the right or to the left of the white bag?", "program": "BOX0=LOC(image=IMAGE,object='white bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='white device')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8418, "imageId": "n367944", "question": "What is sitting on the square table?", "program": "BOX0=LOC(image=IMAGE,object='square table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is sitting on the square table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8419, "imageId": "n263180", "question": "What vehicle is huge?", "program": "BOX0=LOC(image=IMAGE,object='huge')\nANSWER0=VQA(image=IMAGE,question='What vehicle is huge?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8420, "imageId": "n557666", "question": "What vehicle is to the left of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is to the left of the woman?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8421, "imageId": "n97485", "question": "How clean is the appliance which is above the oven?", "program": "BOX0=LOC(image=IMAGE,object='oven')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How clean is the appliance?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8422, "imageId": "n557666", "question": "Is the large vehicle to the right or to the left of the round mirror?", "program": "BOX0=LOC(image=IMAGE,object='round mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='large vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8423, "imageId": "n290409", "question": "Does the tall basket look old?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the tall basket look old?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8424, "imageId": "n554880", "question": "Are both the shirt that is not closed and the blue sweater made of cotton?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='blue sweater')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the shirt made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the blue sweater made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'cotton' and {ANSWER1} == 'cotton' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8425, "imageId": "n496803", "question": "Who is wearing a skirt?", "program": "BOX0=LOC(image=IMAGE,object='skirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8426, "imageId": "n119944", "question": "Is the man to the right or to the left of the elephant that stands in front of the benches?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='benches')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='man')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8427, "imageId": "n496803", "question": "Is the athlete wearing a skirt?", "program": "BOX0=LOC(image=IMAGE,object='athlete')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the athlete wearing a skirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8428, "imageId": "n119944", "question": "Is the bag that looks brown made of paper or wood?", "program": "BOX0=LOC(image=IMAGE,object='brown bag')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the bag made of?')\nANSWER1=EVAL(expr=\"'paper' if {ANSWER0} == 'paper' else 'wood'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8429, "imageId": "n119944", "question": "What is the man in front of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8430, "imageId": "n496803", "question": "Who is holding the racket?", "program": "BOX0=LOC(image=IMAGE,object='racket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding the racket?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8431, "imageId": "n346247", "question": "What are the doors on the front of the school made of?", "program": "BOX0=LOC(image=IMAGE,object='school')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='doors')\nANSWER0=VQA(image=IMAGE0,question='What are the doors made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8432, "imageId": "n275857", "question": "On which side is the fence, the left or the right?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8433, "imageId": "n513100", "question": "Is the table white and wooden?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the table?')\nANSWER1=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'wooden' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8434, "imageId": "n486200", "question": "Does the signal light made of metal look low?", "program": "BOX0=LOC(image=IMAGE,object='signal light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What material is the signal light made of?')\nANSWER1=VQA(image=IMAGE0,question='Does the signal light look low?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'metal' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8435, "imageId": "n279173", "question": "Is the sky orange or gray?", "program": "BOX0=LOC(image=IMAGE,object='sky')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sky?')\nANSWER1=EVAL(expr=\"'orange' if {ANSWER0} == 'orange' else 'gray'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8436, "imageId": "n562105", "question": "Does the stadium look clean?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the stadium look clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8437, "imageId": "n477702", "question": "Do the short shorts look black?", "program": "BOX0=LOC(image=IMAGE,object='short shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the short shorts?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8438, "imageId": "n413319", "question": "Is the racket in the bottom part of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='racket')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8439, "imageId": "n477702", "question": "Are the shorts blue and long?", "program": "BOX0=LOC(image=IMAGE,object='shorts')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the shorts?')\nANSWER1=VQA(image=IMAGE0,question='Are the shorts long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8440, "imageId": "n295771", "question": "Is it indoors?", "program": "ANSWER0=VQA(image=IMAGE,question='Is it indoors?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8441, "imageId": "n243701", "question": "Does the girl beside the signal light seem to be walking?", "program": "BOX0=LOC(image=IMAGE,object='signal light')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='girl')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8442, "imageId": "n526228", "question": "Are both the couch in front of the mirror and the side table brown?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE,object='side table')\nIMAGE2=CROP(image=IMAGE,box=BOX2)\nANSWER0=VQA(image=IMAGE1,question='What color is the couch?')\nANSWER1=VQA(image=IMAGE2,question='What color is the side table?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'brown' and {ANSWER1} == 'brown' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8443, "imageId": "n472825", "question": "Are the jeans black or light blue?", "program": "BOX0=LOC(image=IMAGE,object='jeans')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the jeans?')\nANSWER1=EVAL(expr=\"'black' if {ANSWER0} == 'black' else 'light blue'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8444, "imageId": "n143935", "question": "The pasture is surrounded by what?", "program": "BOX0=LOC(image=IMAGE,object='pasture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='The pasture is surrounded by what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8445, "imageId": "n578564", "question": "What is the picture hanging above?", "program": "BOX0=LOC(image=IMAGE,object='picture')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging above?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8446, "imageId": "n293477", "question": "What is the spoon made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the spoon made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8447, "imageId": "n293477", "question": "What is the utensil that looks gray made of?", "program": "BOX0=LOC(image=IMAGE,object='gray utensil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the utensil made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8448, "imageId": "n140421", "question": "Is the large appliance white or dark?", "program": "BOX0=LOC(image=IMAGE,object='large appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the large appliance?')\nANSWER1=EVAL(expr=\"'white' if {ANSWER0} == 'white' else 'dark'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8449, "imageId": "n166008", "question": "What kind of furniture is made of wood?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of furniture is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8450, "imageId": "n166008", "question": "Which kind of furniture is wooden?", "program": "BOX0=LOC(image=IMAGE,object='wooden')\nANSWER0=VQA(image=IMAGE,question='Which kind of furniture is wooden?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8451, "imageId": "n49310", "question": "Is that dress shirt long sleeved and black?", "program": "ANSWER0=VQA(image=IMAGE,question='Is that dress shirt long sleeved?')\nANSWER1=VQA(image=IMAGE,question='What color is the dress shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8452, "imageId": "n49310", "question": "Which kind of clothing is black?", "program": "BOX0=LOC(image=IMAGE,object='black clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8453, "imageId": "n538039", "question": "What is the color of the car that is on the left?", "program": "BOX0=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nANSWER0=VQA(image=IMAGE0,question='What color is the car?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8454, "imageId": "n527589", "question": "Which color is the sweater?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the sweater?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8455, "imageId": "n54180", "question": "What is on the wall?", "program": "ANSWER0=VQA(image=IMAGE,question='What is on the wall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8456, "imageId": "n54180", "question": "Is this a dirty mirror?", "program": "BOX0=LOC(image=IMAGE,object='mirror')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is this a dirty mirror?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8457, "imageId": "n186491", "question": "What vegetables are to the right of the laptop?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetables')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8458, "imageId": "n346247", "question": "How wide is the low window?", "program": "BOX0=LOC(image=IMAGE,object='low window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How wide is the low window?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8459, "imageId": "n525029", "question": "What kind of vehicle is driving, the train or the car?", "program": "BOX0=LOC(image=IMAGE,object='train')\nBOX1=LOC(image=IMAGE,object='car')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'train' if {ANSWER0} > {ANSWER1} else 'car'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8460, "imageId": "n398257", "question": "Is the flower pot different in color than the keyboard?", "program": "BOX0=LOC(image=IMAGE,object='flower pot')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='keyboard')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the flower pot?')\nANSWER1=VQA(image=IMAGE1,question='What color is the keyboard?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8461, "imageId": "n429961", "question": "Is the vehicle behind the table red or white?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'red' if {ANSWER0} > 0 else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8462, "imageId": "n363445", "question": "What is the color of the food container?", "program": "BOX0=LOC(image=IMAGE,object='food container')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the color of the food container?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8463, "imageId": "n415215", "question": "Which side is the toilet brush on?", "program": "BOX0=LOC(image=IMAGE,object='toilet brush')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='LEFT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8464, "imageId": "n23181", "question": "On which side is the clean bed?", "program": "BOX0=LOC(image=IMAGE,object='clean bed')\nANSWER0=EVAL(expr=\"'right' if {BOX0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8465, "imageId": "n98544", "question": "Which part of the photo is the shelf in, the top or the bottom?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='TOP')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'top' if {ANSWER0} > 0 else 'bottom'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8466, "imageId": "n417401", "question": "Is the white toilet to the right of the toilet paper that is next to the sink?", "program": "BOX0=LOC(image=IMAGE,object='toilet paper')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='sink')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='white toilet')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8467, "imageId": "n228268", "question": "What is the man holding onto?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the man holding onto?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8468, "imageId": "n485969", "question": "Are the baseball mitt and the belt the same color?", "program": "BOX0=LOC(image=IMAGE,object='baseball mitt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='belt')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the baseball mitt?')\nANSWER1=VQA(image=IMAGE1,question='What color is the belt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8469, "imageId": "n98544", "question": "Does that shelf have black color?", "program": "BOX0=LOC(image=IMAGE,object='shelf')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shelf?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8470, "imageId": "n14087", "question": "Which color are the small decorations?", "program": "BOX0=LOC(image=IMAGE,object='small decorations')\nANSWER0=VQA(image=IMAGE,question='Which color are the small decorations?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8471, "imageId": "n238266", "question": "What kind of dessert is the candle on?", "program": "BOX0=LOC(image=IMAGE,object='candle')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of dessert is the candle on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8472, "imageId": "n543966", "question": "Which kind of animal is in front of the flowers?", "program": "BOX0=LOC(image=IMAGE,object='flowers')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=VQA(image=IMAGE0,question='Which kind of animal is in front of the flowers?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8473, "imageId": "n262920", "question": "What is the piece of furniture on top of the floor?", "program": "BOX0=LOC(image=IMAGE,object='floor')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8474, "imageId": "n518912", "question": "On which side of the picture are the white cups?", "program": "BOX0=LOC(image=IMAGE,object='white cups')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8475, "imageId": "n69237", "question": "What leans against the bookcase?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What leans against the bookcase?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8476, "imageId": "n167164", "question": "Is there a bench or a fence in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='bench')\nBOX1=LOC(image=IMAGE,object='fence')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8477, "imageId": "n69237", "question": "What kind of furniture does the pillow lean against?", "program": "BOX0=LOC(image=IMAGE,object='pillow')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture does the pillow lean against?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8478, "imageId": "n526228", "question": "Does the happy man sit on the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='happy man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8479, "imageId": "n200907", "question": "Does the car to the left of the girl look black?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='car')\nANSWER0=VQA(image=IMAGE0,question='What color is the car?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'black' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8480, "imageId": "n446242", "question": "Is the sink round?", "program": "BOX0=LOC(image=IMAGE,object='sink')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the sink round?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8481, "imageId": "n260521", "question": "Is the tall tree in front of a fence?", "program": "BOX0=LOC(image=IMAGE,object='tree')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8482, "imageId": "n527290", "question": "Are there any chairs next to the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chair')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8483, "imageId": "n355339", "question": "Is the man to the left of the chair on the left?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8484, "imageId": "n355339", "question": "Is the man to the left or to the right of the chair?", "program": "BOX0=LOC(image=IMAGE,object='man')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < {BOX1[0]} else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8485, "imageId": "n260521", "question": "What is the statue before?", "program": "BOX0=LOC(image=IMAGE,object='statue')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is before the statue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8486, "imageId": "n184385", "question": "What cooking utensil is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='wood')\nANSWER0=VQA(image=IMAGE,question='What cooking utensil is made of wood?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8487, "imageId": "n305495", "question": "What is the piece of furniture that is to the left of the boy the lamp is behind of?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='lamp')\nIMAGE1=CROP_BEHIND(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='furniture')\nANSWER0=VQA(image=IMAGE1,question='What is the piece of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8488, "imageId": "n70461", "question": "Does the sky look clear and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the sky look clear and blue?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8489, "imageId": "n184385", "question": "What cooking utensil is made of wood, the cutting board or the pan?", "program": "BOX0=LOC(image=IMAGE,object='cutting board')\nBOX1=LOC(image=IMAGE,object='pan')\nANSWER0=VQA(image=IMAGE,question='What material is the cutting board made of?')\nANSWER1=VQA(image=IMAGE,question='What material is the pan made of?')\nANSWER2=EVAL(expr=\"'cutting board' if {ANSWER0} == 'wood' else 'pan'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8490, "imageId": "n470920", "question": "What is in front of the bag the man is behind of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the bag?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8491, "imageId": "n470920", "question": "What are the fruits in front of the bag that is sitting on top of the blanket?", "program": "BOX0=LOC(image=IMAGE,object='blanket')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='fruits')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8492, "imageId": "n83784", "question": "What kind of furniture is above the carpet?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of furniture is above the carpet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8493, "imageId": "n119886", "question": "Does the sink look ceramic?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the sink look ceramic?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8494, "imageId": "n119886", "question": "What's the sink made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the sink made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8495, "imageId": "n118102", "question": "Which side of the photo is the cake on?", "program": "BOX0=LOC(image=IMAGE,object='cake')\nANSWER0=EVAL(expr=\"'left' if {BOX0[0]} < IMAGE.width/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8496, "imageId": "n543966", "question": "What animal is on the soft dirt?", "program": "BOX0=LOC(image=IMAGE,object='soft dirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What animal is on the soft dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8497, "imageId": "n488874", "question": "Who is wearing the bracelet?", "program": "BOX0=LOC(image=IMAGE,object='bracelet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the bracelet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8498, "imageId": "n488874", "question": "Who is holding onto the surfboard?", "program": "BOX0=LOC(image=IMAGE,object='surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding onto the surfboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8499, "imageId": "n488874", "question": "Who is holding onto the surf board that is made of wood?", "program": "BOX0=LOC(image=IMAGE,object='surf board')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is holding onto the surf board?')\nANSWER1=EVAL(expr=\"'unknown' if {ANSWER0} != 'wood' else 'no one'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8500, "imageId": "n313060", "question": "Is there any coffee in front of the person that is in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP_FRONT(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='coffee')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8501, "imageId": "n14087", "question": "Is the couch behind the dog green or white?", "program": "BOX0=LOC(image=IMAGE,object='dog')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='couch')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'green' if {ANSWER0} > 0 else 'white'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8502, "imageId": "n125122", "question": "Is the table full and wooden?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the table full?')\nANSWER1=VQA(image=IMAGE0,question='Is the table wooden?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8503, "imageId": "n117888", "question": "What is the depth of the sand?", "program": "BOX0=LOC(image=IMAGE,object='sand')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the depth of the sand?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8504, "imageId": "n162108", "question": "Is the plastic bottle to the right or to the left of the toilet in this image?", "program": "BOX0=LOC(image=IMAGE,object='toilet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plastic bottle')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8505, "imageId": "n525029", "question": "Is that train long and brown?", "program": "ANSWER0=VQA(image=IMAGE,question='Is that train long and brown?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8506, "imageId": "n146555", "question": "Who is the person that is standing watching?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the person that is standing watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8507, "imageId": "n146555", "question": "Who is the man watching?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the man watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8508, "imageId": "n579256", "question": "Is the gray floor made of metal or granite?", "program": "ANSWER0=VQA(image=IMAGE,question='What material is the gray floor made of?')\nANSWER1=EVAL(expr=\"'metal' if {ANSWER0} == 'metal' else 'granite'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8509, "imageId": "n507959", "question": "What watercraft has the same color as the shirts in this image?", "program": "ANSWER0=VQA(image=IMAGE,question='What watercraft has the same color as the shirts?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8510, "imageId": "n507959", "question": "Are both the shirts and the boats the same color?", "program": "BOX0=LOC(image=IMAGE,object='shirts')\nBOX1=LOC(image=IMAGE,object='boats')\nANSWER0=VQA(image=IMAGE,question='What color are the shirts?')\nANSWER1=VQA(image=IMAGE,question='What color are the boats?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8511, "imageId": "n16378", "question": "Is the color of the pants different than the jeans?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='jeans')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color are the pants?')\nANSWER1=VQA(image=IMAGE1,question='What color are the jeans?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8512, "imageId": "n488874", "question": "Is the dirt behind the beach dirty and dark brown?", "program": "BOX0=LOC(image=IMAGE,object='beach')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='dirt')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nBOX2=LOC(image=IMAGE0,object='dark brown')\nANSWER2=COUNT(box=BOX2)\nANSWER3=EVAL(expr=\"'yes' if {ANSWER2} > 0 else 'no'\")\nANSWER4=EVAL(expr=\"'yes' if {ANSWER1} == 'yes' and {ANSWER3} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER4)"}, {"index": 8513, "imageId": "n77818", "question": "Which shape does the entertainment center the television is on top of have?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='entertainment center')\nANSWER0=VQA(image=IMAGE0,question='Which shape does the entertainment center have?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8514, "imageId": "n59627", "question": "Which kind of animal is looking up?", "program": "BOX0=LOC(image=IMAGE,object='looking up')\nANSWER0=VQA(image=IMAGE,question='Which kind of animal is looking up?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8515, "imageId": "n290409", "question": "The logo in front of the truck is which color?", "program": "BOX0=LOC(image=IMAGE,object='truck')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='logo')\nANSWER0=VQA(image=IMAGE0,question='What color is the logo?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8516, "imageId": "n59627", "question": "What kind of animal is large?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of animal is large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8517, "imageId": "n293477", "question": "What is the snack lying on top of, a bookcase or a bed?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='bed')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is the snack lying on top of?')\nANSWER1=VQA(image=IMAGE1,question='What is the snack lying on top of?')\nANSWER2=EVAL(expr=\"'bookcase' if {ANSWER0} == 'bookcase' else 'bed'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8518, "imageId": "n59627", "question": "What animal is this?", "program": "ANSWER0=VQA(image=IMAGE,question='What animal is this?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8519, "imageId": "n51002", "question": "Is the computer monitor different in color than the fireplace?", "program": "BOX0=LOC(image=IMAGE,object='computer monitor')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='fireplace')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the computer monitor?')\nANSWER1=VQA(image=IMAGE1,question='What color is the fireplace?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8520, "imageId": "n111390", "question": "What is the window made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the window made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8521, "imageId": "n313060", "question": "Is there a brown bag or umbrella?", "program": "BOX0=LOC(image=IMAGE,object='brown bag')\nBOX1=LOC(image=IMAGE,object='umbrella')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8522, "imageId": "n534106", "question": "What is located on top of the couch near the window?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='window')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is located on top of the couch?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8523, "imageId": "n90294", "question": "What's the charger made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the charger made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8524, "imageId": "n16656", "question": "Does the shoe lace look black and long?", "program": "BOX0=LOC(image=IMAGE,object='shoe lace')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shoe lace?')\nANSWER1=VQA(image=IMAGE0,question='Does the shoe lace look long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8525, "imageId": "n534106", "question": "Are there any pillows on top of the couch?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pillows')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8526, "imageId": "n526228", "question": "What is the item of furniture in front of the huge mirror called?", "program": "BOX0=LOC(image=IMAGE,object='huge mirror')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8527, "imageId": "n250715", "question": "How does the digital device that is to the left of the telephone appear to be, on or off?", "program": "BOX0=LOC(image=IMAGE,object='telephone')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='digital device')\nANSWER0=VQA(image=IMAGE0,question='How does the digital device appear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8528, "imageId": "n16656", "question": "Which color is the shoe lace on top of the shoe?", "program": "BOX0=LOC(image=IMAGE,object='shoe')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='shoe lace')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which color is the shoe lace?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8529, "imageId": "n369595", "question": "Is the green park small or large?", "program": "ANSWER0=VQA(image=IMAGE,question='Is the green park small or large?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8530, "imageId": "n302358", "question": "What is the color of the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8531, "imageId": "n154160", "question": "Who is wearing pants?", "program": "BOX0=LOC(image=IMAGE,object='pants')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing pants?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8532, "imageId": "n544255", "question": "Who is on the elephant?", "program": "BOX0=LOC(image=IMAGE,object='elephant')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is on the elephant?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8533, "imageId": "n159284", "question": "Is the cap old and blue?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the cap?')\nANSWER1=VQA(image=IMAGE,question='Is the cap old?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8534, "imageId": "n95313", "question": "Are there chairs or tables that are not made of metal?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8535, "imageId": "n159284", "question": "Is that cap blue or tan?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the cap?')\nANSWER1=EVAL(expr=\"'blue' if {ANSWER0} == 'blue' else 'tan'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8536, "imageId": "n544255", "question": "Who is under the umbrella?", "program": "BOX0=LOC(image=IMAGE,object='umbrella')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is under the umbrella?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8537, "imageId": "n116329", "question": "Does the door look wooden and large?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the door look wooden?')\nANSWER1=VQA(image=IMAGE,question='Does the door look large?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8538, "imageId": "n52544", "question": "Does the bucket sit atop a bed?", "program": "BOX0=LOC(image=IMAGE,object='bed')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bucket')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8539, "imageId": "n137182", "question": "How large is the surfboard that looks white?", "program": "BOX0=LOC(image=IMAGE,object='white surfboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='How large is the surfboard?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8540, "imageId": "n52544", "question": "What sits atop the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What sits atop the table?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8541, "imageId": "n334278", "question": "What is the person in front of the umpire wearing?", "program": "BOX0=LOC(image=IMAGE,object='umpire')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8542, "imageId": "n334278", "question": "Who is wearing the uniform?", "program": "BOX0=LOC(image=IMAGE,object='uniform')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the uniform?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8543, "imageId": "n131634", "question": "Does the seat have a different color than the street?", "program": "BOX0=LOC(image=IMAGE,object='seat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='street')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the seat?')\nANSWER1=VQA(image=IMAGE1,question='What color is the street?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8544, "imageId": "n83784", "question": "What is the item of furniture on top of the carpet called?", "program": "BOX0=LOC(image=IMAGE,object='carpet')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='item of furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8545, "imageId": "n275148", "question": "Is the storage box made out of metal empty or full?", "program": "BOX0=LOC(image=IMAGE,object='storage box')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the storage box made out of metal?')\nANSWER1=VQA(image=IMAGE0,question='Is the storage box empty or full?')\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8546, "imageId": "n16425", "question": "Is the bus to the right of the other bus red and large?", "program": "BOX0=LOC(image=IMAGE,object='bus')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='other bus')\nIMAGE1=CROP_RIGHTOF(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What color is the bus?')\nANSWER1=VQA(image=IMAGE1,question='How large is the bus?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'red' and {ANSWER1} == 'large' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8547, "imageId": "n562105", "question": "The dirt has what color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the dirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8548, "imageId": "n181210", "question": "What do both the lid and the orange have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do both the lid and the orange have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8549, "imageId": "n302358", "question": "How is the weather?", "program": "ANSWER0=VQA(image=IMAGE,question='How is the weather?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8550, "imageId": "n326988", "question": "What is the doll inside of?", "program": "BOX0=LOC(image=IMAGE,object='doll')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the doll inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8551, "imageId": "n150962", "question": "Is the pot below the window in the image?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='pot')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8552, "imageId": "n95313", "question": "What color is the tray that is made of plastic?", "program": "BOX0=LOC(image=IMAGE,object='plastic tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the tray?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8553, "imageId": "n501609", "question": "What is the appliance to the right of the appliance on the floor called?", "program": "BOX0=LOC(image=IMAGE,object='appliance on the floor')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='appliance')\nANSWER0=VQA(image=IMAGE0,question='What is the appliance to the right called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8554, "imageId": "n311910", "question": "What sign is in the scene?", "program": "BOX0=LOC(image=IMAGE,object='sign')\nANSWER0=VQA(image=IMAGE,question='What sign is in the scene?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8555, "imageId": "n311910", "question": "What sign is it?", "program": "ANSWER0=VQA(image=IMAGE,question='What sign is it?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8556, "imageId": "n520071", "question": "Which kind of animal is tail?", "program": "ANSWER0=VQA(image=IMAGE,question='Which kind of animal is tail?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8557, "imageId": "n64959", "question": "What is the vacuum made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the vacuum made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8558, "imageId": "n98544", "question": "Is the color of the heater different than that of the wall?", "program": "BOX0=LOC(image=IMAGE,object='heater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='wall')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the heater?')\nANSWER1=VQA(image=IMAGE1,question='What color is the wall?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8559, "imageId": "n64959", "question": "On which side is the bed sheet, the right or the left?", "program": "BOX0=LOC(image=IMAGE,object='bed sheet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='RIGHT')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8560, "imageId": "n309148", "question": "What vehicle does the professional person sit inside of?", "program": "BOX0=LOC(image=IMAGE,object='professional person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What vehicle does the professional person sit inside of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8561, "imageId": "n566028", "question": "What is the person that is not short doing?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='short')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE0,object='person',exclude=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What is the person doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8562, "imageId": "n146555", "question": "Is the street dirty and paved?", "program": "BOX0=LOC(image=IMAGE,object='street')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the street dirty?')\nANSWER1=VQA(image=IMAGE0,question='Is the street paved?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8563, "imageId": "n494918", "question": "What is the boy in front of?", "program": "BOX0=LOC(image=IMAGE,object='boy')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the boy in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8564, "imageId": "n494918", "question": "He is in front of what?", "program": "BOX0=LOC(image=IMAGE,object='he')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='He is in front of what?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8565, "imageId": "n357784", "question": "Are there any electric toothbrushes or helmets?", "program": "BOX0=LOC(image=IMAGE,object='electric toothbrush')\nBOX1=LOC(image=IMAGE,object='helmet')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8566, "imageId": "n494918", "question": "Is there a fence in front of the trees?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='fence')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8567, "imageId": "n209843", "question": "Is the door the same material as the air?", "program": "BOX0=LOC(image=IMAGE,object='door')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='air')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the door made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the air made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8568, "imageId": "n37274", "question": "On which side of the image is the crate?", "program": "BOX0=LOC(image=IMAGE,object='crate')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8569, "imageId": "n146555", "question": "How clean is the street?", "program": "ANSWER0=VQA(image=IMAGE,question='How clean is the street?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8570, "imageId": "n315887", "question": "What kind of device is not framed?", "program": "BOX0=LOC(image=IMAGE,object='frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of device is not framed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8571, "imageId": "n222297", "question": "Is there a fence or a frisbee in the picture?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nBOX1=LOC(image=IMAGE,object='frisbee')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8572, "imageId": "n6309", "question": "On which side of the photo is the old vehicle?", "program": "BOX0=LOC(image=IMAGE,object='old vehicle')\nBOX1=LOC(image=IMAGE,object='LEFT')\nIMAGE0=CROP(image=IMAGE,box=BOX1)\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'left' if {ANSWER0} > 0 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8573, "imageId": "n311910", "question": "Does the bus to the right of the car look metallic and colorful?", "program": "BOX0=LOC(image=IMAGE,object='car')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bus')\nANSWER0=VQA(image=IMAGE0,question='What color is the bus?')\nANSWER1=VQA(image=IMAGE0,question='Is the bus metallic?')\nANSWER2=VQA(image=IMAGE0,question='Is the bus colorful?')\nANSWER3=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' and {ANSWER1} == 'yes' and {ANSWER2} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER3)"}, {"index": 8574, "imageId": "n315887", "question": "What device is framed?", "program": "BOX0=LOC(image=IMAGE,object='frame')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What device is framed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8575, "imageId": "n311910", "question": "Which type of vehicle is not colorful, the car or the bus?", "program": "BOX0=LOC(image=IMAGE,object='car')\nBOX1=LOC(image=IMAGE,object='bus')\nANSWER0=VQA(image=IMAGE,question='What color is the car?')\nANSWER1=VQA(image=IMAGE,question='What color is the bus?')\nANSWER2=EVAL(expr=\"'car' if {ANSWER0} != 'colorful' else 'bus'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8576, "imageId": "n317260", "question": "On which side is the coach?", "program": "BOX0=LOC(image=IMAGE,object='coach')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8577, "imageId": "n164272", "question": "Does the grass look tall and brown?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the grass look tall?')\nANSWER1=VQA(image=IMAGE,question='Does the grass look brown?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'yes' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8578, "imageId": "n541688", "question": "Is the shirt both striped and gray?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt?')\nANSWER1=VQA(image=IMAGE,question='Are there stripes on the shirt?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'gray' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8579, "imageId": "n513429", "question": "What is the device that is to the right of the laptop computer near the keyboard called?", "program": "BOX0=LOC(image=IMAGE,object='laptop computer')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='keyboard')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is the device called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8580, "imageId": "n551964", "question": "What is the size of the motorcycle on the right side?", "program": "BOX0=LOC(image=IMAGE,object='RIGHT')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='motorcycle')\nANSWER0=VQA(image=IMAGE0,question='What is the size of the motorcycle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8581, "imageId": "n148872", "question": "Is the tennis racket black and short?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the tennis racket?')\nANSWER1=VQA(image=IMAGE,question='What is the length of the tennis racket?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'black' and {ANSWER1} == 'short' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8582, "imageId": "n433532", "question": "Are there pots or glasses in this photo?", "program": "BOX0=LOC(image=IMAGE,object='pot')\nBOX1=LOC(image=IMAGE,object='glass')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8583, "imageId": "n551964", "question": "On which side of the image is the large motorcycle?", "program": "BOX0=LOC(image=IMAGE,object='large motorcycle')\nANSWER0=EVAL(expr=\"'left' if {BOX0} < 0.5 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8584, "imageId": "n541688", "question": "What color do you think the shirt the boy is wearing is?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the shirt the boy is wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8585, "imageId": "n86120", "question": "Are these white goats?", "program": "BOX0=LOC(image=IMAGE,object='goats')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color are the goats?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'white' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8586, "imageId": "n186491", "question": "Is there any tea in this photograph that is not wet?", "program": "BOX0=LOC(image=IMAGE,object='tea')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the tea wet?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'no' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8587, "imageId": "n314630", "question": "What is the house made of?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the house made of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8588, "imageId": "n86120", "question": "Is there black goat or zebra?", "program": "BOX0=LOC(image=IMAGE,object='goat')\nBOX1=LOC(image=IMAGE,object='zebra')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8589, "imageId": "n68769", "question": "Is the plate in the bottom part or in the top of the picture?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'bottom' if {ANSWER0} > 0 else 'top'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8590, "imageId": "n314630", "question": "Is this a brick house?", "program": "BOX0=LOC(image=IMAGE,object='house')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is this a brick house?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8591, "imageId": "n525901", "question": "Do you see any books to the right of the white keyboard?", "program": "BOX0=LOC(image=IMAGE,object='white keyboard')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='books')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8592, "imageId": "n511881", "question": "What do you think is the sheep that is looking up doing?", "program": "ANSWER0=VQA(image=IMAGE,question='What do you think is the sheep that is looking up doing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8593, "imageId": "n167164", "question": "What kind of vehicle is behind the vehicle that is below the signal light?", "program": "BOX0=LOC(image=IMAGE,object='signal light')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vehicle')\nANSWER0=VQA(image=IMAGE1,question='What kind of vehicle is behind the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8594, "imageId": "n55058", "question": "What do the mug and the plate have in common?", "program": "ANSWER0=VQA(image=IMAGE,question='What do the mug and the plate have in common?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8595, "imageId": "n55058", "question": "Are the table and the serving dish made of the same material?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='serving dish')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What material is the table made of?')\nANSWER1=VQA(image=IMAGE1,question='What material is the serving dish made of?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8596, "imageId": "n200692", "question": "Which appliance in this photo is huge?", "program": "BOX0=LOC(image=IMAGE,object='appliance')\nANSWER0=VQA(image=IMAGE,question='Which appliance is huge?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8597, "imageId": "n55058", "question": "Are the serving tray and the cutting board the same color?", "program": "BOX0=LOC(image=IMAGE,object='serving tray')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='cutting board')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the serving tray?')\nANSWER1=VQA(image=IMAGE1,question='What color is the cutting board?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8598, "imageId": "n501951", "question": "Who is wearing the helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8599, "imageId": "n501951", "question": "Who is wearing a helmet?", "program": "BOX0=LOC(image=IMAGE,object='helmet')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a helmet?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8600, "imageId": "n282436", "question": "Are there any blue chairs or computer mice?", "program": "BOX0=LOC(image=IMAGE,object='blue chair')\nBOX1=LOC(image=IMAGE,object='computer mouse')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8601, "imageId": "n526228", "question": "Does the man that is to the left of the other man look blond and Caucasian?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=VQA(image=IMAGE0,question='Does the man look blond and Caucasian?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8602, "imageId": "n6309", "question": "What kind of animal is the fence in front of?", "program": "BOX0=LOC(image=IMAGE,object='fence')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What kind of animal is the fence in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8603, "imageId": "n501951", "question": "Who is wearing a shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8604, "imageId": "n295771", "question": "Are there both a couch and a table in the picture?", "program": "BOX0=LOC(image=IMAGE,object='couch')\nBOX1=LOC(image=IMAGE,object='table')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8605, "imageId": "n282607", "question": "Are there any black hats or gloves?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nBOX1=LOC(image=IMAGE,object='gloves')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8606, "imageId": "n429883", "question": "What is the piece of clothing that is black?", "program": "BOX0=LOC(image=IMAGE,object='black')\nANSWER0=VQA(image=IMAGE,question='What is the piece of clothing that is black?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8607, "imageId": "n258500", "question": "Who is wearing a hair band?", "program": "BOX0=LOC(image=IMAGE,object='hair band')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing a hair band?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8608, "imageId": "n258500", "question": "Who is wearing the headband?", "program": "BOX0=LOC(image=IMAGE,object='headband')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the headband?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8609, "imageId": "n258500", "question": "What is the person that is skateboarding wearing?", "program": "BOX0=LOC(image=IMAGE,object='skateboard')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the person wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8610, "imageId": "n258500", "question": "What is the skater wearing?", "program": "BOX0=LOC(image=IMAGE,object='skater')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the skater wearing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8611, "imageId": "n233607", "question": "What is the piece of furniture that this table is sitting beside called?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the piece of furniture that this table is sitting beside called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8612, "imageId": "n429883", "question": "What kind of clothing is black?", "program": "BOX0=LOC(image=IMAGE,object='black clothing')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'shirt' if {ANSWER0} > 0 else 'pants'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8613, "imageId": "n508641", "question": "Who in this photo is standing?", "program": "BOX0=LOC(image=IMAGE,object='standing')\nANSWER0=VQA(image=IMAGE,question='Who is standing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8614, "imageId": "n164272", "question": "What animal is in front of the trees that look green?", "program": "BOX0=LOC(image=IMAGE,object='trees')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='green')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='animal')\nANSWER0=VQA(image=IMAGE1,question='What animal is in front of the trees?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8615, "imageId": "n262920", "question": "What are the devices that are in front of the cords called?", "program": "BOX0=LOC(image=IMAGE,object='cords')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What are the devices called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8616, "imageId": "n219840", "question": "Is the animal to the left of the horses black and white and striped?", "program": "BOX0=LOC(image=IMAGE,object='horses')\nIMAGE0=CROP_LEFTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='animal')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8617, "imageId": "n258500", "question": "Who is the audience watching?", "program": "BOX0=LOC(image=IMAGE,object='audience')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the audience watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8618, "imageId": "n55058", "question": "What the tasty meat is called?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the tasty meat called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8619, "imageId": "n281241", "question": "Is there either a lamp or a chair in this image?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nBOX1=LOC(image=IMAGE,object='chair')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8620, "imageId": "n258500", "question": "Who is watching the person that is skateboarding?", "program": "BOX0=LOC(image=IMAGE,object='person')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is watching the person that is skateboarding?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8621, "imageId": "n258500", "question": "Who is the happy audience watching?", "program": "BOX0=LOC(image=IMAGE,object='audience')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the happy audience watching?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8622, "imageId": "n126891", "question": "What color is the jersey?", "program": "BOX0=LOC(image=IMAGE,object='jersey')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the jersey?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8623, "imageId": "n49438", "question": "Does the curtain in front of the other curtain seem to be small and dark?", "program": "BOX0=LOC(image=IMAGE,object='curtain')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='curtain')\nANSWER0=VQA(image=IMAGE0,question='Does the curtain seem small and dark?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8624, "imageId": "n55058", "question": "Do you see both mugs and cups?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nBOX1=LOC(image=IMAGE,object='cup')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 and {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8625, "imageId": "n65230", "question": "What piece of clothing is hanging?", "program": "BOX0=LOC(image=IMAGE,object='hanging')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What piece of clothing is hanging?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8626, "imageId": "n501951", "question": "Who is wearing the shirt?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is wearing the shirt?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8627, "imageId": "n469525", "question": "Do these animals all have the same type?", "program": "ANSWER0=VQA(image=IMAGE,question='Do these animals all have the same type?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8628, "imageId": "n65230", "question": "What kind of clothing is knit?", "program": "ANSWER0=VQA(image=IMAGE,question='What kind of clothing is knit?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8629, "imageId": "n326988", "question": "What is the man looking at?", "program": "ANSWER0=VQA(image=IMAGE,question='What is the man looking at?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8630, "imageId": "n379991", "question": "Which color is the pen?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the pen?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8631, "imageId": "n379991", "question": "Is the long pen white and thin?", "program": "BOX0=LOC(image=IMAGE,object='long pen')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the long pen?')\nANSWER1=VQA(image=IMAGE0,question='Is the long pen thin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'white' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8632, "imageId": "n44249", "question": "Is the heavy person to the right or to the left of the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='heavy person')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8633, "imageId": "n336443", "question": "Are there spoons or mugs in this photograph?", "program": "BOX0=LOC(image=IMAGE,object='spoon')\nBOX1=LOC(image=IMAGE,object='mug')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8634, "imageId": "n312206", "question": "Is the chocolate on top of a mug?", "program": "BOX0=LOC(image=IMAGE,object='mug')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='chocolate')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8635, "imageId": "n498712", "question": "Which color is the poster?", "program": "ANSWER0=VQA(image=IMAGE,question='Which color is the poster?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8636, "imageId": "n264887", "question": "What is the mouse pad in front of?", "program": "BOX0=LOC(image=IMAGE,object='mouse pad')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the mouse pad in front of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8637, "imageId": "n312206", "question": "Which kind of food is on top of the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='food')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='Which kind of food is on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8638, "imageId": "n312206", "question": "What is the food on top of the plate that is to the right of the packet?", "program": "BOX0=LOC(image=IMAGE,object='packet')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='plate')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='food')\nANSWER0=VQA(image=IMAGE1,question='What is the food on top of the plate?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8639, "imageId": "n283587", "question": "Is the sofa beige?", "program": "BOX0=LOC(image=IMAGE,object='sofa')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the sofa?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'beige' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8640, "imageId": "n498712", "question": "What is hanging above the person the man is standing behind of?", "program": "BOX0=LOC(image=IMAGE,object='man')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='person')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='hanging')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8641, "imageId": "n498712", "question": "What is hanging above the woman?", "program": "BOX0=LOC(image=IMAGE,object='woman')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hanging')\nANSWER0=VQA(image=IMAGE0,question='What is hanging?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8642, "imageId": "n527589", "question": "What is the long sleeved clothing item?", "program": "BOX0=LOC(image=IMAGE,object='long sleeved clothing')\nANSWER0=VQA(image=IMAGE,question='What is the long sleeved clothing item?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8643, "imageId": "n293477", "question": "Is the hair clip lying on top of a bookcase?", "program": "BOX0=LOC(image=IMAGE,object='bookcase')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='hair clip')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8644, "imageId": "n39114", "question": "Does the shirt look short sleeved?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the shirt look short sleeved?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8645, "imageId": "n324908", "question": "Does the pasture seem to be tall?", "program": "BOX0=LOC(image=IMAGE,object='pasture')\nANSWER0=VQA(image=IMAGE,question='Does the pasture seem to be tall?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8646, "imageId": "n264887", "question": "Are there any computer mice or Wii remotes that are not white?", "program": "BOX0=LOC(image=IMAGE,object='computer mouse')\nBOX1=LOC(image=IMAGE,object='Wii remote')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} > 0 or {ANSWER1} > 0 else 'no'\")\nANSWER3=VQA(image=IMAGE,question='What color is the computer mouse?')\nANSWER4=VQA(image=IMAGE,question='What color is the Wii remote?')\nANSWER5=EVAL(expr=\"'yes' if {ANSWER3} != 'white' or {ANSWER4} != 'white' else 'no'\")\nANSWER6=EVAL(expr=\"'yes' if {ANSWER2} == 'yes' and {ANSWER5} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER6)"}, {"index": 8647, "imageId": "n433532", "question": "The oil is of which color?", "program": "ANSWER0=VQA(image=IMAGE,question='What color is the oil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8648, "imageId": "n293477", "question": "What is the black thing that is to the right of the snack made of?", "program": "BOX0=LOC(image=IMAGE,object='snack')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the black thing?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8649, "imageId": "n433532", "question": "Is that oil dark and thin?", "program": "BOX0=LOC(image=IMAGE,object='oil')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the oil?')\nANSWER1=VQA(image=IMAGE0,question='What is the consistency of the oil?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'dark' and {ANSWER1} == 'thin' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8650, "imageId": "n293477", "question": "What is the hair clip lying on top of?", "program": "BOX0=LOC(image=IMAGE,object='hair clip')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the hair clip lying on top of?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8651, "imageId": "n234683", "question": "Is he wearing a hat?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nANSWER0=COUNT(box=BOX0)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8652, "imageId": "n97485", "question": "Is the counter top that is made of granite both clean and light blue?", "program": "BOX0=LOC(image=IMAGE,object='granite counter top')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the counter top clean?')\nANSWER1=VQA(image=IMAGE0,question='What color is the counter top?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'clean' and {ANSWER1} == 'light blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8653, "imageId": "n472825", "question": "Which side of the photo is the lamp on?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nANSWER0=EVAL(expr=\"'left' if {BOX0}['x'] < IMAGE['width']/2 else 'right'\")\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8654, "imageId": "n118102", "question": "Is the knife to the right of the girl silver and long?", "program": "BOX0=LOC(image=IMAGE,object='girl')\nIMAGE0=CROP_RIGHTOF(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='knife')\nANSWER0=VQA(image=IMAGE0,question='What color is the knife?')\nANSWER1=VQA(image=IMAGE0,question='Is the knife long?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == 'silver' and {ANSWER1} == 'yes' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8655, "imageId": "n536256", "question": "Is the television off?", "program": "BOX0=LOC(image=IMAGE,object='television')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Is the television off?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8656, "imageId": "n470920", "question": "Do you see men to the left of the bag in the bottom part of the photo?", "program": "BOX0=LOC(image=IMAGE,object='BOTTOM')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bag')\nIMAGE1=CROP_LEFTOF(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='men')\nANSWER0=COUNT(box=BOX2)\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8657, "imageId": "n486200", "question": "What is in front of the building that the antenna is on?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_BEHIND(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='antenna')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='What is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8658, "imageId": "n486200", "question": "What's in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP_FRONT(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8659, "imageId": "n560243", "question": "Who is the shirt that is not long sleeved worn on?", "program": "BOX0=LOC(image=IMAGE,object='shirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Who is the shirt worn on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8660, "imageId": "n486200", "question": "What is the vehicle in front of the old building?", "program": "BOX0=LOC(image=IMAGE,object='old building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What is the vehicle?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8661, "imageId": "n150962", "question": "Are the window and the door the same color?", "program": "BOX0=LOC(image=IMAGE,object='window')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='door')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the window?')\nANSWER1=VQA(image=IMAGE1,question='What color is the door?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8662, "imageId": "n486200", "question": "What vehicle is in front of the building?", "program": "BOX0=LOC(image=IMAGE,object='building')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What vehicle is in front of the building?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8663, "imageId": "n479092", "question": "Is the color of the napkin the same as the plate?", "program": "BOX0=LOC(image=IMAGE,object='plate')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='napkin')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the plate?')\nANSWER1=VQA(image=IMAGE1,question='What color is the napkin?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} == {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8664, "imageId": "n162586", "question": "How wide is the bed that the sheets are on?", "program": "BOX0=LOC(image=IMAGE,object='sheets')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='bed')\nIMAGE1=CROP(image=IMAGE0,box=BOX1)\nANSWER0=VQA(image=IMAGE1,question='How wide is the bed?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8665, "imageId": "n310828", "question": "What is the laptop on?", "program": "BOX0=LOC(image=IMAGE,object='laptop')\nIMAGE0=CROP_BELOW(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the laptop on?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8666, "imageId": "n309148", "question": "Is the color of the bucket different than the sticker?", "program": "BOX0=LOC(image=IMAGE,object='bucket')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE,object='sticker')\nIMAGE1=CROP(image=IMAGE,box=BOX1)\nANSWER0=VQA(image=IMAGE0,question='What color is the bucket?')\nANSWER1=VQA(image=IMAGE1,question='What color is the sticker?')\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} != {ANSWER1} else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8667, "imageId": "n536256", "question": "Is the man to the right or to the left of the lamp?", "program": "BOX0=LOC(image=IMAGE,object='lamp')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='man')\nANSWER0=COUNT(box=BOX1)\nANSWER1=EVAL(expr=\"'right' if {ANSWER0} > 0 else 'left'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8668, "imageId": "n209843", "question": "Does the striped towel look blue?", "program": "BOX0=LOC(image=IMAGE,object='striped towel')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What color is the striped towel?')\nANSWER1=EVAL(expr=\"'yes' if {ANSWER0} == 'blue' else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER1)"}, {"index": 8669, "imageId": "n28996", "question": "Do you see small spoons or cups?", "program": "BOX0=LOC(image=IMAGE,object='small spoons')\nBOX1=LOC(image=IMAGE,object='cups')\nANSWER0=COUNT(box=BOX0)\nANSWER1=COUNT(box=BOX1)\nANSWER2=EVAL(expr=\"'yes' if {ANSWER0} + {ANSWER1} > 0 else 'no'\")\nFINAL_RESULT=RESULT(var=ANSWER2)"}, {"index": 8670, "imageId": "n181355", "question": "Which material is used to make that hat, cloth or leather?", "program": "BOX0=LOC(image=IMAGE,object='hat')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='Which material is used to make the hat?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8671, "imageId": "n124651", "question": "Does the road look clean?", "program": "ANSWER0=VQA(image=IMAGE,question='Does the road look clean?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8672, "imageId": "n500308", "question": "What is the clear appliance called?", "program": "BOX0=LOC(image=IMAGE,object='clear appliance')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the clear appliance called?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8673, "imageId": "n500308", "question": "What kind of appliance is clear?", "program": "BOX0=LOC(image=IMAGE,object='clear')\nANSWER0=VQA(image=IMAGE,question='What kind of appliance is clear?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8674, "imageId": "n192021", "question": "What is the shape of the blue picture?", "program": "BOX0=LOC(image=IMAGE,object='blue picture')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the shape of the blue picture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8675, "imageId": "n398257", "question": "What is the sweatshirt hanging from?", "program": "BOX0=LOC(image=IMAGE,object='sweatshirt')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is the sweatshirt hanging from?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8676, "imageId": "n513100", "question": "What is the item of furniture that the bird is standing on top of?", "program": "BOX0=LOC(image=IMAGE,object='bird')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='furniture')\nANSWER0=VQA(image=IMAGE0,question='What is the item of furniture?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8677, "imageId": "n259002", "question": "What type of vehicle is that goal in front of?", "program": "BOX0=LOC(image=IMAGE,object='goal')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vehicle')\nANSWER0=VQA(image=IMAGE0,question='What type of vehicle is in front of the goal?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8678, "imageId": "n398257", "question": "What is hanging from the chair?", "program": "BOX0=LOC(image=IMAGE,object='chair')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nANSWER0=VQA(image=IMAGE0,question='What is hanging from the chair?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8679, "imageId": "n55058", "question": "What kind of vegetable is on top of the cutting board?", "program": "BOX0=LOC(image=IMAGE,object='cutting board')\nIMAGE0=CROP_ABOVE(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='vegetable')\nANSWER0=VQA(image=IMAGE0,question='What kind of vegetable is on top of the cutting board?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}, {"index": 8680, "imageId": "n55058", "question": "What kind of vegetable is on top of the cooking utensil that is on top of the table?", "program": "BOX0=LOC(image=IMAGE,object='table')\nIMAGE0=CROP(image=IMAGE,box=BOX0)\nBOX1=LOC(image=IMAGE0,object='cooking utensil')\nIMAGE1=CROP_ABOVE(image=IMAGE0,box=BOX1)\nBOX2=LOC(image=IMAGE1,object='vegetable')\nANSWER0=VQA(image=IMAGE1,question='What kind of vegetable is on top of the cooking utensil?')\nFINAL_RESULT=RESULT(var=ANSWER0)"}]